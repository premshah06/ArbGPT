[
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/message/ParentTransaction",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nChildToParentMessage\nChildToParentMessageClassic\nChildToParentMessageNitro\nChildTransaction\nParentToChildMessage\nParentToChildMessageCreator\nParentToChildMessageGasEstimator\nParentTransaction\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nParentTransaction\nClasses​\nParentContractCallTransactionReceipt​\n\nA ParentTransactionReceipt with additional functionality that only exists if the transaction created a single call to a child chain contract - this includes token deposits.\n\nExtends​\nParentTransactionReceipt\nMethods​\ngetEthDeposits()​\ngetEthDeposits(childProvider: Provider): Promise<EthDepositMessage[]>\n\n\nGet any eth deposit messages created by this transaction\n\nParameters​\nParameter\tType\nchildProvider\tProvider\nReturns​\n\nPromise <EthDepositMessage[]>\n\nInherited from​\n\nParentTransactionReceipt.getEthDeposits\n\nSource​\n\nmessage/ParentTransaction.ts:191\n\ngetInboxMessageDeliveredEvents()​\ngetInboxMessageDeliveredEvents(): object[]\n\n\nGet any InboxMessageDelivered events that were emitted during this transaction\n\nReturns​\n\nobject[]\n\nInherited from​\n\nParentTransactionReceipt.getInboxMessageDeliveredEvents\n\nSource​\n\nmessage/ParentTransaction.ts:134\n\ngetMessageDeliveredEvents()​\ngetMessageDeliveredEvents(): object[]\n\n\nGet any MessageDelivered events that were emitted during this transaction\n\nReturns​\n\nobject[]\n\nInherited from​\n\nParentTransactionReceipt.getMessageDeliveredEvents\n\nSource​\n\nmessage/ParentTransaction.ts:126\n\ngetMessageEvents()​\ngetMessageEvents(): object[]\n\n\nGet combined data for any InboxMessageDelivered and MessageDelivered events emitted during this transaction\n\nReturns​\n\nobject[]\n\nInherited from​\n\nParentTransactionReceipt.getMessageEvents\n\nSource​\n\nmessage/ParentTransaction.ts:147\n\ngetParentToChildMessages()​\ngetParentToChildMessages<T>(childSignerOrProvider: T): Promise<ParentToChildMessageReaderOrWriter<T>[]>\n\n\nGet any parent-to-child messages created by this transaction\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\tDescription\nchildSignerOrProvider\tT\t\nReturns​\n\nPromise <ParentToChildMessageReaderOrWriter<T>[]>\n\nInherited from​\n\nParentTransactionReceipt.getParentToChildMessages\n\nSource​\n\nmessage/ParentTransaction.ts:248\n\ngetParentToChildMessagesClassic()​\ngetParentToChildMessagesClassic(childProvider: Provider): Promise<ParentToChildMessageReaderClassic[]>\n\n\nGet classic parent-to-child messages created by this transaction\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nReturns​\n\nPromise<ParentToChildMessageReaderClassic[]>\n\nInherited from​\n\nParentTransactionReceipt.getParentToChildMessagesClassic\n\nSource​\n\nmessage/ParentTransaction.ts:216\n\ngetTokenDepositEvents()​\ngetTokenDepositEvents(): object[]\n\n\nGet any token deposit events created by this transaction\n\nReturns​\n\nobject[]\n\nInherited from​\n\nParentTransactionReceipt.getTokenDepositEvents\n\nSource​\n\nmessage/ParentTransaction.ts:298\n\nisClassic()​\nisClassic<T>(childSignerOrProvider: T): Promise<boolean>\n\n\nCheck if is a classic transaction\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\tDescription\nchildSignerOrProvider\tT\t\nReturns​\n\nPromise<boolean>\n\nInherited from​\n\nParentTransactionReceipt.isClassic\n\nSource​\n\nmessage/ParentTransaction.ts:106\n\nwaitForChildTransactionReceipt()​\nwaitForChildTransactionReceipt<T>(\n   childSignerOrProvider: T, \n   confirmations?: number, \ntimeout?: number): Promise<object & ParentToChildMessageWaitForStatusResult>\n\n\nWait for the transaction to arrive and be executed on the child chain\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\tDescription\nchildSignerOrProvider\tT\t-\nconfirmations?\tnumber\tAmount of confirmations the retryable ticket and the auto redeem receipt should have\ntimeout?\tnumber\tAmount of time to wait for the retryable ticket to be created\nDefaults to 15 minutes, as by this time all transactions are expected to be included on the child chain. Throws on timeout.\nReturns​\n\nPromise<object & ParentToChildMessageWaitForStatusResult>\n\nThe wait result contains complete, a status, a ParentToChildMessage and optionally the childTxReceipt. If complete is true then this message is in the terminal state. For contract calls this is true only if the status is REDEEMED.\n\nSource​\n\nmessage/ParentTransaction.ts:407\n\nmonkeyPatchContractCallWait()​\nstatic monkeyPatchContractCallWait(contractTransaction: ContractTransaction): ParentContractCallTransaction\n\n\nReplaces the wait function with one that returns a ParentContractCallTransactionReceipt\n\nParameters​\nParameter\tType\tDescription\ncontractTransaction\tContractTransaction\t\nReturns​\n\nParentContractCallTransaction\n\nInherited from​\n\nParentTransactionReceipt.monkeyPatchContractCallWait\n\nSource​\n\nmessage/ParentTransaction.ts:343\n\nmonkeyPatchEthDepositWait()​\nstatic monkeyPatchEthDepositWait(contractTransaction: ContractTransaction): ParentEthDepositTransaction\n\n\nReplaces the wait function with one that returns a ParentEthDepositTransactionReceipt\n\nParameters​\nParameter\tType\tDescription\ncontractTransaction\tContractTransaction\t\nReturns​\n\nParentEthDepositTransaction\n\nInherited from​\n\nParentTransactionReceipt.monkeyPatchEthDepositWait\n\nSource​\n\nmessage/ParentTransaction.ts:327\n\nmonkeyPatchWait()​\nstatic monkeyPatchWait(contractTransaction: ContractTransaction): ParentContractTransaction<ParentTransactionReceipt>\n\n\nReplaces the wait function with one that returns a ParentTransactionReceipt\n\nParameters​\nParameter\tType\tDescription\ncontractTransaction\tContractTransaction\t\nReturns​\n\nParentContractTransaction<ParentTransactionReceipt>\n\nInherited from​\n\nParentTransactionReceipt.monkeyPatchWait\n\nSource​\n\nmessage/ParentTransaction.ts:311\n\nParentEthDepositTransactionReceipt​\n\nA ParentTransactionReceipt with additional functionality that only exists if the transaction created a single eth deposit.\n\nExtends​\nParentTransactionReceipt\nMethods​\ngetEthDeposits()​\ngetEthDeposits(childProvider: Provider): Promise<EthDepositMessage[]>\n\n\nGet any eth deposit messages created by this transaction\n\nParameters​\nParameter\tType\nchildProvider\tProvider\nReturns​\n\nPromise <EthDepositMessage[]>\n\nInherited from​\n\nParentTransactionReceipt.getEthDeposits\n\nSource​\n\nmessage/ParentTransaction.ts:191\n\ngetInboxMessageDeliveredEvents()​\ngetInboxMessageDeliveredEvents(): object[]\n\n\nGet any InboxMessageDelivered events that were emitted during this transaction\n\nReturns​\n\nobject[]\n\nInherited from​\n\nParentTransactionReceipt.getInboxMessageDeliveredEvents\n\nSource​\n\nmessage/ParentTransaction.ts:134\n\ngetMessageDeliveredEvents()​\ngetMessageDeliveredEvents(): object[]\n\n\nGet any MessageDelivered events that were emitted during this transaction\n\nReturns​\n\nobject[]\n\nInherited from​\n\nParentTransactionReceipt.getMessageDeliveredEvents\n\nSource​\n\nmessage/ParentTransaction.ts:126\n\ngetMessageEvents()​\ngetMessageEvents(): object[]\n\n\nGet combined data for any InboxMessageDelivered and MessageDelivered events emitted during this transaction\n\nReturns​\n\nobject[]\n\nInherited from​\n\nParentTransactionReceipt.getMessageEvents\n\nSource​\n\nmessage/ParentTransaction.ts:147\n\ngetParentToChildMessages()​\ngetParentToChildMessages<T>(childSignerOrProvider: T): Promise<ParentToChildMessageReaderOrWriter<T>[]>\n\n\nGet any parent-to-child messages created by this transaction\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\tDescription\nchildSignerOrProvider\tT\t\nReturns​\n\nPromise <ParentToChildMessageReaderOrWriter<T>[]>\n\nInherited from​\n\nParentTransactionReceipt.getParentToChildMessages\n\nSource​\n\nmessage/ParentTransaction.ts:248\n\ngetParentToChildMessagesClassic()​\ngetParentToChildMessagesClassic(childProvider: Provider): Promise<ParentToChildMessageReaderClassic[]>\n\n\nGet classic parent-to-child messages created by this transaction\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nReturns​\n\nPromise<ParentToChildMessageReaderClassic[]>\n\nInherited from​\n\nParentTransactionReceipt.getParentToChildMessagesClassic\n\nSource​\n\nmessage/ParentTransaction.ts:216\n\ngetTokenDepositEvents()​\ngetTokenDepositEvents(): object[]\n\n\nGet any token deposit events created by this transaction\n\nReturns​\n\nobject[]\n\nInherited from​\n\nParentTransactionReceipt.getTokenDepositEvents\n\nSource​\n\nmessage/ParentTransaction.ts:298\n\nisClassic()​\nisClassic<T>(childSignerOrProvider: T): Promise<boolean>\n\n\nCheck if is a classic transaction\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\tDescription\nchildSignerOrProvider\tT\t\nReturns​\n\nPromise<boolean>\n\nInherited from​\n\nParentTransactionReceipt.isClassic\n\nSource​\n\nmessage/ParentTransaction.ts:106\n\nwaitForChildTransactionReceipt()​\nwaitForChildTransactionReceipt(\n   childProvider: Provider, \n   confirmations?: number, \ntimeout?: number): Promise<object & EthDepositMessageWaitForStatusResult>\n\n\nWait for the funds to arrive on the child chain\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t-\nconfirmations?\tnumber\tAmount of confirmations the retryable ticket and the auto redeem receipt should have\ntimeout?\tnumber\tAmount of time to wait for the retryable ticket to be created\nDefaults to 15 minutes, as by this time all transactions are expected to be included on the child chain. Throws on timeout.\nReturns​\n\nPromise<object & EthDepositMessageWaitForStatusResult>\n\nThe wait result contains complete, a status, the ParentToChildMessage and optionally the childTxReceipt If complete is true then this message is in the terminal state. For eth deposits complete this is when the status is FUNDS_DEPOSITED, EXPIRED or REDEEMED.\n\nSource​\n\nmessage/ParentTransaction.ts:369\n\nmonkeyPatchContractCallWait()​\nstatic monkeyPatchContractCallWait(contractTransaction: ContractTransaction): ParentContractCallTransaction\n\n\nReplaces the wait function with one that returns a ParentContractCallTransactionReceipt\n\nParameters​\nParameter\tType\tDescription\ncontractTransaction\tContractTransaction\t\nReturns​\n\nParentContractCallTransaction\n\nInherited from​\n\nParentTransactionReceipt.monkeyPatchContractCallWait\n\nSource​\n\nmessage/ParentTransaction.ts:343\n\nmonkeyPatchEthDepositWait()​\nstatic monkeyPatchEthDepositWait(contractTransaction: ContractTransaction): ParentEthDepositTransaction\n\n\nReplaces the wait function with one that returns a ParentEthDepositTransactionReceipt\n\nParameters​\nParameter\tType\tDescription\ncontractTransaction\tContractTransaction\t\nReturns​\n\nParentEthDepositTransaction\n\nInherited from​\n\nParentTransactionReceipt.monkeyPatchEthDepositWait\n\nSource​\n\nmessage/ParentTransaction.ts:327\n\nmonkeyPatchWait()​\nstatic monkeyPatchWait(contractTransaction: ContractTransaction): ParentContractTransaction<ParentTransactionReceipt>\n\n\nReplaces the wait function with one that returns a ParentTransactionReceipt\n\nParameters​\nParameter\tType\tDescription\ncontractTransaction\tContractTransaction\t\nReturns​\n\nParentContractTransaction<ParentTransactionReceipt>\n\nInherited from​\n\nParentTransactionReceipt.monkeyPatchWait\n\nSource​\n\nmessage/ParentTransaction.ts:311\n\nEdit this page\nPrevious\nParentToChildMessageGasEstimator\nNext\nArbProvider\nClasses\nParentContractCallTransactionReceipt\nExtends\nMethods\ngetEthDeposits()\ngetInboxMessageDeliveredEvents()\ngetMessageDeliveredEvents()\ngetMessageEvents()\ngetParentToChildMessages()\ngetParentToChildMessagesClassic()\ngetTokenDepositEvents()\nisClassic()\nwaitForChildTransactionReceipt()\nmonkeyPatchContractCallWait()\nmonkeyPatchEthDepositWait()\nmonkeyPatchWait()\nParentEthDepositTransactionReceipt\nExtends\nMethods\ngetEthDeposits()\ngetInboxMessageDeliveredEvents()\ngetMessageDeliveredEvents()\ngetMessageEvents()\ngetParentToChildMessages()\ngetParentToChildMessagesClassic()\ngetTokenDepositEvents()\nisClassic()\nwaitForChildTransactionReceipt()\nmonkeyPatchContractCallWait()\nmonkeyPatchEthDepositWait()\nmonkeyPatchWait()\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "ParentToChildMessageGasEstimator | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/message/ParentToChildMessageGasEstimator",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nChildToParentMessage\nChildToParentMessageClassic\nChildToParentMessageNitro\nChildTransaction\nParentToChildMessage\nParentToChildMessageCreator\nParentToChildMessageGasEstimator\nParentTransaction\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nParentToChildMessageGasEstimator\nType Aliases​\nPercentIncrease​\ntype PercentIncrease: object;\n\n\nAn optional big number percentage increase\n\nType declaration​\nMember\tType\tDescription\nbase\tBigNumber\tIf provided, will override the estimated base\npercentIncrease\tBigNumber\tHow much to increase the base by. If not provided system defaults may be used.\nSource​\n\nmessage/ParentToChildMessageGasEstimator.ts:38\n\nEdit this page\nPrevious\nParentToChildMessageCreator\nNext\nParentTransaction\nType Aliases\nPercentIncrease\nType declaration\nSource\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "ChildToParentMessageClassic | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/message/ChildToParentMessageClassic",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nChildToParentMessage\nChildToParentMessageClassic\nChildToParentMessageNitro\nChildTransaction\nParentToChildMessage\nParentToChildMessageCreator\nParentToChildMessageGasEstimator\nParentTransaction\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nChildToParentMessageClassic\nClasses​\nChildToParentMessageReaderClassic​\n\nProvides read-only access for classic Child-to-Parent-messages\n\nExtends​\nChildToParentMessageClassic\nExtended by​\nChildToParentMessageWriterClassic\nProperties​\nProperty\tModifier\tType\tDefault value\tDescription\tInherited from\nbatchNumber\treadonly\tBigNumber\tundefined\tThe number of the batch this message is part of\tChildToParentMessageClassic.batchNumber\nindexInBatch\treadonly\tBigNumber\tundefined\tThe index of this message in the batch\tChildToParentMessageClassic.indexInBatch\noutboxAddress\tprotected\tnull | string\tnull\tContains the classic outbox address, or set to zero address if this network\ndid not have a classic outbox deployed\t-\nMethods​\ngetFirstExecutableBlock()​\ngetFirstExecutableBlock(childProvider: Provider): Promise<null | BigNumber>\n\n\nEstimates the Parent Chain block number in which this Child-to-Parent tx will be available for execution\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nReturns​\n\nPromise<null | BigNumber>\n\nAlways returns null for classic chainToParentChain messages since they can be executed in any block now.\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:386\n\ngetOutboxAddress()​\nprotected getOutboxAddress(childProvider: Provider, batchNumber: number): Promise<string>\n\n\nClassic had 2 outboxes, we need to find the correct one for the provided batch number\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nbatchNumber\tnumber\t\nReturns​\n\nPromise<string>\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:211\n\nhasExecuted()​\nhasExecuted(childProvider: Provider): Promise<boolean>\n\n\nCheck if given outbox message has already been executed\n\nParameters​\nParameter\tType\nchildProvider\tProvider\nReturns​\n\nPromise<boolean>\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:301\n\nstatus()​\nstatus(childProvider: Provider): Promise<ChildToParentMessageStatus>\n\n\nGet the status of this message In order to check if the message has been executed proof info must be provided.\n\nParameters​\nParameter\tType\nchildProvider\tProvider\nReturns​\n\nPromise<ChildToParentMessageStatus>\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:339\n\ntryGetProof()​\ntryGetProof(childProvider: Provider): Promise<null | MessageBatchProofInfo>\n\n\nGet the execution proof for this message. Returns null if the batch does not exist yet.\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nReturns​\n\nPromise<null | MessageBatchProofInfo>\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:285\n\nwaitUntilOutboxEntryCreated()​\nwaitUntilOutboxEntryCreated(childProvider: Provider, retryDelay: number): Promise<CONFIRMED | EXECUTED>\n\n\nWaits until the outbox entry has been created, and will not return until it has been. WARNING: Outbox entries are only created when the corresponding node is confirmed. Which can take 1 week+, so waiting here could be a very long operation.\n\nParameters​\nParameter\tType\tDefault value\tDescription\nchildProvider\tProvider\tundefined\t-\nretryDelay\tnumber\t500\t\nReturns​\n\nPromise<CONFIRMED | EXECUTED>\n\noutbox entry status (either executed or confirmed but not pending)\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:364\n\nfromBatchNumber()​\nstatic fromBatchNumber<T>(\n   parentSignerOrProvider: T, \n   batchNumber: BigNumber, \n   indexInBatch: BigNumber, \nparentProvider?: Provider): ChildToParentMessageReaderOrWriterClassic<T>\n\n\nInstantiates a new ChildToParentMessageWriterClassic or ChildToParentMessageReaderClassic object.\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\tDescription\nparentSignerOrProvider\tT\tSigner or provider to be used for executing or reading the Child-to-Parent message.\nbatchNumber\tBigNumber\tThe number of the batch containing the Child-to-Parent message.\nindexInBatch\tBigNumber\tThe index of the Child-to-Parent message within the batch.\nparentProvider?\tProvider\tOptional. Used to override the Provider which is attached to parentSignerOrProvider in case you need more control. This will be a required parameter in a future major version update.\nReturns​\n\nChildToParentMessageReaderOrWriterClassic<T>\n\nInherited from​\n\nChildToParentMessageClassic.fromBatchNumber\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:128\n\nChildToParentMessageWriterClassic​\n\nProvides read and write access for classic Child-to-Parent-messages\n\nExtends​\nChildToParentMessageReaderClassic\nConstructors​\nnew ChildToParentMessageWriterClassic()​\nnew ChildToParentMessageWriterClassic(\n   parentSigner: Signer, \n   batchNumber: BigNumber, \n   indexInBatch: BigNumber, \n   parentProvider?: Provider): ChildToParentMessageWriterClassic\n\n\nInstantiates a new ChildToParentMessageWriterClassic object.\n\nParameters​\nParameter\tType\tDescription\nparentSigner\tSigner\tThe signer to be used for executing the Child-to-Parent message.\nbatchNumber\tBigNumber\tThe number of the batch containing the Child-to-Parent message.\nindexInBatch\tBigNumber\tThe index of the Child-to-Parent message within the batch.\nparentProvider?\tProvider\tOptional. Used to override the Provider which is attached to parentSigner in case you need more control. This will be a required parameter in a future major version update.\nReturns​\n\nChildToParentMessageWriterClassic\n\nOverrides​\n\nChildToParentMessageReaderClassic.constructor\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:406\n\nProperties​\nProperty\tModifier\tType\tDefault value\tDescription\tInherited from\nbatchNumber\treadonly\tBigNumber\tundefined\tThe number of the batch this message is part of\tChildToParentMessageReaderClassic.batchNumber\nindexInBatch\treadonly\tBigNumber\tundefined\tThe index of this message in the batch\tChildToParentMessageReaderClassic.indexInBatch\noutboxAddress\tprotected\tnull | string\tnull\tContains the classic outbox address, or set to zero address if this network\ndid not have a classic outbox deployed\tChildToParentMessageReaderClassic.outboxAddress\nparentSigner\tprivate\tSigner\tundefined\tThe signer to be used for executing the Child-to-Parent message.\t-\nMethods​\nexecute()​\nexecute(childProvider: Provider, overrides?: Overrides): Promise<ContractTransaction>\n\n\nExecutes the ChildToParentMessage on Parent Chain. Will throw an error if the outbox entry has not been created, which happens when the corresponding assertion is confirmed.\n\nParameters​\nParameter\tType\nchildProvider\tProvider\noverrides?\tOverrides\nReturns​\n\nPromise<ContractTransaction>\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:421\n\ngetFirstExecutableBlock()​\ngetFirstExecutableBlock(childProvider: Provider): Promise<null | BigNumber>\n\n\nEstimates the Parent Chain block number in which this Child-to-Parent tx will be available for execution\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nReturns​\n\nPromise<null | BigNumber>\n\nAlways returns null for classic chainToParentChain messages since they can be executed in any block now.\n\nInherited from​\n\nChildToParentMessageReaderClassic . getFirstExecutableBlock\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:386\n\ngetOutboxAddress()​\nprotected getOutboxAddress(childProvider: Provider, batchNumber: number): Promise<string>\n\n\nClassic had 2 outboxes, we need to find the correct one for the provided batch number\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nbatchNumber\tnumber\t\nReturns​\n\nPromise<string>\n\nInherited from​\n\nChildToParentMessageReaderClassic . getOutboxAddress\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:211\n\nhasExecuted()​\nhasExecuted(childProvider: Provider): Promise<boolean>\n\n\nCheck if given outbox message has already been executed\n\nParameters​\nParameter\tType\nchildProvider\tProvider\nReturns​\n\nPromise<boolean>\n\nInherited from​\n\nChildToParentMessageReaderClassic . hasExecuted\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:301\n\nstatus()​\nstatus(childProvider: Provider): Promise<ChildToParentMessageStatus>\n\n\nGet the status of this message In order to check if the message has been executed proof info must be provided.\n\nParameters​\nParameter\tType\nchildProvider\tProvider\nReturns​\n\nPromise<ChildToParentMessageStatus>\n\nInherited from​\n\nChildToParentMessageReaderClassic . status\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:339\n\ntryGetProof()​\ntryGetProof(childProvider: Provider): Promise<null | MessageBatchProofInfo>\n\n\nGet the execution proof for this message. Returns null if the batch does not exist yet.\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nReturns​\n\nPromise<null | MessageBatchProofInfo>\n\nInherited from​\n\nChildToParentMessageReaderClassic . tryGetProof\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:285\n\nwaitUntilOutboxEntryCreated()​\nwaitUntilOutboxEntryCreated(childProvider: Provider, retryDelay: number): Promise<CONFIRMED | EXECUTED>\n\n\nWaits until the outbox entry has been created, and will not return until it has been. WARNING: Outbox entries are only created when the corresponding node is confirmed. Which can take 1 week+, so waiting here could be a very long operation.\n\nParameters​\nParameter\tType\tDefault value\tDescription\nchildProvider\tProvider\tundefined\t-\nretryDelay\tnumber\t500\t\nReturns​\n\nPromise<CONFIRMED | EXECUTED>\n\noutbox entry status (either executed or confirmed but not pending)\n\nInherited from​\n\nChildToParentMessageReaderClassic . waitUntilOutboxEntryCreated\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:364\n\nfromBatchNumber()​\nstatic fromBatchNumber<T>(\n   parentSignerOrProvider: T, \n   batchNumber: BigNumber, \n   indexInBatch: BigNumber, \nparentProvider?: Provider): ChildToParentMessageReaderOrWriterClassic<T>\n\n\nInstantiates a new ChildToParentMessageWriterClassic or ChildToParentMessageReaderClassic object.\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\tDescription\nparentSignerOrProvider\tT\tSigner or provider to be used for executing or reading the Child-to-Parent message.\nbatchNumber\tBigNumber\tThe number of the batch containing the Child-to-Parent message.\nindexInBatch\tBigNumber\tThe index of the Child-to-Parent message within the batch.\nparentProvider?\tProvider\tOptional. Used to override the Provider which is attached to parentSignerOrProvider in case you need more control. This will be a required parameter in a future major version update.\nReturns​\n\nChildToParentMessageReaderOrWriterClassic<T>\n\nInherited from​\n\nChildToParentMessageReaderClassic . fromBatchNumber\n\nSource​\n\nmessage/ChildToParentMessageClassic.ts:128\n\nType Aliases​\nChildToParentMessageReaderOrWriterClassic<T>​\ntype ChildToParentMessageReaderOrWriterClassic<T>: T extends Provider ? ChildToParentMessageReaderClassic : ChildToParentMessageWriterClassic;\n\n\nConditional type for Signer or Provider. If T is of type Provider then ChildToParentMessageReaderOrWriter<T> will be of type ChildToParentMessageReader. If T is of type Signer then ChildToParentMessageReaderOrWriter<T> will be of type ChildToParentMessageWriter.\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nSource​\n\nmessage/ChildToParentMessageClassic.ts:98\n\nEdit this page\nPrevious\nChildToParentMessage\nNext\nChildToParentMessageNitro\nClasses\nChildToParentMessageReaderClassic\nExtends\nExtended by\nProperties\nMethods\ngetFirstExecutableBlock()\ngetOutboxAddress()\nhasExecuted()\nstatus()\ntryGetProof()\nwaitUntilOutboxEntryCreated()\nfromBatchNumber()\nChildToParentMessageWriterClassic\nExtends\nConstructors\nnew ChildToParentMessageWriterClassic()\nProperties\nMethods\nexecute()\ngetFirstExecutableBlock()\ngetOutboxAddress()\nhasExecuted()\nstatus()\ntryGetProof()\nwaitUntilOutboxEntryCreated()\nfromBatchNumber()\nType Aliases\nChildToParentMessageReaderOrWriterClassic<T>\nType parameters\nSource\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "ChildTransaction | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/message/ChildTransaction",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nChildToParentMessage\nChildToParentMessageClassic\nChildToParentMessageNitro\nChildTransaction\nParentToChildMessage\nParentToChildMessageCreator\nParentToChildMessageGasEstimator\nParentTransaction\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nChildTransaction\nClasses​\nChildTransactionReceipt​\n\nExtension of ethers-js TransactionReceipt, adding Arbitrum-specific functionality\n\nImplements​\nTransactionReceipt\nMethods​\ngetBatchConfirmations()​\ngetBatchConfirmations(childProvider: JsonRpcProvider): Promise<BigNumber>\n\n\nGet number of parent chain confirmations that the batch including this tx has\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tJsonRpcProvider\t\nReturns​\n\nPromise<BigNumber>\n\nnumber of confirmations of batch including tx, or 0 if no batch included this tx\n\nSource​\n\nmessage/ChildTransaction.ts:138\n\ngetBatchNumber()​\ngetBatchNumber(childProvider: JsonRpcProvider): Promise<BigNumber>\n\n\nGet the number of the batch that included this tx (will throw if no such batch exists)\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tJsonRpcProvider\t\nReturns​\n\nPromise<BigNumber>\n\nnumber of batch in which tx was included, or errors if no batch includes the current tx\n\nSource​\n\nmessage/ChildTransaction.ts:151\n\ngetChildToParentEvents()​\ngetChildToParentEvents(): ChildToParentTransactionEvent[]\n\n\nGet ChildToParentTransactionEvent events created by this transaction\n\nReturns​\n\nChildToParentTransactionEvent[]\n\nSource​\n\nmessage/ChildTransaction.ts:97\n\ngetChildToParentMessages()​\ngetChildToParentMessages<T>(parentSignerOrProvider: T): Promise<ChildToParentMessageReaderOrWriter<T>[]>\n\n\nGet any child-to-parent-messages created by this transaction\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\nparentSignerOrProvider\tT\nReturns​\n\nPromise <ChildToParentMessageReaderOrWriter<T>[]>\n\nSource​\n\nmessage/ChildTransaction.ts:119\n\ngetRedeemScheduledEvents()​\ngetRedeemScheduledEvents(): object[]\n\n\nGet event data for any redeems that were scheduled in this transaction\n\nReturns​\n\nobject[]\n\nSource​\n\nmessage/ChildTransaction.ts:111\n\nisDataAvailable()​\nisDataAvailable(childProvider: JsonRpcProvider, confirmations: number): Promise<boolean>\n\n\nWhether the data associated with this transaction has been made available on parent chain\n\nParameters​\nParameter\tType\tDefault value\tDescription\nchildProvider\tJsonRpcProvider\tundefined\t\nconfirmations\tnumber\t10\tThe number of confirmations on the batch before data is to be considered available\nReturns​\n\nPromise<boolean>\n\nSource​\n\nmessage/ChildTransaction.ts:173\n\nmonkeyPatchWait()​\nstatic monkeyPatchWait(contractTransaction: ContractTransaction): ChildContractTransaction\n\n\nReplaces the wait function with one that returns an L2TransactionReceipt\n\nParameters​\nParameter\tType\tDescription\ncontractTransaction\tContractTransaction\t\nReturns​\n\nChildContractTransaction\n\nSource​\n\nmessage/ChildTransaction.ts:187\n\ntoRedeemTransaction()​\nstatic toRedeemTransaction(redeemTx: ChildContractTransaction, childProvider: Provider): RedeemTransaction\n\n\nAdds a waitForRedeem function to a redeem transaction\n\nParameters​\nParameter\tType\tDescription\nredeemTx\tChildContractTransaction\t\nchildProvider\tProvider\t\nReturns​\n\nRedeemTransaction\n\nSource​\n\nmessage/ChildTransaction.ts:208\n\nEdit this page\nPrevious\nChildToParentMessageNitro\nNext\nParentToChildMessage\nClasses\nChildTransactionReceipt\nImplements\nMethods\ngetBatchConfirmations()\ngetBatchNumber()\ngetChildToParentEvents()\ngetChildToParentMessages()\ngetRedeemScheduledEvents()\nisDataAvailable()\nmonkeyPatchWait()\ntoRedeemTransaction()\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/message/ParentToChildMessageCreator",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nChildToParentMessage\nChildToParentMessageClassic\nChildToParentMessageNitro\nChildTransaction\nParentToChildMessage\nParentToChildMessageCreator\nParentToChildMessageGasEstimator\nParentTransaction\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nParentToChildMessageCreator\nClasses​\nParentToChildMessageCreator​\n\nCreates retryable tickets by directly calling the Inbox contract on Parent chain\n\nMethods​\ncreateRetryableTicket()​\ncreateRetryableTicket(\n   params: OmitTyped<ParentToChildMessageNoGasParams, \"excessFeeRefundAddress\" | \"callValueRefundAddress\"> & Partial<ParentToChildMessageNoGasParams> & object | ParentToChildTransactionRequest & object, \n   childProvider: Provider, \noptions?: GasOverrides): Promise<ParentContractTransaction<ParentTransactionReceipt>>\n\n\nCreates a retryable ticket by directly calling the Inbox contract on Parent chain\n\nParameters​\nParameter\tType\nparams\tOmitTyped<ParentToChildMessageNoGasParams, \"excessFeeRefundAddress\" | \"callValueRefundAddress\"> & Partial<ParentToChildMessageNoGasParams> & object | ParentToChildTransactionRequest & object\nchildProvider\tProvider\noptions?\tGasOverrides\nReturns​\n\nPromise<ParentContractTransaction<ParentTransactionReceipt>>\n\nSource​\n\nmessage/ParentToChildMessageCreator.ts:203\n\ngetTicketCreationRequest()​\nstatic getTicketCreationRequest(\n   params: ParentToChildMessageParams, \n   parentProvider: Provider, \n   childProvider: Provider, \noptions?: GasOverrides): Promise<ParentToChildTransactionRequest>\n\n\nGenerate a transaction request for creating a retryable ticket\n\nParameters​\nParameter\tType\tDescription\nparams\tParentToChildMessageParams\t\nparentProvider\tProvider\t\nchildProvider\tProvider\t\noptions?\tGasOverrides\t\nReturns​\n\nPromise <ParentToChildTransactionRequest>\n\nSource​\n\nmessage/ParentToChildMessageCreator.ts:136\n\ngetTicketCreationRequestCallData()​\nstatic protected getTicketCreationRequestCallData(\n   params: ParentToChildMessageParams, \n   estimates: Pick<RetryableData, ParentToChildGasKeys>, \n   excessFeeRefundAddress: string, \n   callValueRefundAddress: string, \n   nativeTokenIsEth: boolean): string\n\n\nPrepare calldata for a call to create a retryable ticket\n\nParameters​\nParameter\tType\tDescription\nparams\tParentToChildMessageParams\t\nestimates\tPick<RetryableData, ParentToChildGasKeys>\t\nexcessFeeRefundAddress\tstring\t\ncallValueRefundAddress\tstring\t\nnativeTokenIsEth\tboolean\t\nReturns​\n\nstring\n\nSource​\n\nmessage/ParentToChildMessageCreator.ts:89\n\ngetTicketEstimate()​\nstatic protected getTicketEstimate(\n   params: ParentToChildMessageNoGasParams, \n   parentProvider: Provider, \n   childProvider: Provider, \nretryableGasOverrides?: GasOverrides): Promise<Pick<RetryableData, ParentToChildGasKeys>>\n\n\nGets a current estimate for the supplied params\n\nParameters​\nParameter\tType\tDescription\nparams\tParentToChildMessageNoGasParams\t\nparentProvider\tProvider\t\nchildProvider\tProvider\t\nretryableGasOverrides?\tGasOverrides\t\nReturns​\n\nPromise<Pick<RetryableData, ParentToChildGasKeys>>\n\nSource​\n\nmessage/ParentToChildMessageCreator.ts:63\n\nEdit this page\nPrevious\nParentToChildMessage\nNext\nParentToChildMessageGasEstimator\nClasses\nParentToChildMessageCreator\nMethods\ncreateRetryableTicket()\ngetTicketCreationRequest()\ngetTicketCreationRequestCallData()\ngetTicketEstimate()\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "ChildToParentMessageNitro | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/message/ChildToParentMessageNitro",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nChildToParentMessage\nChildToParentMessageClassic\nChildToParentMessageNitro\nChildTransaction\nParentToChildMessage\nParentToChildMessageCreator\nParentToChildMessageGasEstimator\nParentTransaction\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nChildToParentMessageNitro\nClasses​\nChildToParentMessageNitro​\n\nBase functionality for nitro Child->Parent messages\n\nExtended by​\nChildToParentMessageReaderNitro\nMethods​\nfromEvent()​\nstatic fromEvent<T>(\n   parentSignerOrProvider: T, \n   event: object, \nparentProvider?: Provider): ChildToParentMessageReaderOrWriterNitro<T>\n\n\nInstantiates a new ChildToParentMessageWriterNitro or ChildToParentMessageReaderNitro object.\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\tDescription\nparentSignerOrProvider\tT\tSigner or provider to be used for executing or reading the Child-to-Parent message.\nevent\tobject\tThe event containing the data of the Child-to-Parent message.\nevent.arbBlockNum\tBigNumber\t-\nevent.caller?\tstring\t-\nevent.callvalue?\tBigNumber\t-\nevent.data?\tstring\t-\nevent.destination?\tstring\t-\nevent.ethBlockNum?\tBigNumber\t-\nevent.hash?\tBigNumber\t-\nevent.position?\tBigNumber\t-\nevent.timestamp?\tBigNumber\t-\nparentProvider?\tProvider\tOptional. Used to override the Provider which is attached to parentSignerOrProvider in case you need more control. This will be a required parameter in a future major version update.\nReturns​\n\nChildToParentMessageReaderOrWriterNitro<T>\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:148\n\nChildToParentMessageReaderNitro​\n\nProvides read-only access nitro for child-to-parent-messages\n\nExtends​\nChildToParentMessageNitro\nExtended by​\nChildToParentMessageWriterNitro\nMethods​\ngetFirstExecutableBlock()​\ngetFirstExecutableBlock(childProvider: Provider): Promise<null | BigNumber>\n\n\nEstimates the L1 block number in which this L2 to L1 tx will be available for execution. If the message can or already has been executed, this returns null\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nReturns​\n\nPromise<null | BigNumber>\n\nexpected parent chain block number where the child chain to parent chain message will be executable. Returns null if the message can be or already has been executed\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:596\n\ngetRollupAndUpdateNetwork()​\nprivate getRollupAndUpdateNetwork(arbitrumNetwork: ArbitrumNetwork): Promise<RollupUserLogic | BoldRollupUserLogic>\n\n\nIf the local network is not currently bold, checks if the remote network is bold and if so updates the local network with a new rollup address\n\nParameters​\nParameter\tType\tDescription\narbitrumNetwork\tArbitrumNetwork\t\nReturns​\n\nPromise<RollupUserLogic | BoldRollupUserLogic>\n\nThe rollup contract, bold or legacy\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:567\n\nhasExecuted()​\nprotected hasExecuted(childProvider: Provider): Promise<boolean>\n\n\nCheck if this message has already been executed in the Outbox\n\nParameters​\nParameter\tType\nchildProvider\tProvider\nReturns​\n\nPromise<boolean>\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:225\n\nisBold()​\nprivate isBold(arbitrumNetwork: ArbitrumNetwork, parentProvider: Provider): Promise<undefined | string>\n\n\nCheck whether the provided network has a BoLD rollup\n\nParameters​\nParameter\tType\narbitrumNetwork\tArbitrumNetwork\nparentProvider\tProvider\nReturns​\n\nPromise<undefined | string>\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:531\n\nstatus()​\nstatus(childProvider: Provider): Promise<ChildToParentMessageStatus>\n\n\nGet the status of this message In order to check if the message has been executed proof info must be provided.\n\nParameters​\nParameter\tType\nchildProvider\tProvider\nReturns​\n\nPromise<ChildToParentMessageStatus>\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:240\n\nwaitUntilReadyToExecute()​\nwaitUntilReadyToExecute(childProvider: Provider, retryDelay: number): Promise<CONFIRMED | EXECUTED>\n\n\nWaits until the outbox entry has been created, and will not return until it has been. WARNING: Outbox entries are only created when the corresponding node is confirmed. Which can take 1 week+, so waiting here could be a very long operation.\n\nParameters​\nParameter\tType\tDefault value\tDescription\nchildProvider\tProvider\tundefined\t-\nretryDelay\tnumber\t500\t\nReturns​\n\nPromise<CONFIRMED | EXECUTED>\n\noutbox entry status (either executed or confirmed but not pending)\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:507\n\nfromEvent()​\nstatic fromEvent<T>(\n   parentSignerOrProvider: T, \n   event: object, \nparentProvider?: Provider): ChildToParentMessageReaderOrWriterNitro<T>\n\n\nInstantiates a new ChildToParentMessageWriterNitro or ChildToParentMessageReaderNitro object.\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\tDescription\nparentSignerOrProvider\tT\tSigner or provider to be used for executing or reading the Child-to-Parent message.\nevent\tobject\tThe event containing the data of the Child-to-Parent message.\nevent.arbBlockNum\tBigNumber\t-\nevent.caller?\tstring\t-\nevent.callvalue?\tBigNumber\t-\nevent.data?\tstring\t-\nevent.destination?\tstring\t-\nevent.ethBlockNum?\tBigNumber\t-\nevent.hash?\tBigNumber\t-\nevent.position?\tBigNumber\t-\nevent.timestamp?\tBigNumber\t-\nparentProvider?\tProvider\tOptional. Used to override the Provider which is attached to parentSignerOrProvider in case you need more control. This will be a required parameter in a future major version update.\nReturns​\n\nChildToParentMessageReaderOrWriterNitro<T>\n\nInherited from​\n\nChildToParentMessageNitro . fromEvent\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:148\n\nChildToParentMessageWriterNitro​\n\nProvides read and write access for nitro child-to-Parent-messages\n\nExtends​\nChildToParentMessageReaderNitro\nConstructors​\nnew ChildToParentMessageWriterNitro()​\nnew ChildToParentMessageWriterNitro(\n   parentSigner: Signer, \n   event: object, \n   parentProvider?: Provider): ChildToParentMessageWriterNitro\n\n\nInstantiates a new ChildToParentMessageWriterNitro object.\n\nParameters​\nParameter\tType\tDescription\nparentSigner\tSigner\tThe signer to be used for executing the Child-to-Parent message.\nevent\tobject\tThe event containing the data of the Child-to-Parent message.\nevent.arbBlockNum\tBigNumber\t-\nevent.caller?\tstring\t-\nevent.callvalue?\tBigNumber\t-\nevent.data?\tstring\t-\nevent.destination?\tstring\t-\nevent.ethBlockNum?\tBigNumber\t-\nevent.hash?\tBigNumber\t-\nevent.position?\tBigNumber\t-\nevent.timestamp?\tBigNumber\t-\nparentProvider?\tProvider\tOptional. Used to override the Provider which is attached to parentSigner in case you need more control. This will be a required parameter in a future major version update.\nReturns​\n\nChildToParentMessageWriterNitro\n\nOverrides​\n\nChildToParentMessageReaderNitro.constructor\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:724\n\nProperties​\nProperty\tModifier\tType\tDescription\nparentSigner\tprivate\tSigner\tThe signer to be used for executing the Child-to-Parent message.\nMethods​\nexecute()​\nexecute(childProvider: Provider, overrides?: Overrides): Promise<ContractTransaction>\n\n\nExecutes the ChildToParentMessage on Parent Chain. Will throw an error if the outbox entry has not been created, which happens when the corresponding assertion is confirmed.\n\nParameters​\nParameter\tType\nchildProvider\tProvider\noverrides?\tOverrides\nReturns​\n\nPromise<ContractTransaction>\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:738\n\ngetFirstExecutableBlock()​\ngetFirstExecutableBlock(childProvider: Provider): Promise<null | BigNumber>\n\n\nEstimates the L1 block number in which this L2 to L1 tx will be available for execution. If the message can or already has been executed, this returns null\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nReturns​\n\nPromise<null | BigNumber>\n\nexpected parent chain block number where the child chain to parent chain message will be executable. Returns null if the message can be or already has been executed\n\nInherited from​\n\nChildToParentMessageReaderNitro . getFirstExecutableBlock\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:596\n\nhasExecuted()​\nprotected hasExecuted(childProvider: Provider): Promise<boolean>\n\n\nCheck if this message has already been executed in the Outbox\n\nParameters​\nParameter\tType\nchildProvider\tProvider\nReturns​\n\nPromise<boolean>\n\nInherited from​\n\nChildToParentMessageReaderNitro . hasExecuted\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:225\n\nstatus()​\nstatus(childProvider: Provider): Promise<ChildToParentMessageStatus>\n\n\nGet the status of this message In order to check if the message has been executed proof info must be provided.\n\nParameters​\nParameter\tType\nchildProvider\tProvider\nReturns​\n\nPromise<ChildToParentMessageStatus>\n\nInherited from​\n\nChildToParentMessageReaderNitro . status\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:240\n\nwaitUntilReadyToExecute()​\nwaitUntilReadyToExecute(childProvider: Provider, retryDelay: number): Promise<CONFIRMED | EXECUTED>\n\n\nWaits until the outbox entry has been created, and will not return until it has been. WARNING: Outbox entries are only created when the corresponding node is confirmed. Which can take 1 week+, so waiting here could be a very long operation.\n\nParameters​\nParameter\tType\tDefault value\tDescription\nchildProvider\tProvider\tundefined\t-\nretryDelay\tnumber\t500\t\nReturns​\n\nPromise<CONFIRMED | EXECUTED>\n\noutbox entry status (either executed or confirmed but not pending)\n\nInherited from​\n\nChildToParentMessageReaderNitro . waitUntilReadyToExecute\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:507\n\nfromEvent()​\nstatic fromEvent<T>(\n   parentSignerOrProvider: T, \n   event: object, \nparentProvider?: Provider): ChildToParentMessageReaderOrWriterNitro<T>\n\n\nInstantiates a new ChildToParentMessageWriterNitro or ChildToParentMessageReaderNitro object.\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\tDescription\nparentSignerOrProvider\tT\tSigner or provider to be used for executing or reading the Child-to-Parent message.\nevent\tobject\tThe event containing the data of the Child-to-Parent message.\nevent.arbBlockNum\tBigNumber\t-\nevent.caller?\tstring\t-\nevent.callvalue?\tBigNumber\t-\nevent.data?\tstring\t-\nevent.destination?\tstring\t-\nevent.ethBlockNum?\tBigNumber\t-\nevent.hash?\tBigNumber\t-\nevent.position?\tBigNumber\t-\nevent.timestamp?\tBigNumber\t-\nparentProvider?\tProvider\tOptional. Used to override the Provider which is attached to parentSignerOrProvider in case you need more control. This will be a required parameter in a future major version update.\nReturns​\n\nChildToParentMessageReaderOrWriterNitro<T>\n\nInherited from​\n\nChildToParentMessageReaderNitro . fromEvent\n\nSource​\n\nmessage/ChildToParentMessageNitro.ts:148\n\nType Aliases​\nChildToParentMessageReaderOrWriterNitro<T>​\ntype ChildToParentMessageReaderOrWriterNitro<T>: T extends Provider ? ChildToParentMessageReaderNitro : ChildToParentMessageWriterNitro;\n\n\nConditional type for Signer or Provider. If T is of type Provider then ChildToParentMessageReaderOrWriter<T> will be of type ChildToParentMessageReader. If T is of type Signer then ChildToParentMessageReaderOrWriter<T> will be of type ChildToParentMessageWriter.\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nSource​\n\nmessage/ChildToParentMessageNitro.ts:64\n\nEdit this page\nPrevious\nChildToParentMessageClassic\nNext\nChildTransaction\nClasses\nChildToParentMessageNitro\nExtended by\nMethods\nfromEvent()\nChildToParentMessageReaderNitro\nExtends\nExtended by\nMethods\ngetFirstExecutableBlock()\ngetRollupAndUpdateNetwork()\nhasExecuted()\nisBold()\nstatus()\nwaitUntilReadyToExecute()\nfromEvent()\nChildToParentMessageWriterNitro\nExtends\nConstructors\nnew ChildToParentMessageWriterNitro()\nProperties\nMethods\nexecute()\ngetFirstExecutableBlock()\nhasExecuted()\nstatus()\nwaitUntilReadyToExecute()\nfromEvent()\nType Aliases\nChildToParentMessageReaderOrWriterNitro<T>\nType parameters\nSource\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/dataEntities/transactionRequest",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nAddress\nConstants\nErrors\nEvent\nMessage\nNetworks\nRetryableData\nRpc\nSignerOrProvider\nTransactionRequest\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\ntransactionRequest\nInterfaces​\nChildToParentTransactionRequest​\n\nA transaction request for a transaction that will trigger a child to parent message\n\nProperties​\nProperty\tType\tDescription\nestimateParentGasLimit\t(l1Provider: Provider) => Promise<BigNumber>\tEstimate the gas limit required to execute the withdrawal on the parent chain.\nNote that this is only a rough estimate as it may not be possible to know\nthe exact size of the proof straight away, however the real value should be\nwithin a few thousand gas of this estimate.\nParentToChildTransactionRequest​\n\nA transaction request for a transaction that will trigger some sort of execution on the child chain\n\nProperties​\nProperty\tType\tDescription\nretryableData\tOmitTyped<ParentToChildMessageNoGasParams, \"excessFeeRefundAddress\" | \"callValueRefundAddress\"> & Partial<ParentToChildMessageNoGasParams> & ParentToChildMessageGasParams\tInformation about the retryable ticket, and it's subsequent execution, that\nwill occur on the child chain\ntxRequest\tRequired<Pick<TransactionRequest, \"data\" | \"value\" | \"from\" | \"to\">>\tCore fields needed to form the parent component of the transaction request\nMethods​\nisValid()​\nisValid(): Promise<boolean>\n\n\nIf this request were sent now, would it have enough margin to reliably succeed\n\nReturns​\n\nPromise<boolean>\n\nSource​\n\ndataEntities/transactionRequest.ts:28\n\nFunctions​\nisChildToParentTransactionRequest()​\nfunction isChildToParentTransactionRequest<T>(possibleRequest: ChildToParentTransactionRequest | IsNotTransactionRequest<T>): possibleRequest is ChildToParentTransactionRequest\n\n\nCheck if an object is of ChildToParentTransactionRequest type\n\nType parameters​\nType parameter\nT\nParameters​\nParameter\tType\tDescription\npossibleRequest\tChildToParentTransactionRequest | IsNotTransactionRequest<T>\t\nReturns​\n\npossibleRequest is ChildToParentTransactionRequest\n\nSource​\n\ndataEntities/transactionRequest.ts:70\n\nisParentToChildTransactionRequest()​\nfunction isParentToChildTransactionRequest<T>(possibleRequest: ParentToChildTransactionRequest | IsNotTransactionRequest<T>): possibleRequest is ParentToChildTransactionRequest\n\n\nCheck if an object is of ParentToChildTransactionRequest type\n\nType parameters​\nType parameter\nT\nParameters​\nParameter\tType\tDescription\npossibleRequest\tParentToChildTransactionRequest | IsNotTransactionRequest<T>\t\nReturns​\n\npossibleRequest is ParentToChildTransactionRequest\n\nSource​\n\ndataEntities/transactionRequest.ts:57\n\nEdit this page\nPrevious\nSignerOrProvider\nNext\nInbox\nInterfaces\nChildToParentTransactionRequest\nProperties\nParentToChildTransactionRequest\nProperties\nMethods\nisValid()\nFunctions\nisChildToParentTransactionRequest()\nType parameters\nParameters\nReturns\nSource\nisParentToChildTransactionRequest()\nType parameters\nParameters\nReturns\nSource\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "signerOrProvider | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/dataEntities/signerOrProvider",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nAddress\nConstants\nErrors\nEvent\nMessage\nNetworks\nRetryableData\nRpc\nSignerOrProvider\nTransactionRequest\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nsignerOrProvider\nClasses​\nSignerProviderUtils​\n\nUtility functions for signer/provider union types\n\nMethods​\ncheckNetworkMatches()​\nstatic checkNetworkMatches(signerOrProvider: SignerOrProvider, chainId: number): Promise<void>\n\n\nChecks that the signer/provider that's provider matches the chain id Throws if not.\n\nParameters​\nParameter\tType\tDescription\nsignerOrProvider\tSignerOrProvider\t\nchainId\tnumber\t\nReturns​\n\nPromise<void>\n\nSource​\n\ndataEntities/signerOrProvider.ts:56\n\ngetProvider()​\nstatic getProvider(signerOrProvider: SignerOrProvider): undefined | Provider\n\n\nIf signerOrProvider is a provider then return itself. If signerOrProvider is a signer then return signer.provider\n\nParameters​\nParameter\tType\tDescription\nsignerOrProvider\tSignerOrProvider\t\nReturns​\n\nundefined | Provider\n\nSource​\n\ndataEntities/signerOrProvider.ts:24\n\nsignerHasProvider()​\nstatic signerHasProvider(signer: Signer): signer is Signer & Object\n\n\nCheck if the signer has a connected provider\n\nParameters​\nParameter\tType\tDescription\nsigner\tSigner\t\nReturns​\n\nsigner is Signer & Object\n\nSource​\n\ndataEntities/signerOrProvider.ts:44\n\nEdit this page\nPrevious\nRpc\nNext\nTransactionRequest\nClasses\nSignerProviderUtils\nMethods\ncheckNetworkMatches()\ngetProvider()\nsignerHasProvider()\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "rpc | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/dataEntities/rpc",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nAddress\nConstants\nErrors\nEvent\nMessage\nNetworks\nRetryableData\nRpc\nSignerOrProvider\nTransactionRequest\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nrpc\nInterfaces​\nArbTransactionReceipt​\n\nEth transaction receipt with additional arbitrum specific fields\n\nExtends​\nTransactionReceipt\nProperties​\nProperty\tType\tDescription\ngasUsedForL1\tBigNumber\tAmount of gas spent on l1 computation in units of l2 gas\nl1BlockNumber\tnumber\tThe l1 block number that would be used for block.number calls\nthat occur within this transaction.\nSee https://developer.offchainlabs.com/docs/time_in_arbitrum\nEdit this page\nPrevious\nRetryableData\nNext\nSignerOrProvider\nInterfaces\nArbTransactionReceipt\nExtends\nProperties\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/dataEntities/retryableData",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nAddress\nConstants\nErrors\nEvent\nMessage\nNetworks\nRetryableData\nRpc\nSignerOrProvider\nTransactionRequest\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nretryableData\nClasses​\nRetryableDataTools​\n\nTools for parsing retryable data from errors. When calling createRetryableTicket on Inbox.sol special values can be passed for gasLimit and maxFeePerGas. This causes the call to revert with the info needed to estimate the gas needed for a retryable ticket using L1ToL2GasPriceEstimator.\n\nProperties​\nProperty\tModifier\tType\tDefault value\tDescription\nErrorTriggeringParams\tstatic\tobject\t...\tThe parameters that should be passed to createRetryableTicket in order to induce\na revert with retryable data\nErrorTriggeringParams.gasLimit\tpublic\tBigNumber\t...\t-\nErrorTriggeringParams.maxFeePerGas\tpublic\tBigNumber\t...\t-\nMethods​\ntryParseError()​\nstatic tryParseError(ethersJsErrorOrData: string | Error | object): null | RetryableData\n\n\nTry to parse a retryable data struct from the supplied ethersjs error, or any explicitly supplied error data\n\nParameters​\nParameter\tType\tDescription\nethersJsErrorOrData\tstring | Error | object\t\nReturns​\n\nnull | RetryableData\n\nSource​\n\ndataEntities/retryableData.ts:114\n\nEdit this page\nPrevious\nNetworks\nNext\nRpc\nClasses\nRetryableDataTools\nProperties\nMethods\ntryParseError()\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "l1l3Bridger | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/assetBridger/l1l3Bridger",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nAssetBridger\nErc20Bridger\nEthBridger\nL1l3Bridger\nDataEntities\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nl1l3Bridger\nClasses​\nErc20L1L3Bridger​\n\nBridger for moving ERC20 tokens from L1 to L3\n\nExtends​\nBaseL1L3Bridger\nProperties​\nProperty\tModifier\tType\tDefault value\tDescription\n_l1FeeTokenAddress\tprotected\tundefined | string\tundefined\tIf the L3 network uses a custom fee token, this is the address of that token on L1\nl2ForwarderFactoryDefaultGasLimit\treadonly\tBigNumber\t...\tDefault gas limit for L2ForwarderFactory.callForwarder of 1,000,000\n\nMeasured Standard: 361746\n\nMeasured OnlyGasToken: 220416\n\nMeasured NonGasTokenToCustomGas: 373449\nl2GasTokenAddress\treadonly\tundefined | string\tundefined\tIf the L3 network uses a custom (non-eth) fee token, this is the address of that token on L2\nteleporter\treadonly\tTeleporter\tundefined\tAddresses of teleporter contracts on L2\nMethods​\n_checkL1Network()​\nprotected _checkL1Network(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the l1Network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nInherited from​\n\nBaseL1L3Bridger._checkL1Network\n\nSource​\n\nassetBridger/l1l3Bridger.ts:306\n\n_checkL2Network()​\nprotected _checkL2Network(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the l2Network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nInherited from​\n\nBaseL1L3Bridger._checkL2Network\n\nSource​\n\nassetBridger/l1l3Bridger.ts:314\n\n_checkL3Network()​\nprotected _checkL3Network(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the l3Network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nInherited from​\n\nBaseL1L3Bridger._checkL3Network\n\nSource​\n\nassetBridger/l1l3Bridger.ts:322\n\n_decodeCallForwarderCalldata()​\nprotected _decodeCallForwarderCalldata(data: string): L2ForwarderParamsStruct\n\n\nGiven raw calldata for a callForwarder call, decode the parameters\n\nParameters​\nParameter\tType\ndata\tstring\nReturns​\n\nL2ForwarderParamsStruct\n\nSource​\n\nassetBridger/l1l3Bridger.ts:1402\n\n_decodeTeleportCalldata()​\nprotected _decodeTeleportCalldata(data: string): TeleportParamsStruct\n\n\nGiven raw calldata for a teleport tx, decode the teleport parameters\n\nParameters​\nParameter\tType\ndata\tstring\nReturns​\n\nTeleportParamsStruct\n\nSource​\n\nassetBridger/l1l3Bridger.ts:1388\n\n_fillPartialTeleportParams()​\nprotected _fillPartialTeleportParams(\n   partialTeleportParams: OmitTyped<TeleportParamsStruct, \"gasParams\">, \n   retryableOverrides: Erc20L1L3DepositRequestRetryableOverrides, \n   l1Provider: Provider, \n   l2Provider: Provider, \nl3Provider: Provider): Promise<object>\n\n\nGiven TeleportParams without the gas parameters, return TeleportParams with gas parameters populated. Does not modify the input parameters.\n\nParameters​\nParameter\tType\npartialTeleportParams\tOmitTyped<TeleportParamsStruct, \"gasParams\">\nretryableOverrides\tErc20L1L3DepositRequestRetryableOverrides\nl1Provider\tProvider\nl2Provider\tProvider\nl3Provider\tProvider\nReturns​\n\nPromise<object>\n\nMember\tType\ncosts\t[BigNumber, BigNumber, number, RetryableGasCostsStructOutput] & object\nteleportParams\tobject\nteleportParams.amount\tBigNumberish\nteleportParams.gasParams\tRetryableGasParamsStruct\nteleportParams.l1Token\tstring\nteleportParams.l1l2Router\tstring\nteleportParams.l2l3RouterOrInbox\tstring\nteleportParams.l3FeeTokenL1Addr\tstring\nteleportParams.to\tstring\nSource​\n\nassetBridger/l1l3Bridger.ts:1194\n\n_getL1L2FeeTokenBridgeGasEstimates()​\nprotected _getL1L2FeeTokenBridgeGasEstimates(params: object): Promise<RetryableGasValues>\n\n\nEstimate the gasLimit and maxSubmissionFee for the L1 to L2 fee token bridge leg of a teleportation\n\nParameters​\nParameter\tType\nparams\tobject\nparams.feeTokenAmount\tBigNumber\nparams.l1GasPrice\tBigNumber\nparams.l1Provider\tProvider\nparams.l2ForwarderAddress\tstring\nparams.l2Provider\tProvider\nparams.l3FeeTokenL1Addr\tstring\nReturns​\n\nPromise<RetryableGasValues>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:1056\n\n_getL1L2TokenBridgeGasEstimates()​\nprotected _getL1L2TokenBridgeGasEstimates(params: object): Promise<RetryableGasValues>\n\n\nEstimate the gasLimit and maxSubmissionFee for the L1 to L2 token bridge leg of a teleportation\n\nParameters​\nParameter\tType\nparams\tobject\nparams.amount\tBigNumberish\nparams.l1GasPrice\tBigNumber\nparams.l1Provider\tProvider\nparams.l1Token\tstring\nparams.l2ForwarderAddress\tstring\nparams.l2Provider\tProvider\nReturns​\n\nPromise<RetryableGasValues>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:1024\n\n_getL2ForwarderFactoryGasEstimates()​\nprotected _getL2ForwarderFactoryGasEstimates(l1GasPrice: BigNumber, l1Provider: Provider): Promise<RetryableGasValues>\n\n\nEstimate the gasLimit and maxSubmissionFee for L2ForwarderFactory.callForwarder leg of a teleportation. Gas limit is hardcoded to 1,000,000\n\nParameters​\nParameter\tType\nl1GasPrice\tBigNumber\nl1Provider\tProvider\nReturns​\n\nPromise<RetryableGasValues>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:1095\n\n_getL2L3BridgeGasEstimates()​\nprotected _getL2L3BridgeGasEstimates(params: object): Promise<RetryableGasValues>\n\n\nEstimate the gasLimit and maxSubmissionFee for the L2 -> L3 leg of a teleportation.\n\nParameters​\nParameter\tType\nparams\tobject\nparams.l1Provider\tProvider\nparams.l2ForwarderAddress\tstring\nparams.l2GasPrice\tBigNumber\nparams.l2Provider\tProvider\nparams.l3Provider\tProvider\nparams.partialTeleportParams\tOmitTyped<TeleportParamsStruct, \"gasParams\">\nReturns​\n\nPromise<RetryableGasValues>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:1117\n\n_getTokenBridgeGasEstimates()​\nprotected _getTokenBridgeGasEstimates(params: object): Promise<RetryableGasValues>\n\n\nEstimate the gasLimit and maxSubmissionFee for a token bridge retryable\n\nParameters​\nParameter\tType\nparams\tobject\nparams.amount\tBigNumber\nparams.childProvider\tProvider\nparams.from\tstring\nparams.isWeth\tboolean\nparams.parentErc20Address\tstring\nparams.parentGasPrice\tBigNumber\nparams.parentGatewayAddress\tstring\nparams.parentProvider\tProvider\nparams.to\tstring\nReturns​\n\nPromise<RetryableGasValues>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:976\n\n_l2ForwarderFactoryCalldataSize()​\nprotected _l2ForwarderFactoryCalldataSize(): number\n\nReturns​\n\nnumber\n\nThe size of the calldata for a call to L2ForwarderFactory.callForwarder\n\nSource​\n\nassetBridger/l1l3Bridger.ts:1366\n\napproveGasToken()​\napproveGasToken(params: TxRequestParams | object): Promise<ContractTransaction>\n\n\nApprove the L3's fee token for teleportation. The tokens will be approved for L1Teleporter. Will throw if the L3 network uses ETH for fees or the fee token doesn't exist on L1.\n\nParameters​\nParameter\tType\nparams\tTxRequestParams | object\nReturns​\n\nPromise<ContractTransaction>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:701\n\napproveToken()​\napproveToken(params: TxRequestParams | TokenApproveParams & object): Promise<ContractTransaction>\n\n\nApprove tokens for teleportation. The tokens will be approved for L1Teleporter.\n\nParameters​\nParameter\tType\nparams\tTxRequestParams | TokenApproveParams & object\nReturns​\n\nPromise<ContractTransaction>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:659\n\ndeposit()​\ndeposit(params: TxRequestParams | Erc20L1L3DepositRequestParams & object): Promise<ParentContractCallTransaction>\n\n\nExecute a teleportation of some tokens from L1 to L3.\n\nParameters​\nParameter\tType\nparams\tTxRequestParams | Erc20L1L3DepositRequestParams & object\nReturns​\n\nPromise<ParentContractCallTransaction>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:811\n\ngetApproveGasTokenRequest()​\ngetApproveGasTokenRequest(params: object): Promise<Required<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>>\n\n\nGet a tx request to approve the L3's fee token for teleportation. The tokens will be approved for L1Teleporter. Will throw if the L3 network uses ETH for fees or the fee token doesn't exist on L1.\n\nParameters​\nParameter\tType\nparams\tobject\nparams.amount?\tBigNumber\nparams.l1Provider\tProvider\nparams.l2Provider\tProvider\nReturns​\n\nPromise<Required<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:682\n\ngetApproveTokenRequest()​\ngetApproveTokenRequest(params: TokenApproveParams): Promise<Required<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>>\n\n\nGet a tx request to approve tokens for teleportation. The tokens will be approved for L1Teleporter.\n\nParameters​\nParameter\tType\nparams\tTokenApproveParams\nReturns​\n\nPromise<Required<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:640\n\ngetDepositParameters()​\ngetDepositParameters(params: object & TxReference): Promise<object>\n\n\nGiven a teleportation tx, get the L1Teleporter parameters, L2Forwarder parameters, and L2Forwarder address\n\nParameters​\nParameter\tType\nparams\tobject & TxReference\nReturns​\n\nPromise<object>\n\nMember\tType\nl2ForwarderAddress\tPromise<string>\nl2ForwarderParams\tL2ForwarderParamsStruct\nteleportParams\tTeleportParamsStruct\nSource​\n\nassetBridger/l1l3Bridger.ts:837\n\ngetDepositRequest()​\ngetDepositRequest(params: Erc20L1L3DepositRequestParams & object | object): Promise<DepositRequestResult>\n\n\nGet a tx request for teleporting some tokens from L1 to L3. Also returns the amount of fee tokens required for teleportation.\n\nParameters​\nParameter\tType\nparams\tErc20L1L3DepositRequestParams & object | object\nReturns​\n\nPromise<DepositRequestResult>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:732\n\ngetDepositStatus()​\ngetDepositStatus(params: GetL1L3DepositStatusParams): Promise<Erc20L1L3DepositStatus>\n\n\nFetch the cross chain messages and their status\n\nCan provide either the txHash, the tx, or the txReceipt\n\nParameters​\nParameter\tType\nparams\tGetL1L3DepositStatusParams\nReturns​\n\nPromise<Erc20L1L3DepositStatus>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:878\n\ngetGasTokenOnL1()​\ngetGasTokenOnL1(l1Provider: Provider, l2Provider: Provider): Promise<string>\n\n\nIf the L3 network uses a custom gas token, return the address of that token on L1. If the fee token is not available on L1, does not use 18 decimals on L1 and L2, or the L3 network uses ETH for fees, throw.\n\nParameters​\nParameter\tType\nl1Provider\tProvider\nl2Provider\tProvider\nReturns​\n\nPromise<string>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:431\n\ngetL1L2GatewayAddress()​\ngetL1L2GatewayAddress(erc20L1Address: string, l1Provider: Provider): Promise<string>\n\n\nGiven an L1 token's address, get the address of the token's L1 <-> L2 gateway on L1\n\nParameters​\nParameter\tType\nerc20L1Address\tstring\nl1Provider\tProvider\nReturns​\n\nPromise<string>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:532\n\ngetL1TokenContract()​\ngetL1TokenContract(l1TokenAddr: string, l1Provider: Provider): IERC20\n\n\nGet the L1 token contract at the provided address Note: This function just returns a typed ethers object for the provided address, it doesn't check the underlying form of the contract bytecode to see if it's an erc20, and doesn't ensure the validity of any of the underlying functions on that contract.\n\nParameters​\nParameter\tType\nl1TokenAddr\tstring\nl1Provider\tProvider\nReturns​\n\nIERC20\n\nSource​\n\nassetBridger/l1l3Bridger.ts:560\n\ngetL2Erc20Address()​\ngetL2Erc20Address(erc20L1Address: string, l1Provider: Provider): Promise<string>\n\n\nGet the corresponding L2 token address for the provided L1 token\n\nParameters​\nParameter\tType\nerc20L1Address\tstring\nl1Provider\tProvider\nReturns​\n\nPromise<string>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:508\n\ngetL2L3GatewayAddress()​\ngetL2L3GatewayAddress(\n   erc20L1Address: string, \n   l1Provider: Provider, \nl2Provider: Provider): Promise<string>\n\n\nGet the address of the L2 <-> L3 gateway on L2 given an L1 token address\n\nParameters​\nParameter\tType\nerc20L1Address\tstring\nl1Provider\tProvider\nl2Provider\tProvider\nReturns​\n\nPromise<string>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:545\n\ngetL2TokenContract()​\ngetL2TokenContract(l2TokenAddr: string, l2Provider: Provider): L2GatewayToken\n\n\nGet the L2 token contract at the provided address Note: This function just returns a typed ethers object for the provided address, it doesn't check the underlying form of the contract bytecode to see if it's an erc20, and doesn't ensure the validity of any of the underlying functions on that contract.\n\nParameters​\nParameter\tType\nl2TokenAddr\tstring\nl2Provider\tProvider\nReturns​\n\nL2GatewayToken\n\nSource​\n\nassetBridger/l1l3Bridger.ts:570\n\ngetL3Erc20Address()​\ngetL3Erc20Address(\n   erc20L1Address: string, \n   l1Provider: Provider, \nl2Provider: Provider): Promise<string>\n\n\nGet the corresponding L3 token address for the provided L1 token\n\nParameters​\nParameter\tType\nerc20L1Address\tstring\nl1Provider\tProvider\nl2Provider\tProvider\nReturns​\n\nPromise<string>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:518\n\ngetL3TokenContract()​\ngetL3TokenContract(l3TokenAddr: string, l3Provider: Provider): L2GatewayToken\n\n\nGet the L3 token contract at the provided address Note: This function just returns a typed ethers object for the provided address, it doesn't check the underlying form of the contract bytecode to see if it's an erc20, and doesn't ensure the validity of any of the underlying functions on that contract.\n\nParameters​\nParameter\tType\nl3TokenAddr\tstring\nl3Provider\tProvider\nReturns​\n\nL2GatewayToken\n\nSource​\n\nassetBridger/l1l3Bridger.ts:583\n\nl1TokenIsDisabled()​\nl1TokenIsDisabled(l1TokenAddress: string, l1Provider: Provider): Promise<boolean>\n\n\nWhether the L1 token has been disabled on the L1 <-> L2 router given an L1 token address\n\nParameters​\nParameter\tType\nl1TokenAddress\tstring\nl1Provider\tProvider\nReturns​\n\nPromise<boolean>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:593\n\nl2ForwarderAddress()​\nl2ForwarderAddress(\n   owner: string, \n   routerOrInbox: string, \n   destinationAddress: string, \nl1OrL2Provider: Provider): Promise<string>\n\n\nGiven some L2Forwarder parameters, get the address of the L2Forwarder contract\n\nParameters​\nParameter\tType\nowner\tstring\nrouterOrInbox\tstring\ndestinationAddress\tstring\nl1OrL2Provider\tProvider\nReturns​\n\nPromise<string>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:613\n\nl2TokenIsDisabled()​\nl2TokenIsDisabled(l2TokenAddress: string, l2Provider: Provider): Promise<boolean>\n\n\nWhether the L2 token has been disabled on the L2 <-> L3 router given an L2 token address\n\nParameters​\nParameter\tType\nl2TokenAddress\tstring\nl2Provider\tProvider\nReturns​\n\nPromise<boolean>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:603\n\nteleportationType()​\nteleportationType(partialTeleportParams: Pick<TeleportParamsStruct, \"l1Token\" | \"l3FeeTokenL1Addr\">): TeleportationType\n\n\nGet the type of teleportation from the l1Token and l3FeeTokenL1Addr teleport parameters\n\nParameters​\nParameter\tType\npartialTeleportParams\tPick<TeleportParamsStruct, \"l1Token\" | \"l3FeeTokenL1Addr\">\nReturns​\n\nTeleportationType\n\nSource​\n\nassetBridger/l1l3Bridger.ts:953\n\nEthL1L3Bridger​\n\nBridge ETH from L1 to L3 using a double retryable ticket\n\nExtends​\nBaseL1L3Bridger\nMethods​\n_checkL1Network()​\nprotected _checkL1Network(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the l1Network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nInherited from​\n\nBaseL1L3Bridger._checkL1Network\n\nSource​\n\nassetBridger/l1l3Bridger.ts:306\n\n_checkL2Network()​\nprotected _checkL2Network(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the l2Network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nInherited from​\n\nBaseL1L3Bridger._checkL2Network\n\nSource​\n\nassetBridger/l1l3Bridger.ts:314\n\n_checkL3Network()​\nprotected _checkL3Network(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the l3Network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nInherited from​\n\nBaseL1L3Bridger._checkL3Network\n\nSource​\n\nassetBridger/l1l3Bridger.ts:322\n\ndeposit()​\ndeposit(params: TxRequestParams | EthL1L3DepositRequestParams & object): Promise<ParentContractCallTransaction>\n\n\nDeposit ETH to L3 via a double retryable ticket\n\nParameters​\nParameter\tType\nparams\tTxRequestParams | EthL1L3DepositRequestParams & object\nReturns​\n\nPromise<ParentContractCallTransaction>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:1521\n\ngetDepositParameters()​\ngetDepositParameters(params: object & TxReference): Promise<object>\n\n\nGiven an L1 transaction, get the retryable parameters for both l2 and l3 tickets\n\nParameters​\nParameter\tType\nparams\tobject & TxReference\nReturns​\n\nPromise<object>\n\nMember\tType\nl1l2TicketData\tRetryableMessageParams\nl2l3TicketData\tRetryableMessageParams\nSource​\n\nassetBridger/l1l3Bridger.ts:1547\n\ngetDepositRequest()​\ngetDepositRequest(params: EthL1L3DepositRequestParams & object | object): Promise<ParentToChildTransactionRequest>\n\n\nGet a tx request to deposit ETH to L3 via a double retryable ticket\n\nParameters​\nParameter\tType\nparams\tEthL1L3DepositRequestParams & object | object\nReturns​\n\nPromise <ParentToChildTransactionRequest>\n\nSource​\n\nassetBridger/l1l3Bridger.ts:1463\n\ngetDepositStatus()​\ngetDepositStatus(params: GetL1L3DepositStatusParams): Promise<EthL1L3DepositStatus>\n\n\nGet the status of a deposit given an L1 tx receipt. Does not check if the tx is actually a deposit tx.\n\nParameters​\nParameter\tType\nparams\tGetL1L3DepositStatusParams\nReturns​\n\nPromise<EthL1L3DepositStatus>\n\nInformation regarding each step of the deposit and EthL1L3DepositStatus.completed which indicates whether the deposit has fully completed.\n\nSource​\n\nassetBridger/l1l3Bridger.ts:1577\n\nEdit this page\nPrevious\nEthBridger\nNext\nAddress\nClasses\nErc20L1L3Bridger\nExtends\nProperties\nMethods\n_checkL1Network()\n_checkL2Network()\n_checkL3Network()\n_decodeCallForwarderCalldata()\n_decodeTeleportCalldata()\n_fillPartialTeleportParams()\n_getL1L2FeeTokenBridgeGasEstimates()\n_getL1L2TokenBridgeGasEstimates()\n_getL2ForwarderFactoryGasEstimates()\n_getL2L3BridgeGasEstimates()\n_getTokenBridgeGasEstimates()\n_l2ForwarderFactoryCalldataSize()\napproveGasToken()\napproveToken()\ndeposit()\ngetApproveGasTokenRequest()\ngetApproveTokenRequest()\ngetDepositParameters()\ngetDepositRequest()\ngetDepositStatus()\ngetGasTokenOnL1()\ngetL1L2GatewayAddress()\ngetL1TokenContract()\ngetL2Erc20Address()\ngetL2L3GatewayAddress()\ngetL2TokenContract()\ngetL3Erc20Address()\ngetL3TokenContract()\nl1TokenIsDisabled()\nl2ForwarderAddress()\nl2TokenIsDisabled()\nteleportationType()\nEthL1L3Bridger\nExtends\nMethods\n_checkL1Network()\n_checkL2Network()\n_checkL3Network()\ndeposit()\ngetDepositParameters()\ngetDepositRequest()\ngetDepositStatus()\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/dataEntities/event",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nAddress\nConstants\nErrors\nEvent\nMessage\nNetworks\nRetryableData\nRpc\nSignerOrProvider\nTransactionRequest\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nevent\nType Aliases​\nEventArgs<T>​\ntype EventArgs<T>: T extends TypedEvent<infer _, infer TObj> ? TObj : never;\n\n\nThe type of the event arguments. Gets the second generic arg\n\nType parameters​\nType parameter\nT\nSource​\n\ndataEntities/event.ts:10\n\nEventFromFilter<TFilter>​\ntype EventFromFilter<TFilter>: TFilter extends TypedEventFilter<infer TEvent> ? TEvent : never;\n\n\nThe event type of a filter Gets the first generic arg\n\nType parameters​\nType parameter\nTFilter\nSource​\n\ndataEntities/event.ts:18\n\nTypeChainContractFactory<TContract>​\ntype TypeChainContractFactory<TContract>: object;\n\n\nTypechain contract factories have additional properties\n\nType parameters​\nType parameter\nTContract extends Contract\nType declaration​\nMember\tType\nconnect\tTContract\ncreateInterface\tInterface\nSource​\n\ndataEntities/event.ts:41\n\nFunctions​\nparseTypedLog()​\nfunction parseTypedLog<TContract, TFilterName>(\n   contractFactory: TypeChainContractFactory<TContract>, \n   log: Log, \nfilterName: TFilterName): null | EventArgs<EventFromFilter<ReturnType<TContract[\"filters\"][TFilterName]>>>\n\n\nParse a log that matches a given filter name.\n\nType parameters​\nType parameter\nTContract extends Contract\nTFilterName extends string\nParameters​\nParameter\tType\tDescription\ncontractFactory\tTypeChainContractFactory<TContract>\t\nlog\tLog\tThe log to parse\nfilterName\tTFilterName\t\nReturns​\n\nnull | EventArgs <EventFromFilter<ReturnType<TContract[\"filters\"][TFilterName]>>>\n\nNull if filter name topic does not match log topic\n\nSource​\n\ndataEntities/event.ts:53\n\nparseTypedLogs()​\nfunction parseTypedLogs<TContract, TFilterName>(\n   contractFactory: TypeChainContractFactory<TContract>, \n   logs: Log[], \n   filterName: TFilterName): EventArgs<EventFromFilter<ReturnType<TContract[\"filters\"][TFilterName]>>>[]\n\n\nParses an array of logs. Filters out any logs whose topic does not match provided the filter name topic.\n\nType parameters​\nType parameter\nTContract extends Contract\nTFilterName extends string\nParameters​\nParameter\tType\tDescription\ncontractFactory\tTypeChainContractFactory<TContract>\t\nlogs\tLog[]\tThe logs to parse\nfilterName\tTFilterName\t\nReturns​\n\nEventArgs <EventFromFilter<ReturnType<TContract[\"filters\"][TFilterName]>>>[]\n\nSource​\n\ndataEntities/event.ts:78\n\nEdit this page\nPrevious\nErrors\nNext\nMessage\nType Aliases\nEventArgs<T>\nType parameters\nSource\nEventFromFilter<TFilter>\nType parameters\nSource\nTypeChainContractFactory<TContract>\nType parameters\nType declaration\nSource\nFunctions\nparseTypedLog()\nType parameters\nParameters\nReturns\nSource\nparseTypedLogs()\nType parameters\nParameters\nReturns\nSource\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/token-bridging/token-bridge-erc20#other-flavors-of-gateways",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nOverview\nETH bridging\nERC-20 token bridging\nBridge tokens programmatically\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nERC-20 token bridging\n\nThe Arbitrum protocol itself technically has no native notion of any token standards, and gives no built-in advantage or special recognition to any particular token bridge. In this page we describe the \"canonical bridge\", which was implemented by Offchain Labs, and should be the primary bridge most users and applications use; it is (effectively) a decentralized app (dApp) with contracts on both Ethereum (the Layer 1, or L1) and Arbitrum (the Layer 2, or L2) that leverages Arbitrum's cross-chain message passing system to achieve basic desired token-bridging functionality. We recommend that you use it!\n\nDesign rationale​\n\nIn our token bridge design, we use the term \"gateway\" as per this proposal; i.e., one of a pair of contracts on two different domains (i.e., Ethereum and an Arbitrum chain), used to facilitate cross-domain asset transfers.\n\nWe now describe some core goals that motivated the design of our bridging system.\n\nCustom gateway functionality​\n\nFor many ERC-20 tokens, \"standard\" bridging functionality is sufficient, which entails the following: a token contract on Ethereum is associated with a \"paired\" token contract on Arbitrum.\n\nDepositing a token entails escrowing some amount of the token in an L1 bridge contract, and minting the same amount at the paired token contract on L2. On L2, the paired contract behaves much like a normal ERC-20 token contract. Withdrawing entails burning some amount of the token in the L2 contract, which then can later be claimed from the L1 bridge contract.\n\nMany tokens, however, require custom gateway systems, the possibilities of which are hard to generalize, e.g.:\n\nTokens which accrue interest to their holders need to ensure that the interest is dispersed properly across layers, and doesn't simply accrue to the bridge contracts\nOur cross-domain WETH implementations requires tokens be wrapped and unwrapped as they move across layers.\n\nThus, our bridge architecture must allow not just the standard deposit and withdraw functionalities, but for new, custom gateways to be dynamically added over time.\n\nCanonical L2 representation per L1 token contract​\n\nHaving multiple custom gateways is well and good, but we also want to avoid a situation in which a single L1 token that uses our bridging system can be represented at multiple addresses/contracts on the L2 as this adds significant friction and confusion for users and developers. Thus, we need a way to track which L1 token uses which gateway, and in turn, to have a canonical address oracle that maps the tokens addresses across the Ethereum and Arbitrum domains.\n\nCanonical token bridge implementation​\n\nWith this in mind, we provide an overview of our token bridging architecture.\n\nOur architecture consists of three types of contracts:\n\nAsset contracts: These are the token contracts themselves, i.e., an ERC-20 on L1 and it's counterpart on Arbitrum.\nGateways: Pairs of contracts (one on L1, one on L2) that implement a particular type of cross-chain asset bridging.\nRouters: Exactly two contracts (one on L1, one on L2) that route each asset to its designated gateway.\n\nAll Ethereum to Arbitrum token transfers are initiated via the router contract on L1, the L1GatewayRouter contract. L1GatewayRouter forwards the token's deposit call to the appropriate gateway contract on L1, the L1ArbitrumGateway contract. L1GatewayRouter is responsible for mapping L1 token addresses to L1Gateway contracts, thus acting as an L1/L2 address oracle, and ensuring that each token corresponds to only one gateway. The L1ArbitrumGateway then communicates to its counterpart gateway contract on L2, the L2ArbitrumGateway contract (typically/expectedly via retryable tickets).\n\nSimilarly, Arbitrum to Ethereum transfers are initiated via the router contract on L2, the L2GatewayRouter contract, which calls the token's gateway contract on L2, the L2ArbitrumGateway contract, which in turn communicates to its corresponding gateway contract on L1, the L1ArbitrumGateway contract (typically/expectedly via sending L2-to-L1 messages to the outbox).\n\nFor any given gateway pairing, we require that calls be initiated through the corresponding router (L1GatewayRouter or L2GatewayRouter), and that the gateways conform to the TokenGateway interfaces; the TokenGateway interfaces should be flexible and extensible enough to support any bridging functionality a particular token may require.\n\nThe standard ERC-20 gateway​\n\nBy default, any ERC-20 token on L1 that isn't registered to a gateway can be permissionlessly bridged through the StandardERC20Gateway.\n\nYou can use the bridge UI or follow the instructions in How to bridge tokens via Arbitrum’s standard ERC-20 gateway to bridge a token to L2 via this gateway.\n\nExample: Standard Arb-ERC20 deposit and withdraw​\n\nTo help illustrate what this all looks like in practice, let's go through the steps of what depositing and withdrawing SomeERC20Token via our standard ERC-20 gateway looks like. Here, we're assuming that SomeERC20Token has already been registered in the L1GatewayRouter to use the standard ERC-20 gateway.\n\nDeposits​\nA user calls L1GatewayRouter.outboundTransferCustomRefund [1] (with SomeERC20Token's L1 address as an argument).\nL1GatewayRouter looks up SomeERC20Token's gateway, and finds that it's the standard ERC-20 gateway (the L1ERC20Gateway contract).\nL1GatewayRouter calls L1ERC20Gateway.outboundTransferCustomRefund, forwarding the appropriate parameters.\nL1ERC20Gateway escrows the tokens sent and creates a retryable ticket to trigger L2ERC20Gateway's finalizeInboundTransfer method on L2.\nL2ERC20Gateway.finalizeInboundTransfer mints the appropriate amount of tokens at the arbSomeERC20Token contract on L2.\n\n❗️ [1] Please keep in mind that some older custom gateways might not have outboundTransferCustomRefund implemented and L1GatewayRouter.outboundTransferCustomRefund does not fallback to outboundTransfer. In those cases, please use function L1GatewayRouter.outboundTransfer.\n\nNote that arbSomeERC20Token is an instance of StandardArbERC20, which includes bridgeMint and bridgeBurn methods only callable by the L2ERC20Gateway.\n\nWithdrawals​\nOn Arbitrum, a user calls L2GatewayRouter.outBoundTransfer, which in turn calls outBoundTransfer on arbSomeERC20Token's gateway (i.e., L2ERC20Gateway).\nThis burns arbSomeERC20Token tokens, and calls ArbSys with an encoded message to L1ERC20Gateway.finalizeInboundTransfer, which will be eventually executed on L1.\nAfter the dispute window expires and the assertion with the user's transaction is confirmed, a user can call Outbox.executeTransaction, which in turn calls the encoded L1ERC20Gateway.finalizeInboundTransfer message, releasing the user's tokens from the L1ERC20Gateway contract's escrow.\nThe Arbitrum generic-custom gateway​\n\nJust because a token has requirements beyond what are offered via the standard ERC-20 gateway, that doesn't necessarily mean that a unique gateway needs to be tailor-made for the token in question. Our generic-custom gateway is designed to be flexible enough to be suitable for most (but not necessarily all) custom fungible token needs. As a general rule:\n\nIf your custom token has the ability to increase its supply (i.e., mint) directly on the L2, and you want the L2-minted tokens be withdrawable back to L1 and recognized by the L1 contract, it will probably require its own special gateway. Otherwise, the generic-custom gateway is likely the right solution for you!\n\nSome examples of token features suitable for the generic-custom gateway:\n\nAn L2 token contract upgradable via a proxy\nAn L2 token contract that includes address whitelisting/blacklisting\nThe deployer determines the address of the L2 token contract\nSetting up your token with the generic-custom gateway​\n\nFollow the following steps to get your token set up to use the generic-custom gateway. You can also find more detailed instructions in the page How to bridge tokens via Arbitrum’s generic-custom gateway.\n\n0. Have an L1 token\n\nYour token on L1 should conform to the ICustomToken interface (see TestCustomTokenL1 for an example implementation). Crucially, it must have an isArbitrumEnabled method in its interface.\n\n1. Deploy your token on Arbitrum\n\nYour token should conform to the minimum IArbToken interface; i.e., it should have bridgeMint and bridgeBurn methods only callable by the L2CustomGateway contract, and the address of its corresponding Ethereum token accessible via l1Address. For an example implementation, see L2GatewayToken.\n\nTOKEN COMPATIBILITY WITH AVAILABLE TOOLING\n\nIf you want your token to be compatible out of the box with all the tooling available (e.g., the Arbitrum bridge), we recommend that you keep the implementation of the IArbToken interface as close as possible to the L2GatewayToken implementation example.\n\nFor example, if an allowance check is added to the bridgeBurn() function, the token will not be easily withdrawable through the Arbitrum bridge UI, as the UI does not prompt an approval transaction of tokens by default (it expects the tokens to follow the recommended L2GatewayToken implementation).\n\n2. Register your token on L1 to your token on L2 via the L1CustomGateway contract\n\nHave your L1 token's contract make an external call to L1CustomGateway.registerTokenToL2. This registration can alternatively be performed as a chain-owner registration via an Arbitrum DAO proposal.\n\n3. Register your token on L1 to the L1GatewayRouter\n\nAfter your token's registration to the generic-custom gateway is complete, have your L1 token's contract make an external call to L1GatewayRouter.setGateway; this registration can also alternatively be performed as a chain-owner registration via an Arbitrum DAO proposal.\n\nWE ARE HERE TO HELP\n\nIf you have questions about your custom token needs, feel free to reach out on our Discord server.\n\nOther flavors of gateways​\n\nNote that in the system described above, one pair of gateway contracts handles the bridging of many ERC-20s; i.e., many ERC-20s on L1 are each paired with their own ERC-20s on Arbitrum via a single gateway contract pairing. Other gateways may well bear different relations with the contracts that they bridge.\n\nTake our wrapped Ether implementation for example: here, a single WETH contract on L1 is connected to a single WETH contract on L2. When transferring WETH from one domain to another, the L1/L2 gateway architecture is used to unwrap the WETH on domain A, transfer the now-unwrapped Ether, and then re-wrap it on domain B. This ensures that WETH can behave on Arbitrum the way users are used to it behaving on Ethereum, while ensuring that all WETH tokens are always fully collateralized on the layer in which they reside.\n\nNo matter the complexity of a particular token's bridging needs, a gateway can in principle be created to accommodate it within our canonical bridging system.\n\nYou can find an example of implementation of a custom gateway in the page How to bridge tokens via a custom gateway.\n\nDemos​\n\nOur How to bridge tokens section provides example of interacting with Arbitrum's token bridge via the Arbitrum SDK.\n\nA word of caution on bridges (aka, \"I've got a bridge to sell you\")​\n\nCross chain bridging is an exciting design space; alternative bridge designs can potentially offer faster withdrawals, interoperability with other chains, different trust assumptions with their own potentially valuable UX tradeoffs, etc. They can also potentially be completely insecure and/or outright scams. Users should treat other, non-canonical bridge applications the same way they treat any application running on Arbitrum, and exercise caution and due diligence before entrusting them with their value.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nETH bridging\nNext\nGet started\nDesign rationale\nCustom gateway functionality\nCanonical L2 representation per L1 token contract\nCanonical token bridge implementation\nThe standard ERC-20 gateway\nExample: Standard Arb-ERC20 deposit and withdraw\nThe Arbitrum generic-custom gateway\nSetting up your token with the generic-custom gateway\nOther flavors of gateways\nDemos\nA word of caution on bridges (aka, \"I've got a bridge to sell you\")\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/dataEntities/errors",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nAddress\nConstants\nErrors\nEvent\nMessage\nNetworks\nRetryableData\nRpc\nSignerOrProvider\nTransactionRequest\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nerrors\nClasses​\nArbSdkError​\n\nErrors originating in Arbitrum SDK\n\nExtends​\nError\nExtended by​\nMissingProviderArbSdkError\nMissingProviderArbSdkError​\n\nThrown when a signer does not have a connected provider\n\nExtends​\nArbSdkError\nEdit this page\nPrevious\nConstants\nNext\nEvent\nClasses\nArbSdkError\nExtends\nExtended by\nMissingProviderArbSdkError\nExtends\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/dataEntities/message",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nAddress\nConstants\nErrors\nEvent\nMessage\nNetworks\nRetryableData\nRpc\nSignerOrProvider\nTransactionRequest\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nmessage\nEnumerations​\nInboxMessageKind​\n\nThe inbox message kind as defined in: https://github.com/OffchainLabs/nitro/blob/c7f3429e2456bf5ca296a49cec3bb437420bc2bb/contracts/src/libraries/MessageTypes.sol\n\nEnumeration Members​\nEnumeration Member\tValue\nL1MessageType_ethDeposit\t12\nL1MessageType_submitRetryableTx\t9\nL2MessageType_signedTx\t4\nInterfaces​\nRetryableMessageParams​\n\nThe components of a submit retryable message. Can be parsed from the events emitted from the Inbox.\n\nProperties​\nProperty\tType\tDescription\ncallValueRefundAddress\tstring\tAddress to credit l2Callvalue on L2 if retryable txn times out or gets cancelled\ndata\tstring\tCalldata for of the L2 message\ndestAddress\tstring\tDestination address for L2 message\nexcessFeeRefundAddress\tstring\tL2 address address to credit (gaslimit x gasprice - execution cost)\ngasLimit\tBigNumber\tMax gas deducted from user's L2 balance to cover L2 execution\nl1Value\tBigNumber\tValue sent at L1\nl2CallValue\tBigNumber\tCall value in L2 message\nmaxFeePerGas\tBigNumber\tGas price for L2 execution\nmaxSubmissionFee\tBigNumber\tMax gas deducted from L2 balance to cover base submission fee\nEdit this page\nPrevious\nEvent\nNext\nNetworks\nEnumerations\nInboxMessageKind\nEnumeration Members\nInterfaces\nRetryableMessageParams\nProperties\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to set up an AEP fee router | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/set-up-aep-fee-router",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nCustomize your chain's deployment\nAdditional configuration parameters\nUse a custom gas token\nCustomize your chain's precompiles\nCustomize your chain's behavior\nConfigure delayed inbox finality\nManage the fee collectors\nCustomize ArbOS version\nImplement Circle bridged USDC\nEnable fast withdrawals\nAEP fee router\nAEP fee router: overview\nSet up an AEP fee router\nCalculating AEP license fees\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to set up an AEP fee router\nQuick start​\nYou can adopt the AEP Fee Router by using the AEP Router deployment scripts provided in the Orbit SDK\nCanonical Contracts​\nNetwork\tContract\tAddress\tConfigured For\nEthereum\tParent2ChildRouter\thttps://etherscan.io/address/0x40Cd7D713D7ae463f95cE5d342Ea6E7F5cF7C999\tETH, ERC-20\nArbitrum Nova\tChild2ParentRouter\thttps://nova.arbiscan.io/address/0x36D0170D92F66e8949eB276C3AC4FEA64f83704d\tETH\nThe AEP fee router contract system​\n\nLink to the Router contracts' source code.\n\nRewardDistributor​\n\nThe AEP fee router system relies on configuring an escrow contract as the intended reward address for protocol fee components. This intermediary contract is known as the RewardDistributor.\n\nThe RewardDistributor is configured to separate the AEP portion of the fees from fees intended for the chain owner. The RewardDistributor can be permissionlessly called to perform a withdrawal which simultaneously transfers 90% of accrued fees to the chain’s fee collector and 10% of accrued fees to a routing contract on the parent chain. From here, the chain owner has complete control over their earned fees, and the routing contracts can direct AEP fees to a collecting address for the Arbitrum DAO.\n\nChildToParentRouter​\n\nAEP fees from the RewardDistributor must first be sent to Ethereum before they can be deposited to the DAO-controlled address on Arbitrum One. To facilitate this transfer to Ethereum, AEP fees are sent through a series of contracts known as ChildToParentRouters.\n\nThe ChildToParentRouter is configured to withdraw a single token (immutable and specified at deployment) from the child chain to a specific target address on the parent chain: either another ChildToParentRouter or the ParentToChildRouter on Ethereum.\n\nParentToChildRouter​\n\nAll AEP fees from the network of Orbit chains will arrive at the ParentToChildRouter on Ethereum. This contract can send ETH and arbitrary ERC-20 tokens to a DAO-controlled address on Arbitrum One.\n\nDeploying your AEP fee router contracts​\n\nAn Orbit chain is responsible for deploying all ChildToParentRouters necessary for their AEP funds to arrive at the ParentToChildRouter on Ethereum.\n\nThis includes:\n\nDeploying a ChildToParentRouter on their Orbit chain configured for their gas token and configured to send funds to either:\nThe ParentToChildRouter on Ethereum (assuming the network is a Layer-2)\nAnother ChildToParentRouter configured to the same gas token and configured to send funds to a successive parent chain (this is the case for a Layer-3 network or higher)\nDeploying a RewardDistributor contract configured to forward 10% of fees to the ChildToParentRouter and 90% to the chain owner’s preferred reward-receiving address.\n\nIn the event that a ChildToParentRouter does not connect to the ParentToChildRouter on Ethereum, an Orbit chain must deploy successive ChildToParentRouter contracts until a connection to ParentToChildRouter is established.\n\nAnd optionally, an Orbit chain can decide to deduct assertion costs by following the instructions in the Deducting Assertion Costs section:\n\n🚨 Layer-3 chains with custom gas tokens with L2-based token contracts cannot send their custom gas tokens to Ethereum. A future version of the AEP Fee Router may allow Orbit chains with L2-based tokens to distribute fees using the routing system.\n\nIn the absence of these, please send ETH through the AEP Fee Router to fulfill your AEP license obligations.\n\nDeployment scripts​\n\nThe Orbit SDK provides a configurable script that allows a chain operator to deploy quickly and set up the AEP fee router contracts.\n\n⚠️ The standard script deploys and sets up the AEP fee router contracts for L2 chains. For L3 chains (or further layers), a different target address on the parent chain will need to be specified, depending on the native token of the chain. Please contact the Arbitrum Foundation to confirm the target address to withdraw the AEP fees to.\n\nThe script performs the following operations:\n\nObtain the Rollup and inbox contract of the chain. These are needed to execute the next steps.\nObtain the current fee collectors of the chain: Orbit base fee collector, Orbit surplus fee collector, and Parent chain surplus fee collector.\nDeploy the ChildToParentRouter contract, configured to send the amounts received to the appropriate Arbitrum DAO controlled address on the parent chain.\nDeploy a RewardDistributor contract for each different fee collector account, configured to distribute 90% of the amounts received to the current fee collector and 10% to the ChildToParentRouter contract deployed in the previous step.\nSet each of the fee collectors to the RewardDistributor contracts\n\nℹ️ Note that if the same address collects all three fee types, only one RewardDistributor contract will be deployed, which will collect all those fees.\n\nTo configure the script, you need to specify the following environment variables:\n\nROLLUP_ADDRESS: address of the Rollup contract\nCHAIN_OWNER_PRIVATE_KEY: private key of the account with executor privileges in the UpgradeExecutor admin contract for the chain\nORBIT_CHAIN_ID: chainId of the Orbit chain\nORBIT_CHAIN_RPC: RPC of the Orbit chain\nPARENT_CHAIN_ID: chainId of the parent chain, which can neither be an Arbitrum chain nor Ethereum.\nPARENT_CHAIN_TARGET_ADDRESS: address on the parent chain where 10% of the revenue will be sent to. You can find the potential target addresses in the canonical contracts section of this document. If the parent chain your chain settles to is not on that list, contact the Arbitrum Foundation to obtain a specific target address for your chain.\n\nFinally, follow these steps to execute the script (from the examples/setup-aep-fee-router folder):\n\nInstall dependencies\nyarn install\n\nCreate .env file and add the env vars\ncp .env.example .env\n\nRun the script\nyarn dev\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nAEP fee router: overview\nNext\nCalculating AEP license fees\nQuick start\nCanonical Contracts\nThe AEP fee router contract system\nRewardDistributor\nChildToParentRouter\nParentToChildRouter\nDeploying your AEP fee router contracts\nDeployment scripts\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/run-local-dev-node",
    "html": "Skip to main content\nArbitrum Docs\nPage Not Found\n\nWe could not find what you were looking for.\n\nPlease contact the owner of the site that linked you to the original URL and let them know their link is broken.\n\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/arbos-releases/arbos11",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nOverview\nArbOS 32 Bianca\nArbOS 20 Atlas\nArbOS 11\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nArbOS 11\n\nArbOS 11 is shipped via Nitro v2.2.0, which is available on Docker hub with the image tag: offchainlabs/nitro-node:v2.2.0-f7dc9de. This release of Nitro is a mandatory upgrade for Arbitrum One and Nova validators. For Arbitrum One and Nova, the ArbOS 11 upgrade requires a governance vote to activate.\n\nFormal release notes can be found here.\n\nRequirements:​\nNitro v2.2.0 or higher\nnitro-contracts v1.1.0 or higher\nWasm module root: 0x6b94a7fc388fd8ef3def759297828dc311761e88d8179c7ee8d3887dc554f3c3\nHigh-level description of ArbOS 11 changes​\nAddition of all EVM changes made on L1 Ethereum as part of the Shanghai upgrade. This includes:\nEIP-3651: Warm COINBASE\nEIP-3855: PUSH0 instruction\nEIP-3860: Limit and meter initcode\nEIP-6049: Deprecate SELFDESTRUCT\nImprovements and fixes for retryable tickets to ensure that the fee calculation to redeem retryable tickets will take into account both the infrastructure fee and the network fee. The infrastructure fee is the minimum L2 base fee only, while the network fee collects L2 congestion charges. This is important for AnyTrust chains like Arbitrum Nova because members of the Data Availability Committee (DAC) gets paid a percentage of the infrastructure fee but not the network fee. Previously, the calculations to determine the fee for redeeming retryable tickets did not consider the infrastructure fee.\nFixes an issue where the ArbOwnerPublic precompile returned the incorrect list of chain owners. This does not change the parties who are able to perform chain owner actions. As intended, only the Arbitrum DAO is able to take chain owner actions for Arbitrum One and Nova.\nResolves an issue where the arbBlockHash method would take up all the gas when reverting. The previous incorrect behavior meant that if a transaction calls arbBlockHash with an out-of-range block number, then the transaction would consume all the gas when reverting.\nAddition of the L1RewardReceipient and L1RewardRate precompile methods to view L1 pricing parameters and make it easier to view the current chain configuration.\nFix the ArbOwner precompile to disallow emitting logs in STATICCALL contexts, bringing this in line with how the EVM is expected to behave as STATICCALL invocations should never be able to emit logs. The previous incorrect behavior would mean that a log was emitted when a chain owner made a STATICCALL on the ArbOwner precompile.\nReference links for ArbOS 11​\nNitro v2.2.0 Release details on Github\nOriginal DAO proposal: AIP: ArbOS Version 11\nAIP: ArbOS Version 11 Snapshot Vote\nFormal Tally (on-chain) vote for AIP: ArbOS Version 11\nArbOS 11 Audit Report by Trail of Bits\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nArbOS 20 Atlas\nNext\nRun an archive node\nRequirements:\nHigh-level description of ArbOS 11 changes\nReference links for ArbOS 11\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/arbos-releases/arbos32",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nOverview\nArbOS 32 Bianca\nArbOS 20 Atlas\nArbOS 11\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nArbOS 32 Bianca\nCAUTION\n\nPlease upgrade directly to ArbOS 32 from ArbOS 20 and not to ArbOS 30 or ArbOS 31. The ArbOS 32 release builds upon ArbOS 30 and ArBbOS 31 and includes critical fixes & optimizations coming out of rigorous testing and feedback from Stylus teams. ArbOS 32 “Bianca” will be the canonical ArbOS version for the “Bianca” family of releases.\n\nFuture versions of Nitro may remove support for Orbit chains which have historically upgraded to, and remain on, ArbOS 30 or ArbOS 31. Due to this, we highly recommend upgrading immediately and directly to ArbOS 32.\n\nArbOS 32 \"Bianca\" is shipped via Nitro v3.2.1, which is available on Docker hub with the image tag: offchainlabs/nitro-node:v3.2.1-d81324d. This release of Nitro is a mandatory upgrade for Arbitrum One and Nova validators. For Arbitrum One and Nova, the ArbOS 32 \"Bianca\" upgrade required a governance vote to activate.\n\nPlease note that it is important that you only run the Nitro v3.2.1 against trusted databases. If you want to use an untrusted database, you can first remove the wasm directory if it exists (it might be inside the nitro folder). Otherwise, the database may have malicious, unvalidated code that can result in remote code execution. This is also mitigated by ensuring you run the Arbitrum Nitro node inside Docker.\n\nThe Arbitrum docs will remain the canonical home for information regarding ArbOS releases, with more details found on the ArbOS Software Releases Overview page.\n\nRequirements:​\nNitro 3.2.1 or higher\nnitro-contracts v2.1.0 or higher\nWASM module root: 0x184884e1eb9fefdc158f6c8ac912bb183bf3cf83f0090317e0bc4ac5860baa39\nHigh-level description of ArbOS 32 changes​\n\nArbOS 32 Bianca is a major upgrade for Arbitrum chains. As a refresher, ArbOS upgrades can be treated as Arbitrum’s equivalent of a hard fork - more can be read about this subject over in Arbitrum ArbOS upgrades. Please note that ArbOS 21 Bianca is an upgrade that builds upon ArbOS 20 Atlas.\n\nArbOS 32 Bianca brings many features, improvements, and bug fixes to Arbitrum chains. A full list of changes can be found in the Nitro release notes for Nitro 3.2.1 or higher (as Nitro 3.2.1 is the endorsed Nitro node version for ArbOS 32 Bianca). Highlighted below are a few of the most impactful and critical features that are introduced with ArbOS 32 Bianca:\n\nAddition and subsequent activation of Stylus on Arbitrum chains through the addition of a new WebAssembly-based (WASM) virtual machine that runs alongside the EVM. Stylus enables developers to write smart contracts in new programming languages that compile to WASM, like Rust, that are more efficient and safer than Solidity smart contracts while retaining complete interoperability.\nAdding support for RIP-7212 decreases the costs of verifying the secp256r1 curve on-chain by 99% when compared to current implementations, making secp256r1 verification more feasible for everyday use and enabling dApp developers and protocols to offer their users improved UX on Arbitrum One and Arbitrum Nova. Without this precompile, verifying this signature on-chain is extremely expensive. Passkey-based wallets offer better security than a typical EOA and seamless cross-device support. Many wallets, notably apps using embedded wallets, have been requesting this feature for over a year.\n[Only relevant to Arbitrum Nova] Updated the transaction fee router contracts on Arbitrum Nova to allow for fees collected to be automatically sent to the ArbitrumDAO Treasury on Arbitrum One. Currently, the ArbitrumDAO receives Arbitrum Nova transaction fees that are sent to an ArbitrumDAO-controlled address that requires a constitutional proposal to move, which is less efficient. This change is specific to Arbitrum Nova and is not expected to impact Orbit chains.\nIntroduction of a new Fast Withdrawals feature for Orbit chains to achieve fast finality. This feature allows for transactions processed by a committee of validators to be unanimously confirmed as quickly as 15 minutes, as opposed to the default 6.4-day challenge period. While any Orbit chain can adopt Fast Withdrawals, we only recommend Fast Withdrawals for AnyTrust chains. Note that to enable this feature, separate steps must be followed (below).\nAdditional requirement for Arbitrum Orbit chains who wish to take advantage of the Stylus Cache Manager​\nSTYLUS CACHE MANAGER\n\nIt is strongly recommended that teams upgrading to ArbOS 32 also spend the time following the instructions described below to deploy and enable the Stylus Cache Manager. Even if your team does not intend to build with Stylus in the immediate term, enabling the Cache Manager ensures that future usage of Arbitrum Stylus on your chain is smooth and provides a consistent UX with the developer experience of building with Arbitrum Stylus on Arbitrum One.\n\nSpecific to Stylus and ArbOS 32 \"Bianca\", we have developed a caching strategy that stores frequently accessed contracts in memory to reduce the costs and time associated with contract execution from repeated initializations. Check out the Stylus caching strategy docs to learn more.\n\nIn order to take advantage of this caching strategy, an additional step is required to deploy and enable it's use on your Orbit chain.\n\nAfter you have upgraded your Orbit chain to ArbOS 32 \"Bianca\" (i.e. you have fully completed Step 3 in the \"How to upgrade ArbOS on your Orbit chain\" guide for your Orbit chain), please follow these additional instructions in the orbit-actions repository to deploy the cache manager contract on your chain.\n\nAdditional requirement for Arbitrum Orbit chains who wish to enable Fast Withdrawals​\n\nAfter you have upgraded your Orbit chain to ArbOS 32 \"Bianca\" (i.e. you have fully completed Step 3 in the \"How to upgrade ArbOS on your Orbit chain\" guide for your Orbit chain), please follow these additional instructions in the orbit-actions repository to deploy the Safe contract for the fast confirmation committee and set the Safe contract to be both the validator and fast confirmer on your rollup, note that Fast Withdrawals is disabled by default unless explicitly set up and enabled by the Orbit chain owner/maintainer.\n\nReference links for ArbOS 32 Bianca​\nNitro v3.2.1 release notes\nArbOS 32 \"Bianca\" on-chain Tally vote\nAIP: Activate Stylus and Enable Next-Gen WebAssembly Smart Contracts (ArbOS 32)\nAIP: Support RIP-7212 for Account Abstraction Wallets (ArbOS 32)\nAIP: Nova Fee Router Proposal (ArbOS 32)\nArbitrum Stylus Audit Report by Trail of Bits\nEdit this page\nLast updated on Nov 20, 2024\nPrevious\nOverview\nNext\nArbOS 20 Atlas\nRequirements:\nHigh-level description of ArbOS 32 changes\nAdditional requirement for Arbitrum Orbit chains who wish to take advantage of the Stylus Cache Manager\nAdditional requirement for Arbitrum Orbit chains who wish to enable Fast Withdrawals\nReference links for ArbOS 32 Bianca\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/assetBridger/erc20Bridger",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nAssetBridger\nErc20Bridger\nEthBridger\nL1l3Bridger\nDataEntities\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nerc20Bridger\nClasses​\nAdminErc20Bridger​\n\nAdmin functionality for the token bridge\n\nExtends​\nErc20Bridger\nConstructors​\nnew AdminErc20Bridger()​\nnew AdminErc20Bridger(childNetwork: ArbitrumNetwork): AdminErc20Bridger\n\n\nBridger for moving ERC20 tokens back and forth between parent-to-child\n\nParameters​\nParameter\tType\nchildNetwork\tArbitrumNetwork\nReturns​\n\nAdminErc20Bridger\n\nInherited from​\n\nErc20Bridger . constructor\n\nSource​\n\nassetBridger/erc20Bridger.ts:201\n\nProperties​\nProperty\tModifier\tType\tDescription\tInherited from\nnativeToken?\treadonly\tstring\tIn case of a chain that uses ETH as its native/gas token, this is either undefined or the zero address\n\nIn case of a chain that uses an ERC-20 token from the parent network as its native/gas token, this is the address of said token on the parent network\tErc20Bridger.nativeToken\nAccessors​\nnativeTokenIsEth​\nget protected nativeTokenIsEth(): boolean\n\n\nWhether the chain uses ETH as its native/gas token\n\nReturns​\n\nboolean\n\nSource​\n\nassetBridger/assetBridger.ts:71\n\nMethods​\napproveGasToken()​\napproveGasToken(params: ApproveParamsOrTxRequest): Promise<ContractTransaction>\n\n\nApproves the custom gas token to be spent by the relevant gateway on the parent network\n\nParameters​\nParameter\tType\tDescription\nparams\tApproveParamsOrTxRequest\t\nReturns​\n\nPromise<ContractTransaction>\n\nInherited from​\n\nErc20Bridger . approveGasToken\n\nSource​\n\nassetBridger/erc20Bridger.ts:272\n\napproveToken()​\napproveToken(params: ApproveParamsOrTxRequest): Promise<ContractTransaction>\n\n\nApprove tokens for deposit to the bridge. The tokens will be approved for the relevant gateway.\n\nParameters​\nParameter\tType\tDescription\nparams\tApproveParamsOrTxRequest\t\nReturns​\n\nPromise<ContractTransaction>\n\nInherited from​\n\nErc20Bridger . approveToken\n\nSource​\n\nassetBridger/erc20Bridger.ts:335\n\ncheckChildNetwork()​\nprotected checkChildNetwork(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the child network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nInherited from​\n\nErc20Bridger . checkChildNetwork\n\nSource​\n\nassetBridger/assetBridger.ts:60\n\ncheckParentNetwork()​\nprotected checkParentNetwork(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the parent network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nInherited from​\n\nErc20Bridger . checkParentNetwork\n\nSource​\n\nassetBridger/assetBridger.ts:49\n\ndeposit()​\ndeposit(params: Erc20DepositParams | ParentToChildTxReqAndSignerProvider): Promise<ParentContractCallTransaction>\n\n\nExecute a token deposit from parent to child network\n\nParameters​\nParameter\tType\tDescription\nparams\tErc20DepositParams | ParentToChildTxReqAndSignerProvider\t\nReturns​\n\nPromise<ParentContractCallTransaction>\n\nInherited from​\n\nErc20Bridger . deposit\n\nSource​\n\nassetBridger/erc20Bridger.ts:754\n\ngetApproveGasTokenRequest()​\ngetApproveGasTokenRequest(params: ProviderTokenApproveParams): Promise<Required<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>>\n\n\nCreates a transaction request for approving the custom gas token to be spent by the relevant gateway on the parent network\n\nParameters​\nParameter\tType\tDescription\nparams\tProviderTokenApproveParams\t\nReturns​\n\nPromise<Required<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>>\n\nInherited from​\n\nErc20Bridger . getApproveGasTokenRequest\n\nSource​\n\nassetBridger/erc20Bridger.ts:256\n\ngetApproveTokenRequest()​\ngetApproveTokenRequest(params: ProviderTokenApproveParams): Promise<Required<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>>\n\n\nGet a tx request to approve tokens for deposit to the bridge. The tokens will be approved for the relevant gateway.\n\nParameters​\nParameter\tType\tDescription\nparams\tProviderTokenApproveParams\t\nReturns​\n\nPromise<Required<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>>\n\nInherited from​\n\nErc20Bridger . getApproveTokenRequest\n\nSource​\n\nassetBridger/erc20Bridger.ts:302\n\ngetChildErc20Address()​\ngetChildErc20Address(erc20ParentAddress: string, parentProvider: Provider): Promise<string>\n\n\nGet the corresponding child network token address for the provided parent network token\n\nParameters​\nParameter\tType\tDescription\nerc20ParentAddress\tstring\t\nparentProvider\tProvider\t\nReturns​\n\nPromise<string>\n\nInherited from​\n\nErc20Bridger . getChildErc20Address\n\nSource​\n\nassetBridger/erc20Bridger.ts:487\n\ngetChildGatewayAddress()​\ngetChildGatewayAddress(erc20ParentAddress: string, childProvider: Provider): Promise<string>\n\n\nGet the address of the child gateway for this token\n\nParameters​\nParameter\tType\tDescription\nerc20ParentAddress\tstring\t\nchildProvider\tProvider\t\nReturns​\n\nPromise<string>\n\nInherited from​\n\nErc20Bridger . getChildGatewayAddress\n\nSource​\n\nassetBridger/erc20Bridger.ts:240\n\ngetChildGatewaySetEvents()​\ngetChildGatewaySetEvents(\n   childProvider: Provider, \n   filter: object, \ncustomNetworkL2GatewayRouter?: string): Promise<object[]>\n\n\nGet all the gateway set events on the L2 gateway router\n\nParameters​\nParameter\tType\nchildProvider\tProvider\nfilter\tobject\nfilter.fromBlock\tBlockTag\nfilter.toBlock?\tBlockTag\ncustomNetworkL2GatewayRouter?\tstring\nReturns​\n\nPromise<object[]>\n\nSource​\n\nassetBridger/erc20Bridger.ts:1201\n\ngetChildTokenContract()​\ngetChildTokenContract(childProvider: Provider, childTokenAddr: string): L2GatewayToken\n\n\nGet the child network token contract at the provided address Note: This function just returns a typed ethers object for the provided address, it doesn't check the underlying form of the contract bytecode to see if it's an erc20, and doesn't ensure the validity of any of the underlying functions on that contract.\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nchildTokenAddr\tstring\t\nReturns​\n\nL2GatewayToken\n\nInherited from​\n\nErc20Bridger . getChildTokenContract\n\nSource​\n\nassetBridger/erc20Bridger.ts:458\n\ngetDepositRequest()​\ngetDepositRequest(params: DepositRequest): Promise<ParentToChildTransactionRequest>\n\n\nGet the arguments for calling the deposit function\n\nParameters​\nParameter\tType\tDescription\nparams\tDepositRequest\t\nReturns​\n\nPromise <ParentToChildTransactionRequest>\n\nInherited from​\n\nErc20Bridger . getDepositRequest\n\nSource​\n\nassetBridger/erc20Bridger.ts:647\n\ngetParentErc20Address()​\ngetParentErc20Address(erc20ChildChainAddress: string, childProvider: Provider): Promise<string>\n\n\nGet the corresponding parent network address for the provided child network token Validates the returned address against the child network router to ensure it is correctly mapped to the provided erc20ChildChainAddress\n\nParameters​\nParameter\tType\tDescription\nerc20ChildChainAddress\tstring\t\nchildProvider\tProvider\t\nReturns​\n\nPromise<string>\n\nInherited from​\n\nErc20Bridger . getParentErc20Address\n\nSource​\n\nassetBridger/erc20Bridger.ts:510\n\ngetParentGatewayAddress()​\ngetParentGatewayAddress(erc20ParentAddress: string, parentProvider: Provider): Promise<string>\n\n\nGet the address of the parent gateway for this token\n\nParameters​\nParameter\tType\tDescription\nerc20ParentAddress\tstring\t\nparentProvider\tProvider\t\nReturns​\n\nPromise<string>\n\nInherited from​\n\nErc20Bridger . getParentGatewayAddress\n\nSource​\n\nassetBridger/erc20Bridger.ts:222\n\ngetParentGatewaySetEvents()​\ngetParentGatewaySetEvents(parentProvider: Provider, filter: object): Promise<object[]>\n\n\nGet all the gateway set events on the Parent gateway router\n\nParameters​\nParameter\tType\tDescription\nparentProvider\tProvider\t\nfilter\tobject\t-\nfilter.fromBlock\tBlockTag\t-\nfilter.toBlock\tBlockTag\t-\nReturns​\n\nPromise<object[]>\n\nSource​\n\nassetBridger/erc20Bridger.ts:1177\n\ngetParentTokenContract()​\ngetParentTokenContract(parentProvider: Provider, parentTokenAddr: string): ERC20\n\n\nGet the parent token contract at the provided address Note: This function just returns a typed ethers object for the provided address, it doesnt check the underlying form of the contract bytecode to see if it's an erc20, and doesn't ensure the validity of any of the underlying functions on that contract.\n\nParameters​\nParameter\tType\tDescription\nparentProvider\tProvider\t\nparentTokenAddr\tstring\t\nReturns​\n\nERC20\n\nInherited from​\n\nErc20Bridger . getParentTokenContract\n\nSource​\n\nassetBridger/erc20Bridger.ts:474\n\ngetWithdrawalEvents()​\ngetWithdrawalEvents(\n   childProvider: Provider, \n   gatewayAddress: string, \n   filter: object, \n   parentTokenAddress?: string, \n   fromAddress?: string, \ntoAddress?: string): Promise<object & object[]>\n\n\nGet the child network events created by a withdrawal\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\ngatewayAddress\tstring\t\nfilter\tobject\t\nfilter.fromBlock\tBlockTag\t-\nfilter.toBlock?\tBlockTag\t-\nparentTokenAddress?\tstring\t\nfromAddress?\tstring\t\ntoAddress?\tstring\t-\nReturns​\n\nPromise<object & object[]>\n\nInherited from​\n\nErc20Bridger . getWithdrawalEvents\n\nSource​\n\nassetBridger/erc20Bridger.ts:363\n\ngetWithdrawalRequest()​\ngetWithdrawalRequest(params: Erc20WithdrawParams): Promise<ChildToParentTransactionRequest>\n\n\nGet the arguments for calling the token withdrawal function\n\nParameters​\nParameter\tType\tDescription\nparams\tErc20WithdrawParams\t\nReturns​\n\nPromise <ChildToParentTransactionRequest>\n\nInherited from​\n\nErc20Bridger . getWithdrawalRequest\n\nSource​\n\nassetBridger/erc20Bridger.ts:811\n\nisDepositDisabled()​\nisDepositDisabled(parentTokenAddress: string, parentProvider: Provider): Promise<boolean>\n\n\nWhether the token has been disabled on the router\n\nParameters​\nParameter\tType\tDescription\nparentTokenAddress\tstring\t\nparentProvider\tProvider\t\nReturns​\n\nPromise<boolean>\n\nInherited from​\n\nErc20Bridger . isDepositDisabled\n\nSource​\n\nassetBridger/erc20Bridger.ts:556\n\nisRegistered()​\nisRegistered(__namedParameters: object): Promise<boolean>\n\n\nChecks if the token has been properly registered on both gateways. Mostly useful for tokens that use a custom gateway.\n\nParameters​\nParameter\tType\n__namedParameters\tobject\n__namedParameters.childProvider\tProvider\n__namedParameters.erc20ParentAddress\tstring\n__namedParameters.parentProvider\tProvider\nReturns​\n\nPromise<boolean>\n\nInherited from​\n\nErc20Bridger . isRegistered\n\nSource​\n\nassetBridger/erc20Bridger.ts:907\n\nregisterCustomToken()​\nregisterCustomToken(\n   parentTokenAddress: string, \n   childTokenAddress: string, \n   parentSigner: Signer, \nchildProvider: Provider): Promise<ParentContractTransaction<ParentTransactionReceipt>>\n\n\nRegister a custom token on the Arbitrum bridge See https://developer.offchainlabs.com/docs/bridging_assets#the-arbitrum-generic-custom-gateway for more details\n\nParameters​\nParameter\tType\tDescription\nparentTokenAddress\tstring\tAddress of the already deployed parent token. Must inherit from https://developer.offchainlabs.com/docs/sol_contract_docs/md_docs/arb-bridge-peripherals/tokenbridge/ethereum/icustomtoken.\nchildTokenAddress\tstring\tAddress of the already deployed child token. Must inherit from https://developer.offchainlabs.com/docs/sol_contract_docs/md_docs/arb-bridge-peripherals/tokenbridge/arbitrum/iarbtoken.\nparentSigner\tSigner\tThe signer with the rights to call registerTokenOnL2 on the parent token\nchildProvider\tProvider\tArbitrum rpc provider\nReturns​\n\nPromise<ParentContractTransaction<ParentTransactionReceipt>>\n\nSource​\n\nassetBridger/erc20Bridger.ts:1018\n\nsetGateways()​\nsetGateways(\n   parentSigner: Signer, \n   childProvider: Provider, \n   tokenGateways: TokenAndGateway[], \noptions?: GasOverrides): Promise<ParentContractCallTransaction>\n\n\nRegister the provided token addresses against the provided gateways\n\nParameters​\nParameter\tType\tDescription\nparentSigner\tSigner\t\nchildProvider\tProvider\t\ntokenGateways\tTokenAndGateway[]\t\noptions?\tGasOverrides\t-\nReturns​\n\nPromise<ParentContractCallTransaction>\n\nSource​\n\nassetBridger/erc20Bridger.ts:1234\n\nwithdraw()​\nwithdraw(params: ChildToParentTxReqAndSigner | OmitTyped<Erc20WithdrawParams, \"from\"> & object): Promise<ChildContractTransaction>\n\n\nWithdraw tokens from child to parent network\n\nParameters​\nParameter\tType\tDescription\nparams\tChildToParentTxReqAndSigner | OmitTyped<Erc20WithdrawParams, \"from\"> & object\t\nReturns​\n\nPromise<ChildContractTransaction>\n\nInherited from​\n\nErc20Bridger . withdraw\n\nSource​\n\nassetBridger/erc20Bridger.ts:874\n\nfromProvider()​\nstatic fromProvider(childProvider: Provider): Promise<Erc20Bridger>\n\n\nInstantiates a new Erc20Bridger from a child provider\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nReturns​\n\nPromise <Erc20Bridger>\n\nInherited from​\n\nErc20Bridger . fromProvider\n\nSource​\n\nassetBridger/erc20Bridger.ts:212\n\nErc20Bridger​\n\nBridger for moving ERC20 tokens back and forth between parent-to-child\n\nExtends​\nAssetBridger<Erc20DepositParams | ParentToChildTxReqAndSignerProvider, OmitTyped<Erc20WithdrawParams, \"from\"> | ChildToParentTransactionRequest>\nExtended by​\nAdminErc20Bridger\nConstructors​\nnew Erc20Bridger()​\nnew Erc20Bridger(childNetwork: ArbitrumNetwork): Erc20Bridger\n\n\nBridger for moving ERC20 tokens back and forth between parent-to-child\n\nParameters​\nParameter\tType\nchildNetwork\tArbitrumNetwork\nReturns​\n\nErc20Bridger\n\nOverrides​\n\nAssetBridger< Erc20DepositParams | ParentToChildTxReqAndSignerProvider, OmitTyped<Erc20WithdrawParams, 'from'> | ChildToParentTransactionRequest >.constructor\n\nSource​\n\nassetBridger/erc20Bridger.ts:201\n\nProperties​\nProperty\tModifier\tType\tDescription\tInherited from\nnativeToken?\treadonly\tstring\tIn case of a chain that uses ETH as its native/gas token, this is either undefined or the zero address\n\nIn case of a chain that uses an ERC-20 token from the parent network as its native/gas token, this is the address of said token on the parent network\tAssetBridger.nativeToken\nAccessors​\nnativeTokenIsEth​\nget protected nativeTokenIsEth(): boolean\n\n\nWhether the chain uses ETH as its native/gas token\n\nReturns​\n\nboolean\n\nSource​\n\nassetBridger/assetBridger.ts:71\n\nMethods​\napproveGasToken()​\napproveGasToken(params: ApproveParamsOrTxRequest): Promise<ContractTransaction>\n\n\nApproves the custom gas token to be spent by the relevant gateway on the parent network\n\nParameters​\nParameter\tType\tDescription\nparams\tApproveParamsOrTxRequest\t\nReturns​\n\nPromise<ContractTransaction>\n\nSource​\n\nassetBridger/erc20Bridger.ts:272\n\napproveToken()​\napproveToken(params: ApproveParamsOrTxRequest): Promise<ContractTransaction>\n\n\nApprove tokens for deposit to the bridge. The tokens will be approved for the relevant gateway.\n\nParameters​\nParameter\tType\tDescription\nparams\tApproveParamsOrTxRequest\t\nReturns​\n\nPromise<ContractTransaction>\n\nSource​\n\nassetBridger/erc20Bridger.ts:335\n\ncheckChildNetwork()​\nprotected checkChildNetwork(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the child network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nInherited from​\n\nAssetBridger . checkChildNetwork\n\nSource​\n\nassetBridger/assetBridger.ts:60\n\ncheckParentNetwork()​\nprotected checkParentNetwork(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the parent network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nInherited from​\n\nAssetBridger . checkParentNetwork\n\nSource​\n\nassetBridger/assetBridger.ts:49\n\ndeposit()​\ndeposit(params: Erc20DepositParams | ParentToChildTxReqAndSignerProvider): Promise<ParentContractCallTransaction>\n\n\nExecute a token deposit from parent to child network\n\nParameters​\nParameter\tType\tDescription\nparams\tErc20DepositParams | ParentToChildTxReqAndSignerProvider\t\nReturns​\n\nPromise<ParentContractCallTransaction>\n\nOverrides​\n\nAssetBridger . deposit\n\nSource​\n\nassetBridger/erc20Bridger.ts:754\n\ngetApproveGasTokenRequest()​\ngetApproveGasTokenRequest(params: ProviderTokenApproveParams): Promise<Required<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>>\n\n\nCreates a transaction request for approving the custom gas token to be spent by the relevant gateway on the parent network\n\nParameters​\nParameter\tType\tDescription\nparams\tProviderTokenApproveParams\t\nReturns​\n\nPromise<Required<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>>\n\nSource​\n\nassetBridger/erc20Bridger.ts:256\n\ngetApproveTokenRequest()​\ngetApproveTokenRequest(params: ProviderTokenApproveParams): Promise<Required<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>>\n\n\nGet a tx request to approve tokens for deposit to the bridge. The tokens will be approved for the relevant gateway.\n\nParameters​\nParameter\tType\tDescription\nparams\tProviderTokenApproveParams\t\nReturns​\n\nPromise<Required<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>>\n\nSource​\n\nassetBridger/erc20Bridger.ts:302\n\ngetChildErc20Address()​\ngetChildErc20Address(erc20ParentAddress: string, parentProvider: Provider): Promise<string>\n\n\nGet the corresponding child network token address for the provided parent network token\n\nParameters​\nParameter\tType\tDescription\nerc20ParentAddress\tstring\t\nparentProvider\tProvider\t\nReturns​\n\nPromise<string>\n\nSource​\n\nassetBridger/erc20Bridger.ts:487\n\ngetChildGatewayAddress()​\ngetChildGatewayAddress(erc20ParentAddress: string, childProvider: Provider): Promise<string>\n\n\nGet the address of the child gateway for this token\n\nParameters​\nParameter\tType\tDescription\nerc20ParentAddress\tstring\t\nchildProvider\tProvider\t\nReturns​\n\nPromise<string>\n\nSource​\n\nassetBridger/erc20Bridger.ts:240\n\ngetChildTokenContract()​\ngetChildTokenContract(childProvider: Provider, childTokenAddr: string): L2GatewayToken\n\n\nGet the child network token contract at the provided address Note: This function just returns a typed ethers object for the provided address, it doesn't check the underlying form of the contract bytecode to see if it's an erc20, and doesn't ensure the validity of any of the underlying functions on that contract.\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nchildTokenAddr\tstring\t\nReturns​\n\nL2GatewayToken\n\nSource​\n\nassetBridger/erc20Bridger.ts:458\n\ngetDepositRequest()​\ngetDepositRequest(params: DepositRequest): Promise<ParentToChildTransactionRequest>\n\n\nGet the arguments for calling the deposit function\n\nParameters​\nParameter\tType\tDescription\nparams\tDepositRequest\t\nReturns​\n\nPromise <ParentToChildTransactionRequest>\n\nSource​\n\nassetBridger/erc20Bridger.ts:647\n\ngetDepositRequestCallValue()​\nprivate getDepositRequestCallValue(depositParams: OmitTyped<ParentToChildMessageGasParams, \"deposit\">): BigNumber | BigNumber\n\n\nGet the call value for the deposit transaction request\n\nParameters​\nParameter\tType\tDescription\ndepositParams\tOmitTyped<ParentToChildMessageGasParams, \"deposit\">\t\nReturns​\n\nBigNumber | BigNumber\n\nSource​\n\nassetBridger/erc20Bridger.ts:589\n\ngetDepositRequestOutboundTransferInnerData()​\nprivate getDepositRequestOutboundTransferInnerData(depositParams: OmitTyped<ParentToChildMessageGasParams, \"deposit\">): string\n\n\nGet the data param for call to outboundTransfer\n\nParameters​\nParameter\tType\tDescription\ndepositParams\tOmitTyped<ParentToChildMessageGasParams, \"deposit\">\t\nReturns​\n\nstring\n\nSource​\n\nassetBridger/erc20Bridger.ts:612\n\ngetParentErc20Address()​\ngetParentErc20Address(erc20ChildChainAddress: string, childProvider: Provider): Promise<string>\n\n\nGet the corresponding parent network address for the provided child network token Validates the returned address against the child network router to ensure it is correctly mapped to the provided erc20ChildChainAddress\n\nParameters​\nParameter\tType\tDescription\nerc20ChildChainAddress\tstring\t\nchildProvider\tProvider\t\nReturns​\n\nPromise<string>\n\nSource​\n\nassetBridger/erc20Bridger.ts:510\n\ngetParentGatewayAddress()​\ngetParentGatewayAddress(erc20ParentAddress: string, parentProvider: Provider): Promise<string>\n\n\nGet the address of the parent gateway for this token\n\nParameters​\nParameter\tType\tDescription\nerc20ParentAddress\tstring\t\nparentProvider\tProvider\t\nReturns​\n\nPromise<string>\n\nSource​\n\nassetBridger/erc20Bridger.ts:222\n\ngetParentTokenContract()​\ngetParentTokenContract(parentProvider: Provider, parentTokenAddr: string): ERC20\n\n\nGet the parent token contract at the provided address Note: This function just returns a typed ethers object for the provided address, it doesnt check the underlying form of the contract bytecode to see if it's an erc20, and doesn't ensure the validity of any of the underlying functions on that contract.\n\nParameters​\nParameter\tType\tDescription\nparentProvider\tProvider\t\nparentTokenAddr\tstring\t\nReturns​\n\nERC20\n\nSource​\n\nassetBridger/erc20Bridger.ts:474\n\ngetWithdrawalEvents()​\ngetWithdrawalEvents(\n   childProvider: Provider, \n   gatewayAddress: string, \n   filter: object, \n   parentTokenAddress?: string, \n   fromAddress?: string, \ntoAddress?: string): Promise<object & object[]>\n\n\nGet the child network events created by a withdrawal\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\ngatewayAddress\tstring\t\nfilter\tobject\t\nfilter.fromBlock\tBlockTag\t-\nfilter.toBlock?\tBlockTag\t-\nparentTokenAddress?\tstring\t\nfromAddress?\tstring\t\ntoAddress?\tstring\t-\nReturns​\n\nPromise<object & object[]>\n\nSource​\n\nassetBridger/erc20Bridger.ts:363\n\ngetWithdrawalRequest()​\ngetWithdrawalRequest(params: Erc20WithdrawParams): Promise<ChildToParentTransactionRequest>\n\n\nGet the arguments for calling the token withdrawal function\n\nParameters​\nParameter\tType\tDescription\nparams\tErc20WithdrawParams\t\nReturns​\n\nPromise <ChildToParentTransactionRequest>\n\nSource​\n\nassetBridger/erc20Bridger.ts:811\n\nisDepositDisabled()​\nisDepositDisabled(parentTokenAddress: string, parentProvider: Provider): Promise<boolean>\n\n\nWhether the token has been disabled on the router\n\nParameters​\nParameter\tType\tDescription\nparentTokenAddress\tstring\t\nparentProvider\tProvider\t\nReturns​\n\nPromise<boolean>\n\nSource​\n\nassetBridger/erc20Bridger.ts:556\n\nisRegistered()​\nisRegistered(__namedParameters: object): Promise<boolean>\n\n\nChecks if the token has been properly registered on both gateways. Mostly useful for tokens that use a custom gateway.\n\nParameters​\nParameter\tType\n__namedParameters\tobject\n__namedParameters.childProvider\tProvider\n__namedParameters.erc20ParentAddress\tstring\n__namedParameters.parentProvider\tProvider\nReturns​\n\nPromise<boolean>\n\nSource​\n\nassetBridger/erc20Bridger.ts:907\n\nisWethGateway()​\nprivate isWethGateway(gatewayAddress: string, parentProvider: Provider): Promise<boolean>\n\n\nIs this a known or unknown WETH gateway\n\nParameters​\nParameter\tType\tDescription\ngatewayAddress\tstring\t\nparentProvider\tProvider\t\nReturns​\n\nPromise<boolean>\n\nSource​\n\nassetBridger/erc20Bridger.ts:432\n\nlooksLikeWethGateway()​\nprivate looksLikeWethGateway(potentialWethGatewayAddress: string, parentProvider: Provider): Promise<boolean>\n\n\nDoes the provided address look like a weth gateway\n\nParameters​\nParameter\tType\tDescription\npotentialWethGatewayAddress\tstring\t\nparentProvider\tProvider\t\nReturns​\n\nPromise<boolean>\n\nSource​\n\nassetBridger/erc20Bridger.ts:402\n\nwithdraw()​\nwithdraw(params: ChildToParentTxReqAndSigner | OmitTyped<Erc20WithdrawParams, \"from\"> & object): Promise<ChildContractTransaction>\n\n\nWithdraw tokens from child to parent network\n\nParameters​\nParameter\tType\tDescription\nparams\tChildToParentTxReqAndSigner | OmitTyped<Erc20WithdrawParams, \"from\"> & object\t\nReturns​\n\nPromise<ChildContractTransaction>\n\nOverrides​\n\nAssetBridger . withdraw\n\nSource​\n\nassetBridger/erc20Bridger.ts:874\n\nfromProvider()​\nstatic fromProvider(childProvider: Provider): Promise<Erc20Bridger>\n\n\nInstantiates a new Erc20Bridger from a child provider\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nReturns​\n\nPromise <Erc20Bridger>\n\nSource​\n\nassetBridger/erc20Bridger.ts:212\n\nEdit this page\nPrevious\nAssetBridger\nNext\nEthBridger\nClasses\nAdminErc20Bridger\nExtends\nConstructors\nnew AdminErc20Bridger()\nProperties\nAccessors\nnativeTokenIsEth\nMethods\napproveGasToken()\napproveToken()\ncheckChildNetwork()\ncheckParentNetwork()\ndeposit()\ngetApproveGasTokenRequest()\ngetApproveTokenRequest()\ngetChildErc20Address()\ngetChildGatewayAddress()\ngetChildGatewaySetEvents()\ngetChildTokenContract()\ngetDepositRequest()\ngetParentErc20Address()\ngetParentGatewayAddress()\ngetParentGatewaySetEvents()\ngetParentTokenContract()\ngetWithdrawalEvents()\ngetWithdrawalRequest()\nisDepositDisabled()\nisRegistered()\nregisterCustomToken()\nsetGateways()\nwithdraw()\nfromProvider()\nErc20Bridger\nExtends\nExtended by\nConstructors\nnew Erc20Bridger()\nProperties\nAccessors\nnativeTokenIsEth\nMethods\napproveGasToken()\napproveToken()\ncheckChildNetwork()\ncheckParentNetwork()\ndeposit()\ngetApproveGasTokenRequest()\ngetApproveTokenRequest()\ngetChildErc20Address()\ngetChildGatewayAddress()\ngetChildTokenContract()\ngetDepositRequest()\ngetDepositRequestCallValue()\ngetDepositRequestOutboundTransferInnerData()\ngetParentErc20Address()\ngetParentGatewayAddress()\ngetParentTokenContract()\ngetWithdrawalEvents()\ngetWithdrawalRequest()\nisDepositDisabled()\nisRegistered()\nisWethGateway()\nlooksLikeWethGateway()\nwithdraw()\nfromProvider()\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/message/ParentToChildMessage",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nChildToParentMessage\nChildToParentMessageClassic\nChildToParentMessageNitro\nChildTransaction\nParentToChildMessage\nParentToChildMessageCreator\nParentToChildMessageGasEstimator\nParentTransaction\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nParentToChildMessage\nClasses​\nEthDepositMessage​\n\nA message for Eth deposits from Parent to Child\n\nConstructors​\nnew EthDepositMessage()​\nnew EthDepositMessage(\n   childProvider: Provider, \n   childChainId: number, \n   messageNumber: BigNumber, \n   from: string, \n   to: string, \n   value: BigNumber): EthDepositMessage\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nchildChainId\tnumber\t\nmessageNumber\tBigNumber\t\nfrom\tstring\t-\nto\tstring\tRecipient address of the ETH on Chain\nvalue\tBigNumber\t\nReturns​\n\nEthDepositMessage\n\nSource​\n\nmessage/ParentToChildMessage.ts:852\n\nProperties​\nProperty\tModifier\tType\tDescription\nchildChainId\treadonly\tnumber\t-\nchildProvider\tprivate\tProvider\t-\nmessageNumber\treadonly\tBigNumber\t-\nto\treadonly\tstring\tRecipient address of the ETH on Chain\nvalue\treadonly\tBigNumber\t-\nMethods​\nfromEventComponents()​\nstatic fromEventComponents(\n   childProvider: Provider, \n   messageNumber: BigNumber, \n   senderAddr: string, \ninboxMessageEventData: string): Promise<EthDepositMessage>\n\n\nCreate an EthDepositMessage from data emitted in event when calling ethDeposit on Inbox.sol\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nmessageNumber\tBigNumber\tThe message number in the Inbox.InboxMessageDelivered event\nsenderAddr\tstring\tThe sender address from Bridge.MessageDelivered event\ninboxMessageEventData\tstring\tThe data field from the Inbox.InboxMessageDelivered event\nReturns​\n\nPromise <EthDepositMessage>\n\nSource​\n\nmessage/ParentToChildMessage.ts:823\n\nparseEthDepositData()​\nstatic private parseEthDepositData(eventData: string): object\n\n\nParse the data field in event InboxMessageDelivered(uint256 indexed messageNum, bytes data);\n\nParameters​\nParameter\tType\tDescription\neventData\tstring\t\nReturns​\n\nobject\n\ndestination and amount\n\nMember\tType\nto\tstring\nvalue\tBigNumber\nSource​\n\nmessage/ParentToChildMessage.ts:802\n\nType Aliases​\nParentToChildMessageReaderOrWriter<T>​\ntype ParentToChildMessageReaderOrWriter<T>: T extends Provider ? ParentToChildMessageReader : ParentToChildMessageWriter;\n\n\nConditional type for Signer or Provider. If T is of type Provider then ParentToChildMessageReaderOrWriter<T> will be of type ParentToChildMessageReader. If T is of type Signer then ParentToChildMessageReaderOrWriter<T> will be of type ParentToChildMessageWriter.\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nSource​\n\nmessage/ParentToChildMessage.ts:98\n\nParentToChildMessageWaitForStatusResult​\ntype ParentToChildMessageWaitForStatusResult: object | object;\n\n\nIf the status is redeemed, childTxReceipt is populated. For all other statuses childTxReceipt is not populated\n\nSource​\n\nmessage/ParentToChildMessage.ts:240\n\nEdit this page\nPrevious\nChildTransaction\nNext\nParentToChildMessageCreator\nClasses\nEthDepositMessage\nConstructors\nnew EthDepositMessage()\nProperties\nMethods\nfromEventComponents()\nparseEthDepositData()\nType Aliases\nParentToChildMessageReaderOrWriter<T>\nType parameters\nSource\nParentToChildMessageWaitForStatusResult\nSource\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "constants | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/dataEntities/constants",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nAddress\nConstants\nErrors\nEvent\nMessage\nNetworks\nRetryableData\nRpc\nSignerOrProvider\nTransactionRequest\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nconstants\nVariables​\nADDRESS_ALIAS_OFFSET​\nconst ADDRESS_ALIAS_OFFSET: \"0x1111000000000000000000000000000000001111\" = '0x1111000000000000000000000000000000001111';\n\n\nThe offset added to an L1 address to get the corresponding L2 address\n\nSource​\n\ndataEntities/constants.ts:41\n\nARB1_NITRO_GENESIS_L1_BLOCK​\nconst ARB1_NITRO_GENESIS_L1_BLOCK: 15447158 = 15447158;\n\n\nThe L1 block at which Nitro was activated for Arbitrum One.\n\nSee​\n\nhttps://etherscan.io/block/15447158\n\nSource​\n\ndataEntities/constants.ts:71\n\nARB1_NITRO_GENESIS_L2_BLOCK​\nconst ARB1_NITRO_GENESIS_L2_BLOCK: 22207817 = 22207817;\n\n\nThe L2 block at which Nitro was activated for Arbitrum One.\n\nSee​\n\nhttps://arbiscan.io/block/22207817\n\nSource​\n\ndataEntities/constants.ts:78\n\nCUSTOM_TOKEN_IS_ENABLED​\nconst CUSTOM_TOKEN_IS_ENABLED: 42161 = 42161;\n\n\nIf a custom token is enabled for arbitrum it will implement a function called isArbitrumEnabled which returns this value. Intger: 0xa4b1\n\nSource​\n\ndataEntities/constants.ts:52\n\nDEFAULT_DEPOSIT_TIMEOUT​\nconst DEFAULT_DEPOSIT_TIMEOUT: number;\n\n\nHow long to wait (in milliseconds) for a deposit to arrive before timing out a request.\n\nFinalisation on mainnet can be up to 2 epochs = 64 blocks. We add 10 minutes for the system to create and redeem the ticket, plus some extra buffer of time.\n\nTotal timeout: 30 minutes.\n\nSource​\n\ndataEntities/constants.ts:64\n\nDISABLED_GATEWAY​\nconst DISABLED_GATEWAY: \"0x0000000000000000000000000000000000000001\" = '0x0000000000000000000000000000000000000001';\n\n\nAddress of the gateway a token will be assigned to if it is disabled\n\nSource​\n\ndataEntities/constants.ts:46\n\nEdit this page\nPrevious\nAddress\nNext\nErrors\nVariables\nADDRESS_ALIAS_OFFSET\nSource\nARB1_NITRO_GENESIS_L1_BLOCK\nSee\nSource\nARB1_NITRO_GENESIS_L2_BLOCK\nSee\nSource\nCUSTOM_TOKEN_IS_ENABLED\nSource\nDEFAULT_DEPOSIT_TIMEOUT\nSource\nDISABLED_GATEWAY\nSource\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "networks | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/dataEntities/networks",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nAddress\nConstants\nErrors\nEvent\nMessage\nNetworks\nRetryableData\nRpc\nSignerOrProvider\nTransactionRequest\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nnetworks\nInterfaces​\nArbitrumNetwork​\n\nRepresents an Arbitrum chain, e.g. Arbitrum One, Arbitrum Sepolia, or an L3 chain.\n\nProperties​\nProperty\tType\tDescription\nchainId\tnumber\tId of the chain.\nconfirmPeriodBlocks\tnumber\tThe time allowed for validators to dispute or challenge state assertions. Measured in L1 blocks.\nethBridge\tEthBridge\tThe core contracts\nisBold?\tboolean\tHas the network been upgraded to bold. True if yes, otherwise undefined\nThis is a temporary property and will be removed in future if Bold is widely adopted and\nthe legacy challenge protocol is deprecated\nisCustom\tboolean\tWhether or not the chain was registered by the user.\nname\tstring\tName of the chain.\nnativeToken?\tstring\tIn case of a chain that uses ETH as its native/gas token, this is either undefined or the zero address\n\nIn case of a chain that uses an ERC-20 token from the parent chain as its native/gas token, this is the address of said token on the parent chain\nparentChainId\tnumber\tChain id of the parent chain, i.e. the chain on which this chain settles to.\nretryableLifetimeSeconds?\tnumber\tRepresents how long a retryable ticket lasts for before it expires (in seconds). Defaults to 7 days.\nteleporter?\tTeleporter\tThe teleporter contracts.\ntokenBridge?\tTokenBridge\tThe token bridge contracts.\nL2NetworkTokenBridge​\n\nThis type is only here for when you want to achieve backwards compatibility between SDK v3 and v4.\n\nPlease see TokenBridge for the latest type.\n\nDeprecated​\n\nsince v4\n\nType Aliases​\nL2Network​\ntype L2Network: Prettify<Omit<ArbitrumNetwork, \"chainId\" | \"parentChainId\" | \"tokenBridge\"> & object>;\n\n\nThis type is only here for when you want to achieve backwards compatibility between SDK v3 and v4.\n\nPlease see ArbitrumNetwork for the latest type.\n\nDeprecated​\n\nsince v4\n\nSource​\n\ndataEntities/networks.ts:88\n\nFunctions​\nassertArbitrumNetworkHasTokenBridge()​\nfunction assertArbitrumNetworkHasTokenBridge<T>(network: T): asserts network is T & Object\n\n\nAsserts that the given object has a token bridge. This is useful because not all Arbitrum network operations require a token bridge.\n\nType parameters​\nType parameter\nT extends ArbitrumNetwork\nParameters​\nParameter\tType\tDescription\nnetwork\tT\tArbitrumNetwork object\nReturns​\n\nasserts network is T & Object\n\nThrows​\n\nArbSdkError if the object does not have a token bridge\n\nSource​\n\ndataEntities/networks.ts:533\n\ngetArbitrumNetwork()​\nfunction getArbitrumNetwork(chainId: number): ArbitrumNetwork\n\n\nReturns the Arbitrum chain associated with the given signer, provider or chain id.\n\nParameters​\nParameter\tType\nchainId\tnumber\nReturns​\n\nArbitrumNetwork\n\nNote​\n\nThrows if the chain is not an Arbitrum chain.\n\nSource​\n\ndataEntities/networks.ts:307\n\ngetArbitrumNetworkInformationFromRollup()​\nfunction getArbitrumNetworkInformationFromRollup(rollupAddress: string, parentProvider: Provider): Promise<ArbitrumNetworkInformationFromRollup>\n\n\nReturns all the information about an Arbitrum network that can be fetched from its Rollup contract.\n\nParameters​\nParameter\tType\tDescription\nrollupAddress\tstring\tAddress of the Rollup contract on the parent chain\nparentProvider\tProvider\tProvider for the parent chain\nReturns​\n\nPromise<ArbitrumNetworkInformationFromRollup>\n\nAn ArbitrumNetworkInformationFromRollup object\n\nSource​\n\ndataEntities/networks.ts:356\n\ngetArbitrumNetworks()​\nfunction getArbitrumNetworks(): ArbitrumNetwork[]\n\n\nReturns all Arbitrum networks registered in the SDK, both default and custom.\n\nReturns​\n\nArbitrumNetwork[]\n\nSource​\n\ndataEntities/networks.ts:339\n\ngetChildrenForNetwork()​\nfunction getChildrenForNetwork(parentChainOrChainId: number | ArbitrumNetwork): ArbitrumNetwork[]\n\n\nReturns a list of children chains for the given chain or chain id.\n\nParameters​\nParameter\tType\nparentChainOrChainId\tnumber | ArbitrumNetwork\nReturns​\n\nArbitrumNetwork[]\n\nSource​\n\ndataEntities/networks.ts:289\n\nisParentNetwork()​\nfunction isParentNetwork(parentChainOrChainId: number | ArbitrumNetwork): boolean\n\n\nDetermines if a chain is a parent of any other chain. Could be an L1 or an L2 chain.\n\nParameters​\nParameter\tType\nparentChainOrChainId\tnumber | ArbitrumNetwork\nReturns​\n\nboolean\n\nSource​\n\ndataEntities/networks.ts:274\n\nmapL2NetworkToArbitrumNetwork()​\nfunction mapL2NetworkToArbitrumNetwork(l2Network: object): ArbitrumNetwork\n\n\nMaps the old L2Network (from SDK v3) to ArbitrumNetwork (from SDK v4).\n\nParameters​\nParameter\tType\tDescription\nl2Network\tobject\t-\nl2Network.chainID\tnumber\t-\nl2Network.confirmPeriodBlocks\tnumber\tThe time allowed for validators to dispute or challenge state assertions. Measured in L1 blocks.\nl2Network.ethBridge\tEthBridge\tThe core contracts\nl2Network.isBold?\tboolean\tHas the network been upgraded to bold. True if yes, otherwise undefined\nThis is a temporary property and will be removed in future if Bold is widely adopted and\nthe legacy challenge protocol is deprecated\nl2Network.isCustom\tboolean\tWhether or not the chain was registered by the user.\nl2Network.name\tstring\tName of the chain.\nl2Network.nativeToken?\tstring\tIn case of a chain that uses ETH as its native/gas token, this is either undefined or the zero address\n\nIn case of a chain that uses an ERC-20 token from the parent chain as its native/gas token, this is the address of said token on the parent chain\nl2Network.partnerChainID\tnumber\t-\nl2Network.retryableLifetimeSeconds?\tnumber\tRepresents how long a retryable ticket lasts for before it expires (in seconds). Defaults to 7 days.\nl2Network.teleporter?\tTeleporter\tThe teleporter contracts.\nl2Network.tokenBridge\tL2NetworkTokenBridge\t-\nReturns​\n\nArbitrumNetwork\n\nSource​\n\ndataEntities/networks.ts:513\n\nmapL2NetworkTokenBridgeToTokenBridge()​\nfunction mapL2NetworkTokenBridgeToTokenBridge(input: L2NetworkTokenBridge): TokenBridge\n\n\nMaps the old L2Network.tokenBridge (from SDK v3) to ArbitrumNetwork.tokenBridge (from SDK v4).\n\nParameters​\nParameter\tType\ninput\tL2NetworkTokenBridge\nReturns​\n\nTokenBridge\n\nSource​\n\ndataEntities/networks.ts:489\n\nregisterCustomArbitrumNetwork()​\nfunction registerCustomArbitrumNetwork(network: ArbitrumNetwork, options?: object): ArbitrumNetwork\n\n\nRegisters a custom Arbitrum network.\n\nParameters​\nParameter\tType\tDescription\nnetwork\tArbitrumNetwork\tArbitrumNetwork to be registered\noptions?\tobject\tAdditional options\noptions.throwIfAlreadyRegistered?\tboolean\tWhether or not the function should throw if the network is already registered, defaults to false\nReturns​\n\nArbitrumNetwork\n\nSource​\n\ndataEntities/networks.ts:394\n\nEdit this page\nPrevious\nMessage\nNext\nRetryableData\nInterfaces\nArbitrumNetwork\nProperties\nL2NetworkTokenBridge\nDeprecated\nType Aliases\nL2Network\nDeprecated\nSource\nFunctions\nassertArbitrumNetworkHasTokenBridge()\nType parameters\nParameters\nReturns\nThrows\nSource\ngetArbitrumNetwork()\nParameters\nReturns\nNote\nSource\ngetArbitrumNetworkInformationFromRollup()\nParameters\nReturns\nSource\ngetArbitrumNetworks()\nReturns\nSource\ngetChildrenForNetwork()\nParameters\nReturns\nSource\nisParentNetwork()\nParameters\nReturns\nSource\nmapL2NetworkToArbitrumNetwork()\nParameters\nReturns\nSource\nmapL2NetworkTokenBridgeToTokenBridge()\nParameters\nReturns\nSource\nregisterCustomArbitrumNetwork()\nParameters\nReturns\nSource\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/run-local-dev-node",
    "html": "Skip to main content\nArbitrum Docs\nPage Not Found\n\nWe could not find what you were looking for.\n\nPlease contact the owner of the site that linked you to the original URL and let them know their link is broken.\n\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/assetBridger/ethBridger",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nAssetBridger\nErc20Bridger\nEthBridger\nL1l3Bridger\nDataEntities\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nethBridger\nClasses​\nEthBridger​\n\nBridger for moving either ETH or custom gas tokens back and forth between parent and child networks\n\nExtends​\nAssetBridger<EthDepositParams | EthDepositToParams | ParentToChildTxReqAndSigner, EthWithdrawParams | ChildToParentTxReqAndSigner>\nProperties​\nProperty\tModifier\tType\tDescription\tInherited from\nnativeToken?\treadonly\tstring\tIn case of a chain that uses ETH as its native/gas token, this is either undefined or the zero address\n\nIn case of a chain that uses an ERC-20 token from the parent network as its native/gas token, this is the address of said token on the parent network\tAssetBridger.nativeToken\nAccessors​\nnativeTokenIsEth​\nget protected nativeTokenIsEth(): boolean\n\n\nWhether the chain uses ETH as its native/gas token\n\nReturns​\n\nboolean\n\nSource​\n\nassetBridger/assetBridger.ts:71\n\nMethods​\napproveGasToken()​\napproveGasToken(params: WithParentSigner<ApproveGasTokenParamsOrTxRequest>): Promise<TransactionResponse>\n\n\nApproves the custom gas token to be spent by the Inbox on the parent network.\n\nParameters​\nParameter\tType\tDescription\nparams\tWithParentSigner<ApproveGasTokenParamsOrTxRequest>\t\nReturns​\n\nPromise<TransactionResponse>\n\nSource​\n\nassetBridger/ethBridger.ts:219\n\ncheckChildNetwork()​\nprotected checkChildNetwork(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the child network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nInherited from​\n\nAssetBridger . checkChildNetwork\n\nSource​\n\nassetBridger/assetBridger.ts:60\n\ncheckParentNetwork()​\nprotected checkParentNetwork(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the parent network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nInherited from​\n\nAssetBridger . checkParentNetwork\n\nSource​\n\nassetBridger/assetBridger.ts:49\n\ndeposit()​\ndeposit(params: EthDepositParams | ParentToChildTxReqAndSigner): Promise<ParentEthDepositTransaction>\n\n\nDeposit ETH from Parent onto Child network\n\nParameters​\nParameter\tType\tDescription\nparams\tEthDepositParams | ParentToChildTxReqAndSigner\t\nReturns​\n\nPromise<ParentEthDepositTransaction>\n\nOverrides​\n\nAssetBridger . deposit\n\nSource​\n\nassetBridger/ethBridger.ts:287\n\ndepositTo()​\ndepositTo(params: EthDepositToParams | ParentToChildTransactionRequest & object & object): Promise<ParentContractCallTransaction>\n\n\nDeposit ETH from parent network onto a different child network address\n\nParameters​\nParameter\tType\tDescription\nparams\tEthDepositToParams | ParentToChildTransactionRequest & object & object\t\nReturns​\n\nPromise<ParentContractCallTransaction>\n\nSource​\n\nassetBridger/ethBridger.ts:339\n\ngetApproveGasTokenRequest()​\ngetApproveGasTokenRequest(params?: ApproveGasTokenParams): Required<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>\n\n\nCreates a transaction request for approving the custom gas token to be spent by the inbox on the parent network\n\nParameters​\nParameter\tType\tDescription\nparams?\tApproveGasTokenParams\t\nReturns​\n\nRequired<Pick<TransactionRequest, \"data\" | \"value\" | \"to\">>\n\nSource​\n\nassetBridger/ethBridger.ts:191\n\ngetDepositRequest()​\ngetDepositRequest(params: EthDepositRequestParams): Promise<OmitTyped<ParentToChildTransactionRequest, \"retryableData\">>\n\n\nGets tx request for depositing ETH or custom gas token\n\nParameters​\nParameter\tType\tDescription\nparams\tEthDepositRequestParams\t\nReturns​\n\nPromise <OmitTyped <ParentToChildTransactionRequest, \"retryableData\">>\n\nSource​\n\nassetBridger/ethBridger.ts:268\n\ngetDepositRequestData()​\nprivate getDepositRequestData(params: EthDepositRequestParams): string\n\n\nGets transaction calldata for a tx request for depositing ETH or custom gas token\n\nParameters​\nParameter\tType\tDescription\nparams\tEthDepositRequestParams\t\nReturns​\n\nstring\n\nSource​\n\nassetBridger/ethBridger.ts:241\n\ngetDepositToRequest()​\ngetDepositToRequest(params: EthDepositToRequestParams): Promise<ParentToChildTransactionRequest>\n\n\nGet a transaction request for an ETH deposit to a different child network address using Retryables\n\nParameters​\nParameter\tType\tDescription\nparams\tEthDepositToRequestParams\t\nReturns​\n\nPromise <ParentToChildTransactionRequest>\n\nSource​\n\nassetBridger/ethBridger.ts:312\n\ngetWithdrawalRequest()​\ngetWithdrawalRequest(params: EthWithdrawParams): Promise<ChildToParentTransactionRequest>\n\n\nGet a transaction request for an eth withdrawal\n\nParameters​\nParameter\tType\tDescription\nparams\tEthWithdrawParams\t\nReturns​\n\nPromise <ChildToParentTransactionRequest>\n\nSource​\n\nassetBridger/ethBridger.ts:372\n\nisApproveGasTokenParams()​\nprivate isApproveGasTokenParams(params: ApproveGasTokenParamsOrTxRequest): params is WithParentSigner<ApproveGasTokenParams>\n\n\nAsserts that the provided argument is of type ApproveGasTokenParams and not ApproveGasTokenTxRequest.\n\nParameters​\nParameter\tType\tDescription\nparams\tApproveGasTokenParamsOrTxRequest\t\nReturns​\n\nparams is WithParentSigner<ApproveGasTokenParams>\n\nSource​\n\nassetBridger/ethBridger.ts:181\n\nwithdraw()​\nwithdraw(params: ChildToParentTxReqAndSigner | EthWithdrawParams & object): Promise<ChildContractTransaction>\n\n\nWithdraw ETH from child network onto parent network\n\nParameters​\nParameter\tType\tDescription\nparams\tChildToParentTxReqAndSigner | EthWithdrawParams & object\t\nReturns​\n\nPromise<ChildContractTransaction>\n\nOverrides​\n\nAssetBridger . withdraw\n\nSource​\n\nassetBridger/ethBridger.ts:408\n\nfromProvider()​\nstatic fromProvider(childProvider: Provider): Promise<EthBridger>\n\n\nInstantiates a new EthBridger from a child network Provider\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nReturns​\n\nPromise <EthBridger>\n\nSource​\n\nassetBridger/ethBridger.ts:173\n\nEdit this page\nPrevious\nErc20Bridger\nNext\nL1l3Bridger\nClasses\nEthBridger\nExtends\nProperties\nAccessors\nnativeTokenIsEth\nMethods\napproveGasToken()\ncheckChildNetwork()\ncheckParentNetwork()\ndeposit()\ndepositTo()\ngetApproveGasTokenRequest()\ngetDepositRequest()\ngetDepositRequestData()\ngetDepositToRequest()\ngetWithdrawalRequest()\nisApproveGasTokenParams()\nwithdraw()\nfromProvider()\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/arbos/geth#ArbitrumInternalTx",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nArbOS\nGeth\nFraud proofs\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nGeth\n\nNitro makes minimal modifications to Geth in hopes of not violating its assumptions. This document will explore the relationship between Geth and ArbOS, which consists of a series of hooks, interface implementations, and strategic re-appropriations of Geth's basic types.\n\nWe store ArbOS's state at an address inside a Geth statedb. In doing so, ArbOS inherits the statedb's statefulness and lifetime properties. For example, a transaction's direct state changes to ArbOS are discarded upon a revert.\n\n0xA4B05FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\nThe fictional account representing ArbOS\n\nINFO\n\nPlease note any links on this page may be referencing old releases of Nitro or our fork of Geth. While we try to keep this up to date and most of this should be stable, please check against latest releases for Nitro and Geth for most recent changes.\n\nHooks​\n\nArbitrum uses various hooks to modify Geth's behavior when processing transactions. Each provides an opportunity for ArbOS to update its state and make decisions about the transaction during its lifetime. Transactions are applied using Geth's ApplyTransaction function.\n\nBelow is ApplyTransaction's callgraph, with additional info on where the various Arbitrum-specific hooks are inserted. Click on any to go to their section. By default, these hooks do nothing so as to leave Geth's default behavior unchanged, but for chains configured with EnableArbOS set to true, ReadyEVMForL2 installs the alternative L2 hooks.\n\ncore.ApplyTransaction ⮕ core.applyTransaction ⮕ core.ApplyMessage\ncore.NewStateTransition\nReadyEVMForL2\ncore.TransitionDb\nStartTxHook\ncore.transitionDbImpl\nif IsArbitrum() remove tip\nGasChargingHook\nevm.Call\ncore.vm.EVMInterpreter.Run\nPushCaller\nPopCaller\ncore.StateTransition.refundGas\nForceRefundGas\nNonrefundableGas\nEndTxHook\nadded return parameter: transactionResult\n\nWhat follows is an overview of each hook, in chronological order.\n\nReadyEVMForL2​\n\nA call to ReadyEVMForL2 installs the other transaction-specific hooks into each Geth EVM right before it performs a state transition. Without this call, the state transition will instead use the default DefaultTxProcessor and get exactly the same results as vanilla Geth. A TxProcessor object is what carries these hooks and the associated Arbitrum-specific state during the transaction's lifetime.\n\nStartTxHook​\n\nThe StartTxHook is called by Geth before a transaction starts executing. This allows ArbOS to handle two Arbitrum-specific transaction types.\n\nIf the transaction is ArbitrumDepositTx, ArbOS adds balance to the destination account. This is safe because the L1 bridge submits such a transaction only after collecting the same amount of funds on L1.\n\nIf the transaction is an ArbitrumSubmitRetryableTx, ArbOS creates a retryable based on the transaction's fields. If the transaction includes sufficient gas, ArbOS schedules a retry of the new retryable.\n\nThe hook returns true for both of these transaction types, signifying that the state transition is complete.\n\nGasChargingHook​\n\nThis fallible hook ensures the user has enough funds to pay their poster's L1 calldata costs. If not, the transaction is reverted and the EVM does not start. In the common case that the user can pay, the amount paid for calldata is set aside for later reimbursement of the poster. All other fees go to the network account, as they represent the transaction's burden on validators and nodes more generally.\n\nIf the user attempts to purchase compute gas in excess of ArbOS's per-block gas limit, the difference is set aside and refunded later via ForceRefundGas so that only the gas limit is used. Note that the limit observed may not be the same as that seen at the start of the block if ArbOS's larger gas pool falls below the MaxPerBlockGasLimit while processing the block's previous transactions.\n\nPushCaller​\n\nThese hooks track the callers within the EVM callstack, pushing and popping as calls are made and complete. This provides ArbSys with info about the callstack, which it uses to implement the methods WasMyCallersAddressAliased and MyCallersAddressWithoutAliasing.\n\nL1BlockHash​\n\nIn Arbitrum, the BlockHash and Number operations return data that relies on underlying L1 blocks instead of L2 blocks, to accommodate the normal use-case of these opcodes, which often assume Ethereum-like time passes between different blocks. The L1BlockHash and L1BlockNumber hooks have the required data for these operations.\n\nForceRefundGas​\n\nThis hook allows ArbOS to add additional refunds to the user's tx. This is currently only used to refund any compute gas purchased in excess of ArbOS's per-block gas limit during the GasChargingHook.\n\nNonrefundableGas​\n\nBecause poster costs come at the expense of L1 aggregators and not the network more broadly, the amounts paid for L1 calldata should not be refunded. This hook provides Geth access to the equivalent amount of L2 gas the poster's cost equals, ensuring this amount is not reimbursed for network-incentivized behaviors like freeing storage slots.\n\nEndTxHook​\n\nThe EndTxHook is called after the EVM has returned a transaction's result, allowing one last opportunity for ArbOS to intervene before the state transition is finalized. Final gas amounts are known at this point, enabling ArbOS to credit the network and poster each's share of the user's gas expenditures as well as adjust the pools. The hook returns from the TxProcessor a final time, in effect discarding its state as the system moves on to the next transaction where the hook's contents will be set afresh.\n\nInterfaces and components​\nAPIBackend​\n\nAPIBackend implements the ethapi.Backend interface, which allows simple integration of the Arbitrum chain to existing Geth API. Most calls are answered using the Backend member.\n\nBackend​\n\nThis struct was created as an Arbitrum equivalent to the Ethereum struct. It is mostly glue logic, including a pointer to the ArbInterface interface.\n\nArbInterface​\n\nThis interface is the main interaction-point between geth-standard APIs and the Arbitrum chain. Geth APIs mostly either check status by working on the Blockchain struct retrieved from the Blockchain call, or send transactions to Arbitrum using the PublishTransactions call.\n\nRecordingKV​\n\nRecordingKV is a read-only key-value store, which retrieves values from an internal trie database. All values accessed by a RecordingKV are also recorded internally. This is used to record all preimages accessed during block creation, which will be needed to prove execution of this particular block. A RecordingChainContext should also be used, to record which block headers the block execution reads (another option would be to always assume the last 256 block headers were accessed). The process is simplified using two functions: PrepareRecording creates a stateDB and chaincontext objects, running block creation process using these objects records the required preimages, and PreimagesFromRecording function extracts the preimages recorded.\n\nTransaction Types​\n\nNitro Geth includes a few L2-specific transaction types. Click on any to jump to their section.\n\nTx Type\tRepresents\tLast Hook Reached  \tSource\nArbitrumUnsignedTx\tAn L1 to L2 message\tEndTxHook\tBridge\nArbitrumContractTx\tA nonce-less L1 to L2 message  \tEndTxHook\tBridge\nArbitrumDepositTx\tA user deposit\tStartTxHook\tBridge\nArbitrumSubmitRetryableTx  \tCreating a retryable\tStartTxHook  \tBridge\nArbitrumRetryTx\tA retryable redeem attempt\tEndTxHook\tL2\nArbitrumInternalTx\tArbOS state update\tStartTxHook\tArbOS\n\nThe following reference documents each type.\n\nArbitrumUnsignedTx​\n\nProvides a mechanism for a user on L1 to message a contract on L2. This uses the bridge for authentication rather than requiring the user's signature. Note, the user's acting address will be remapped on L2 to distinguish them from a normal L2 caller.\n\nArbitrumContractTx​\n\nThese are like an ArbitrumUnsignedTx but are intended for smart contracts. These use the bridge's unique, sequential nonce rather than requiring the caller specify their own. An L1 contract may still use an ArbitrumUnsignedTx, but doing so may necessitate tracking the nonce in L1 state.\n\nArbitrumDepositTx​\n\nRepresents a user deposit from L1 to L2. This increases the user's balance by the amount deposited on L1.\n\nArbitrumSubmitRetryableTx​\n\nRepresents a retryable submission and may schedule an ArbitrumRetryTx if provided enough gas. Please see the retryables documentation for more info.\n\nArbitrumRetryTx​\n\nThese are scheduled by calls to the redeem method of the ArbRetryableTx precompile and via retryable auto-redemption. Please see the retryables documentation for more info.\n\nArbitrumInternalTx​\n\nBecause tracing support requires ArbOS's state-changes happen inside a transaction, ArbOS may create a transaction of this type to update its state in-between user-generated transactions. Such a transaction has a Type field signifying the state it will update, though currently this is just future-proofing as there's only one value it may have. Below are the internal transaction types.\n\nInternalTxStartBlock​\n\nUpdates the L1 block number and L1 base fee. This transaction is generated whenever a new block is created. They are guaranteed to be the first in their L2 block.\n\nTransaction Run Modes and Underlying Transactions​\n\nA geth message may be processed for various purposes. For example, a message may be used to estimate the gas of a contract call, whereas another may perform the corresponding state transition. Nitro Geth denotes the intent behind a message by means of its TxRunMode, which it sets before processing it. ArbOS uses this info to make decisions about the transaction the message ultimately constructs.\n\nA message derived from a transaction will carry that transaction in a field accessible via its UnderlyingTransaction method. While this is related to the way a given message is used, they are not one-to-one. The table below shows the various run modes and whether each could have an underlying transaction.\n\nRun Mode\tScope\tCarries an Underlying Tx?\nMessageCommitMode\tstate transition  \talways\nMessageGasEstimationMode  \tgas estimation\twhen created via NodeInterface or when scheduled\nMessageEthcallMode\teth_calls\tnever\nArbitrum Chain Parameters​\n\nNitro's Geth may be configured with the following l2-specific chain parameters. These allow the rollup creator to customize their rollup at genesis.\n\nEnableArbos​\n\nIntroduces ArbOS, converting what would otherwise be a vanilla L1 chain into an L2 Arbitrum rollup.\n\nAllowDebugPrecompiles​\n\nAllows access to debug precompiles. Not enabled for Arbitrum One. When false, calls to debug precompiles will always revert.\n\nDataAvailabilityCommittee​\n\nCurrently does nothing besides indicate that the rollup will access a data availability service for preimage resolution in the future. This is not enabled for Arbitrum One, which is a strict state-function of its L1 inbox messages.\n\nMiscellaneous Geth Changes​\nABI Gas Margin​\n\nVanilla Geth's abi library submits txes with the exact estimate the node returns, employing no padding. This means a transaction may revert should another arriving just before even slightly change the transaction's codepath. To account for this, we've added a GasMargin field to bind.TransactOpts that pads estimates by the number of basis points set.\n\nConservation of L2 ETH​\n\nThe total amount of L2 ether in the system should not change except in controlled cases, such as when bridging. As a safety precaution, ArbOS checks Geth's balance delta each time a block is created, alerting or panicking should conservation be violated.\n\nMixDigest and ExtraData​\n\nTo aid with outbox proof construction, the root hash and leaf count of ArbOS's send merkle accumulator are stored in the MixDigest and ExtraData fields of each L2 block. The yellow paper specifies that the ExtraData field may be no larger than 32 bytes, so we use the first 8 bytes of the MixDigest, which has no meaning in a system without miners/stakers, to store the send count.\n\nRetryable Support​\n\nRetryables are mostly implemented in ArbOS. Some modifications were required in Geth to support them.\n\nAdded ScheduledTxes field to ExecutionResult. This lists transactions scheduled during the execution. To enable using this field, we also pass the ExecutionResult to callers of ApplyTransaction.\nAdded gasEstimation param to DoCall. When enabled, DoCall will also also executing any retryable activated by the original call. This allows estimating gas to enable retryables.\nAdded accessors​\n\nAdded UnderlyingTransaction to Message interface Added GetCurrentTxLogs to StateDB We created the AdvancedPrecompile interface, which executes and charges gas with the same function call. This is used by Arbitrum's precompiles, and also wraps Geth's standard precompiles.\n\nWASM build support​\n\nThe WASM Arbitrum executable does not support file operations. We created fileutil.go to wrap fileutil calls, stubbing them out when building WASM. fake_leveldb.go is a similar WASM-mock for leveldb. These are not required for the WASM block-replayer.\n\nTypes​\n\nArbitrum introduces a new signer, and multiple new transaction types.\n\nReorgToOldBlock​\n\nGeth natively only allows reorgs to a fork of the currently-known network. In nitro, reorgs can sometimes be detected before computing the forked block. We added the ReorgToOldBlock function to support reorging to a block that's an ancestor of current head.\n\nGenesis block creation​\n\nGenesis block in nitro is not necessarily block #0. Nitro supports importing blocks that take place before genesis. We split out WriteHeadBlock from genesis.Commit and use it to commit non-zero genesis blocks.\n\nEdit this page\nLast updated on Nov 22, 2024\nPrevious\nArbOS\nNext\nInteractive challenges\nHooks\nReadyEVMForL2\nStartTxHook\nGasChargingHook\nPushCaller\nL1BlockHash\nForceRefundGas\nNonrefundableGas\nEndTxHook\nInterfaces and components\nAPIBackend\nBackend\nArbInterface\nRecordingKV\nTransaction Types\nArbitrumUnsignedTx\nArbitrumContractTx\nArbitrumDepositTx\nArbitrumSubmitRetryableTx\nArbitrumRetryTx\nArbitrumInternalTx\nTransaction Run Modes and Underlying Transactions\nArbitrum Chain Parameters\nEnableArbos\nAllowDebugPrecompiles\nDataAvailabilityCommittee\nMiscellaneous Geth Changes\nABI Gas Margin\nConservation of L2 ETH\nMixDigest and ExtraData\nRetryable Support\nAdded accessors\nWASM build support\nTypes\nReorgToOldBlock\nGenesis block creation\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/how-to-estimate-gas",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to estimate gas in Arbitrum\nLOOKING FOR STYLUS GUIDANCE?\n\nHead over to the Stylus gas docs for Stylus-specific guidance.\n\nThis how-to is intended for users and developers interested in understanding how gas operates in Arbitrum, how it's calculated, and how to estimate it before submitting transactions. More detailed information about these calculations can be found in this Medium article and the Gas and Fees page.\n\nSkip the formula, focus on practical know-how​\n\nBefore diving into the specifics and the formula, if you're looking for a practical way to estimate gas for your transaction, you can rely on the standard gas estimation process. This can be achieved by calling an Arbitrum node's eth_estimateGas, which provides a value (gas limit) that should sufficiently cover the entire transaction fee at the specified L2 gas price.\n\nMultiplying the value obtained from eth_estimateGas by the L2 gas price will give you the total amount of Ether required for the transaction to be successful. It's important to note that, for a specific operation, the result of eth_estimateGas value may vary over time due to fluctuations in the L1 calldata price, see below to learn why!\n\nAlternatively, to obtain the gas limit for your transaction, you can call NodeInterface.gasEstimateComponents() and then use the first result, which is gasEstimate. Next, to find the total cost, you need to multiply this amount by the L2 gas price, which is available in the third result, baseFee.\n\nNote that when working with L1 to L2 messages (also known as retryable tickets), you can use the function L1ToL2MessageGasEstimator.estimateAll() of the Arbitrum SDK or NodeInterface.estimateRetryableTicket() to get all the gas information needed to send a successful transaction.\n\nBreaking down the formula​\n\nWe'll now break down the formula mentioned in the Medium article, moving then to where to get the information of each variable, and finally seeing an example of how to apply the formula in your code as well as other practical ways of estimating gas costs.\n\nHowever, if you want to jump straight to the code, we have created this script in our tutorials repository that goes through all the calculations explained in this how-to.\n\nAs explained in the Medium article, the transaction fees to pay at any given moment are the result of the following product:\n\nTransaction fees (TXFEES) = L2 Gas Price (P) * Gas Limit (G)\n\n\nThis Gas Limit includes the gas of the L2 computation and an additional buffer to cover the L1 gas to be paid by the Sequencer when posting the batch including this transaction on L1.\n\nGas Limit (G) = Gas used on L2 (L2G) + Extra Buffer for L1 cost (B)\n\n\nThis buffer takes into account the cost of posting the transaction, batched and compressed, on L1. The L1 estimated posting cost is calculated by multiplying these two values:\n\nL1S, which estimates the amount of data the transaction will take up in the batch by compressing the transaction with Brotli.\nL1P, which is the L2's estimated view of the current L1's price of data (per byte), which the L2 dynamically adjusts over time.\n\nMore information is available in this page.\n\nL1 Estimated Cost (L1C) = L1 price per byte of data (L1P) * Size of data to be posted in bytes (L1S)\n\n\nTo calculate the buffer, that estimated cost is divided by the L2 Gas Price.\n\nExtra Buffer (B) = L1 Estimated Cost (L1C) / L2 Gas Price (P)\n\n\nFinally, using all of the above elements, the formula can be written as follows:\n\nTXFEES = P * (L2G + ((L1P * L1S) / P))\n\nWhere do we get all this information from?​\n\nWe'll use one resource available in Arbitrum: the NodeInterface.\n\nP (L2 Gas Price) ⇒ Price to pay for each gas unit. It starts at 0.01 gwei on Arbitrum One (0.01 gwei on Arbitrum Nova) and can increase depending on the demand for network resources.\nCall NodeInterface.GasEstimateComponents() and get the third element, baseFee.\nL2G (Gas used on L2) ⇒ Gas used to compute the transaction on L2. This does not include the “posting on L1” part of the calculations. The value of L2G will depend on the transaction itself, but having the data of the transaction, we can calculate it as follows:\nCall NodeInterface.GasEstimateComponents() with the transaction data and subtract the second element (gasEstimateForL1, which estimates the L1 part of the fees) from the first (gasEstimate, which includes both the L1 and the L2 parts).\nL1P (L1 estimated price per byte of data) ⇒ Estimated cost of posting 1 byte of data on L1:\nCall NodeInterface.GasEstimateComponents(), get the fourth element l1BaseFeeEstimate and multiply it by 16.\nL1S (Size of data to be posted on L1, in bytes) ⇒ This will depend on the data of the transaction. Keep in mind that Arbitrum adds a fixed amount to this number to make up for the static part of the transaction, which is also posted on L1 (140 bytes). We can do a small calculation to obtain this value: call NodeInterface.GasEstimateComponents() take the second element, gasEstimateForL1 (this is equivalent to B in our formula), multiply it by P and divide it by L1P.\nFor Arbitrum Nova (AnyTrust), the size of the data is also a fixed value, as only the Data Availability Certificate is posted on L1, as explained here.\n\n(Note: for L1P and L1S, you can also call NodeInterface.gasEstimateL1Component() to get l1BaseFeeEstimate and gasEstimateForL1)\n\nAn example of how to apply this formula in your code​\n\nFinally, we show an example of how to get the values we just described and how to estimate the gas usage of a transaction in Javascript. We'll use our SDK to connect to the NodeInterface.\n\nWe first instantiate a factory object for the NodeInterface, using two methods from the SDK. l2Provider is a regular JSON RPC provider for the L2 network we are using, and NODE_INTERFACE_ADDRESS is the addresses that we need to call to access NodeInterface methods in said network.\n\nconst { NodeInterface__factory } = require(\"@arbitrum/sdk/dist/lib/abi/factories/NodeInterface__factory\");\nconst { NODE_INTERFACE_ADDRESS } = require(\"@arbitrum/sdk/dist/lib/dataEntities/constants\");\n\n...\n\n// Instantiation of the NodeInterface object\nconst nodeInterface = NodeInterface__factory.connect(\n    NODE_INTERFACE_ADDRESS,\n    baseL2Provider\n);\n\n\nFor this example, we'll use the method NodeInterface.gasEstimateComponents() to get the information we need. For the gasEstimateComponents() call, we'll pass a destinationAddress (this should be the address that you intend to call in your transaction) and the data we want to send, to get results as accurate as possible. You can also specify a different block number (in hex) in the object passed as the last parameter.\n\n// Getting the gas prices from ArbGasInfo.getPricesInWei()\nconst gasComponents = await arbGasInfo.callStatic.getPricesInWei();\n\n// And the estimations from NodeInterface.GasEstimateComponents()\nconst gasEstimateComponents = await nodeInterface.callStatic.gasEstimateComponents(\n  destinationAddress,\n  false,\n  txData,\n  {\n    blockTag: 'latest',\n  },\n);\n\n\nWith this, we can now get the values of the 4 variables we'll use in our formula:\n\n// Getting useful values for calculating the formula\nconst l1GasEstimated = gasEstimateComponents.gasEstimateForL1;\nconst l2GasUsed = gasEstimateComponents.gasEstimate.sub(gasEstimateComponents.gasEstimateForL1);\nconst l2EstimatedPrice = gasEstimateComponents.baseFee;\nconst l1EstimatedPrice = gasEstimateComponents.l1BaseFeeEstimate.mul(16);\n\n// Calculating some extra values to be able to apply all variables of the formula\n// -------------------------------------------------------------------------------\n// NOTE: This one might be a bit confusing, but l1GasEstimated (B in the formula) is calculated based on l2 gas fees\nconst l1Cost = l1GasEstimated.mul(l2EstimatedPrice);\n// NOTE: This is similar to 140 + utils.hexDataLength(txData);\nconst l1Size = l1Cost.div(l1EstimatedPrice);\n\n// Setting the basic variables of the formula\nconst P = l2EstimatedPrice;\nconst L2G = l2GasUsed;\nconst L1P = l1EstimatedPrice;\nconst L1S = l1Size;\n\n\nAnd finally, we estimate the transaction fees applying the formula described in the beginning.\n\n// L1C (L1 Cost) = L1P * L1S\nconst L1C = L1P.mul(L1S);\n\n// B (Extra Buffer) = L1C / P\nconst B = L1C.div(P);\n\n// G (Gas Limit) = L2G + B\nconst G = L2G.add(B);\n\n// TXFEES (Transaction fees) = P * G\nconst TXFEES = P.mul(G);\n\n\nRefer to our tutorials repository for a working example of this code.\n\nFinal note​\n\nNote that gas estimations from the above techniques are approximate and the actual gas fees may differ. We encourage developers to set this expectation explicitly wherever this information is shared with end-users.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nQuickstart (Solidity)\nNext\nChains and testnets\nSkip the formula, focus on practical know-how\nBreaking down the formula\nWhere do we get all this information from?\nAn example of how to apply this formula in your code\nFinal note\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/precompiles/reference",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nOverview\nReference\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nPrecompiles reference\n\nArbOS provides L2-specific precompiles with methods smart contracts can call the same way they can solidity functions. This reference page exhaustively documents the specific calls ArbOS makes available through precompiles. For a more conceptual description of what precompiles are and how they work, please refer to the precompiles conceptual page.\n\nThis reference page is divided into two sections. The first one lists all precompiles in a summary table with links to the reference of the specific precompile, along with the address where they live, their purpose and links to the go implementation and solidity interface. The second one details the methods available in each precompile with links to the specific implementation.\n\nGeneral information of precompiles​\n\nThis section is divided into two tables. We first list precompiles we expect users to most often use, and then the rest of precompiles. However, both tables display the same information: name and purpose of the precompile, address, and links to the solidity interface and the go implementation.\n\nCommon precompiles​\nPrecompile\tAddress\tSolidity interface\tGo implementation\tPurpose\nArbAggregator\t0x6d\tInterface\tImplementation\tConfiguring transaction aggregation\nArbGasInfo\t0x6c\tInterface\tImplementation\tInfo about gas pricing\nArbRetryableTx\t0x6e\tInterface\tImplementation\tManaging retryables\nArbSys\t0x64\tInterface\tImplementation\tSystem-level functionality\nArbWasm\t0x71\tInterface\tImplementation\tManages Stylus contracts\nArbWasmCache\t0x72\tInterface\tImplementation\tManages Stylus cache\nOther precompiles​\nPrecompile\tAddress\tSolidity interface\tGo implementation\tPurpose\nArbAddressTable\t0x66\tInterface\tImplementation\tSupporting compression of addresses\nArbBLS\t-\t-\t-\tDisabled (Former registry of BLS public keys)\nArbDebug\t0xff\tInterface\tImplementation\tTesting tools\nArbFunctionTable\t0x68\tInterface\tImplementation\tNo longer used\nArbInfo\t0x65\tInterface\tImplementation\tInfo about accounts\nArbOwner\t0x70\tInterface\tImplementation\tChain administration, callable only by chain owner\nArbOwnerPublic\t0x6b\tInterface\tImplementation\tInfo about chain owners\nArbosTest\t0x69\tInterface\tImplementation\tNo longer used\nArbStatistics\t0x6f\tInterface\tImplementation\tInfo about the pre-Nitro state\nPrecompiles reference​\nArbAddressTable​\n\nArbAddressTable (Interface | Implementation) provides the ability to create short-hands for commonly used accounts.\n\nPrecompile address: 0x0000000000000000000000000000000000000066\n\nMethod\tSolidity interface\tGo implementation\tDescription\naddressExists(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tAddressExists checks if an address exists in the table\ncompress(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tCompress and returns the bytes that represent the address\ndecompress(bytes calldata buf, uint256 offset)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nDecompress the compressed bytes at the given offset with those of the corresponding account\n\n\nlookup(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tLookup the index of an address in the table\nlookupIndex(uint256 index)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tLookupIndex for an address in the table by index\nregister(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tRegister adds an account to the table, shrinking its compressed representation\nsize()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSize gets the number of addresses in the table\nArbAggregator​\n\nArbAggregator (Interface | Implementation) provides aggregators and their users methods for configuring how they participate in L1 aggregation. Arbitrum One's default aggregator is the Sequencer, which a user will prefer unless SetPreferredAggregator is invoked to change it.\n\nCompression ratios are measured in basis points. Methods that are checkmarked are access-controlled and will revert if not called by the aggregator, its fee collector, or a chain owner.\n\nPrecompile address: 0x000000000000000000000000000000000000006D\n\nMethod\tSolidity interface\tGo implementation\tDescription\n\n\n⚠️getPreferredAggregator(address addr)\n\n\t\n\nInterface\n\n\t\n\nImplementation\n\n\tDeprecated: Do not use this method.\n\n\n⚠️getDefaultAggregator()\n\n\t\n\nInterface\n\n\t\n\nImplementation\n\n\tDeprecated: Do not use this method.\ngetBatchPosters()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetBatchPosters gets the addresses of all current batch posters\naddBatchPoster(address newBatchPoster)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tAdds newBatchPoster as a batch poster\ngetFeeCollector(address batchPoster)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetFeeCollector gets a batch poster's fee collector\nsetFeeCollector(address batchPoster, address newFeeCollector)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nSetFeeCollector sets a batch poster's fee collector (caller must be the batch poster, its fee collector, or an owner)\n\n\n\n\n⚠️getTxBaseFee(address aggregator)\n\n\t\n\nInterface\n\n\t\n\nImplementation\n\n\tDeprecated: returns 0\n\n\n⚠️setTxBaseFee(address aggregator, uint256 feeInL1Gas)\n\n\t\n\nInterface\n\n\t\n\nImplementation\n\n\tDeprecated: does nothing\n\nNote: methods marked with ⚠️ are deprecated and their use is not supported.\n\nArbBLS​\nDISABLED\n\nThis precompile has been disabled. It previously provided a registry of BLS public keys for accounts.\n\nArbDebug​\n\nArbDebug (Interface | Implementation) provides mechanisms useful for testing. The methods of ArbDebug are only available for chains with the AllowDebugPrecompiles chain parameter set. Otherwise, calls to this precompile will revert.\n\nPrecompile address: 0x00000000000000000000000000000000000000ff\n\nMethod\tSolidity interface\tGo implementation\tDescription\nbecomeChainOwner()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tCaller becomes a chain owner\nevents(bool flag, bytes32 value)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmit events with values based on the args provided\neventsView()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tTries (and fails) to emit logs in a view context\ncustomRevert(uint64 number)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tThrows a custom error\npanic()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tHalts the chain by panicking in the STF\nlegacyError()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tThrows a hardcoded error\nEvent\tSolidity interface\tGo implementation\tDescription\nBasic\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nEmitted in Events for testing\n\n\nMixed\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nEmitted in Events for testing\n\n\nStore\t\n\nInterface\n\n\t\n\nImplementation\n\n\tNever emitted (used for testing log sizes)\nArbFunctionTable​\n\nArbFunctionTable (Interface | Implementation) provides aggregators the ability to manage function tables, to enable one form of transaction compression. The Nitro aggregator implementation does not use these, so these methods have been stubbed and their effects disabled. They are kept for backwards compatibility.\n\nPrecompile address: 0x0000000000000000000000000000000000000068\n\nMethod\tSolidity interface\tGo implementation\tDescription\nupload(bytes calldata buf)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tUpload does nothing\nsize(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSize returns the empty table's size, which is 0\nget(address addr, uint256 index)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGet reverts since the table is empty\nArbGasInfo​\n\nArbGasInfo (Interface | Implementation) provides insight into the cost of using the chain. These methods have been adjusted to account for Nitro's heavy use of calldata compression. Of note to end-users, we no longer make a distinction between non-zero and zero-valued calldata bytes.\n\nPrecompile address: 0x000000000000000000000000000000000000006C\n\nMethod\tSolidity interface\tGo implementation\tDescription\ngetPricesInWeiWithAggregator(address aggregator)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetPricesInWeiWithAggregator gets prices in wei when using the provided aggregator\ngetPricesInWei()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetPricesInWei gets prices in wei when using the caller's preferred aggregator\ngetPricesInArbGasWithAggregator(address aggregator)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nGetPricesInArbGasWithAggregator gets prices in ArbGas when using the provided aggregator\n\n\ngetPricesInArbGas()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetPricesInArbGas gets prices in ArbGas when using the caller's preferred aggregator\ngetGasAccountingParams()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetGasAccountingParams gets the rollup's speed limit, pool size, and tx gas limit\ngetMinimumGasPrice()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetMinimumGasPrice gets the minimum gas price needed for a transaction to succeed\ngetL1BaseFeeEstimate()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetL1BaseFeeEstimate gets the current estimate of the L1 basefee\ngetL1BaseFeeEstimateInertia()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nGetL1BaseFeeEstimateInertia gets how slowly ArbOS updates its estimate of the L1 basefee\n\n\ngetL1RewardRate()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetL1RewardRate gets the L1 pricer reward rate\ngetL1RewardRecipient()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetL1RewardRecipient gets the L1 pricer reward recipient\ngetL1GasPriceEstimate()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetL1GasPriceEstimate gets the current estimate of the L1 basefee\ngetCurrentTxL1GasFees()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetCurrentTxL1GasFees gets the fee paid to the aggregator for posting this tx\ngetGasBacklog()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetGasBacklog gets the backlogged amount of gas burnt in excess of the speed limit\ngetPricingInertia()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns how slowly ArbOS updates the L2 basefee in response to backlogged gas\ngetGasBacklogTolerance()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nGetGasBacklogTolerance gets the forgivable amount of backlogged gas ArbOS will ignore when raising the basefee\n\n\ngetL1PricingSurplus()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns the surplus of funds for L1 batch posting payments (may be negative)\ngetPerBatchGasCharge()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nReturns the base charge (in L1 gas) attributed to each data batch in the calldata pricer\n\n\ngetAmortizedCostCapBips()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns the cost amortization cap in basis points\ngetL1FeesAvailable()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns the available funds from L1 fees\ngetL1PricingEquilibrationUnits()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nReturns the equilibration units parameter for L1 price adjustment algorithm (Available since ArbOS 20)\n\n\ngetLastL1PricingUpdateTime()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns the last time the L1 calldata pricer was updated (Available since ArbOS 20)\ngetL1PricingFundsDueForRewards()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nReturns the amount of L1 calldata payments due for rewards (per the L1 reward rate) (Available since ArbOS 20)\n\n\ngetL1PricingUnitsSinceUpdate()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nReturns the amount of L1 calldata posted since the last update (Available since ArbOS 20)\n\n\ngetLastL1PricingSurplus()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nReturns the L1 pricing surplus as of the last update (may be negative) (Available since ArbOS 20)\n\nArbInfo​\n\nArbInfo (Interface | Implementation) provides the ability to lookup basic info about accounts and contracts.\n\nPrecompile address: 0x0000000000000000000000000000000000000065\n\nMethod\tSolidity interface\tGo implementation\tDescription\ngetBalance(address account)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetBalance retrieves an account's balance\ngetCode(address account)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetCode retrieves a contract's deployed code\nArbosTest​\n\nArbosTest (Interface | Implementation) provides a method of burning arbitrary amounts of gas, which exists for historical reasons. In Classic, ArbosTest had additional methods only the zero address could call. These have been removed since users don't use them and calls to missing methods revert.\n\nPrecompile address: 0x0000000000000000000000000000000000000069\n\nMethod\tSolidity interface\tGo implementation\tDescription\nburnArbGas(uint256 gasAmount)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tBurnArbGas unproductively burns the amount of L2 ArbGas\nArbOwner​\n\nArbOwner (Interface | Implementation) provides owners with tools for managing the rollup. Calls by non-owners will always revert.\n\nMost of Arbitrum Classic's owner methods have been removed since they no longer make sense in Nitro:\n\nWhat were once chain parameters are now parts of ArbOS's state, and those that remain are set at genesis.\nArbOS upgrades happen with the rest of the system rather than being independent\nExemptions to address aliasing are no longer offered. Exemptions were intended to support backward compatibility for contracts deployed before aliasing was introduced, but no exemptions were ever requested.\n\nPrecompile address: 0x0000000000000000000000000000000000000070\n\nMethod\tSolidity interface\tGo implementation\tDescription\naddChainOwner(address newOwner)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tAddChainOwner adds account as a chain owner\nremoveChainOwner(address ownerToRemove)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tRemoveChainOwner removes account from the list of chain owners\nisChainOwner(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tIsChainOwner checks if the account is a chain owner\ngetAllChainOwners()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetAllChainOwners retrieves the list of chain owners\nsetL1BaseFeeEstimateInertia(uint64 inertia)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nSetL1BaseFeeEstimateInertia sets how slowly ArbOS updates its estimate of the L1 basefee\n\n\nsetL2BaseFee(uint256 priceInWei)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetL2BaseFee sets the L2 gas price directly, bypassing the pool calculus\nsetMinimumL2BaseFee(uint256 priceInWei)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetMinimumL2BaseFee sets the minimum base fee needed for a transaction to succeed\nsetSpeedLimit(uint64 limit)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetSpeedLimit sets the computational speed limit for the chain\nsetMaxTxGasLimit(uint64 limit)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetMaxTxGasLimit sets the maximum size a tx (and block) can be\nsetL2GasPricingInertia(uint64 sec)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetL2GasPricingInertia sets the L2 gas pricing inertia\nsetL2GasBacklogTolerance(uint64 sec)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetL2GasBacklogTolerance sets the L2 gas backlog tolerance\ngetNetworkFeeAccount()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetNetworkFeeAccount gets the network fee collector\ngetInfraFeeAccount()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetInfraFeeAccount gets the infrastructure fee collector\nsetNetworkFeeAccount(address newNetworkFeeAccount)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetNetworkFeeAccount sets the network fee collector to the new network fee account\nsetInfraFeeAccount(address newInfraFeeAccount)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetInfraFeeAccount sets the infra fee collector to the new network fee account\nscheduleArbOSUpgrade(uint64 newVersion, uint64 timestamp)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tScheduleArbOSUpgrade to the requested version at the requested timestamp\nsetL1PricingEquilibrationUnits(uint256 equilibrationUnits)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets equilibration units parameter for L1 price adjustment algorithm\nsetL1PricingInertia(uint64 inertia)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets inertia parameter for L1 price adjustment algorithm\nsetL1PricingRewardRecipient(address recipient)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets reward recipient address for L1 price adjustment algorithm\nsetL1PricingRewardRate(uint64 weiPerUnit)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets reward amount for L1 price adjustment algorithm, in wei per unit\nsetL1PricePerUnit(uint256 pricePerUnit)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSet how much ArbOS charges per L1 gas spent on transaction data.\nsetPerBatchGasCharge(int64 cost)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the base charge (in L1 gas) attributed to each data batch in the calldata pricer\nsetBrotliCompressionLevel(uint64 level)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nSets the Brotli compression level used for fast compression (Available in ArbOS version 12 with default level as 1)\n\n\nsetAmortizedCostCapBips(uint64 cap)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the cost amortization cap in basis points\nreleaseL1PricerSurplusFunds(uint256 maxWeiToRelease)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReleases surplus funds from L1PricerFundsPoolAddress for use\nsetInkPrice(uint32 price)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the amount of ink 1 gas buys\nsetWasmMaxStackDepth(uint32 depth)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the maximum depth (in wasm words) a wasm stack may grow\nsetWasmFreePages(uint16 pages)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the number of free wasm pages a tx gets\nsetWasmPageGas(uint16 gas)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the base cost of each additional wasm page\nsetWasmPageLimit(uint16 limit)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the initial number of pages a wasm may allocate\nsetWasmMinInitGas(uint8 gas, uint16 cached)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the minimum costs to invoke a program\nsetWasmInitCostScalar(uint64 percent)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the linear adjustment made to program init costs\nsetWasmExpiryDays(uint16 _days)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the number of days after which programs deactivate\nsetWasmKeepaliveDays(uint16 _days)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the age a program must be to perform a keepalive\nsetWasmBlockCacheSize(uint16 count)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the number of extra programs ArbOS caches during a given block\naddWasmCacheManager(address manager)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tAdds account as a wasm cache manager\nremoveWasmCacheManager(address manager)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tRemoves account from the list of wasm cache managers\nsetChainConfig(string calldata chainConfig)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets serialized chain config in ArbOS state\nEvent\tSolidity interface\tGo implementation\tDescription\nOwnerActs\t\n\nInterface\n\n\t\n\nImplementation\n\n\t/ Emitted when a successful call is made to this precompile\nArbOwnerPublic​\n\nArbOwnerPublic (Interface | Implementation) provides non-owners with info about the current chain owners.\n\nPrecompile address: 0x000000000000000000000000000000000000006b\n\nMethod\tSolidity interface\tGo implementation\tDescription\nisChainOwner(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tIsChainOwner checks if the user is a chain owner\nrectifyChainOwner(address ownerToRectify)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nRectifyChainOwner checks if the account is a chain owner (Available in ArbOS version 11)\n\n\ngetAllChainOwners()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetAllChainOwners retrieves the list of chain owners\ngetNetworkFeeAccount()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetNetworkFeeAccount gets the network fee collector\ngetInfraFeeAccount()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetInfraFeeAccount gets the infrastructure fee collector\ngetBrotliCompressionLevel()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nGetBrotliCompressionLevel gets the current brotli compression level used for fast compression\n\n\ngetScheduledUpgrade()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns (0, 0, nil) if no ArbOS upgrade is scheduled.\nEvent\tSolidity interface\tGo implementation\tDescription\nChainOwnerRectified\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when verifying a chain owner\nArbRetryableTx​\n\nArbRetryableTx (Interface | Implementation) provides methods for managing retryables. The model has been adjusted for Nitro, most notably in terms of how retry transactions are scheduled. For more information on retryables, please see the retryable documentation.\n\nPrecompile address: 0x000000000000000000000000000000000000006E\n\nMethod\tSolidity interface\tGo implementation\tDescription\nredeem(bytes32 ticketId)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nRedeem schedules an attempt to redeem the retryable, donating all of the call's gas to the redeem attempt\n\n\ngetLifetime()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetLifetime gets the default lifetime period a retryable has at creation\ngetTimeout(bytes32 ticketId)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetTimeout gets the timestamp for when ticket will expire\nkeepalive(bytes32 ticketId)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tKeepalive adds one lifetime period to the ticket's expiry\ngetBeneficiary(bytes32 ticketId)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetBeneficiary gets the beneficiary of the ticket\ncancel(bytes32 ticketId)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tCancel the ticket and refund its callvalue to its beneficiary\ngetCurrentRedeemer()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the redeemer of the current retryable redeem attempt\nsubmitRetryable()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nDo not call. This method represents a retryable submission to aid explorers. Calling it will always revert.\n\nEvent\tSolidity interface\tGo implementation\tDescription\nTicketCreated\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when creating a retryable\nLifetimeExtended\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when extending a retryable's expiry date\nRedeemScheduled\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when scheduling a retryable\nCanceled\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when cancelling a retryable\nRedeemed\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nDEPRECATED in favour of new RedeemScheduled event after the nitro upgrade.\n\nArbStatistics​\n\nArbStatistics (Interface | Implementation) provides statistics about the chain as of just before the Nitro upgrade. In Arbitrum Classic, this was how a user would get info such as the total number of accounts, but there are better ways to get that info in Nitro.\n\nPrecompile address: 0x000000000000000000000000000000000000006F\n\nMethod\tSolidity interface\tGo implementation\tDescription\ngetStats()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nGetStats returns the current block number and some statistics about the rollup's pre-Nitro state\n\nArbSys​\n\nArbSys (Interface | Implementation) provides system-level functionality for interacting with L1 and understanding the call stack.\n\nPrecompile address: 0x0000000000000000000000000000000000000064\n\nMethod\tSolidity interface\tGo implementation\tDescription\narbBlockNumber()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tArbBlockNumber gets the current L2 block number\narbBlockHash(uint256 arbBlockNum)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tArbBlockHash gets the L2 block hash, if sufficiently recent\narbChainID()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tArbChainID gets the rollup's unique chain identifier\narbOSVersion()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tArbOSVersion gets the current ArbOS version\ngetStorageGasAvailable()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetStorageGasAvailable returns 0 since Nitro has no concept of storage gas\nisTopLevelCall()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tIsTopLevelCall checks if the call is top-level (deprecated)\nmapL1SenderContractAddressToL2Alias(address sender, address unused)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tMapL1SenderContractAddressToL2Alias gets the contract's L2 alias\nwasMyCallersAddressAliased()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tWasMyCallersAddressAliased checks if the caller's caller was aliased\nmyCallersAddressWithoutAliasing()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nMyCallersAddressWithoutAliasing gets the caller's caller without any potential aliasing\n\n\nwithdrawEth(address destination)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tWithdrawEth send paid eth to the destination on L1\nsendTxToL1(address destination, bytes calldata data)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSendTxToL1 sends a transaction to L1, adding it to the outbox\nsendMerkleTreeState()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nSendMerkleTreeState gets the root, size, and partials of the outbox Merkle tree state (caller must be the 0 address)\n\nEvent\tSolidity interface\tGo implementation\tDescription\nL2ToL1Tx\t\n\nInterface\n\n\t\n\nImplementation\n\n\tLogs a send transaction from L2 to L1, including data for outbox proving\nL2ToL1Transaction\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nDEPRECATED in favour of the new L2ToL1Tx event above after the nitro upgrade\n\n\nSendMerkleUpdate\t\n\nInterface\n\n\t\n\nImplementation\n\n\tLogs a new merkle branch needed for constructing outbox proofs\nArbWasm​\n\nArbWasm (Interface | Implementation) provides helper methods for managing Stylus contracts\n\nPrecompile address: 0x0000000000000000000000000000000000000071\n\nMethod\tSolidity interface\tGo implementation\tDescription\nactivateProgram(address program)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tCompile a wasm program with the latest instrumentation\nstylusVersion()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the latest stylus version\ncodehashVersion(bytes32 codehash)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the stylus version that program with codehash was most recently compiled with\ncodehashKeepalive(bytes32 codehash)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tExtends a program's expiration date (reverts if too soon)\ncodehashAsmSize(bytes32 codehash)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets a program's asm size in bytes\nprogramVersion(address program)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the stylus version that program at addr was most recently compiled with\nprogramInitGas(address program)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the cost to invoke the program\nprogramMemoryFootprint(address program)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the footprint of program at addr\nprogramTimeLeft(address program)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets returns the amount of time remaining until the program expires\ninkPrice()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the amount of ink 1 gas buys\nmaxStackDepth()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the wasm stack size limit\nfreePages()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the number of free wasm pages a tx gets\npageGas()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the base cost of each additional wasm page\npageRamp()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the ramp that drives exponential memory costs\npageLimit()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the maximum initial number of pages a wasm may allocate\nminInitGas()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the minimum costs to invoke a program\ninitCostScalar()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the linear adjustment made to program init costs\nexpiryDays()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the number of days after which programs deactivate\nkeepaliveDays()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the age a program must be to perform a keepalive\nblockCacheSize()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the number of extra programs ArbOS caches during a given block.\nEvent\tSolidity interface\tGo implementation\tDescription\nProgramActivated\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when activating a WASM program\nProgramLifetimeExtended\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when extending the expiration date of a WASM program\nArbWasmCache​\n\nArbWasmCache (Interface | Implementation) provides helper methods for managing Stylus cache\n\nPrecompile address: 0x0000000000000000000000000000000000000072\n\nMethod\tSolidity interface\tGo implementation\tDescription\nisCacheManager(address manager)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSee if the user is a cache manager owner.\nallCacheManagers()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tRetrieve all authorized address managers.\ncacheCodehash(bytes32 codehash)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tDeprecated: replaced with CacheProgram.\ncacheProgram(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nCaches all programs with a codehash equal to the given address. Caller must be a cache manager or chain owner.\n\n\nevictCodehash(bytes32 codehash)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nEvicts all programs with the given codehash. Caller must be a cache manager or chain owner.\n\n\ncodehashIsCached(bytes32 codehash)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets whether a program is cached. Note that the program may be expired.\nEvent\tSolidity interface\tGo implementation\tDescription\nUpdateProgramCache\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when caching a WASM program\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nOverview\nNext\nOverview\nGeneral information of precompiles\nCommon precompiles\nOther precompiles\nPrecompiles reference\nArbAddressTable\nArbAggregator\nArbBLS\nArbDebug\nArbFunctionTable\nArbGasInfo\nArbInfo\nArbosTest\nArbOwner\nArbOwnerPublic\nArbRetryableTx\nArbStatistics\nArbSys\nArbWasm\nArbWasmCache\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Overview: The Lifecycle of an Arbitrum Transaction | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/tx-lifecycle",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nTransaction lifecycle\nSequencer\nAnyTrust protocol\nGas / fees\nAdvanced concepts\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nOverview: The Lifecycle of an Arbitrum Transaction\n\nAs an introduction to the various components that compose the Arbitrum protocol, we'll go step-by-step over the phases an Arbitrum transaction goes through, starting with a client creating a signed transaction, to it ultimately being confirmed back on layer 1.\n\nWe'll also intersperse it with \"finality checks,\" explaining what guarantees the client has over their transaction's finality (i.e., assurances that their transaction's result is guaranteed and won't later be altered) over the course of a transaction's various stages.\n\nThis overview will be focused on the Arbitrum Rollup protocol; see Inside AnyTrust for differences in the Arbitrum AnyTrust protocol. Also, for convenience/simplicity, we'll be describing the security properties of the core system itself; see \"State of Progressive Decentralization\" for current decentralization status.\n\nFor clarity on any terminology that may be unfamiliar, see our glossary.\n\n1. Sequencer receives transaction​\n\nTypically, a transaction's lifecycle starts with the Sequencer, the entity designated with transaction ordering, receiving a transaction from a client. The Sequencer can receive a transaction one of two ways:\n\n1a. Directly / Offchain​\n\nFor typical transacting within the L2 environment (i.e., using an L2 native dapp), a client will connect their wallet to an L2 node and directly deliver a signed transaction.\n\n1b. ... or from L1 (via the Delayed Inbox).​\n\nAlternatively, a client can send a message to the Sequencer by signing and publishing an L1 transaction in the Arbitrum chain's Delayed Inbox. This functionality is most commonly used for depositing ETH or tokens via a bridge.\n\nSee:\n\nRetryables\nThe Sequencer\nToken Bridge\n2. Sequencer orders transaction (off-chain)​\n\nUpon receiving a transaction, the Sequencer will:\n\nOrder it in its off-chain Inbox\nLocally execute it using the Arbitrum Nitro VM (including collecting/allocating L1 and L2 fees, etc.)\n\"Instantly\" give a transaction receipt to the client (\"instant\" in that it doesn't require any additional on-chain confirmations, and typically takes less than a second - with the average user experiencing ~260ms).\n\nSee:\n\nArbOS\nGeth\nL1 pricing / L2 Gas\n~ ~ ~ FINALITY CHECK: Trusted / Soft Confirmation ~ ~ ~​\n\nAt this phase, the client's acceptance of finality relies on trusting the Sequencer. I.e., a malicious/faulty Sequencer could deviate between what it promised in the transaction receipt and what is ultimately published in a batch (see phase 3).\n\nNOTE\n\nEven a malicious/faulty Sequencer can only, at worst, reorder or temporarily delay transactions; it cannot, e.g., forge a client's transaction or propose an invalid state update. Given the degree of trust in the Sequencer at phase 2, we sometimes refer to the \"instant\" receipt that the Sequencer provides as a \"soft confirmation.\"\n\n3. Sequencer posts transaction in a batch (on-chain)​\n\nThe Sequencer will eventually post a batch of L2 transactions which includes our client's transaction onto the underlying L1 (as calldata); under normal conditions, the Sequencer will post batches every few minutes.\n\n3a. What if the Sequencer never includes our transaction?​\n\nEven if the Sequencer never includes our transaction in a batch, the client can include it in the L2 by posting in the delayed inbox and then \"force including\" it after some delay period (currently ~ 24 hours on Arbitrum One).\n\nNOTE\n\nThe Sequencer is forced to include messages from the delayed Inbox in the queued order that they appear on chain, i.e. it processes messages using the \"first in, first out\" method. Thus, it can't selectively delay particular messages while including others; i.e., delaying the message at the front of the queue means delaying all messages behind it as well.\n\nSee:\n\n\"The Sequencer / Censorship Resistance.\"\n~ ~ ~ FINALITY CHECK: Ethereum-Equivalent Finality! ~ ~ ~​\n\nAt this stage, assuming that a client believes there to be at least one well behaved active Arbitrum validator. Currently, the process of validation on the Arbitrum protocol is permissioned, but it's important to be aware that our latest dispute protocol, BoLD (Bounded Liquidity Delay), has the potential to allow validation on Arbitrum chains without requiring permission, thereby potentially eliminating the necessity for restricted validation. The client can treat their transaction's finality as equivalent to an ordinary Ethereum transaction. In other words, their L2 transaction has the same finality as the L1 transaction that recorded it in a batch. This means the client should use whatever finality heuristic they use for regular Ethereum transactions (i.e., waiting on L1 block confirmations, etc.), applied to the L1 batch-posting transaction. This also means that a client uncomfortable with the trust model of the Sequencer's soft confirmations (phase 2) can simply wait for the Sequencer to post their transaction in a batch (phase 3).\n\nHow are we able to make such bold a claim? A few (related) things:\n\nOnce the Sequencer posts a batch, its transactions' ordering is entirely determined by the L1; the Sequencer effectively has no more say in our transaction's lifecycle at all.\nThe Inbox contract on L1 ensures that when the Sequencer posts a batch, it posts data sufficient for any Arbitrum Node to reconstruct and validate the state of the L2 chain; i.e., the availability of this \"input\" data is guaranteed by Ethereum itself.\nExecution on Arbitrum is fully deterministic; i.e., a current chain state along with new input data is sufficient to compute the new chain state; thus, the moment this input data is available (i.e., when the Sequencer posts a batch), the L2 chain's state can be computed.\nArbitrum's fault-proof system is sound; i.e., if any validator (later) tries to deviate from the valid L2 state, an honest validator will ultimately be able to challenge this and win. Since we already know that valid state will ultimately win out, we can treat our transaction as L1-finalized now.\n4. Validator asserts RBlock that includes transaction​\n\nA staked, active validator will then run the Arbitrum VM over the inputs in the Inbox (just like the Sequencer did earlier, except now only over transactions posted on L1) and make an on-chain assertion about the chain's latest state, i.e., a rollup block or \"RBlock.\" RBlocks typically get asserted every 30-60 minutes.\n\nSee:\n\nArbOS\nGeth\nL1 pricing / L2 Gas\nNOTE\n\nRBlock assertions include claims about the state of the Outbox; if our transaction triggered any L2 to L1 messages, a RBlock will include an update to the Outbox to reflect its inclusion.\n\nSee:\n\nThe Outbox\n4a. RBlock is valid / goes unchallenged​\n\nIn the happy / common case, the validator asserted a valid RBlock, and over the course of the dispute window — 1 week on Arbitrum One — no other validators challenge it.\n\n4b. Assertion is challenged!​\n\nIf two validators assert different RBlocks, only (at most) one of them can be valid, so they are put into a dispute.\n\nA dispute consists of two staked validators dissecting their disagreement down to a single L2 block, and then dissecting the sequence of VM instructions within this block down to a single OPCODE, then finally, executing this single operation. The underlying VM the Arbitrum uses is WebAssembly (Wasm), or, more precisely, \"WAVM.\" This is all refereed by contracts on L1.\n\nSee:\n\nChallenges\nWasm/WAVM\n\nL1 contracts also keep track of the tree of all assertions; i.e., how many stakers are in disagreement, who is currently disputing with whom, etc. We refer to this level of Arbitrum's design architecture as its \"assertion tree protocol.\"\n\nSee:\n\nAssertion Tree Protocol\n~ ~ ~ FINALITY CHECK: STILL THE SAME Ethereum-Equivalent Finality! ~ ~ ~​\n\nRemember in phase 3 when said that once the L1 has committed to inputs, we can guarantee the L2 output? We meant it! Even during a dispute, Arbitrum nodes continue to execute and active validators continue to make assertions on the valid leaf in the state-tree; nothing that can happen in phase 4 has any effect on the L1-level finality we've already locked in at phase 3.\n\n5. RBlock is confirmed on L1​\n\nOnce any and all disputes have been resolved and sufficient time has passed, our RBlock can be confirmed on L1 (any Ethereum account on L1 can confirm it). Upon confirmation, the Outbox root on L1 gets updated.\n\n~ ~ ~ FINALITY CHECK: L2-to-L1 Messages Executable on L1 ~ ~ ~​\n\nIf our client's transaction didn't include any L2-to-L1 messages (e.g., withdrawals), phase 5 has no material effect on their transaction. If it did include an L2-to-L1 transaction, it is only after confirmation that the message can be executed in the Outbox on L1.\n\nNOTE\n\nEven before phase 5, the client has L1 finality on the result of their L2-to-L1 message, they just can't execute it yet; i.e., they have a guarantee that they'll eventually be able to, e.g., finalize their withdrawal, they just can't claim their funds on L1 until the RBlock is confirmed.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nTroubleshooting\nNext\nSequencer\n1. Sequencer receives transaction\n2. Sequencer orders transaction (off-chain)\n3. Sequencer posts transaction in a batch (on-chain)\n4. Validator asserts RBlock that includes transaction\n5. RBlock is confirmed on L1\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/arbos/l1-l2-messaging#submission",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nL1-to-L2 messaging\nL2-to-L1 messaging\nArbOS\nFraud proofs\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nL1 to L2 messaging\nRetryable Tickets​\n\nRetryable tickets are Arbitrum's canonical method for creating L1 to L2 messages, i.e., L1 transactions that initiate a message to be executed on L2. A retryable can be submitted for a fixed cost (dependent only on its calldata size) paid at L1; its submission on L1 is separable / asynchronous with its execution on L2. Retryables provide atomicity between the cross chain operations; if the L1 transaction to request submission succeeds (i.e. does not revert) then the execution of the Retryable on L2 has a strong guarantee to ultimately succeed as well.\n\nRetryable Tickets Lifecycle​\n\nHere we walk through the different stages of the lifecycle of a retryable ticket; (1) submission, (2) auto-redemption, and (3) manual redemption.\n\nSubmission​\nCreating a retryable ticket is initiated with a call (direct or internal) to the createRetryableTicket function of the inbox contract. A ticket is guaranteed to be created if this call succeeds. Here, we describe parameters that need to be carefully set. Note that, this function forces the sender to provide a reasonable amount of funds (at least enough to submitting, and attempting to executing the ticket), but that doesn't guarantee a successful auto-redemption.\nParameter\tDescription\nl1CallValue (also referred to as deposit)\tNot a real function parameter, it is rather the callValue that is sent along with the transaction\naddress to\tThe destination L2 address\nuint256 l2CallValue\tThe callvalue for retryable L2 message that is supplied within the deposit (l1CallValue)\nuint256 maxSubmissionCost\tThe maximum amount of ETH to be paid for submitting the ticket. This amount is (1) supplied within the deposit (l1CallValue) to be later deducted from sender's L2 balance and is (2) directly proportional to the size of the retryable’s data and L1 basefee\naddress excessFeeRefundAddress\tThe unused gas cost and submssion cost will deposit to this address, formula is: (gasLimit x maxFeePerGas - execution cost) + (maxSubmission - (autoredeem ? 0 : submission cost)). (Note: excess deposit will transfer to the alias address of the parent chain tx's msg.sender rather than this address)\naddress callValueRefundAddress\tThe L2 address to which the l2CallValue is credited if the ticket times out or gets cancelled (this is also called the beneficiary, who's got a critical permission to cancel the ticket)\nuint256 gasLimit\tMaximum amount of gas used to cover L2 execution of the ticket\nuint256 maxFeePerGas\tThe gas price bid for L2 execution of the ticket that is supplied within the deposit (l1CallValue)\nbytes calldata data\tThe calldata to the destination L2 address\n\nSender's deposit must be enough to make the L1 submission succeed and for the L2 execution to be attempted. If provided correctly, a new ticket with a unique TicketID is created and added to retryable buffer. Also, funds (submissionCost + l2CallValue) are deducted from the sender and placed into the escrow for later use in redeeming the ticket.\n\nTicket creation causes the ArbRetryableTx precompile to emit a TicketCreated event containing the TicketID on L2.\n\n🧍 The user who initiates an L1-L2 message\n\nInitiating an L1-L2 message A call to inbox.createRetryableTicket function that puts the message in the L2 inbox that can be re-executed for some fixed amount of time if it reverts\n\nCheck user's deposit Logic that checks if the user have enough funds to create a ticket. This is done by checking if the msg.value provided by the user is greater than or equal to maxSubmissionCost + l2CallValue + gasLimit * maxFeePerGas\n\nTicket creation fails Ticket creation fails and no funds are deducted from the user\n\nTicket is created A ticket is created and added to the retryable buffer on L2 Funds (l2CallValue + submissionCost) are deducted to cover the callvalue from the user and placed into escrow (on L2) for later use in redeeming the ticket\n\nAutomatic Redemption​\nIt is very important to note that the submission of a ticket on L1 is separable / asynchronous from its execution on L2, i.e., a successful L1 ticket creation does not guarantee a successful redemption. Once the ticket is successfully created, the two following conditions are checked: (1) if the user's L2 balance is greater than (or equal to) maxFeePerGas * gasLimit and (2) if the maxFeePerGas (provided by the user in the ticket submission process) is greater than (or equal to) the l2Basefee. If these conditions are both met, ticket's submission is followed by an attempt to execute it on L2 (i.e., an auto-redeem using the supplied gas, as if the redeem method of the ArbRetryableTx precompile had been called). Depending on how much gas the sender has provided in step 1, ticket's redemption can either (1) immediately succeed or (2) fail. We explain both situations here:\n\nIf the ticket is successfully auto-redeemed, it will execute with the sender, destination, callvalue, and calldata of the original submission. The submission fee is refunded to the user on L2 (excessFeeRefundAddress). Note that to ensure successful auto-redeem of the ticket, one could use the Arbitrum SDK which provides a convenience function that returns the desired gas parameters when sending L1-L2 messages.\n\nIf a redeem is not done at submission or the submission's initial redeem fails (for example, because the L2 gas price has increased unexpectedly), the submission fee is collected on L2 to cover the resources required to temporarily keep the ticket in memory for a fixed period (one week), and only in this case, a manual redemption of the ticket is required (see next section).\n\n--- title: Automatic Redemption of the Ticket --- graph TB 1(\"Auto-redeem succeeds?\") -. yes .-> 2(\"Ticket is executed\") 2 -.-> 3(\"Ticket is deleted\") 1 -. no .-> 4(\"callValueRefundAddress gets refunded\")\n\nDoes the auto-redeem succeed? Logic that determines if the user's L2 Balance is greater than (or equal to) maxFeePerGas * gasLimit && maxFeePerGas is greater than (or equal to) the l2Basefee\n\nTicket is executed Ticket is executed, the actual submissionFee is refunded to the excessFeeRefundAddress since the ticket was not kept in the buffer on L2\n\nTicket is deleted Ticket gets deleted from the L2 retryable buffer\n\ncallValueRefundAddress gets refunded callValueRefundAddress gets refunded with (maxGas - gasUsed) * gasPrice. Note that this amount is capped by l1CallValue in the auto-redeem\n\nManual Redemption​\n\nAt this point, anyone can attempt to manually redeem the ticket again by calling ArbRetryableTx's redeem precompile method, which donates the call's gas to the next attempt. Note that the amount of gas is NOT limited by the original gasLimit set during the ticket creation. ArbOS will enqueue the redeem, which is its own special ArbitrumRetryTx type, to its list of redeems that ArbOS guarantees to exhaust before moving on to the next non-redeem transaction in the block its forming. In this manner redeems are scheduled to happen as soon as possible, and will always be in the same block as the tx that scheduled it. Note that the redeem attempt's gas comes from the call to redeem, so there's no chance the block's gas limit is reached before execution.\n\nIf the fixed period (one week) elapses without a successful redeem, the ticket expires and will be automatically discarded, unless some party has paid a fee to keep the ticket alive for another full period. A ticket can live indefinitely as long as it is renewed each time before it expires.\n\n--- title: Manual Redemption of the Ticket --- graph TB 1(\"Ticket manually cancelled or not redeemed in 7 days?\") -. yes .-> 2(\"callValueRefundAddress gets refunded\") 2 -.-> 3(\"Ticket is deleted\") 1 -. no .-> 4(\"Ticket manually redeemed?\") 4 -. yes .-> 3 4 -. no .-> 1\n\nIs the ticket manually cancelled or not redeemed within 7 days? Logic that determines if the ticket is manually cancelled or not redeemed within 7 days (i.e., is expired)\n\ncallValueRefundAddress gets refunded callValueRefundAddress is refunded with the l2CallValue\n\nTicket is deleted Ticket gets deleted from the L2 retryable buffer\n\nIs the ticket manually redeemed Logic that determines if the ticket is manually redeemed\n\nAVOID LOSING FUNDS!\n\nIf a ticket expires after 7 days without being redeemed or re-scheduled to a future date, any message and value (other than the escrowed callvalue) it carries could be lost without possibility of being recovered.\n\nOn success, the To address receives the escrowed callvalue, and any unused gas is returned to ArbOS's gas pools. On failure, the callvalue is returned to the escrow for the future redeem attempt. In either case, the network fee was paid during the scheduling tx, so no fees are charged and no refunds are made.\n\nNote that during redemption of a ticket, attempts to cancel the same ticket, or to schedule another redeem of the same ticket, will revert. In this manner retryable tickets are not self-modifying.\n\nIf a ticket with a callvalue is eventually discarded (cancelled or expired), having never successfully run, the escrowed callvalue will be paid out to a callValueRefundAddress account that was specified in the initial submission (step 1).\n\nIMPORTANT NOTES:\n\nIf a redeem is not done at submission or the submission's initial redeem fails, anyone can attempt to redeem the retryable again by calling ArbRetryableTx's redeem precompile method, which donates the call's gas to the next attempt. ArbOS will enqueue the redeem, which is its own special ArbitrumRetryTx type, to its list of redeems that ArbOS guarantees to exhaust before moving on to the next non-redeem transaction in the block its forming. In this manner redeems are scheduled to happen as soon as possible, and will always be in the same block as the transaction that scheduled it. Note that the redeem attempt's gas comes from the call to redeem, so there's no chance the block's gas limit is reached before execution.\n\nOne can redeem live tickets using the Arbitrum Retryables Transaction Panel\nThe calldata of a ticket is saved on L2 until it is redeemed or expired\nRedeeming cost of a ticket will not increase over time, it only depends on the current gas price and gas required for execution\nReceipts​\n\nIn the lifecycle of a retryable ticket, two types of L2 transaction receipts will be emitted:\n\nTicket Creation Receipt: This receipt indicates that a ticket was successfully created; any successful L1 call to the Inbox's createRetryableTicket method is guaranteed to create a ticket. The ticket creation receipt includes a TicketCreated event (from ArbRetryableTx), which includes a ticketId field. This ticketId is computable via RLP encoding and hashing the transaction; see calculateSubmitRetryableId.\nRedeem Attempt: A redeem attempt receipt represents the result of an attempted L2 execution of a ticket, i.e, success / failure of that specific redeem attempt. It includes a RedeemScheduled event from ArbRetryableTx, with a ticketId field. At most, one successful redeem attempt can ever exist for a given ticket; if, e.g., the auto-redeem upon initial creation succeeds, only the receipt from the auto-redeem will ever get emitted for that ticket. If the auto-redeem fails (or was never attempted — i.e., the provided L2 gas limit * L2 gas price = 0), each initial attempt will emit a redeem attempt receipt until one succeeds.\nAlternative \"unsafe\" Retryable Ticket Creation​\n\nThe Inbox.createRetryableTicket convenience method includes sanity checks to help minimize the risk of user error: the method will ensure that enough funds are provided directly from L1 to cover the current cost of ticket creation. It also will convert the provided callValueRefundAddress and excessFeeRefundAddress to their address alias (see below) if either is a contract (determined by if the address has code during the call), providing a path for the L1 contract to recover funds. A power-user may bypass these sanity-check measures via the Inbox's unsafeCreateRetryableTicket method; as the method's name desperately attempts to warn you, it should only be accessed by a user who truly knows what they're doing.\n\nEth deposits​\n\nA special message type exists for simple Eth deposits; i.e., sending Eth from L1 to L2. Eth can be deposited via a call to the Inbox's depositEth method. If the L1 caller is EOA, the Eth will be deposited to the same EOA address on L2; the L1 caller is a contract, the funds will deposited to the contract's aliased address (see below).\n\nNote that depositing Eth via depositEth into a contract on L2 will not trigger the contract's fallback function.\n\nIn principle, retryable tickets can alternatively be used to deposit Ether; this could be preferable to the special eth-deposit message type if, e.g., more flexibility for the destination address is needed, or if one wants to trigger the fallback function on the L2 side.\n\nTransacting via the Delayed Inbox​\n\nWhile retryables and Eth deposits must be submitted through the delayed inbox, in principle, any message can be included this way; this is a necessary recourse to ensure the Arbitrum chain preserves censorship resistance even if the Sequencer misbehaves (see The Sequencer and Censorship Resistance). However, under ordinary/happy circumstances, the expectation/recommendation is that clients use the delayed inbox only for Retryables and Eth deposits, and transact via the Sequencer for all other messages.\n\nAddress Aliasing​\n\nUnsigned messages submitted via the Delayed Inbox get their sender's addressed \"aliased\": when these messages are executed on L2, the sender's address —i.e., that which is returned by msg.sender — will not simply be the L1 address that sent the message; rather it will be the address's \"L2 Alias.\" An address's L2 alias is its value increased by the hex value 0x1111000000000000000000000000000000001111:\n\nL2_Alias = L1_Contract_Address + 0x1111000000000000000000000000000000001111\n\nTRY IT OUT\n\nThe Arbitrum protocol's usage of L2 Aliases for L1-to-L2 messages prevents cross-chain exploits that would otherwise be possible if we simply reused the same L1 addresses as the L2 sender; i.e., tricking an L2 contract that expects a call from a given contract address by sending retryable ticket from the expected contract address on L1.\n\nIf for some reason you need to compute the L1 address from an L2 alias on chain, you can use our AddressAliasHelper library:\n\nmodifier onlyFromMyL1Contract() override {\n    require(AddressAliasHelper.undoL1ToL2Alias(msg.sender) == myL1ContractAddress, \"ONLY_COUNTERPART_CONTRACT\");\n    _;\n}\n\nSigned Messages​\n\nThe delayed inbox can also accept messages that include a signature. In this case, the message will execute with the msg.sender address equal to the address that produced the included signature (i.e., not its alias). Intuitively, the signature proves that the sender address is not a contract, and thus is safe from cross-chain exploit concerns described above. Thus, it can safely execute from signer's address, similar to a transaction included in a Sequencer's batch. For these messages, the address of the L1 sender is effectively ignored at L2.\n\nThese signed messages submitted through the delayed inbox can be used to execute messages that bypass the Sequencer and require EOA authorization at L2, e.g., force-including an Ether withdrawal (see \"withdraw eth tutorial\").\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nNitro vs. Classic\nNext\nL2-to-L1 messaging\nRetryable Tickets\nRetryable Tickets Lifecycle\nSubmission\nAutomatic Redemption\nManual Redemption\nReceipts\nAlternative \"unsafe\" Retryable Ticket Creation\nEth deposits\nTransacting via the Delayed Inbox\nAddress Aliasing\nSigned Messages\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/arbitrum-vs-ethereum/block-numbers-and-time",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nComparison overview\nBlock gas limit, numbers and time\nRPC methods\nSolidity support\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nBlock gas limit, numbers and time\nARBITRUM CHAINS AND THEIR PARENT CHAINS\n\nWith the release of Arbitrum Orbit, Arbitrum chains can now be L2s that settle to Ethereum (or one of their testnets), or L3s that settle to one of the Arbitrum L2 chains. For simplicity, in this page we speak in terms of Arbitrum One (L2) and Ethereum (L1), but the same logic can be applied to any chain and its parent chain.\n\nAs in Ethereum, Arbitrum clients submit transactions, and the system executes those transactions at some later time. In Arbitrum, clients submit transactions by posting messages to the Ethereum chain, either through the sequencer or via the chain's delayed inbox.\n\nOnce in the chain's core inbox contract, transactions are processed in order. Generally, some time will elapse between when a message is put into the inbox (and timestamped) and when the contract processes the message and carries out the transaction requested by the message.\n\nAdditionally, since the calldata of Arbitrum transactions (or the DAC certificate on AnyTrustchains) is posted to Ethereum, the gas paid when executing them includes an L1 component to cover the costs of the batch poster.\n\nThis page describes what this mechanism means for the block gas limit, block numbers, and the time assumptions of the transactions submitted to Arbitrum.\n\nBlock gas limit​\n\nWhen submitting a transaction to Arbitrum, users are charged for both the execution cost on Arbitrum and the cost of posting its calldata to Ethereum. This dual cost structure is managed by adjusting the transaction's gas limit to reflect these two dimensions, resulting in a higher gas limit value than what would be seen for pure execution.\n\nThe gas limit of an Arbitrum block is set as the sum of all transaction gas limits, including the costs related to L1 data posting. To accommodate potential variations in L1 costs, Arbitrum assigns an artificially large gas limit (1,125,899,906,842,624) for each block. However, the effective execution gas limit is capped at 32 million. This means that while the visible gas limit might appear very high, the actual execution costs are constrained within this limit. Understanding this distinction helps clarify why querying a block might show an inflated gas limit that doesn’t match the effective execution costs.\n\nFor a more detailed breakdown of the gas model, refer to this article on Arbitrum's 2-dimensional fee structure.\n\nBlock numbers: Arbitrum vs. Ethereum​\n\nArbitrum blocks are assigned their own L2 block numbers, distinct from Ethereum's block numbers.\n\nA single Ethereum block could include multiple Arbitrum blocks within it; however, an Arbitrum block cannot span across multiple Ethereum blocks. Thus, any given Arbitrum transaction is associated with exactly one Ethereum block and one Arbitrum block.\n\nEthereum block numbers within Arbitrum​\n\nAccessing block numbers within an Arbitrum smart contract (i.e., block.number in Solidity) will return a value close to (but not necessarily exactly) the L1 block number at which the sequencer received the transaction.\n\n// some Arbitrum contract:\nblock.number // => returns L1 block number (\"ish\")\n\n\nAs a general rule, any timing assumptions a contract makes about block numbers and timestamps should be considered generally reliable in the longer term (i.e., on the order of at least several hours) but unreliable in the shorter term (minutes). (It so happens these are generally the same assumptions one should operate under when using block numbers directly on Ethereum!)\n\nArbitrum block numbers​\n\nArbitrum blocks have their own block numbers, starting at 0 at the Arbitrum genesis block and updating sequentially.\n\nArbOS and the sequencer are responsible for delineating when one Arbitrum block ends and the next one begins. However, block creation depends entirely on chain usage, meaning that blocks are only produced when there are transactions to sequence. In active chains, one can expect to see Arbitrum blocks produced at a relatively steady rate. In more quiet chains, block production might be sporadic depending on the rate at which transactions are received.\n\nA client that queries an Arbitrum node's RPC interface (for, e.g., transaction receipts) will receive the transaction's Arbitrum block number as the standard block number field. The L1 block number will also be included in the added l1BlockNumber field.\n\nconst txnReceipt = await arbitrumProvider.getTransactionReceipt('0x...');\n/** \n    txnReceipt.blockNumber => Arbitrum block number\n    txnReceipt.l1BlockNumber => L1 block number (\"ish\")\n*/\n\n\nThe Arbitrum block number can also be retrieved within an Arbitrum contract via ArbSys precompile:\n\n ArbSys(100).arbBlockNumber() // returns Arbitrum block number\n\nExample​\nWall Clock time\t12:00 am\t12:00:15 am\t12:00:30 am\t12:00:45 am\t12:01 am\t12:01:15 am\nL1 block.number\t1000\t1001\t1002\t1003\t1004\t1005\nL2 block.number *\t1000\t1000\t1000\t1000\t1004\t1004\nArbitrum Block number (from RPCs) **\t370000\t370005\t370006\t370008\t370012\t370015\n\n* L2 block.number: updated to sync with L1 block.number approximately every minute. Thus, over time, it will, like the L1 block.number, average to ~12 seconds per block.\n\n** Arbitrum block number from RPCs: note that this can be updated multiple times per L1 block (this lets the sequencer give sub-L1-block-time transaction receipts.)\n\nCase study: the Multicall contract​\n\nThe Multicall contract offers a great case study for the differences between L1 and L2 block numbers.\n\nThe canonical implementation of Multicall returns the value of block.number. If attempting to use out-of-the-box, some applications might face unintended behaviour.\n\nYou can find a version of the adapted Multicall2 deployed on Arbitrum One at 0x7eCfBaa8742fDf5756DAC92fbc8b90a19b8815bF.\n\nBy default the getBlockNumber, tryBlockAndAggregate, and aggregate functions return the L2 block number. This allows you to use this value to compare your state against the tip of the chain.\n\nThe getL1BlockNumber function can be queried if applications need to surface the L1 block number.\n\nBlock timestamps: Arbitrum vs. Ethereum​\n\nBlock timestamps on Arbitrum are not linked to the timestamp of the L1 block. They are updated every L2 block based on the sequencer's clock. These timestamps must follow these two rules:\n\nMust be always equal or greater than the previous L2 block timestamp\nMust fall within the established boundaries (24 hours earlier than the current time or 1 hour in the future). More on this below.\n\nFurthermore, for transactions that are force-included from L1 (bypassing the sequencer), the block timestamp will be equal to either the L1 timestamp when the transaction was put in the delayed inbox on L1 (not when it was force-included), or the L2 timestamp of the previous L2 block, whichever of the two timestamps is greater.\n\nTimestamp boundaries of the sequencer​\n\nAs mentioned, block timestamps are usually set based on the sequencer's clock. Because there's a possibility that the sequencer fails to post batches on the parent chain (for example, Ethereum) for a period of time, it should have the ability to slightly adjust the timestamp of the block to account for those delays and prevent any potential reorganisations of the chain. To limit the degree to which the sequencer can adjust timestamps, some boundaries are set, currently to 24 hours earlier than the current time, and 1 hour in the future.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nComparison overview\nNext\nRPC methods\nBlock gas limit\nBlock numbers: Arbitrum vs. Ethereum\nEthereum block numbers within Arbitrum\nArbitrum block numbers\nExample\nCase study: the Multicall contract\nBlock timestamps: Arbitrum vs. Ethereum\nTimestamp boundaries of the sequencer\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "multicall | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/utils/multicall",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nUtils\nArbProvider\nByte_serialize_params\nEventFetcher\nLib\nMulticall\nTypes\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nmulticall\nClasses​\nMultiCaller​\n\nUtil for executing multi calls against the MultiCallV2 contract\n\nProperties​\nProperty\tModifier\tType\tDescription\naddress\treadonly\tstring\tAddress of multicall contract\nMethods​\ngetBlockNumberInput()​\ngetBlockNumberInput(): CallInput<BigNumber>\n\n\nGet the call input for the current block number\n\nReturns​\n\nCallInput<BigNumber>\n\nSource​\n\nutils/multicall.ts:133\n\ngetCurrentBlockTimestampInput()​\ngetCurrentBlockTimestampInput(): CallInput<BigNumber>\n\n\nGet the call input for the current block timestamp\n\nReturns​\n\nCallInput<BigNumber>\n\nSource​\n\nutils/multicall.ts:149\n\ngetTokenData()​\ngetTokenData<T>(erc20Addresses: string[], options?: T): Promise<TokenInputOutput<T>[]>\n\n\nMulticall for token properties. Will collect all the requested properies for each of the supplied token addresses.\n\nType parameters​\nType parameter\nT extends undefined | TokenMultiInput\nParameters​\nParameter\tType\tDescription\nerc20Addresses\tstring[]\t\noptions?\tT\tDefaults to just 'name'\nReturns​\n\nPromise<TokenInputOutput<T>[]>\n\nSource​\n\nutils/multicall.ts:231\n\nmultiCall()​\nmultiCall<T, TRequireSuccess>(params: T, requireSuccess?: TRequireSuccess): Promise<DecoderReturnType<T, TRequireSuccess>>\n\n\nExecutes a multicall for the given parameters Return values are order the same as the inputs. If a call failed undefined is returned instead of the value.\n\nTo get better type inference when the individual calls are of different types create your inputs as a tuple and pass the tuple in. The return type will be a tuple of the decoded return types. eg.\n\n  const inputs: [\n    CallInput<Awaited<ReturnType<ERC20['functions']['balanceOf']>>[0]>,\n    CallInput<Awaited<ReturnType<ERC20['functions']['name']>>[0]>\n  ] = [\n    {\n      targetAddr: token.address,\n      encoder: () => token.interface.encodeFunctionData('balanceOf', ['']),\n      decoder: (returnData: string) =>\n        token.interface.decodeFunctionResult('balanceOf', returnData)[0],\n    },\n    {\n      targetAddr: token.address,\n      encoder: () => token.interface.encodeFunctionData('name'),\n      decoder: (returnData: string) =>\n        token.interface.decodeFunctionResult('name', returnData)[0],\n    },\n  ]\n\n  const res = await multiCaller.call(inputs)\n\nType parameters​\nType parameter\nT extends CallInput<unknown>[]\nTRequireSuccess extends boolean\nParameters​\nParameter\tType\tDescription\nparams\tT\t\nrequireSuccess?\tTRequireSuccess\tFail the whole call if any internal call fails\nReturns​\n\nPromise<DecoderReturnType<T, TRequireSuccess>>\n\nSource​\n\nutils/multicall.ts:197\n\nfromProvider()​\nstatic fromProvider(provider: Provider): Promise<MultiCaller>\n\n\nFinds the correct multicall address for the given provider and instantiates a multicaller\n\nParameters​\nParameter\tType\tDescription\nprovider\tProvider\t\nReturns​\n\nPromise <MultiCaller>\n\nSource​\n\nutils/multicall.ts:125\n\nType Aliases​\nCallInput<T>​\ntype CallInput<T>: object;\n\n\nInput to multicall aggregator\n\nType parameters​\nType parameter\nT\nType declaration​\nMember\tType\tDescription\ndecoder\t(returnData: string) => T\tFunction to decode the result of the call\nencoder\t() => string\tFunction to produce encoded call data\ntargetAddr\tstring\tAddress of the target contract to be called\nSource​\n\nutils/multicall.ts:30\n\nEdit this page\nPrevious\nLib\nNext\nTypes\nClasses\nMultiCaller\nProperties\nMethods\ngetBlockNumberInput()\ngetCurrentBlockTimestampInput()\ngetTokenData()\nmultiCall()\nfromProvider()\nType Aliases\nCallInput<T>\nType parameters\nType declaration\nSource\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "lib | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/utils/lib",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nUtils\nArbProvider\nByte_serialize_params\nEventFetcher\nLib\nMulticall\nTypes\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nlib\nFunctions​\ngetFirstBlockForL1Block()​\nfunction getFirstBlockForL1Block(__namedParameters: GetFirstBlockForL1BlockProps): Promise<number | undefined>\n\n\nThis function performs a binary search to find the first Arbitrum block that corresponds to a given L1 block number. The function returns a Promise that resolves to a number if a block is found, or undefined otherwise.\n\nParameters​\nParameter\tType\n__namedParameters\tGetFirstBlockForL1BlockProps\nReturns​\n\nPromise<number | undefined>\n\nA Promise that resolves to a number if a block is found, or undefined otherwise.\nSource​\n\nutils/lib.ts:89\n\ngetTransactionReceipt()​\nfunction getTransactionReceipt(\n   provider: Provider, \n   txHash: string, \n   confirmations?: number, \ntimeout?: number): Promise<null | TransactionReceipt>\n\n\nWaits for a transaction receipt if confirmations or timeout is provided Otherwise tries to fetch straight away.\n\nParameters​\nParameter\tType\tDescription\nprovider\tProvider\t\ntxHash\tstring\t\nconfirmations?\tnumber\t\ntimeout?\tnumber\t\nReturns​\n\nPromise<null | TransactionReceipt>\n\nSource​\n\nutils/lib.ts:32\n\nEdit this page\nPrevious\nEventFetcher\nNext\nMulticall\nFunctions\ngetFirstBlockForL1Block()\nParameters\nReturns\nSource\ngetTransactionReceipt()\nParameters\nReturns\nSource\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "eventFetcher | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/utils/eventFetcher",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nUtils\nArbProvider\nByte_serialize_params\nEventFetcher\nLib\nMulticall\nTypes\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\neventFetcher\nClasses​\nEventFetcher​\n\nFetches and parses blockchain logs\n\nMethods​\ngetEvents()​\ngetEvents<TContract, TEventFilter>(\n   contractFactory: TypeChainContractFactory<TContract>, \n   topicGenerator: (t: TContract) => TEventFilter, \nfilter: object): Promise<FetchedEvent<TEventOf<TEventFilter>>[]>\n\n\nFetch logs and parse logs\n\nType parameters​\nType parameter\nTContract extends Contract\nTEventFilter extends TypedEventFilter<TypedEvent<any, any>>\nParameters​\nParameter\tType\tDescription\ncontractFactory\tTypeChainContractFactory<TContract>\tA contract factory for generating a contract of type TContract at the addr\ntopicGenerator\t(t: TContract) => TEventFilter\tGenerator function for creating\nfilter\tobject\tBlock and address filter parameters\nfilter.address?\tstring\t-\nfilter.fromBlock\tBlockTag\t-\nfilter.toBlock\tBlockTag\t-\nReturns​\n\nPromise<FetchedEvent<TEventOf<TEventFilter>>[]>\n\nSource​\n\nutils/eventFetcher.ts:57\n\nEdit this page\nPrevious\nByte_serialize_params\nNext\nLib\nClasses\nEventFetcher\nMethods\ngetEvents()\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "byte_serialize_params | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/utils/byte_serialize_params",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nUtils\nArbProvider\nByte_serialize_params\nEventFetcher\nLib\nMulticall\nTypes\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nbyte_serialize_params\nFunctions​\nargSerializerConstructor()​\nfunction argSerializerConstructor(arbProvider: Provider): (params: PrimativeOrPrimativeArray[]) => Promise<Uint8Array>\n\n\nto use:\n\nconst mySerializeParamsFunction = argSerializerConstructor(\"rpcurl\")\nmySerializeParamsFunction([\"4\",\"5\", \"6\"])\n\nParameters​\nParameter\tType\narbProvider\tProvider\nReturns​\n\nFunction\n\nParameters​\nParameter\tType\nparams\tPrimativeOrPrimativeArray[]\nReturns​\n\nPromise<Uint8Array>\n\nSource​\n\nutils/byte_serialize_params.ts:102\n\nserializeParams()​\nfunction serializeParams(params: PrimativeOrPrimativeArray[], addressToIndex: (address: string) => Promise<number>): Promise<Uint8Array>\n\nParameters​\nParameter\tType\tDescription\nparams\tPrimativeOrPrimativeArray[]\tarray of serializable types to\naddressToIndex\t(address: string) => Promise<number>\toptional getter of address index registered in table\nReturns​\n\nPromise<Uint8Array>\n\nSource​\n\nutils/byte_serialize_params.ts:138\n\nEdit this page\nPrevious\nArbProvider\nNext\nEventFetcher\nFunctions\nargSerializerConstructor()\nParameters\nReturns\nParameters\nReturns\nSource\nserializeParams()\nParameters\nReturns\nSource\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "arbProvider | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/utils/arbProvider",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nUtils\nArbProvider\nByte_serialize_params\nEventFetcher\nLib\nMulticall\nTypes\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\narbProvider\nClasses​\nArbitrumProvider​\n\nArbitrum specific formats\n\nExtends​\nWeb3Provider\nConstructors​\nnew ArbitrumProvider()​\nnew ArbitrumProvider(provider: JsonRpcProvider, network?: Networkish): ArbitrumProvider\n\n\nArbitrum specific formats\n\nParameters​\nParameter\tType\tDescription\nprovider\tJsonRpcProvider\tMust be connected to an Arbitrum network\nnetwork?\tNetworkish\tMust be an Arbitrum network\nReturns​\n\nArbitrumProvider\n\nOverrides​\n\nWeb3Provider.constructor\n\nSource​\n\nutils/arbProvider.ts:77\n\nEdit this page\nPrevious\nParentTransaction\nNext\nByte_serialize_params\nClasses\nArbitrumProvider\nExtends\nConstructors\nnew ArbitrumProvider()\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "ChildToParentMessage | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/message/ChildToParentMessage",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nChildToParentMessage\nChildToParentMessageClassic\nChildToParentMessageNitro\nChildTransaction\nParentToChildMessage\nParentToChildMessageCreator\nParentToChildMessageGasEstimator\nParentTransaction\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nChildToParentMessage\nClasses​\nChildToParentMessage​\n\nBase functionality for Child-to-Parent messages\n\nExtended by​\nChildToParentMessageReader\nMethods​\nfromEvent()​\nstatic fromEvent<T>(\n   parentSignerOrProvider: T, \n   event: ChildToParentTransactionEvent, \nparentProvider?: Provider): ChildToParentMessageReaderOrWriter<T>\n\n\nInstantiates a new ChildToParentMessageWriter or ChildToParentMessageReader object.\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\tDescription\nparentSignerOrProvider\tT\t-\nevent\tChildToParentTransactionEvent\tThe event containing the data of the Child-to-Parent message.\nparentProvider?\tProvider\t-\nReturns​\n\nChildToParentMessageReaderOrWriter<T>\n\nSource​\n\nmessage/ChildToParentMessage.ts:76\n\ngetChildToParentEvents()​\nstatic getChildToParentEvents(\n   childProvider: Provider, \n   filter: object, \n   position?: BigNumber, \n   destination?: string, \n   hash?: BigNumber, \nindexInBatch?: BigNumber): Promise<ChildToParentTransactionEvent & object[]>\n\n\nGet event logs for ChildToParent transactions.\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nfilter\tobject\tBlock range filter\nfilter.fromBlock\tBlockTag\t-\nfilter.toBlock?\tBlockTag\t-\nposition?\tBigNumber\tThe batchnumber indexed field was removed in nitro and a position indexed field was added.\nFor pre-nitro events the value passed in here will be used to find events with the same batchnumber.\nFor post nitro events it will be used to find events with the same position.\ndestination?\tstring\tThe parent destination of the ChildToParent message\nhash?\tBigNumber\tThe uniqueId indexed field was removed in nitro and a hash indexed field was added.\nFor pre-nitro events the value passed in here will be used to find events with the same uniqueId.\nFor post nitro events it will be used to find events with the same hash.\nindexInBatch?\tBigNumber\tThe index in the batch, only valid for pre-nitro events. This parameter is ignored post-nitro\nReturns​\n\nPromise<ChildToParentTransactionEvent & object[]>\n\nAny classic and nitro events that match the provided filters.\n\nSource​\n\nmessage/ChildToParentMessage.ts:109\n\nChildToParentMessageReader​\n\nProvides read-only access for Child-to-Parent messages\n\nExtends​\nChildToParentMessage\nExtended by​\nChildToParentMessageWriter\nMethods​\ngetFirstExecutableBlock()​\ngetFirstExecutableBlock(childProvider: Provider): Promise<null | BigNumber>\n\n\nEstimates the Parent block number in which this Child-to-Parent tx will be available for execution. If the message can or already has been executed, this returns null\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nReturns​\n\nPromise<null | BigNumber>\n\nexpected Parent block number where the Child-to-Parent message will be executable. Returns null if the message can or already has been executed\n\nSource​\n\nmessage/ChildToParentMessage.ts:273\n\nstatus()​\nstatus(childProvider: Provider): Promise<ChildToParentMessageStatus>\n\n\nGet the status of this message In order to check if the message has been executed proof info must be provided.\n\nParameters​\nParameter\tType\nchildProvider\tProvider\nReturns​\n\nPromise<ChildToParentMessageStatus>\n\nSource​\n\nmessage/ChildToParentMessage.ts:237\n\nwaitUntilReadyToExecute()​\nwaitUntilReadyToExecute(childProvider: Provider, retryDelay: number): Promise<CONFIRMED | EXECUTED>\n\n\nWaits until the outbox entry has been created, and will not return until it has been. WARNING: Outbox entries are only created when the corresponding node is confirmed. Which can take 1 week+, so waiting here could be a very long operation.\n\nParameters​\nParameter\tType\tDefault value\tDescription\nchildProvider\tProvider\tundefined\t-\nretryDelay\tnumber\t500\t\nReturns​\n\nPromise<CONFIRMED | EXECUTED>\n\noutbox entry status (either executed or confirmed but not pending)\n\nSource​\n\nmessage/ChildToParentMessage.ts:252\n\nfromEvent()​\nstatic fromEvent<T>(\n   parentSignerOrProvider: T, \n   event: ChildToParentTransactionEvent, \nparentProvider?: Provider): ChildToParentMessageReaderOrWriter<T>\n\n\nInstantiates a new ChildToParentMessageWriter or ChildToParentMessageReader object.\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\tDescription\nparentSignerOrProvider\tT\t-\nevent\tChildToParentTransactionEvent\tThe event containing the data of the Child-to-Parent message.\nparentProvider?\tProvider\t-\nReturns​\n\nChildToParentMessageReaderOrWriter<T>\n\nInherited from​\n\nChildToParentMessage . fromEvent\n\nSource​\n\nmessage/ChildToParentMessage.ts:76\n\ngetChildToParentEvents()​\nstatic getChildToParentEvents(\n   childProvider: Provider, \n   filter: object, \n   position?: BigNumber, \n   destination?: string, \n   hash?: BigNumber, \nindexInBatch?: BigNumber): Promise<ChildToParentTransactionEvent & object[]>\n\n\nGet event logs for ChildToParent transactions.\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nfilter\tobject\tBlock range filter\nfilter.fromBlock\tBlockTag\t-\nfilter.toBlock?\tBlockTag\t-\nposition?\tBigNumber\tThe batchnumber indexed field was removed in nitro and a position indexed field was added.\nFor pre-nitro events the value passed in here will be used to find events with the same batchnumber.\nFor post nitro events it will be used to find events with the same position.\ndestination?\tstring\tThe parent destination of the ChildToParent message\nhash?\tBigNumber\tThe uniqueId indexed field was removed in nitro and a hash indexed field was added.\nFor pre-nitro events the value passed in here will be used to find events with the same uniqueId.\nFor post nitro events it will be used to find events with the same hash.\nindexInBatch?\tBigNumber\tThe index in the batch, only valid for pre-nitro events. This parameter is ignored post-nitro\nReturns​\n\nPromise<ChildToParentTransactionEvent & object[]>\n\nAny classic and nitro events that match the provided filters.\n\nInherited from​\n\nChildToParentMessage . getChildToParentEvents\n\nSource​\n\nmessage/ChildToParentMessage.ts:109\n\nChildToParentMessageWriter​\n\nProvides read and write access for Child-to-Parent messages\n\nExtends​\nChildToParentMessageReader\nConstructors​\nnew ChildToParentMessageWriter()​\nnew ChildToParentMessageWriter(\n   parentSigner: Signer, \n   event: ChildToParentTransactionEvent, \n   parentProvider?: Provider): ChildToParentMessageWriter\n\n\nInstantiates a new ChildToParentMessageWriter object.\n\nParameters​\nParameter\tType\tDescription\nparentSigner\tSigner\t-\nevent\tChildToParentTransactionEvent\tThe event containing the data of the Child-to-Parent message.\nparentProvider?\tProvider\t-\nReturns​\n\nChildToParentMessageWriter\n\nOverrides​\n\nChildToParentMessageReader.constructor\n\nSource​\n\nmessage/ChildToParentMessage.ts:296\n\nMethods​\nexecute()​\nexecute(childProvider: Provider, overrides?: Overrides): Promise<ContractTransaction>\n\n\nExecutes the ChildToParentMessage on Parent chain. Will throw an error if the outbox entry has not been created, which happens when the corresponding assertion is confirmed.\n\nParameters​\nParameter\tType\nchildProvider\tProvider\noverrides?\tOverrides\nReturns​\n\nPromise<ContractTransaction>\n\nSource​\n\nmessage/ChildToParentMessage.ts:325\n\ngetFirstExecutableBlock()​\ngetFirstExecutableBlock(childProvider: Provider): Promise<null | BigNumber>\n\n\nEstimates the Parent block number in which this Child-to-Parent tx will be available for execution. If the message can or already has been executed, this returns null\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nReturns​\n\nPromise<null | BigNumber>\n\nexpected Parent block number where the Child-to-Parent message will be executable. Returns null if the message can or already has been executed\n\nInherited from​\n\nChildToParentMessageReader . getFirstExecutableBlock\n\nSource​\n\nmessage/ChildToParentMessage.ts:273\n\nstatus()​\nstatus(childProvider: Provider): Promise<ChildToParentMessageStatus>\n\n\nGet the status of this message In order to check if the message has been executed proof info must be provided.\n\nParameters​\nParameter\tType\nchildProvider\tProvider\nReturns​\n\nPromise<ChildToParentMessageStatus>\n\nInherited from​\n\nChildToParentMessageReader . status\n\nSource​\n\nmessage/ChildToParentMessage.ts:237\n\nwaitUntilReadyToExecute()​\nwaitUntilReadyToExecute(childProvider: Provider, retryDelay: number): Promise<CONFIRMED | EXECUTED>\n\n\nWaits until the outbox entry has been created, and will not return until it has been. WARNING: Outbox entries are only created when the corresponding node is confirmed. Which can take 1 week+, so waiting here could be a very long operation.\n\nParameters​\nParameter\tType\tDefault value\tDescription\nchildProvider\tProvider\tundefined\t-\nretryDelay\tnumber\t500\t\nReturns​\n\nPromise<CONFIRMED | EXECUTED>\n\noutbox entry status (either executed or confirmed but not pending)\n\nInherited from​\n\nChildToParentMessageReader . waitUntilReadyToExecute\n\nSource​\n\nmessage/ChildToParentMessage.ts:252\n\nfromEvent()​\nstatic fromEvent<T>(\n   parentSignerOrProvider: T, \n   event: ChildToParentTransactionEvent, \nparentProvider?: Provider): ChildToParentMessageReaderOrWriter<T>\n\n\nInstantiates a new ChildToParentMessageWriter or ChildToParentMessageReader object.\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nParameters​\nParameter\tType\tDescription\nparentSignerOrProvider\tT\t-\nevent\tChildToParentTransactionEvent\tThe event containing the data of the Child-to-Parent message.\nparentProvider?\tProvider\t-\nReturns​\n\nChildToParentMessageReaderOrWriter<T>\n\nInherited from​\n\nChildToParentMessageReader . fromEvent\n\nSource​\n\nmessage/ChildToParentMessage.ts:76\n\ngetChildToParentEvents()​\nstatic getChildToParentEvents(\n   childProvider: Provider, \n   filter: object, \n   position?: BigNumber, \n   destination?: string, \n   hash?: BigNumber, \nindexInBatch?: BigNumber): Promise<ChildToParentTransactionEvent & object[]>\n\n\nGet event logs for ChildToParent transactions.\n\nParameters​\nParameter\tType\tDescription\nchildProvider\tProvider\t\nfilter\tobject\tBlock range filter\nfilter.fromBlock\tBlockTag\t-\nfilter.toBlock?\tBlockTag\t-\nposition?\tBigNumber\tThe batchnumber indexed field was removed in nitro and a position indexed field was added.\nFor pre-nitro events the value passed in here will be used to find events with the same batchnumber.\nFor post nitro events it will be used to find events with the same position.\ndestination?\tstring\tThe parent destination of the ChildToParent message\nhash?\tBigNumber\tThe uniqueId indexed field was removed in nitro and a hash indexed field was added.\nFor pre-nitro events the value passed in here will be used to find events with the same uniqueId.\nFor post nitro events it will be used to find events with the same hash.\nindexInBatch?\tBigNumber\tThe index in the batch, only valid for pre-nitro events. This parameter is ignored post-nitro\nReturns​\n\nPromise<ChildToParentTransactionEvent & object[]>\n\nAny classic and nitro events that match the provided filters.\n\nInherited from​\n\nChildToParentMessageReader . getChildToParentEvents\n\nSource​\n\nmessage/ChildToParentMessage.ts:109\n\nType Aliases​\nChildToParentMessageReaderOrWriter<T>​\ntype ChildToParentMessageReaderOrWriter<T>: T extends Provider ? ChildToParentMessageReader : ChildToParentMessageWriter;\n\n\nConditional type for Signer or Provider. If T is of type Provider then ChildToParentMessageReaderOrWriter<T> will be of type ChildToParentMessageReader. If T is of type Signer then ChildToParentMessageReaderOrWriter<T> will be of type ChildToParentMessageWriter.\n\nType parameters​\nType parameter\nT extends SignerOrProvider\nSource​\n\nmessage/ChildToParentMessage.ts:54\n\nEdit this page\nPrevious\nInbox\nNext\nChildToParentMessageClassic\nClasses\nChildToParentMessage\nExtended by\nMethods\nfromEvent()\ngetChildToParentEvents()\nChildToParentMessageReader\nExtends\nExtended by\nMethods\ngetFirstExecutableBlock()\nstatus()\nwaitUntilReadyToExecute()\nfromEvent()\ngetChildToParentEvents()\nChildToParentMessageWriter\nExtends\nConstructors\nnew ChildToParentMessageWriter()\nMethods\nexecute()\ngetFirstExecutableBlock()\nstatus()\nwaitUntilReadyToExecute()\nfromEvent()\ngetChildToParentEvents()\nType Aliases\nChildToParentMessageReaderOrWriter<T>\nType parameters\nSource\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/inbox/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\ninbox\nClasses​\nInboxTools​\n\nTools for interacting with the inbox and bridge contracts\n\nProperties​\nProperty\tModifier\tType\tDescription\nparentProvider\tprivate\tProvider\tParent chain provider\nMethods​\nestimateArbitrumGas()​\nprivate estimateArbitrumGas(childTransactionRequest: RequiredTransactionRequestType, childProvider: Provider): Promise<GasComponentsWithChildPart>\n\n\nWe should use nodeInterface to get the gas estimate is because we are making a delayed inbox message which doesn't need parent calldata gas fee part.\n\nParameters​\nParameter\tType\nchildTransactionRequest\tRequiredTransactionRequestType\nchildProvider\tProvider\nReturns​\n\nPromise<GasComponentsWithChildPart>\n\nSource​\n\ninbox/inbox.ts:156\n\nfindFirstBlockBelow()​\nprivate findFirstBlockBelow(blockNumber: number, blockTimestamp: number): Promise<Block>\n\n\nFind the first (or close to first) block whose number is below the provided number, and whose timestamp is below the provided timestamp\n\nParameters​\nParameter\tType\tDescription\nblockNumber\tnumber\t\nblockTimestamp\tnumber\t\nReturns​\n\nPromise<Block>\n\nSource​\n\ninbox/inbox.ts:87\n\nforceInclude()​\nforceInclude<T>(messageDeliveredEvent?: T, overrides?: Overrides): Promise<T extends ForceInclusionParams ? ContractTransaction : null | ContractTransaction>\n\n\nForce includes all eligible messages in the delayed inbox. The inbox contract doesn't allow a message to be force-included until after a delay period has been completed.\n\nType parameters​\nType parameter\nT extends undefined | ForceInclusionParams\nParameters​\nParameter\tType\tDescription\nmessageDeliveredEvent?\tT\tProvide this to include all messages up to this one. Responsibility is on the caller to check the eligibility of this event.\noverrides?\tOverrides\t-\nReturns​\n\nPromise<T extends ForceInclusionParams ? ContractTransaction : null | ContractTransaction>\n\nThe force include transaction, or null if no eligible message were found for inclusion\n\nSource​\n\ninbox/inbox.ts:356\n\ngetEventsAndIncreaseRange()​\nprivate getEventsAndIncreaseRange(\n   bridge: Bridge, \n   searchRangeBlocks: number, \n   maxSearchRangeBlocks: number, \nrangeMultiplier: number): Promise<FetchedEvent<MessageDeliveredEvent>[]>\n\n\nLook for force includable events in the search range blocks, if no events are found the search range is increased incrementally up to the max search range blocks.\n\nParameters​\nParameter\tType\tDescription\nbridge\tBridge\t\nsearchRangeBlocks\tnumber\t\nmaxSearchRangeBlocks\tnumber\t\nrangeMultiplier\tnumber\t-\nReturns​\n\nPromise<FetchedEvent<MessageDeliveredEvent>[]>\n\nSource​\n\ninbox/inbox.ts:256\n\ngetForceIncludableBlockRange()​\nprivate getForceIncludableBlockRange(blockNumberRangeSize: number): Promise<object>\n\n\nGet a range of blocks within messages eligible for force inclusion emitted events\n\nParameters​\nParameter\tType\tDescription\nblockNumberRangeSize\tnumber\t\nReturns​\n\nPromise<object>\n\nMember\tType\tValue\nendBlock\tnumber\tfirstEligibleBlock.number\nstartBlock\tnumber\t...\nSource​\n\ninbox/inbox.ts:186\n\ngetForceIncludableEvent()​\ngetForceIncludableEvent(\n   maxSearchRangeBlocks: number, \n   startSearchRangeBlocks: number, \nrangeMultiplier: number): Promise<null | ForceInclusionParams>\n\n\nFind the event of the latest message that can be force include\n\nParameters​\nParameter\tType\tDefault value\tDescription\nmaxSearchRangeBlocks\tnumber\tundefined\tThe max range of blocks to search in.\nDefaults to 3 * 6545 ( = ~3 days) prior to the first eligible block\nstartSearchRangeBlocks\tnumber\t100\tThe start range of block to search in.\nMoves incrementally up to the maxSearchRangeBlocks. Defaults to 100;\nrangeMultiplier\tnumber\t2\tThe multiplier to use when increasing the block range\nDefaults to 2.\nReturns​\n\nPromise<null | ForceInclusionParams>\n\nNull if non can be found.\n\nSource​\n\ninbox/inbox.ts:307\n\nsendChildSignedTx()​\nsendChildSignedTx(signedTx: string): Promise<null | ContractTransaction>\n\n\nSend Child Chain signed tx using delayed inbox, which won't alias the sender's address It will be automatically included by the sequencer on Chain, if it isn't included within 24 hours, you can force include it\n\nParameters​\nParameter\tType\tDescription\nsignedTx\tstring\tA signed transaction which can be sent directly to chain,\nyou can call inboxTools.signChainMessage to get.\nReturns​\n\nPromise<null | ContractTransaction>\n\nThe parent delayed inbox's transaction itself.\n\nSource​\n\ninbox/inbox.ts:401\n\nsignChildTx()​\nsignChildTx(txRequest: RequiredTransactionRequestType, childSigner: Signer): Promise<string>\n\n\nSign a transaction with msg.to, msg.value and msg.data. You can use this as a helper to call inboxTools.sendChainSignedMessage above.\n\nParameters​\nParameter\tType\tDescription\ntxRequest\tRequiredTransactionRequestType\t-\nchildSigner\tSigner\tethers Signer type, used to sign Chain transaction\nReturns​\n\nPromise<string>\n\nThe parent delayed inbox's transaction signed data.\n\nSource​\n\ninbox/inbox.ts:429\n\nEdit this page\nPrevious\nTransactionRequest\nNext\nChildToParentMessage\nClasses\nInboxTools\nProperties\nMethods\nestimateArbitrumGas()\nfindFirstBlockBelow()\nforceInclude()\ngetEventsAndIncreaseRange()\ngetForceIncludableBlockRange()\ngetForceIncludableEvent()\nsendChildSignedTx()\nsignChildTx()\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/dataEntities/address",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nAddress\nConstants\nErrors\nEvent\nMessage\nNetworks\nRetryableData\nRpc\nSignerOrProvider\nTransactionRequest\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\naddress\nClasses​\nAddress​\n\nEthereum/Arbitrum address class\n\nConstructors​\nnew Address()​\nnew Address(value: string): Address\n\n\nEthereum/Arbitrum address class\n\nParameters​\nParameter\tType\tDescription\nvalue\tstring\tA valid Ethereum address. Doesn't need to be checksum cased.\nReturns​\n\nAddress\n\nSource​\n\ndataEntities/address.ts:18\n\nProperties​\nProperty\tModifier\tType\tDescription\nvalue\treadonly\tstring\tA valid Ethereum address. Doesn't need to be checksum cased.\nMethods​\napplyAlias()​\napplyAlias(): Address\n\n\nFind the L2 alias of an L1 address\n\nReturns​\n\nAddress\n\nSource​\n\ndataEntities/address.ts:43\n\nundoAlias()​\nundoAlias(): Address\n\n\nFind the L1 alias of an L2 address\n\nReturns​\n\nAddress\n\nSource​\n\ndataEntities/address.ts:51\n\nEdit this page\nPrevious\nL1l3Bridger\nNext\nConstants\nClasses\nAddress\nConstructors\nnew Address()\nProperties\nMethods\napplyAlias()\nundoAlias()\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "assetBridger | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/assetBridger/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nAssetBridger\nErc20Bridger\nEthBridger\nL1l3Bridger\nDataEntities\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nassetBridger\nClasses​\nabstract AssetBridger<DepositParams, WithdrawParams>​\n\nBase for bridging assets from parent-to-child and back\n\nExtended by​\nErc20Bridger\nEthBridger\nType parameters​\nType parameter\nDepositParams\nWithdrawParams\nProperties​\nProperty\tModifier\tType\tDescription\nnativeToken?\treadonly\tstring\tIn case of a chain that uses ETH as its native/gas token, this is either undefined or the zero address\n\nIn case of a chain that uses an ERC-20 token from the parent network as its native/gas token, this is the address of said token on the parent network\nAccessors​\nnativeTokenIsEth​\nget protected nativeTokenIsEth(): boolean\n\n\nWhether the chain uses ETH as its native/gas token\n\nReturns​\n\nboolean\n\nSource​\n\nassetBridger/assetBridger.ts:71\n\nMethods​\ncheckChildNetwork()​\nprotected checkChildNetwork(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the child network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nSource​\n\nassetBridger/assetBridger.ts:60\n\ncheckParentNetwork()​\nprotected checkParentNetwork(sop: SignerOrProvider): Promise<void>\n\n\nCheck the signer/provider matches the parent network, throws if not\n\nParameters​\nParameter\tType\tDescription\nsop\tSignerOrProvider\t\nReturns​\n\nPromise<void>\n\nSource​\n\nassetBridger/assetBridger.ts:49\n\ndeposit()​\nabstract deposit(params: DepositParams): Promise<ParentContractTransaction<ParentTransactionReceipt>>\n\n\nTransfer assets from parent-to-child\n\nParameters​\nParameter\tType\tDescription\nparams\tDepositParams\t\nReturns​\n\nPromise<ParentContractTransaction<ParentTransactionReceipt>>\n\nSource​\n\nassetBridger/assetBridger.ts:79\n\nwithdraw()​\nabstract withdraw(params: WithdrawParams): Promise<ChildContractTransaction>\n\n\nTransfer assets from child-to-parent\n\nParameters​\nParameter\tType\tDescription\nparams\tWithdrawParams\t\nReturns​\n\nPromise<ChildContractTransaction>\n\nSource​\n\nassetBridger/assetBridger.ts:87\n\nEdit this page\nPrevious\nIndex\nNext\nErc20Bridger\nClasses\nabstract AssetBridger<DepositParams, WithdrawParams>\nExtended by\nType parameters\nProperties\nAccessors\nnativeTokenIsEth\nMethods\ncheckChildNetwork()\ncheckParentNetwork()\ndeposit()\nwithdraw()\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Migrating from v3 to v4 | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/migrate",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nMigrating from v3 to v4\nIntroduction​\n\n@arbitrum/sdk v4 introduces significant changes to improve support Orbit chains from Offchain Labs. This guide outlines the breaking changes to know before migrating your existing v3 code to v4.\n\nMajor Changes Overview​\nTerminology change from L1/L2 to parent/child\nNetwork types and functions updated\nUpdates to AssetBridger and Erc20Bridger classes\nChanges to Message classes\nDetailed Changes​\n1. Terminology change from L1/L2 to parent/child​\n\nMost instances of \"L1\" and \"L2\" have been replaced with \"parent\" and \"child\" respectively. This change reflects the more general parent-child relationship between chains in the Arbitrum ecosystem.\n\nIn most circumstances, when referring to a parent-child relationship between chains, the terms \"parent\" and \"child\" are used.\nThough, when referring explicitly to \"L1\", \"L2\", or \"L3\", those specific terms are still used.\n2. Network types and functions updated​\nThe L1Network is no longer required to be registered before bridging.\nOnly Arbitrum networks need to be registered.\nArbitrum networks are defined as Arbitrum One, Arbitrum testnets, and any Orbit chain.\nIf you need a full list of Arbitrum networks, you can use the new getArbitrumNetworks function.\nTo list all of the children of a network, use the new getChildrenForNetwork function.\nv3 Name\tv4 Name\nL2Network\tArbitrumNetwork\ngetL2Network\tgetArbitrumNetwork\nl2Networks\tgetArbitrumNetworks\naddCustomNetwork\tregisterCustomArbitrumNetwork\nNetwork\tremoved\nL1Network\tremoved\ngetL1Network\tremoved\ngetParentForNetwork\tremoved\nArbitrumNetwork type​\n\nNetwork type has been replaced with the ArbitrumNetwork type and some properties have been removed or renamed.\n\nv3 Name\tv4 Name\nchainID\tchainId\npartnerChainID\tparentChainId\nexplorerUrl\tremoved\nisArbitrum\tremoved\npartnerChainIDs\tremoved\nnitroGenesisBlock\tremoved\nnitroGenesisL1Block\tremoved\ndepositTimeout\tremoved\nblockTime\tremoved\nTokenBridge type​\n\nThe TokenBridge type within theArbitrumNetwork object has been updated.\n\nv3 Name\tv4 Name\nl1CustomGateway\tparentCustomGateway\nl1ERC20Gateway\tparentErc20Gateway\nl1GatewayRouter\tparentGatewayRouter\nl1MultiCall\tparentMultiCall\nl1ProxyAdmin\tparentProxyAdmin\nl1Weth\tparentWeth\nl1WethGateway\tparentWethGateway\nl2CustomGateway\tchildCustomGateway\nl2ERC20Gateway\tchildErc20Gateway\nl2GatewayRouter\tchildGatewayRouter\nl2Multicall\tchildMultiCall\nl2ProxyAdmin\tchildProxyAdmin\nl2Weth\tchildWeth\nl2WethGateway\tchildWethGateway\n3. Updates to AssetBridger and Erc20Bridger classes​\nAssetBridger Class Methods​\n\nThe AssetBridger class methods and properties have been renamed to reflect the new parent-child terminology.\n\nv3 Name\tv4 Name\nl2Network\tchildNetwork\ncheckL1Network\tcheckParentNetwork\ncheckL2Network\tcheckChildNetwork\nAssetBridger Class Method Parameters​\n\nThe objects passed to the class methods of classes that inherit from AssetBridger (EthBridger and Erc20Bridger) have been renamed.\n\nv3 Name\tv4 Name\nerc20L1Address\terc20ParentAddress\nl1Provider\tparentProvider\nl2Provider\tchildProvider\nl1Signer\tparentSigner\nl2Signer\tchildSigner\nErc20Bridger Class Methods​\nv3 Name\tv4 Name\ngetL1GatewayAddress\tgetParentGatewayAddress\ngetL2GatewayAddress\tgetChildGatewayAddress\ngetL2WithdrawalEvents\tgetWithdrawalEvents\ngetL1TokenContract\tgetParentTokenContract\ngetL1ERC20Address\tgetParentErc20Address\ngetL2TokenContract\tgetChildTokenContract\ngetL2ERC20Address\tgetChildErc20Address\nl1TokenIsDisabled\tisDepositDisabled\nl1Provider\tparentProvider\ngetL1GatewaySetEvents\tgetParentGatewaySetEvents\ngetL2GatewaySetEvents\tgetChildGatewaySetEvents\nErc20L1L3Bridger Class Methods​\nv3 Name\tv4 Name\ngetL2ERC20Address\tgetL2Erc20Address\ngetL3ERC20Address\tgetL3Erc20Address\n4. Changes to Message classes​\n\nMessage classes have been renamed and their methods updated:\n\nv3 Name\tv4 Name\nL1TransactionReceipt\tParentTransactionReceipt\nL1ContractTransaction\tParentContractTransaction\nL1ToL2Message\tParentToChildMessage\nL1ToL2MessageWriter\tParentToChildMessageWriter\nL1ToL2MessageReader\tParentToChildMessageReader\nL1ToL2MessageReaderClassic\tParentToChildMessageReaderClassic\nL1ToL2MessageStatus\tParentToChildMessageStatus\nL1ToL2MessageGasEstimator\tParentToChildMessageGasEstimator\nL2TransactionReceipt\tChildTransactionReceipt\nL2ContractTransaction\tChildContractTransaction\nL2ToL1Message\tChildToParentMessage\nL2ToL1MessageWriter\tChildToParentMessageWriter\nL2ToL1MessageReader\tChildToParentMessageReader\nL2ToL1MessageStatus\tChildToParentMessageStatus\nEthDepositStatus\tEthDepositMessageStatus\nEthDepositMessageWaitResult\tEthDepositMessageWaitForStatusResult\nL1ToL2MessageWaitResult\tParentToChildMessageWaitForStatusResult\nChildToParentMessageClassic​\nv3 Name\tv4 Name\ngetL2ToL1Events\tgetChildToParentEvents\nChildToParentChainMessageNitro​\nv3 Name\tv4 Name\ngetL2ToL1Events\tgetChildToParentEvents\nChildTransactionReceipt​\nv3 Name\tv4 Name\ngetL2ToL1Events\tgetChildToParentEvents\ngetL2ToL1Messages\tgetChildToParentMessages\nParentToChildMessage​\nv3 Name\tv4 Name\nEthDepositStatus\tEthDepositMessageStatus\nParentToChildMessageStatus​\nv3 Name\tv4 Name\nFUNDS_DEPOSITED_ON_L2\tFUNDS_DEPOSITED_ON_CHILD\nParentTransactionReceipt​\nv3 Name\tv4 Name\ngetL1ToL2MessagesClassic\tgetParentToChildMessagesClassic\ngetL1ToL2Messages\tgetParentToChildMessages\nParentEthDepositTransactionReceipt​\nv3 Name\tv4 Name\nwaitForL2\twaitForChildTransactionReceipt\nParentContractCallTransactionReceipt​\nv3 Name\tv4 Name\nwaitForL2\twaitForChildTransactionReceipt\nEdit this page\nPrevious\nIntroduction\nNext\nIndex\nIntroduction\nMajor Changes Overview\nDetailed Changes\n1. Terminology change from L1/L2 to parent/child\n2. Network types and functions updated\n3. Updates to AssetBridger and Erc20Bridger classes\n4. Changes to Message classes\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "index | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nUtils\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nindex\nModules​\nassetBridger/assetBridger\nassetBridger/erc20Bridger\nassetBridger/ethBridger\nassetBridger/l1l3Bridger\ndataEntities/address\ndataEntities/constants\ndataEntities/errors\ndataEntities/event\ndataEntities/message\ndataEntities/networks\ndataEntities/retryableData\ndataEntities/rpc\ndataEntities/signerOrProvider\ndataEntities/transactionRequest\ninbox/inbox\nmessage/ChildToParentMessage\nmessage/ChildToParentMessageClassic\nmessage/ChildToParentMessageNitro\nmessage/ChildTransaction\nmessage/ParentToChildMessage\nmessage/ParentToChildMessageCreator\nmessage/ParentToChildMessageGasEstimator\nmessage/ParentTransaction\nutils/arbProvider\nutils/byte_serialize_params\nutils/eventFetcher\nutils/lib\nutils/multicall\nutils/types\nEdit this page\nPrevious\nMigrating from v3 to v4\nNext\nAssetBridger\nModules\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "The AEP fee router: introduction | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/aep-fee-router-introduction",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nCustomize your chain's deployment\nAdditional configuration parameters\nUse a custom gas token\nCustomize your chain's precompiles\nCustomize your chain's behavior\nConfigure delayed inbox finality\nManage the fee collectors\nCustomize ArbOS version\nImplement Circle bridged USDC\nEnable fast withdrawals\nAEP fee router\nAEP fee router: overview\nSet up an AEP fee router\nCalculating AEP license fees\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nThe AEP fee router: introduction\nWhat is the Arbitrum expansion program?​\n\nThe Arbitrum Expansion Program (AEP) allows Orbit chains to deploy on any chain permissionlessly. As part of the AEP license, Orbit chains deployed outside of Arbitrum One and Arbitrum Nova must pay 10% of their Net Protocol Revenue to the Arbitrum DAO.\n\nThe Arbitrum Expansion Program and Developer Guild are initiatives launched in collaboration with Offchain Labs to promote the development of customized Arbitrum chains using the Orbit framework. The Expansion Program simplifies the process for teams to create Layer 2 (L2) and Layer 3 (L3) chains, offering self-service tools and customization options. Projects benefit from features like:\n\nDedicated block space\nCustom gas tokens\nFlexible governance.\n\nThese chains can settle to any chain relying on the Ethereum security model.\n\nThe Developer Guild incentivizes developers contributing to the Arbitrum codebase, with 2% of revenue from new chains going to a fund dedicated to this purpose. The Expansion Program is designed to align with Ethereum, encourage innovation, and enable projects to tailor the Arbitrum stack to their specific needs. The program also aims to streamline chain deployment, making it easier for developers to adopt Arbitrum's technology while contributing back to the community.\n\nAs an Orbit chain owner, you may have the following questions:\n\nHow do I send my AEP fees from my Orbit chain to the Arbitrum DAO?​\n\nArbitrum provides Orbit chains with easily deployable smart contracts that can streamline the transfer of AEP Fees into the Arbitrum DAO treasury. These contracts are known as AEP Fee Routers.\n\nWhat is net protocol revenue?​\n\nNet Protocol Revenue is equivalent to an Orbit chain's profit (revenue minus costs).\n\nHow can I ensure I'm complying with the AEP license?​\n\nThe Arbitrum Foundation will track compliance based on fees received through the AEP Fee Router.\n\nHow can I set up an AEP fee router on my Orbit chain?​\n\nYou can learn how to set up your AEP fee router in implementation guide.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nEnable fast withdrawals\nNext\nSet up an AEP fee router\nWhat is the Arbitrum expansion program?\nHow do I send my AEP fees from my Orbit chain to the Arbitrum DAO?\nWhat is net protocol revenue?\nHow can I ensure I'm complying with the AEP license?\nHow can I set up an AEP fee router on my Orbit chain?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Enable fast withdrawals on your Orbit chain | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/fast-withdrawals",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nCustomize your chain's deployment\nAdditional configuration parameters\nUse a custom gas token\nCustomize your chain's precompiles\nCustomize your chain's behavior\nConfigure delayed inbox finality\nManage the fee collectors\nCustomize ArbOS version\nImplement Circle bridged USDC\nEnable fast withdrawals\nAEP fee router\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nEnable fast withdrawals on your Orbit chain\n\nOptimistic Rollups must sustain a multi-day challenge period to allow time for fraud proofs. This delays finality for users and dApps, resulting in multi-day withdrawal times and cross-chain communication delays.\n\nFast withdrawals is a new configuration allowing Orbit chains to achieve fast finality. When an Orbit chain operates on Fast Withdrawals, its transactions will be processed by a committee of validators. Transactions reaching a unanimous vote across the committee will be immediately confirmed.\n\nThis will allow:\n\nSetting up a withdrawal frequency of any time period (up to 15 minutes)\nUsers' withdrawals confirmation on the parent chain at frequencies up to ~15 minutes\nCross-chain dApps to read the finalized state at the same rate as the fast withdrawal frequency\nRecommended configuration​\n\nWhile any Orbit chain can adopt Fast Withdrawals, we only recommend that fast withdrawals be adopted by AnyTrust chains with a minimum validator and DAC member requirement. We explain both these recommendations below:\n\nFast withdrawals for AnyTrust chains​\n\nAs AnyTrust chains are an optimum (an optimistic rollup using a separate data availability layer), AnyTrust chains are already placing a trust assumption on their Data Availability Committee (DAC) to provide the data needed for fraud proofs and recreating the chain.\n\nThe optimal setup for an AnyTrust chain is to have all DAC members also run validators as part of the fast withdrawals committee. This will leverage the existing trust assumption placed on the DAC operators such that enabling fast withdrawals does not add any new trusted parties.\n\nIt is possible for an Orbit Rollup to adopt fast withdrawals. However, it would technically no longer be a Rollup as the minimum trust assumption will shift to the trust placed in the Fast Confirmations committee.\n\nMinimum validator and DAC nodes​\n\nWe recommend that any Fast Withdrawals-enabled chain have at least three DAC members and three validators acting in the fast withdrawals committee. Given that fast withdrawals will enable confirmation of new Rollup state much faster than the usual 6.4-day challenge period (15 minutes for L2s and 15 seconds for L3s), it becomes even more important to have additional parties involved in validation to further reduce trust assumptions. This requirement can be be met with three total operators, who each run a single DAS node and a single validator.\n\nTechnical lower bound for fast withdrawals​\n\nOnce fast withdrawals is enabled, the committee will confirm transactions at the configured frequency. However, a higher network load can cause the fast withdrawals committee to experience slight delays from the configured rate.\n\nFor low-to-medium activity chains (< 1 Mgas/s), 15 seconds is considered to be the sustained lower bound for Fast Withdrawals.\nFor chains with higher throughput (>1 Mgas/s), the practical lower bound for fast withdrawals is between 1-2 minutes.\n\nChain owners and operators should be aware that the fast withdrawals committee may take longer to confirm new assertions under conditions with greater network load. This behavior is to be expected and does not interfere with the security or trust model of the fast withdrawals committee.\n\nPractical lower bounds concerning parent chain finality​\n\nWhile a fast withdrawals-enabled chain can be configured to finality in as little as 15 seconds, there are externalities on the parent chain and from cross-chain messaging layers that must be considered.\n\nFor an Ethereum-based Layer-2, we recommend that the fast withdrawal frequency remain above 12.8 minutes, which is the time for Ethereum to achieve finality. For non-Ethereum L1s, we similarly recommend staying above the accepted finality threshold specific to that L1.\n\nFor an Arbitrum One-based Layer-3, there are three tiers of finality to consider:\n\nSoft finality from the sequencer's confirmation of transaction inclusion (~250ms)\nSafe finality from batch inclusion after Arbitrum One's assertion is included in an Ethereum block.\nHard finality after the Ethereum block containing Arbitrum One's batch is finalized on Ethereum (~15 minutes)\n\nLayer-3 Orbit chains can make their own determination about what level of finality to accept. We consider it safe to rely on soft finality, which would practically enable an Orbit chain to configure fast withdrawals down to 15 seconds.\n\nAdoption instructions (example script)​\n\nTo enable the fast withdrawals feature, there are three actions to take:\n\nMake sure the chain is using nitro-contracts v2.1.0 or above\nActivate the fast withdrawals feature\nUpgrade the node software to nitro v3.1.2 or above\nUpgrading to nitro-contracts v2.1.0​\n\nAs mentioned above, the fast withdrawals feature is available for chains that are using nitro-contracts v2.1.0 or above, especially the RollupAdminLogic and the RollupUserLogic contracts. You can check what nitro-contracts version your chain is using by running the orbit versioner script.\n\nIf your chain is not running with nitro-contracts v2.1.0 or above, you’ll need to perform an upgrade to enable this version. The orbit versioner script will provide the upgrade paths needed to reach v2.1.0, but basically:\n\nIf the chain is running nitro-contracts v1.1.x, you need to upgrade first to v1.2.1.\nIf the chain is running nitro-contracts v1.2.1, you need to upgrade to v2.1.0.\n\nUpgrading to the new nitro-contracts version also requires updating the node software. For v2.1.0, validator nodes and the batch poster node should run nitro v3.1.2 or above.\n\nSuppose you’re upgrading your nitro-contracts from v1.2.1 to v2.1.0 and using the standard WASM module root (without customizations). In that case, there are action contracts available in the supported chains. If you’re using a customized nitro software, with a different WASM module root, you can still deploy the action contract referencing your modified WASM module root (pre and post upgrade).\n\nActivating fast withdrawals​\n\nOnce the chain runs nitro-contracts v2.1.0 or above, the new fast withdrawal parameters will be available in the RollupAdminLogic and the RollupUserLogic contracts.\n\nBoth the Orbit SDK and the Orbit actions repository provide configurable scripts to activate and configure fast withdrawals on an AnyTrust chain. You can use either of those to activate the feature. Both scripts perform the same actions.\n\nℹ️ Even though two scripts are available to activate Fast Withdrawals, you only need to execute one of them. Both scripts perform the same actions.\n\nOrbit SDK script\n\nThe Orbit SDK provides an example script to set up a fast withdrawal committee by performing the following operations:\n\nCreate a new n/n Safe wallet with the specified validators as signers\nAdd the specified validators to the Rollup validators allowlist\nSet the new Safe wallet as the anytrustFastConfirmer in the Rollup contract\nSet the new minimumAssertionPeriod if needed\nShow how to configure the batch poster and validator nodes\n\nTo configure the script, you need to specify the following environment variables:\n\nVariable Name\tDescription\nCHAIN_OWNER_PRIVATE_KEY\tPrivate key of the account with executor privileges in the UpgradeExecutor admin contract for the chain. It will be the deployer of the multi-sig Safe wallet.\nPARENT_CHAIN_ID\tChainId of the parent chain.\nROLLUP_ADDRESS\tAddress of the Rollup contract.\nFC_VALIDATORS\tArray of fast-withdrawal validators. They will be added as signers to the multisig Safe wallet and to the Rollup's validator allowlist. It is recommended that these are DAC members of the AnyTrust chain.\nMINIMUM_ASSERTION_PERIOD\tOptional parameter that defaults to 75 blocks (~15 minutes). Minimum number of blocks that have to pass in between assertions (measured in L1 blocks).\n\nFinally, follow these steps to execute the script (from the examples/setup-fast-withdrawal folder):\n\nInstall dependencies\nyarn install\n\nCreate a .env file and add the env vars\ncp .env.example .env\n\nRun the script\nyarn run dev\n\n\nOrbit actions script\n\nThe Orbit actions repository also provides an action script to activate fast withdrawals by performing the following operations:\n\nMake sure the \"Validate fast confirmation\" has not been enabled yet\nCreate a Safe contract for the fast confirmation committee\nSet the Safe contract as the fast confirmer on the Rollup\nSet the Safe contract as a validator on the Rollup\nSet setMinimumAssertionPeriod to 1 block to allow more frequent assertion\n\nTo configure the action script, you need to specify the following environment variables:\n\nVariable Name\tDescription\nUPGRADE_ACTION_ADDRESS\tAddress of the upgrade action to execute. A standard version is deployed in all supported chains. If you need to deploy your own action, execute the first step of this process.\nPARENT_UPGRADE_EXECUTOR_ADDRESS\tPrivate key of the account with executor privileges in the UpgradeExecutor admin contract on the parent chain. It will be the deployer of the multi-sig Safe wallet.\nPARENT_CHAIN_RPC\tRPC endpoint of the parent chain.\nROLLUP\tAddress of the Rollup contract.\nFAST_CONFIRM_COMMITTEE\tComma-separated list of fast-withdrawal validators. They must be allowlisted validators in the Rollup contract. They will be added as signers to the multisig Safe wallet. It is recommended that these are DAC members of the AnyTrust chain.\n\nFinally, follow these steps to execute the script (from the scripts/foundry/fast-confirm folder):\n\nInstall dependencies\nyarn install\n\nCreate a .env file and add the env vars\ncp .env.example .env\n\nExecute the action. The upgrade can be executed using  cast  CLI command (cast is a part of the Foundry tools), using the owner account (the one with executor rights on parent chain UpgradeExecutor) to send the transaction:\n(export $(cat .env | xargs) && cast send $PARENT_UPGRADE_EXECUTOR_ADDRESS \"execute(address, bytes)\" $UPGRADE_ACTION_ADDRESS $(cast calldata \"perform(address, address[])\" $ROLLUP \\[$FAST_CONFIRM_COMMITTEE\\]) --rpc-url $PARENT_CHAIN_RPC --account EXECUTOR)\n# use --account XXX / --private-key XXX / --interactive / --ledger to set the account to send the transaction from\n\n\nNOTE: If you have a multisig as executor, you can use the following command to create the payload for calling into the PARENT_UPGRADE_EXECUTOR:\n\n(export $(cat .env | xargs) && cast calldata \"execute(address, bytes)\" $UPGRADE_ACTION_ADDRESS $(cast calldata \"perform(address, address[])\" $ROLLUP \\[$FAST_CONFIRM_COMMITTEE\\]))\n\nConfigure fast withdrawal on nitro v3.1.2 or above​\n\nTo be able to use Fast Withdrawal on your chain, the batch poster and the validators of the chain need to be running nitro v3.1.2 or above.\n\nThe following parameters need to be configured in those nodes.\n\nBatch poster\n\nOption\tDescription\n--node.batch-poster.max-delay=0h15m0s\tSince batches need to be posted so validators can create and confirm assertions, the maximum delay should be set to an amount close to the minimumAssertionPeriod defined in the Rollup contract. Modify 0h15m0s to the configured value.\n\nValidators\n\nOption\tDescription\n--node.staker.enable-fast-confirmation=true\tEnables fast withdrawals in the validator node\n--node.staker.make-assertion-interval=0h15m0s\tSince assertions need to be created for them to be confirmed, the minimum interval to create these assertions should be set to an amount close to the minimumAssertionPeriod defined in the Rollup contract. Modify 0h15m0s to the configured value.\nEdit this page\nLast updated on Nov 20, 2024\nPrevious\nImplement Circle bridged USDC\nNext\nAEP fee router: overview\nRecommended configuration\nFast withdrawals for AnyTrust chains\nMinimum validator and DAC nodes\nTechnical lower bound for fast withdrawals\nPractical lower bounds concerning parent chain finality\nAdoption instructions (example script)\nUpgrading to nitro-contracts v2.1.0\nActivating fast withdrawals\nConfigure fast withdrawal on nitro v3.1.2 or above\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to adopt the bridged USDC standard on your Orbit chain | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/usdc-standard-bridge",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nCustomize your chain's deployment\nAdditional configuration parameters\nUse a custom gas token\nCustomize your chain's precompiles\nCustomize your chain's behavior\nConfigure delayed inbox finality\nManage the fee collectors\nCustomize ArbOS version\nImplement Circle bridged USDC\nEnable fast withdrawals\nAEP fee router\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to adopt the bridged USDC standard on your Orbit chain\n\nCircle’s Bridged USDC Standard is a specification and process for deploying a bridged form of USDC on EVM blockchains with optionality for Circle to seamlessly upgrade to native issuance in the future.\n\nWhy adopt the bridged USDC standard?​\n\nWhen USDC is bridged into an Orbit chain, the default path is to use the chain’s canonical gateway contracts for ERC-20s. By way of example, when a user bridges USDC from Arbitrum One to an Orbit chain, their Arbitrum One USDC tokens are locked into the Orbit chain’s parent side bridge, and a representative USDC token is minted to the user’s address on the Orbit chain, via the child side bridge.\n\nThe challenge with this user flow is twofold.\n\nNative vs. non-Native USDC: The USDC tokens issued by Circle (’native USDC’) are locked in the parent side bridge contract. Conversely, the USDC tokens on the Orbit chain aren’t native USDC but are collateralized by the locked tokens in the bridge. As such, Circle will not recognize these tokens across their product suite.\nFragmented UX: If Circle were to provide native support for USDC by deploying a USDC contract on the Orbit chain, there would be two forms of USDC on the chain (native and non-native USDC). This leads to a fragmented user experience, and users with non-native USDC would have to withdraw to the parent chain to be able to turn their tokens into native USDC.\n\nBy deploying the bridged USDC standard from the start, all USDC tokens that are bridged are locked in a gateway contract that can be adopted by Circle should a chain upgrade its USDC into native USDC. This allows USDC adoption on Orbit chains today without encountering either of the two problems above.\n\nHow to implement the bridged USDC Standard​\n\nWe provide a custom USDC gateway implementation (for parent and child chains) that follows the Bridged USDC Standard. These contracts can be used by new Orbit chains. This solution will NOT be used in existing Arbitrum chains that are governed by the DAO.\n\nOn a parent chain the contract L1USDCGateway is used in case the child chain uses ETH as native currency, or L1OrbitUSDCGateway in case the child chain uses a custom fee token.\nOn a child chain, L2USDCGateway is used.\nFor the USDC token contracts, Circle's reference implementation is used.\n\nThis page describes how to deploy a USDC bridge compatible with both the Orbit token bridge and Circle’s Bridged USDC Standard.\n\nSteps for a transition to native USDC issuance are also provided. Note that both Circle and the Orbit chain owner must agree to transition to native USDC issuance.\n\nRequirements​\nRecommended token bridge version 1.2.0\nNo additional dependencies with Nitro or Nitro contract version\n\nOther requirements:\n\nIt is assumed there is already a USDC token deployed and used on the parent chain.\nAlso, it is assumed that the standard Orbit chain ownership system is used, i.e., UpgradeExecutor is the owner of the ownable contracts, and there is an EOA or multi-sig that has the executor role on the UpgradeExecutor.\nRefer to the token bridge overview page for more information about the token bridge design and operational dynamics. You can learn more in our overview of gateways operating models.\nDeployment steps​\n\nThroughout the docs and code, the terms L1 and L2 are used interchangeably with parent chain and child chain. They have the same meaning, i.e., if an Orbit chain is deployed on top of ArbitrumOne, then ArbitrumOne is L1/parent chain, while Orbit is L2/child chain.\n\nYou can find more details by consulting the usdc bridge deployment script and its README.\n\nCheckout target code, install dependencies, and build\n\ncd token-bridge-contracts\nyarn install\nyarn build\n\n\nPopulate your .env file based on env.example in the project's root directory\n\nPARENT_RPC=\nPARENT_DEPLOYER_KEY=\nCHILD_RPC=\nCHILD_DEPLOYER_KEY=\nL1_ROUTER=\nL2_ROUTER=\nINBOX=\nL1_USDC=\n## OPTIONAL arg. If set, the script will register the gateway. Otherwise, it will store the transaction's payload in a file\nROLLUP_OWNER_KEY=\n\n\nRun the script\n\nyarn deploy:usdc-token-bridge\n\n\nThe script will do the following:\n\nload deployer wallets for L1 and L2\nregister L1 and L2 networks in SDK\ndeploy new L1 and L2 proxy admins\ndeploy bridged (L2) USDC using the Circle's implementation\ninit L2 USDC\ndeploy L1 USDC gateway\ndeploy L2 USDC gateway\ninit both gateways\nif ROLLUP_OWNER_KEY is provided, register the gateway in the router through the UpgradeExecutor\nif ROLLUP_OWNER_KEY is not provided, prepare calldata and store it in the registerUsdcGatewayTx.json file\nset minter role to L2 USDC gateway with max allowance\n\nNow, new USDC gateways can be used to deposit/withdraw USDC. Everything is now in place to support transition to native USDC issuance if Circle and the Orbit chain owner agree to it.\n\nTransitioning to native USDC​\n\nOnce a transition to native USDC is agreed upon, the following steps are required:\n\nL1 gateway owner pauses deposits on the parent chain by calling pauseDeposits()\nL2 gateway owner pauses withdrawals on the child chain by calling pauseWithdrawals()\nmaster minter removes the minter role from the child chain gateway\nNOTE: there should be no in-flight deposits when the minter role is revoked. If there are any, they should be finalized first. Anyone can do that by claiming the failed retryable tickets that execute a USDC deposit\nL1 gateway owner sets Circle's account as burner on the parent chain gateway using setBurner(address)\nL1 gateway owner reads the total supply of USDC on the child chain and then invokes setBurnAmount(uint256) on the parent/child gateway where the amount matches the total supply\nUSDC masterMinter gives the minter role with 0 allowance to the L1 gateway so that the burn can be executed\non the child chain, the L2 gateway owner calls the setUsdcOwnershipTransferrer(address) to set the account (provided and controlled by Circle), which will be able to transfer the bridged USDC ownership and proxy admin\nif not already owned by the gateway, the L2 USDC owner transfers ownership to the gateway, and proxy admin transfers admin rights to the gateway\nCircle uses the usdcOwnershipTransferrer account to trigger transferUSDCRoles(address), which will set the caller as USDC proxy admin and will transfer USDC ownership to the provided address\nCircle calls burnLockedUSDC() on the L1 gateway using the burner account to burn the burnAmount of USDC\nremaining USDC will be cleared off when remaining in-flight USDC withdrawals are executed, if any\nThe L1 gateway owner is trusted to not front-run this transaction to modify the burning amount\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nCustomize ArbOS version\nNext\nEnable fast withdrawals\nWhy adopt the bridged USDC standard?\nHow to implement the bridged USDC Standard\nRequirements\nDeployment steps\nTransitioning to native USDC\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to customize ArbOS on your Orbit chain | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/customize-arbos",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nCustomize your chain's deployment\nAdditional configuration parameters\nUse a custom gas token\nCustomize your chain's precompiles\nCustomize your chain's behavior\nConfigure delayed inbox finality\nManage the fee collectors\nCustomize ArbOS version\nImplement Circle bridged USDC\nEnable fast withdrawals\nAEP fee router\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to customize ArbOS on your Orbit chain\nCAUTION\nCustomizations require expertise​\n\nCustomizing your chain is a core benefit of building with Arbitrum Orbit. We strongly recommend that teams interested in customizations work alongside a partner with ArbOS and Nitro software expertise, such as a Rollup-as-a-Service team.\n\nWorking alongside an experienced Orbit operator can help your team navigate the complex tradeoff space of rollup customizations, which can include performance, security, and cost considerations. Offchain Labs is positioned to train and enable Rollup-as-a-Service in their work with clients to scale support to the Orbit ecosystem as a whole. As such, Offchain Labs does not necessarily have the capacity to review code changes made by individual Orbit chains.\n\nWe encourage you to leverage your in-house expertise, collaborate with expert partners, and allocate appropriate resources for both an initial implementation (including an audit) and ongoing maintenance and security management of your customization.\n\nCases where you may want to consider customizing your own ArbOS upgrade​\n\nWhen you want to make changes to your Nitro code that affect the State Transition Function, or STF (you may refer to the Customize STF docs), and\n\nIf your desired changes need to be made to a live and operational Orbit chain\n\nIf your changes meet both those 2 points, then you will need a custom ArbOS upgrade.\n\nAlso, if you made changes to a live and operational chain and want to upgrade them later in the future, then you will likely need an ArbOS upgrade to facilitate the upgrade.\n\nWhere should I insert ArbOS Upgrade related code?​\n\nBelow, you will find 4 examples of ArbOS-related code changes and, generally, how to make them:\n\n1. Add a new method to exsiting precompile on a specific ArbOS version:​\n\nAfter you add sayHi() to ArbSys.go according to the guide in customize precompile option 1, you need continue to modify precompile.go.\n\nFor example, the original code is:\n\nArbSys := insert(MakePrecompile(pgen.ArbSysMetaData, &ArbSys{Address: types.ArbSysAddress}))\narbos.ArbSysAddress = ArbSys.address\narbos.L2ToL1TransactionEventID = ArbSys.events[\"L2ToL1Transaction\"].template.ID\narbos.L2ToL1TxEventID = ArbSys.events[\"L2ToL1Tx\"].template.ID\n\n\nYou need to append the following code to it:\n\nArbSys := insert(MakePrecompile(pgen.ArbSysMetaData, &ArbSys{Address: types.ArbSysAddress}))\narbos.ArbSysAddress = ArbSys.address\narbos.L2ToL1TransactionEventID = ArbSys.events[\"L2ToL1Transaction\"].template.ID\narbos.L2ToL1TxEventID = ArbSys.events[\"L2ToL1Tx\"].template.ID\n// The arbos version control logic\nArbOwner.methodsByName[\"SayHi\"].arbosVersion = ${The arbos version you want to activate this method}\n\n\nIn this way, this method will be executed normally and return results only after you update ArbOS to the target version.\n\n2. Create a new precompile contract on a specific ArbOS version​\n\nAfter you add a new precompile named ArbHi according to the guide in customize precompile option 2 and make changes to precompile.go, you also need to make the following changes:\n\nArbHi := insert(MakePrecompile(pgen.ArbHiMetaData, &ArbHi{Address: types.ArbHiAddress})) // types.ArbHiAddress here is an example address\n// Set activate version to the precompile\nArbHi.arbosVersion = ${The arbos version you want to activate this precompile}\n// Set activate version to all method\nfor _, method := range ArbHi.methods {\n   method.arbosVersion = ${The arbos version you want to activate this precompile}\n}\n\n\nIn this way, ArbHi and all its methods will be activated after the ArbOS version you set.\n\n3. Create a new ArbOS state on a specific ArbOS version​\n\nAfter you add a new state myNumber according to the guide in customize precompile Option 5, you also need to rewrite UpgradeArbosVersion in arbosstate.go: Add your expected ArbOS version to the switch case statement of nextArbosVersion. Here we will take ArbOS V21 as an example:\n\nensure := func(err error) {\n    if err != nil {\n        message := fmt.Sprintf(\n            \"Failed to upgrade ArbOS version %v to version %v: %v\",\n            state.arbosVersion, state.arbosVersion+1, err,\n        )\n        panic(message)\n    }\n}\nnextArbosVersion := state.arbosVersion + 1\nswitch nextArbosVersion {\n    case 1:\n        //.....\n    case 2:\n        //....\n    //.....\n    case 21:\n        // Set your new ArbOS state value here\n        ensure(state.SetNewMyNumber(${random number}))\n    //....\n}\n\n\nHere, we will ensure that the initial value of $(a random number) after ArbOS is upgraded to V21.\n\nCAUTION\n\nIt should be noted that when you initialize the state (initial code is in customize precompile Option 5), you need to initialize it to 0 or null value first to avoid a potential re-org on your chain.\n\nAlso, please make sure your program cannot call the state.SetNewMyNumber or other functions may change the value of myNumber before ArbOS V21. To prevent this, if you are using an external call to the precompile contract to change the value, you can refer to point 1 or point 2 to set the activation time of the precompile contract method. If your nitro code needs to call this method to change the state, you can continue reading point 4.\n\n4. Any changes in the STF logic that will affect the final execution result​\n\nIf you change the logic in STF, it will cause the execution result of the transaction to be different, you need to keep the original execution logic and put the new logic into another branch. You can use an if else statement to control it.\n\nFor example, we change the SayHi return after upgrading the ArbOS version:\n\n// The method in ArbHi precompile\nfunc (con *ArbHi) SayHi(c ctx, evm mech) (string, error) {\n    if p.state.ArbOSVersion() >= ${The arbos you want to upgrade to} {\n        // Your new logic code\n        return \"hi, new ArbOS version\", nil\n    } else {\n        // The old logic code needs to be kept\n        return \"hi\", nil\n    }\n}\n\n\nIn the above code, we use precompiles as an example. Some logic might also affect the STF, such as the methods in block_process.go, internal_tx.go, tx_processor.go and so on. The aforementioned ArbOS control methods will be needed for interacting with different versions of the STF logic.\n\nBACKWARD COMPATIBILITY\n\nWasm module roots are backward compatible, so upgrading them before an ArbOS version upgrade will not disrupt your chain's functionality.\n\nUpgrade WASM Module Root on the parent chain​\n\nAfter you have made your custom ArbOS changes, you will need to update the WASM Module root recorded on the parent chain. This is because an Arbitrum chain may execute the validation and fraud proofs on the parent chain. Please continue reading customize stf for follow-up operations.\n\nSchedule ArbOS upgrade​\n\nAfter you add ArbOS version control to the Nitro code, you can update ArbOS. You can refer to the document ArbOS upgrade to upgrade. It is recommended that teams who opt to version control their custom ArbOS version choose an ArbOS version number that builds on top of the canonical releases shipped by Offchain Labs. As an example, if your team is customizing ArbOS 31, we recommend versioning your ArbOS version as ArbOS 32. It should be noted that if you set a higher ArbOS version as the upgrade target, all the features added between the current and target versions will be activated. For example, if your current version is ArbOS v18 and you set the target version to v25, all the features between v18 and v25 will be loaded.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nManage the fee collectors\nNext\nImplement Circle bridged USDC\nCustomizations require expertise\nCases where you may want to consider customizing your own ArbOS upgrade\nWhere should I insert ArbOS Upgrade related code?\n1. Add a new method to exsiting precompile on a specific ArbOS version:\n2. Create a new precompile contract on a specific ArbOS version\n3. Create a new ArbOS state on a specific ArbOS version\n4. Any changes in the STF logic that will affect the final execution result\nUpgrade WASM Module Root on the parent chain\nSchedule ArbOS upgrade\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to manage the fee collector addresses of your Orbit chain | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/manage-fee-collectors",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nCustomize your chain's deployment\nAdditional configuration parameters\nUse a custom gas token\nCustomize your chain's precompiles\nCustomize your chain's behavior\nConfigure delayed inbox finality\nManage the fee collectors\nCustomize ArbOS version\nImplement Circle bridged USDC\nEnable fast withdrawals\nAEP fee router\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to manage the fee collector addresses of your Orbit chain\n\nAs part of the activity of an Orbit chain, different fees are collected with every transaction. These fees are collected as a single amount (the transaction fees) but are internally split into different components depending on their purpose. Each component can also be transferred to a different fee collector address that can be configured on your chain.\n\nThis guide describes the different fees that are collected, and explains how to specify the fee collector address on your chain for each fee type.\n\nWhat fees are collected on an Orbit chain?​\n\nThere are four fee types that are collected on every transaction of an Orbit chain:\n\nOrbit base fee: fees paid for executing the transaction on the chain based on the minimum base price configured.\n\nOrbit surplus fee: if the chain is congested (i.e., the base price paid for the transaction is higher than the minimum base price), these fees account for executing the transaction on the chain based on any gas price paid above the minimum base price configured.\n\nParent chain base fee: relative fees paid for posting the transaction on the parent chain. This amount is calculated based on the transaction's estimated size and the current view of the parent chain's base fee.\n\nParent chain surplus fee: if configured, these are extra fees rewarded to the batch poster.\n\nYou can find more detailed information about these fee types in these pages:\n\nL2 fees for the Orbit base fee and surplus fee\nL1 fees for the Parent chain base fee and surplus fee\nHow to configure the fee collector addresses?​\n\nLet's now look at how to configure the collector addresses for each fee type.\n\nOrbit base fee​\n\nOrbit base fees are paid to the infraFeeAccount configured in your chain. You can retrieve the current configured address by calling the method getInfraFeeAccount() of the ArbOwnerPublic precompile. For example:\n\ncast call --rpc-url $ORBIT_CHAIN_RPC 0x000000000000000000000000000000000000006B \"getInfraFeeAccount() (address)\"\n\n\nNote: The ArbOwner precompile also has a getInfraFeeAccount() method that can be used, but only by the owner of the chain.\n\nAlternatively, you can use the Orbit SDK to retrieve the current address configured as infraFeeAccount, by calling the ArbOwner precompile:\n\nconst orbitChainClient = createPublicClient({\n    chain: <OrbitChainDefinition>,\n    transport: http(),\n}).extend(arbOwnerPublicActions);\n\nconst infraFeeAccount = await orbitChainClient.arbOwnerReadContract({\n    functionName: 'getInfraFeeAccount',\n});\n\n\nTo set a new infraFeeAccount, use the method setInfraFeeAccount(address) of the ArbOwner precompile. For example:\n\ncast send --rpc-url $ORBIT_CHAIN_RPC --private-key $OWNER_PRIVATE_KEY 0x0000000000000000000000000000000000000070 \"setInfraFeeAccount(address) ()\" $NEW_INFRAFEEACCOUNT_ADDRESS\n\n\nOr using the Orbit SDK:\n\nconst owner = privateKeyToAccount(<OwnerPrivateKey>);\nconst orbitChainClient = createPublicClient({\n    chain: <OrbitChainDefinition>,\n    transport: http(),\n}).extend(arbOwnerPublicActions);\n\nconst transactionRequest = await orbitChainClient.arbOwnerPrepareTransactionRequest({\n    functionName: 'setInfraFeeAccount',\n    args: [<NewInfraFeeAccountAddress>],\n    upgradeExecutor: false,\n    account: owner.address,\n});\n\nawait orbitChainClient.sendRawTransaction({\n    serializedTransaction: await owner.signTransaction(transactionRequest),\n});\n\nOrbit surplus fee​\n\nOrbit surplus fees are paid to the networkFeeAccount configured in your chain. You can retrieve the current configured address by calling the method getNetworkFeeAccount() of the ArbOwnerPublic precompile. For example:\n\ncast call --rpc-url $ORBIT_CHAIN_RPC 0x000000000000000000000000000000000000006B \"getNetworkFeeAccount() (address)\"\n\n\nNote: The ArbOwner precompile also has a getNetworkFeeAccount() method that can be used, but only by the owner of the chain.\n\nAlternatively, you can use the Orbit SDK to retrieve the current address configured as networkFeeAccount, by calling the ArbOwner precompile:\n\nconst orbitChainClient = createPublicClient({\n    chain: <OrbitChainDefinition>,\n    transport: http(),\n}).extend(arbOwnerPublicActions);\n\nconst networkFeeAccount = await orbitChainClient.arbOwnerReadContract({\n    functionName: 'getNetworkFeeAccount',\n});\n\n\nTo set a new networkFeeAccount, use the method setNetworkFeeAccount(address) of the ArbOwner precompile. For example:\n\ncast send --rpc-url $ORBIT_CHAIN_RPC --private-key $OWNER_PRIVATE_KEY 0x0000000000000000000000000000000000000070 \"setNetworkFeeAccount(address) ()\" $NEW_NETWORKFEEACCOUNT_ADDRESS\n\n\nOr using the Orbit SDK:\n\nconst owner = privateKeyToAccount(<OwnerPrivateKey>);\nconst orbitChainClient = createPublicClient({\n    chain: <OrbitChainDefinition>,\n    transport: http(),\n}).extend(arbOwnerPublicActions);\n\nconst transactionRequest = await orbitChainClient.arbOwnerPrepareTransactionRequest({\n    functionName: 'setNetworkFeeAccount',\n    args: [<NewNetworkFeeAccountAddress>],\n    upgradeExecutor: false,\n    account: owner.address,\n});\n\nawait orbitChainClient.sendRawTransaction({\n    serializedTransaction: await owner.signTransaction(transactionRequest),\n});\n\nParent chain base fee​\nARBAGGREGATOR CURRENTLY NOT SUPPORTED IN THE ORBIT SDK\n\nReading information from the ArgAggregator precompile or using it to set new information is currently not supported by the Orbit SDK but will be added soon. So, for now, this subsection will only show examples using cast call and cast send.\n\nParent chain base fees are paid to the fee collector of the active batch poster configured in your chain. The current configured batch posters can be obtained by calling the method getBatchPosters() of the ArbAggregator precompile. For example:\n\ncast call --rpc-url $ORBIT_CHAIN_RPC 0x000000000000000000000000000000000000006D \"getBatchPosters() (address[])\"\n\n\nThis list has to also be verified against the SequencerInbox contract living on the parent chain. This contract needs to have any of those addresses in its isBatchPoster mapping. To verify a specific address, you can check the mapping directly like this:\n\ncast call --rpc-url $PARENT_CHAIN_RPC $SEQUENCER_INBOX_ADDRESS \"isBatchPoster(address) (bool)\" $BATCH_POSTER_ADDRESS\n\n\nOnce you have the current batch poster, you can obtain the fee collector address configured for that batch poster by calling the method getFeeCollector(address) of the ArbAggregator precompile and passing the address of the batch poster.\n\ncast call --rpc-url $ORBIT_CHAIN_RPC 0x000000000000000000000000000000000000006D \"getFeeCollector(address) (address)\" $BATCH_POSTER_ADDRESS\n\n\nTo set a new fee collector for a specific batch poster, use the method setFeeCollector(address, address) of the ArbAggregator precompile and pass the address of the batch poster and the address of the new fee collector.\n\ncast send --rpc-url $ORBIT_CHAIN_RPC --private-key $OWNER_PRIVATE_KEY 0x000000000000000000000000000000000000006D \"setFeeCollector(address,address) ()\" $BATCH_POSTER_ADDRESS $NEW_FEECOLLECTOR_ADDRESS\n\n\nFinally, if you want to set a new batch poster, you can call the method addBatchPoster(address) of the of the ArbAggregator precompile and pass the address of the new batch poster, and later call the method setIsBatchPoster(address,bool) of the SequencerInbox contract on the parent chain.\n\ncast send --rpc-url $ORBIT_CHAIN_RPC --private-key $OWNER_PRIVATE_KEY 0x000000000000000000000000000000000000006D \"addBatchPoster(address) ()\" $NEW_BATCH_POSTER_ADDRESS\n\ncast send --rpc-url $PARENT_CHAIN_RPC --private-key $OWNER_PRIVATE_KEY $SEQUENCER_INBOX_ADDRESS \"setIsBatchPoster(address,bool) ()\" $NEW_BATCH_POSTER_ADDRESS true\n\n\nNote: When setting a new batch poster, its fee collector will be configured to the same address by default.\n\nParent chain surplus fee​\n\nParent chain surplus fees are paid to a specific L1RewardRecipient address that is configured individually per chain. The current fee collector address can be obtained by calling the method getL1RewardRecipient() of the ArbGasInfo precompile. For example:\n\ncast call --rpc-url $ORBIT_CHAIN_RPC 0x000000000000000000000000000000000000006C \"getL1RewardRecipient() (address)\"\n\n\nTo get the amount of rewards that are being paid to this fee collector, you can call the method getL1RewardRate() of the ArbGasInfo precompile. This function will return the amount of wei per gas unit paid to the L1RewardRecipient configured. For example:\n\ncast call --rpc-url $ORBIT_CHAIN_RPC 0x000000000000000000000000000000000000006C \"getL1RewardRate() (uint64)\"\n\n\nAlternatively, you can obtain this information using the Orbit SDK:\n\nconst orbitChainClient = createPublicClient({\n    chain: <OrbitChainDefinition>,\n    transport: http(),\n}).extend(arbGasInfoPublicActions);\n\nconst parentChainRewardRecipient = await orbitChainClient.arbGasInfoReadContract({\n    functionName: 'getL1RewardRecipient',\n});\n\nconst parentChainRewardRate = await orbitChainClient.arbGasInfoReadContract({\n    functionName: 'getL1RewardRate',\n});\n\n\nTo set a new L1RewardRecipient address, you can call the method setL1PricingRewardRecipient(address) of the ArbOwner precompile, and pass the address of the new reward recipient. For example:\n\ncast send --rpc-url $ORBIT_CHAIN_RPC --private-key $OWNER_PRIVATE_KEY 0x0000000000000000000000000000000000000070 \"setL1PricingRewardRecipient(address) ()\" $NEW_L1REWARDRECIPIENT_ADDRESS\n\n\nAlternatively, you can use the Orbit SDK to set the new address:\n\nconst owner = privateKeyToAccount(<OwnerPrivateKey>);\nconst orbitChainClient = createPublicClient({\n    chain: <OrbitChainDefinition>,\n    transport: http(),\n}).extend(arbOwnerPublicActions);\n\nconst transactionRequest = await orbitChainClient.arbOwnerPrepareTransactionRequest({\n    functionName: 'setL1PricingRewardRecipient',\n    args: [<NewL1RewardRecipientAddress>],\n    upgradeExecutor: false,\n    account: owner.address,\n});\n\nawait orbitChainClient.sendRawTransaction({\n    serializedTransaction: await owner.signTransaction(transactionRequest),\n});\n\n\nTo change the reward rate, you can use the method setL1PricingRewardRate(uint64) of the ArbOwner precompile and pass the amount of wei per gas unit to reward. For example:\n\ncast send --rpc-url $ORBIT_CHAIN_RPC --private-key $OWNER_PRIVATE_KEY 0x0000000000000000000000000000000000000070 \"setL1PricingRewardRate(uint64) ()\" $NEW_REWARD_RATE\n\n\nOr using the Orbit SDK:\n\nconst owner = privateKeyToAccount(<OwnerPrivateKey>);\nconst orbitChainClient = createPublicClient({\n    chain: <OrbitChainDefinition>,\n    transport: http(),\n}).extend(arbOwnerPublicActions);\n\nconst transactionRequest = await orbitChainClient.arbOwnerPrepareTransactionRequest({\n    functionName: 'setL1PricingRewardRate',\n    args: [<NewRewardRate>],\n    upgradeExecutor: false,\n    account: owner.address,\n});\n\nawait orbitChainClient.sendRawTransaction({\n    serializedTransaction: await owner.signTransaction(transactionRequest),\n});\n\nHow to use the fee distribution contracts?​\n\nFor now, we've described how to set the individual collector addresses for each fee type. Some chains may require multiple addresses to receive the collected fees of any of the available types. In those cases, there's the possibility of using a distributor contract that can gather all fees of a specific type and distribute those among multiple addresses.\n\nThis section shows how to configure a distributor contract to manage the fees of a specific type.\n\nDISTRIBUTOR CONTRACTS CURRENTLY NOT SUPPORTED IN THE ORBIT SDK\n\nCurrently, the Orbit SDK doesn't support deploying and configuring distribution contracts, but it will soon be added. So, for now, this section will only show examples using cast send.\n\nStep 1. Deploy the distributor contract​\n\nAn example implementation of a distributor contract can be found here. You'll have to deploy this contract on your Orbit chain.\n\nStep 2. Set the contract address as the desired fee type collector address​\n\nUse the instructions provided in the previous section to set the address of the deployed distributor contract as the collector of the desired fee type. For example, if you want the distributor contract to manage the Orbit surplus fees, set the networkFeeAccount to the address of the deployed contract.\n\nStep 3. Configure the recipients of fees in the contract​\n\nNow you can set the different addresses that will be receiving fees from that distributor contract. To do that, you can call the method setRecipients(address[], uint256[]) of the distributor contract, and specify the list of addresses that will be receiving fees, and the proportion of fees for each address.\n\nFor example, if you want to set two addresses as receivers, with the first one receiving 80% of the fees and the second one receiving 20% of the fees, you'll use the following parameters:\n\ncast send --rpc-url $ORBIT_CHAIN_RPC --private-key $OWNER_PRIVATE_KEY $DISTRIBUTOR_CONTRACT_ADDRESS \"setRecipients(address[],uint256[]) ()\" \"[$RECEIVER_1, $RECEIVER_2]\" \"[8000, 2000]\"\n\nStep 4. Trigger the distribution of fees​\n\nWith the recipients configured in the distributor contract, and with the contract having collected some fees, you can now trigger the distribution of fees to the recipients by using the method distributeRewards(address[], uint256[]) of the distributor contract, and specifying the list of addresses that are configured, and the proportion of fees for each address. The parameters passed must match the information that is set in the contract (i.e., you can't specify different addresses or proportions than what's been configured beforehand).\n\nFor example, if you want to distribute the fees to the two addresses specified before, you'll use the following parameters:\n\ncast send --rpc-url $ORBIT_CHAIN_RPC --private-key $OWNER_PRIVATE_KEY $DISTRIBUTOR_CONTRACT_ADDRESS \"distributeRewards(address[],uint256[]) ()\" \"[$RECEIVER_1, $RECEIVER_2]\" \"[8000, 2000]\"\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nConfigure delayed inbox finality\nNext\nCustomize ArbOS version\nWhat fees are collected on an Orbit chain?\nHow to configure the fee collector addresses?\nOrbit base fee\nOrbit surplus fee\nParent chain base fee\nParent chain surplus fee\nHow to use the fee distribution contracts?\nStep 1. Deploy the distributor contract\nStep 2. Set the contract address as the desired fee type collector address\nStep 3. Configure the recipients of fees in the contract\nStep 4. Trigger the distribution of fees\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/orbit-chain-finality",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nCustomize your chain's deployment\nAdditional configuration parameters\nUse a custom gas token\nCustomize your chain's precompiles\nCustomize your chain's behavior\nConfigure delayed inbox finality\nManage the fee collectors\nCustomize ArbOS version\nImplement Circle bridged USDC\nEnable fast withdrawals\nAEP fee router\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to configure delayed inbox finality\nChild chain transactions​\n\nGenerally, transactions executed through the sequencer on Orbit chains achieve finality equivalent to their parent chain once the relevant transaction data has been posted in a batch. This means that transactions on Orbit chains are considered final in minutes.\n\nParent chain → child chain transactions​\n\nMessages being sent through the delayed inbox of a parent chain as retryable tickets, including deposits through token bridges, are released by the sequencer once it has reasonable confidence of finality on the parent chain. For example, on an L2 chain settling to Ethereum, the sequencer will release delayed messages to the inbox after 40 blocks. Following this, the transaction must complete another finality period for the Ethereum transaction that promoted it to achieve finality.\n\nOrbit L3s may configure the finality of transactions executed through the delayed inbox to depend on different layers of finality. By default, Orbit chains will rely on the number of L1 block confirmations, effectively finalizing an L3 deposit as soon as L1 finalizes the batch posted by Arbitrum One or when a DACert is posted by Arbitrum Nova. This would be on the order of tens of minutes.\n\nHowever, in the instance of an L3 settling to Arbitrum One or Nova an L3 may also choose to rely only on L2 finality by configuring their sequencer as follows:\n\n--node.delayed-sequencer.use-merge-finality=false\n\n\nAdditionally, the delay in L3 finalization can be decreased to achieve extremely fast (<1 min) deposits by configuring the sequencer to wait for fewer L2 block confirmations:\n\n--node.delayed-sequencer.finalize-distance=1\n\n\nNote, however, that if you choose to enable fast bridging, a re-org of un-finalized blocks on the L3 may occur if Arbitrum One/Nova (or the settlement chain of choice) experiences a re-org.\n\nChild chain → parent chain transactions​\n\nNormally, outgoing transactions must wait until the assertion that includes their L2 message is confirmed (~one week) before a client can execute the message on L1. However, in the near future Anytrust chains will be able to leverage their DAC to enable fast confirmations of withdrawals through the native token bridge. By immediately confirming assertions that have been signed by the DAC, finality can be reduced to ~fifteen minutes.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nCustomize your chain's behavior\nNext\nManage the fee collectors\nChild chain transactions\nParent chain → child chain transactions\nChild chain → parent chain transactions\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/customize-precompile",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nCustomize your chain's deployment\nAdditional configuration parameters\nUse a custom gas token\nCustomize your chain's precompiles\nCustomize your chain's behavior\nConfigure delayed inbox finality\nManage the fee collectors\nCustomize ArbOS version\nImplement Circle bridged USDC\nEnable fast withdrawals\nAEP fee router\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to customize your Orbit chain's precompiles\nCAUTION\nCustomizations require expertise​\n\nCustomizing your chain is a core benefit of building with Arbitrum Orbit. We strongly recommend that teams interested in customizations work alongside a partner with ArbOS and Nitro software expertise, such as a Rollup-as-a-Service team.\n\nWorking alongside an experienced Orbit operator can help your team navigate the complex tradeoff space of rollup customizations, which can include performance, security, and cost considerations. Offchain Labs is positioned to train and enable Rollup-as-a-Service in their work with clients to scale support to the Orbit ecosystem as a whole. As such, Offchain Labs does not necessarily have the capacity to review code changes made by individual Orbit chains.\n\nWe encourage you to leverage your in-house expertise, collaborate with expert partners, and allocate appropriate resources for both an initial implementation (including an audit) and ongoing maintenance and security management of your customization.\n\nCAUTION\n\nThe guidance in this document will only work if you use eth_call to call the new precompiles. If you call them from other contracts or add non-view/pure methods, this approach will break the block validation.\n\nTo support these additional use-cases, follow the instructions described in How to customize your Orbit chain's behavior.\n\nThere are five primary ways to customize your chain's precompiles:\n\nAdd new methods to an existing precompile.\nCreate a new precompile.\nDefine a new event.\nCustomize gas usage for a specific method.\nCall and modify state.\nPrerequisites​\n\nClone the Nitro repository before you begin:\n\ngit clone --branch v3.2.1 <https://github.com/OffchainLabs/nitro.git>\ncd nitro\ngit submodule update --init --recursive --force\n\nOption 1: Add new methods to an existing precompile​\n\nUsing your favorite code editor, open an existing precompile from the precompiles implementation directory, /precompiles. We'll use ArbSys.go as an example. Open the corresponding Go implementation file (ArbSys.go) and add a simple SayHi method:\n\nfunc (con *ArbSys) SayHi(c ctx, evm mech) (string, error) {\n\treturn \"hi\", nil\n}\n\n\nThen, open the corresponding Solidity interface file (ArbSys.sol) from the precompiles interface directory, /src/precompiles, and add the required interface. Ensure that the method name on the interface matches the name of the function you introduced in the previous step, camelCased:\n\nfunction sayHi() external view returns(string memory);\n\n\nNext, follow the steps in How to customize your Orbit chain's behavior to build a modified Arbitrum Nitro node docker image and run it.\n\nINFO\n\nNote that the instructions provided in How to run a full node will not work with your Orbit node. See Optional parameters (Orbit) for Orbit-specific CLI flags.\n\nOnce your node is running, you can call ArbSys.sol either directly using curl, or through Foundry's cast call.\n\nCall your function directly using curl​\ncurl http://localhost:8449 \\\n-X POST \\\n-H \"Content-Type: application/json\" \\\n--data '{\"method\":\"eth_call\",\"params\":[{\"from\":null,\"to\":\"0x0000000000000000000000000000000000000064\",\"data\":\"0x0c49c36c\"}, \"latest\"],\"id\":1,\"jsonrpc\":\"2.0\"}'\n\n\nYou should see something like this:\n\n{\"jsonrpc\":\"2.0\",\"id\":1,\"result\":\"0x000000000000000000000000000000000000000000000000000000000000002000000000000000000000000000000000000000000000000000000000000000026869000000000000000000000000000000000000000000000000000000000000\"}\n\n\n0x6869 is the hex-encoded utf8 representation of hi, which you'll see embedded in the result hex string.\n\nCall your function using Foundry's cast call​\ncast call 0x0000000000000000000000000000000000000064 \"sayHi()(string)”\n\n\nYou should see something like this:\n\nhi\n\nOption 2: Create a new precompile​\n\nFirst, navigate to the precompiles implementation directory, /precompiles, and create a new precompile implementation file called ArbHi.go. We'll define a new method, and we'll give it an address:\n\npackage precompiles\n\n// ArbHi provides a friendly greeting to anyone who calls it.\ntype ArbHi struct {\n\tAddress addr // 0x11a, for example\n}\n\nfunc (con *ArbHi) SayHi(c ctx, evm mech) (string, error) {\n\treturn \"hi\", nil\n}\n\n\nThen, update precompile.go to register the new precompile under the Precompiles() method:\n\ninsert(MakePrecompile(pgen.ArbHiMetaData, &ArbHi{Address: hex(\"11a\")})) // 0x011a here is an example address\n\n\nNavigate to the precompiles interface directory, /src/precompiles, create ArbHi.sol, and add the required interface. Ensure that the method name on the interface matches the name of the function you introduced in the previous step, camelCased:\n\npragma solidity >=0.4.21 <0.9.0;\n\n/// @title Say hi.\n/// @notice just for test\n/// This custom contract will set on 0x000000000000000000000000000000000000011a since we set it in precompile.go.\ninterface ArbHi {\n    function sayHi() external view returns(string memory);\n}\n\n\nNext, follow the steps in How to customize your Orbit chain's behavior to build a modified Arbitrum Nitro node docker image and run it.\n\nINFO\n\nNote that the instructions provided in How to run a full node will not work with your Orbit node. See Optional parameters (Orbit) for Orbit-specific CLI flags.\n\nOnce your node is running, you can call ArbHi.sol either directly using curl, or through Foundry's cast call.\n\nCall your function directly using curl​\ncurl http://localhost:8449 \\\n-X POST \\\n-H \"Content-Type: application/json\" \\\n--data '{\"method\":\"eth_call\",\"params\":[{\"from\":null,\"to\":\"0x000000000000000000000000000000000000011a\",\"data\":\"0x0c49c36c\"}, \"latest\"],\"id\":1,\"jsonrpc\":\"2.0\"}'\n\n\nYou should see something like this:\n\n{\"jsonrpc\":\"2.0\",\"id\":1,\"result\":\"0x000000000000000000000000000000000000000000000000000000000000002000000000000000000000000000000000000000000000000000000000000000026869000000000000000000000000000000000000000000000000000000000000\"}\n\nCall your function using Foundry's cast call​\ncast call 0x000000000000000000000000000000000000011a \"sayHi()(string)”\n\n\nYou should see something like this:\n\nhi\n\nOption 3: Define a new event​\n\nWe'll reuse the Arbsys precompile from Option 1 above to demonstrate how to emit a simple Hi event from the SayHi method in ArbSys.sol.\n\nFirst, go to the precompiles implementation directory, find ArbSys.go, and edit the ArbSys struct:\n\n// ArbSys provides system-level functionality for interacting with L1 and understanding the call stack.\ntype ArbSys struct {\n\tAddress                 addr // 0x64\n\tL2ToL1Tx                func(ctx, mech, addr, addr, huge, huge, huge, huge, huge, huge, []byte) error\n\tL2ToL1TxGasCost         func(addr, addr, huge, huge, huge, huge, huge, huge, []byte) (uint64, error)\n\tSendMerkleUpdate        func(ctx, mech, huge, bytes32, huge) error\n\tSendMerkleUpdateGasCost func(huge, bytes32, huge) (uint64, error)\n\tInvalidBlockNumberError func(huge, huge) error\n\n\t// deprecated event\n\tL2ToL1Transaction        func(ctx, mech, addr, addr, huge, huge, huge, huge, huge, huge, huge, []byte) error\n\tL2ToL1TransactionGasCost func(addr, addr, huge, huge, huge, huge, huge, huge, huge, []byte) (uint64, error)\n\n\t// Add your customize event here:\n\tHi\t\t\t\t\t\t       func(ctx, mech, addr) error\n\t// This is needed and will tell you how much gas it will cost, the param is the same as your event but without the first two (ctx, mech), the return param is always (uint64, error)\n\tHiGasCost\t\t\t\t    func(addr) (uint64, error)\n}\n\n\nThen add the event to the SayHi method:\n\nfunc (con *ArbSys) SayHi(c ctx, evm mech) (string, error) {\n\terr := con.Hi(c, evm, c.caller)\n\treturn \"hi\", err\n}\n\n\nNow navigate to the precompiles interface directory, open Arbsys.sol, and add the required interface. Ensure that the event name on the interface matches the name of the function you introduced in ArbSys struct in the previous step:\n\nevent Hi(address caller);\n\n\nIf you want to index the parameter of the event (if you want to filter by that parameter in the future, for example), just add indexed to the Solidity interface:\n\nevent Hi(address indexed caller);\n\n\nOur function now emits an event, which means that when calling it, the state will change and a gas cost will be incurred. So we have to remove the view function behavior:\n\nfunction sayHi() external returns(string memory);\n\n\nNext, build Nitro by following the instructions in How to build Nitro locally. Note that if you've already built the Docker image, you still need run the last step to rebuild.\n\nRun Nitro with the following command:\n\ndocker run --rm -it  -v /some/local/dir/arbitrum:/home/user/.arbitrum -p 0.0.0.0:8547:8547 -p 0.0.0.0:8548:8548 offchainlabs/nitro-node:v3.2.1-d81324d --parent-chain.connection.url=<YourParentChainUrl> --chain.id=<YourOrbitChainId> --http.api=net,web3,eth,debug --http.corsdomain=* --http.addr=0.0.0.0 --http.vhosts=*\n\nINFO\n\nNote that the instructions provided in How to run a full node will not work with your Orbit node. See Optional parameters (Orbit) for Orbit-specific CLI flags.\n\nSend the transaction and get the transaction receipt​\n\nTo send a transaction to ArbSys, we need to include a gas cost, because the function is no longer a view/pure function:\n\ncast send 0x0000000000000000000000000000000000000064 \"sayHi()(string)\"\n\n\nCall eth_getTransactionReceipt with the returned transaction hash result. You should see something like this:\n\n{\"jsonrpc\":\"2.0\",\"id\":1,\"result\":{\"blockHash\":\"Your_blockHash\",\"blockNumber\":\"Your_blockNumber\",\"contractAddress\":null,\"cumulativeGasUsed\":\"0x680b\",\"effectiveGasPrice\":\"0x5f5e100\",\"from\":\"Your_address\",\"gasUsed\":\"0x680b\",\"gasUsedForL1\":\"0xe35\",\"l1BlockNumber\":\"l1_blockNumber\",\"logs\":[{\"address\":\"0x0000000000000000000000000000000000000064\",\"topics\":[\"0xa9378d5bd800fae4d5b8d4c6712b2b64e8ecc86fdc831cb51944000fc7c8ecfa\",\"0x000000000000000000000000{Your_address}\"],\"data\":\"0x\",\"blockNumber\":\"Your_blockNumber\",\"transactionHash\":\"Your_txHash\",\"transactionIndex\":\"0x1\",\"blockHash\":\"Your_blockHash\",\"logIndex\":\"0x0\",\"removed\":false}],\"logsBloom\":\"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000008000000000000000000000000000000000000000000000100000000000000040000000000000080004000000000000000000000000000000000000000100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000040000000000000000000000000000000004000000000000200000000000000000000000000000000000000000000000000000000000000000000000000000000000\",\"status\":\"0x1\",\"to\":\"0x0000000000000000000000000000000000000064\",\"transactionHash\":\"Your_txHash\",\"transactionIndex\":\"0x1\",\"type\":\"0x2\"}}\n\n\nNote the logs field within the transaction receipt:\n\n\"logs\":[\n         {\n            \"address\":\"0x0000000000000000000000000000000000000064\",\n            \"topics\":[\n               \"0xa9378d5bd800fae4d5b8d4c6712b2b64e8ecc86fdc831cb51944000fc7c8ecfa\",\n               \"0x000000000000000000000000{Your_address}\"\n            ],\n            \"data\":\"0x\",\n            \"blockNumber\":\"0x40\",\n            \"transactionHash\":\"{Your_txHash}\",\n            \"transactionIndex\":\"0x1\",\n            \"blockHash\":\"0x0b367d705002b3575db99354a0964c033f929f26f4442ed347e47ae43a8f28e4\",\n            \"logIndex\":\"0x0\",\n            \"removed\":false\n         }\n      ]\n\nOption 4: Customize gas usage for a specific method​\n\nThe above instructions demonstrate how you can define a new precompile function. However, if this new function is simply defined without performing gas collection within the function, your precompile will be vulnerable to Denial-of-Service (DOS) attacks. These attacks exploit the function by flooding it with excessive requests without bearing the computational cost.\n\nTo deter this type of attack, you can implement a gas collection mechanism within your precompile. The event itself doesn't need to specify the gas cost; the program will calculate the gas cost when the event's execution is initially triggered.\n\nIn addition to introducing gas costs where they don't exist, you can also customize gas costs where they're already being incurred. To demonstrate, consider the GetBalance method in ArbInfo.go:\n\n// GetBalance retrieves an account's balance\nfunc (con ArbInfo) GetBalance(c ctx, evm mech, account addr) (huge, error) {\n\tif err := c.Burn(params.BalanceGasEIP1884); err != nil {\n\t\treturn nil, err\n\t}\n\treturn evm.StateDB.GetBalance(account), nil\n}\n\n\nThe purpose of this method is to retrieve the balance of an address. As defined in EIP1884, the operation code (opcode) for obtaining the address balance has an associated gas cost of 700 gas. The function accounts for this cost by deducting the specified amount of gas, indicated by the protocol constant BalanceGasEIP1884, which is set to 700, through the call to c.Burn(int64).\n\nTo customize the gas cost, let's implement an alternative to GetBalance, called GetBalanceCustom:\n\n// GetBalance retrieves an account's balance\nfunc (con ArbInfo) GetBalanceCustom(c ctx, evm mech, account addr) (huge, error) {\n\tgasForBalanceCall := uint64(300)\n\tif err := c.Burn(gasForBalanceCall); err != nil {\n\t\treturn evm.StateDB.GetBalance(account), err\n\t}\n\treturn balance, nil\n}\n\n\nTo register this new precompile method, refer to Option 1 above.\n\nNext, build Nitro by following the instructions in How to build Nitro locally. Note that if you've already built the Docker image, you still need run the last step to rebuild.\n\nRun Nitro with the following command:\n\ndocker run --rm -it  -v /some/local/dir/arbitrum:/home/user/.arbitrum -p 0.0.0.0:8547:8547 -p 0.0.0.0:8548:8548 offchainlabs/nitro-node:v3.2.1-d81324d --parent-chain.connection.url=<YourParentChainUrl> --chain.id=<YourOrbitChainId> --http.api=net,web3,eth,debug --http.corsdomain=* --http.addr=0.0.0.0 --http.vhosts=*\n\nINFO\n\nNote that the instructions provided in How to run a full node will not work with your Orbit node. See Optional parameters (Orbit) for Orbit-specific CLI flags.\n\nSend the transaction and get the transaction receipt​\n\nIn order to obtain the gas used, we can use the eth_sendRawTransaction RPC method to test execution on the chain. First, call:\n\ncast send 0x0000000000000000000000000000000000000065 \"GetBalance()({Any_Address})\"\n\n\nThen, call:\n\ncast send 0x0000000000000000000000000000000000000065 \"GetBalanceCustom()({Any_Address})\"\n\n\nThe two responses will look like this, respectively:\n\nResult 1:\n\n{\n   \"jsonrpc\":\"2.0\",\n   \"id\":1,\n   \"result\":{\n      \"blockHash\":\"{Your_blockHash}\",\n      \"blockNumber\":\"0x15\",\n      \"contractAddress\":null,\n      \"cumulativeGasUsed\":\"0x638f\",\n      \"effectiveGasPrice\":\"0x5f5e100\",\n      \"from\":\"{Your_address}\",\n      \"gasUsed\":\"0x638f\",\n      \"gasUsedForL1\":\"0x9f5\",\n      \"l1BlockNumber\":\"0x979a02\",\n      \"logs\":[\n\n      ],\n      \"logsBloom\":\"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\",\n      \"status\":\"0x1\",\n      \"to\":\"0x0000000000000000000000000000000000000065\",\n      \"transactionHash\":\"{Your_txHash}\",\n      \"transactionIndex\":\"0x1\",\n      \"type\":\"0x2\"\n   }\n}\n\n\nResult 2:\n\n{\n   \"jsonrpc\":\"2.0\",\n   \"id\":1,\n   \"result\":{\n      \"blockHash\":\"{Your_blockHash}\",\n      \"blockNumber\":\"0x16\",\n      \"contractAddress\":null,\n      \"cumulativeGasUsed\":\"0x61ff\",\n      \"effectiveGasPrice\":\"0x5f5e100\",\n      \"from\":\"{Your_address}\",\n      \"gasUsed\":\"0x61ff\",\n      \"gasUsedForL1\":\"0x9f5\",\n      \"l1BlockNumber\":\"0x979a08\",\n      \"logs\":[\n\n      ],\n      \"logsBloom\":\"0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\",\n      \"status\":\"0x1\",\n      \"to\":\"0x0000000000000000000000000000000000000065\",\n      \"transactionHash\":\"{Your_txHash}\",\n      \"transactionIndex\":\"0x1\",\n      \"type\":\"0x2\"\n   }\n}\n\n\nHere we can see that the gas cost incurred by the execution of the first transaction is gasUsed - gasUsedForL1 = 22938. Similarly, the gas cost incurred by the execution of the second transaction is 22538. If you subtract the two, the result is 400, as expected.\n\nTo learn more about the gas cost model, see how to estimate gas.\n\nOption 5: Call and modify state​\n\nIn this example, we'll demonstrate how to read from and write to a precompile contract's ArbOS state.\n\nFirst, open the arbosstate.go file and locate the ArbosState structure. This is where ArbOS state is defined.\n\nDefine a state key called myNumber of type storage.StorageBackedUint64. You can find more types in storage.go:\n\ntype ArbosState struct {\n\t// Other states\n\tinfraFeeAccount        storage.StorageBackedAddress\n\tbrotliCompressionLevel storage.StorageBackedUint64 // brotli compression level used for pricing\n\tbackingStorage         *storage.Storage\n\tBurner                 burn.Burner\n\tmyNumber               storage.StorageBackedUint64 // this is what we added\n}\n\n\nNext, define the offset of your newly added state (tip: add it to the end so it won't affect other states):\n\nconst (\n\tversionOffset Offset = iota\n\tupgradeVersionOffset\n\tupgradeTimestampOffset\n\tnetworkFeeAccountOffset\n\tchainIdOffset\n\tgenesisBlockNumOffset\n\tinfraFeeAccountOffset\n\tbrotliCompressionLevelOffset\n\tmyNumberOffset // define the offset of your new state here\n)\n\n\nThen, initialize the state under the OpenArbosState and InitializeArbosState methods:\n\nOpenArbosState:\n\nreturn &ArbosState{\n\t\t// other states\n\t\tbackingStorage.OpenStorageBackedAddress(uint64(infraFeeAccountOffset)),\n\t\tbackingStorage.OpenStorageBackedUint64(uint64(brotliCompressionLevelOffset)),\n\t\tbackingStorage,\n\t\tburner,\n\t\tbackingStorage.OpenStorageBackedUint64(uint64(myNumberOffset)), // define your new state here\n\t}, nil\n\n\nInitializeArbosState:\n\n\t_ = sto.SetUint64ByUint64(uint64(versionOffset), 1) // initialize to version 1; upgrade at end of this func if needed\n\t_ = sto.SetUint64ByUint64(uint64(upgradeVersionOffset), 0)\n\t_ = sto.SetUint64ByUint64(uint64(upgradeTimestampOffset), 0)\n\t_ = sto.SetUint64ByUint64(uint64(myNumberOffset), 0) // initialize your new state around here\n\n\nNext, define your getter and setter::\n\nfunc (state *ArbosState) SetNewMyNumber(\n\tnewNumber uint64,\n) error {\n\treturn state.myNumber.Set(newNumber)\n}\n\nfunc (state *ArbosState) GetMyNumber() (uint64, error) {\n\treturn state.myNumber.Get()\n}\n\n\nNext, head back to the precompiles directory and create a new ArbHi.go (introduced in Option 2). This time, we'll add two new methods to read and write the ArbOS state:\n\npackage precompiles\n\n// ArbHi provides a friendly greeting to anyone who calls it.\ntype ArbHi struct {\n\tAddress addr // 0x11a, for example\n}\n\nfunc (con *ArbHi) SayHi(c ctx, evm mech) (string, error) {\n\treturn \"hi\", nil\n}\n\nfunc (con *ArbHi) GetNumber(c ctx, evm mech) (uint64, error) {\n\treturn c.State.GetMyNumber()\n}\n\nfunc (con *ArbHi) SetNumber(c ctx, evm mech, newNumber uint64) error {\n\treturn c.State.SetNewMyNumber(newNumber)\n}\n\n\nFollow the procedure detailed in Option 2 in order to add this new precompile contract, and then run your node.\n\nYour smart contract interface should look like this:\n\npragma solidity >=0.4.21 <0.9.0;\n\n/// @title Say hi.\n/// @notice just for test\n/// This custom contract will set on 0x000000000000000000000000000000000000011a since we set it in precompile.go.\ninterface ArbHi {\n    function sayHi() external view returns(string memory);\n    function getNumber() external view returns(uint64);\n    function setNumber(uint64) external;\n}\n\nSend the transaction and get the transaction receipt​\n\nTo send a transaction to ArbSys, we need to include a gas cost, because the function is no longer a view/pure function:\n\ncast send 0x000000000000000000000000000000000000011a \"setNumber()\" \"2\"\n\nGet results from foundry cast​\ncast call 0x000000000000000000000000000000000000011a \"getNumber()(uint64)”\n\n\nYou should see something like this:\n\n2\n\nIncorporate your changes to precompile into the ArbOS upgrade​\n\nIf you do not customize the precompile before launching your Orbit network, please continue to follow [customize arbos] to perform an ArbOS version control to avoid blockchain reorg.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nUse a custom gas token\nNext\nCustomize your chain's behavior\nCustomizations require expertise\nPrerequisites\nOption 1: Add new methods to an existing precompile\nCall your function directly using curl\nCall your function using Foundry's cast call\nOption 2: Create a new precompile\nCall your function directly using curl\nCall your function using Foundry's cast call\nOption 3: Define a new event\nSend the transaction and get the transaction receipt\nOption 4: Customize gas usage for a specific method\nSend the transaction and get the transaction receipt\nOption 5: Call and modify state\nSend the transaction and get the transaction receipt\nGet results from foundry cast\nIncorporate your changes to precompile into the ArbOS upgrade\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to customize your Orbit chain's behavior | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/customize-stf",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nCustomize your chain's deployment\nAdditional configuration parameters\nUse a custom gas token\nCustomize your chain's precompiles\nCustomize your chain's behavior\nConfigure delayed inbox finality\nManage the fee collectors\nCustomize ArbOS version\nImplement Circle bridged USDC\nEnable fast withdrawals\nAEP fee router\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to customize your Orbit chain's behavior\nCAUTION\nCustomizations require expertise​\n\nCustomizing your chain is a core benefit of building with Arbitrum Orbit. We strongly recommend that teams interested in customizations work alongside a partner with ArbOS and Nitro software expertise, such as a Rollup-as-a-Service team.\n\nWorking alongside an experienced Orbit operator can help your team navigate the complex tradeoff space of rollup customizations, which can include performance, security, and cost considerations. Offchain Labs is positioned to train and enable Rollup-as-a-Service in their work with clients to scale support to the Orbit ecosystem as a whole. As such, Offchain Labs does not necessarily have the capacity to review code changes made by individual Orbit chains.\n\nWe encourage you to leverage your in-house expertise, collaborate with expert partners, and allocate appropriate resources for both an initial implementation (including an audit) and ongoing maintenance and security management of your customization.\n\nIntroduction​\n\nBefore customizing your Orbit chain, it's important to understand what the State Transition Function (aka the STF) is. The STF defines how new blocks are produced from input messages (i.e. transactions). This guide is only necessary for changes that modify the State Transition Function. To customize other node behavior, such as RPC behavior or the sequencer's ordering policy, you can simply build your own node without worrying about the rest of this guide. However, changes that modify the STF require updating the fraud proving system to recognize the new behavior as correct. Otherwise, the fraud prover would side with unmodified nodes, which would win fraud proofs against your modified node.\n\nHere's some examples of modifications that affect the STF:\n\nAdding a new EVM opcode or precompile: This modifies the STF because a node with this change would disagree about the outcome of EVM execution compared to an unmodified Nitro node when the new opcode or precompile is invoked.\nRewarding the deployer of a smart contract with a portion of gas spent in the smart contract's execution: This modifies the STF because a node which has this change applied would disagree about the balance of the deployer after transactions. Such changes would lead to disagreements about block hashes compared to unmodified Nitro nodes.\n\nHere's some examples of modifications that don't affect the STF:\n\nAdding a new RPC method to query an address's balance across multiple blocks: This doesn't modify the STF because it doesn't change on-chain balances or block hashes.\nChanging the sequencer to order blocks by tip: The sequencer is trusted to order transactions in Arbitrum Nitro, and it can choose any ordering it wants. Nodes (and the fraud proofs) will simply accept the new transaction ordering as there is no single ordering they think is correct.\nModification compatibility with Arbitrum Nitro​\n\nSome potential modifications are incompatible with Arbitrum Nitro and would not result in a functioning blockchain. Here are some requirements for the Arbitrum Nitro State Transition Function:\n\nThe STF must be deterministic. For instance, if you gave an address a random balance using the Go randomness library, every node would disagree on the correct amount of balance and the blockchain would not function correctly. However, it is acceptable to take a non-deterministic path to a deterministic output. For instance, if you randomly shuffled a list of addresses, and then gave them each 1 Ether, that would be fine, because no matter how the list of addresses is shuffled the result is the same and all addresses are given 1 Ether.\nThe STF must not reach a new result for old blocks. For instance, if you have been running an Arbitrum Nitro chain for a while, and then you decide to modify the STF to not charge for gas, a new node that syncs the blockchain will reach a different result for historical blocks. It's also important to synchronize between nodes when an upgrade takes effect. A common mechanism for doing this is having an upgrade take effect at a certain timestamp, by which all nodes must be upgraded.\nThe STF must be \"pure\" and not use external resources. For instance, it must not use the filesystem, make external network calls, or launch processes. That's because the fraud proving system does not (and for the most part, cannot) support these resources. For instance, it's impossible to fraud prove what the result of an external network call is, because the fraud prover smart contracts on L1 are unable to do networking.\nThe STF must not carry state between blocks outside of the \"global state\". In practice this means persistent state must be stored within block headers or the Ethereum state trie. For instance, ArbOS stores all retryables in contract storage under a special ArbOS address.\nThe STF must not modify Ethereum state outside of a transaction. This is important to ensure that replaying old blocks reaches the same result, both for tracing and for validation. The ArbOS internal transaction is useful to modify state at the start of blocks.\nThe STF must reach a result in under a second. This is a rough rule, but for nodes to keep in sync it's highly recommended to keep blocks quick. It's also important for the fraud proofs that execution reliably finishes in a relatively short amount of time. A block gas limit of 32 million gas should safely fit within this limit.\nThe STF must not fail or panic. It's important that the STF always produces a new block, even if user input is malformed. For instance, if the STF receives an invalid transaction as input, it'll still produce an empty block.\nBuilding the modified node​\n\nTo modify the State Transition Function, you'll need to build a modified Arbitrum Nitro node Docker image. This guide covers how to build the node and enable fraud proofs by building a new replay binary.\n\nStep 1. Download the Nitro source code​\n\nClone the Nitro repository before you begin:\n\ngit clone --branch v3.2.1 https://github.com/OffchainLabs/nitro.git\ncd nitro\ngit submodule update --init --recursive --force\n\nStep 2. Apply modifications​\n\nNext, make your changes to the State Transition Function. For example, you could add a custom precompile.\n\nAfter this step, you should visit Customize ArbOS version to see if your changes need to upgrade the ArbOS version. If so, please continue follow that document to add an ArbOS upgrade logic to your code.\n\nStep 3. Run the node without fraud proofs​\n\nTo build the Arbitrum Nitro node image, you'll first need to install Docker. You can confirm if it's already setup by running docker version in a terminal. If not, try following Docker's getting started guide, or if you're on Linux, install Docker from your distribution's package manager and start the Docker service.\n\nOnce you have Docker installed, you can simply run docker build . --tag custom-nitro-node in the nitro folder to build your custom node.\n\nOnce you've built your new Nitro node image, you have to modify the configuration file of your node to add a new parameter, --node.staker.dangerous.without-block-validator, which disables fraud proof verification.\n\nTo do that, open your nodeConfig.json file (stored by default in the config folder) and add the new parameter inside the staker element:\n\n...\n\"staker\": {\n  ...\n  \"dangerous\": {\n    \"without-block-validator\": true\n  }\n  ...\n},\n...\n\n\nWith that, you have now two ways of running your node.\n\n1. Using the docker-compose file\n\nThis is the recommended way if you're running your Orbit chain locally through the provided docker-compose file. In docker-compose.yml, modify the Docker image used for the Nitro container:\n\n...\nnitro:\n  image: custom-nitro-node\n  ports:\n...\n\n\nAnd run docker compose up to run all of your containers.\n\n2. Use docker run to run your Nitro node only\n\nThis method will only run the customized Nitro node (i.e., it will not run Blockscout, or the DA server if you're using an AnyTrust chain). Use the following command:\n\ndocker run --rm -it -v /path/to/your/node/dir:/home/user/.arbitrum -p 0.0.0.0:8449:8449 custom-nitro-node --conf.file /home/user/.arbitrum/nodeConfig.json\n\nINFO\n\nNote that the instructions provided in How to run a full node will not work with your Orbit node. See Optional parameters (Orbit) for Orbit-specific CLI flags.\n\nOnce your node is running, you can try out your modifications to the State Transition Function and confirm they work as expected.\n\nStep 4. Enable fraud proofs​\n\nTo enable fraud proofs, you'll need to build the \"replay binary\", which defines the State Transition Function for the fraud prover. The replay binary (sometimes called the machine) re-executes the State Transition Function against input messages to determine the correct output block. It has three forms:\n\nThe replay.wasm binary is the Go replay binary compiled to WASM. It's used by the JIT validator to verify blocks against the fraud prover.\nThe machine.wavm.br binary is a compressed binary containing the Go replay binary and all its dependencies, compiled to WASM, then translated to the Arbitrum fraud proving variant WAVM. It's used by Arbitrator when actually entering a challenge and performing the fraud proofs, and has identical behavior to replay.wasm.\nThe WASM module root (stored in module-root.txt) is a 32 byte hash usually expressed in hexadecimal which is a merkelization of machine.wavm.br. The replay binary is much too large to post on-chain, so this hash is set in the L1 rollup contract to determine the correct replay binary during fraud proofs.\n\nTo run a validator node with fraud proofs enabled, the validator node's Docker image will need to contain all three of these versions of the replay binary.\n\n4.1 Build a dev image​\n\nThe simplest way to build a Docker image with the new replay binary is to build a dev image. These images contain a freshly built replay binary, but note that the replay binary and corresponding WASM module root will generally change when the code is updated, even if the State Transition Function has equivalent behavior. It's important that the validator's WASM module root matches the on-chain WASM module root, which is why this approach is harder to maintain. Over the longer term, you'll want to maintain a separate build of the replay binary that matches the one currently on-chain, usable by any node image.\n\nTo build the dev node image and get the WASM module root, run:\n\ndocker build . --target nitro-node-dev --tag custom-nitro-node-dev\ndocker run --rm --entrypoint cat custom-nitro-node-dev target/machines/latest/module-root.txt\n\n\nOnce you have the WASM module root, you can put it on-chain by calling setWasmModuleRoot(newWasmModuleRoot) through the upgradeExecutor contract's method executeCall() as the owner. To call this method, you need to set target as your rollup contract address. Ensure that targetCallData starts with 0x89384960 (this is the signature of setWasmModuleRoot(byte32)), and that it's followed by your WASM module root. The upgradeExecutor contract address and rollup contract address can be found in the chain deployment info JSON. You can confirm that the WASM module root was updated by calling wasmModuleRoot() on the rollup contract.\n\nOnce you have set the new WASM module root on-chain, you can re-enable fraud proofs and run your node.\n\nTo re-enable fraud proofs, open your nodeConfig.json file again, and remove the \"dangerous\" section (containing the without-block-validator property) that you previously added.\n\nAfter that, you'll have, again, two ways of running your node.\n\n1. Using the docker-compose file\n\nAs mentioned before, this is the recommended way if you're running your Orbit chain locally through the provided docker-compose file. In docker-compose.yml, modify the Docker image used for the Nitro container. Notice that we'll now use the custom-nitro-node-dev you just created:\n\n...\nnitro:\n  image: custom-nitro-node-dev\n  ports:\n...\n\n\nAnd run docker compose up to run all of your containers.\n\n2. Use docker run to run your Nitro node only\n\nThis method will only run the customized Nitro node (i.e., it will not run Blockscout, or the DA server if you're using an AnyTrust chain). Use the following command:\n\ndocker run --rm -it -v /path/to/your/node/dir:/home/user/.arbitrum -p 0.0.0.0:8449:8449 custom-nitro-node-dev --conf.file /home/user/.arbitrum/nodeConfig.json\n\n4.2 Preserving the replay binary​\n\nThe primary issue with simply using a nitro-node-dev build is that, whenever the code changes at all, the replay binary will also change.\n\nIf the node is missing the replay binary corresponding to the on-chain WASM module root, it will be unable to act as a validator. Therefore, when releasing new node Docker images it's important to include the currently on-chain WASM module root.\n\nTo do that, you'll need to first extract the replay binary from the nitro-node-dev Docker image built earlier:\n\ndocker run --rm --name replay-binary-extractor --entrypoint sleep custom-nitro-node-dev infinity\ndocker cp replay-binary-extractor:/home/user/target/machines/latest extracted-replay-binary\ndocker stop replay-binary-extractor\ncat extracted-replay-binary/module.root\nmv extracted-replay-binary \"target/machines/$(cat extracted-replay-binary/module.root)\"\n\n\nThese commands will output the new WASM module root, and create the directory target/machines/<wasm module root>. There you'll find the three versions of the replay binary mentioned earlier: replay.wasm, machine.wavm.br, and module-root.txt, along with some other optional files. Now that you've extracted the replay binary, there are two ways to add it to future Docker images, including non-dev image builds. You can either keep it locally and copy it in, or host it on the web.\n\nOption 1: Store the extracted replay binary locally​\n\nNow that we've extracted the replay binary, we can modify the Dockerfile to copy it into new Docker builds. Edit the Dockerfile file in the root of the nitro folder, and after all the RUN ./download-machines.sh ... lines, add:\n\nCOPY target/machines/<wasm module root> <wasm module root>\nRUN ln -sfT <wasm module root> latest\n\n\nReplace each <wasm module root> with the WASM module root you got earlier.\n\nOption 2: Host the replay binary on the web​\n\nTo support building the Docker image on other computers without this local machine directory, you'll need to either commit the machine to git, or preferably, host the replay binary on the web.\n\nTo host the replay binary on the web, you'll need to host the replay.wasm and machine.wavm.br files somewhere. One good option is GitHub releases, but any hosting service works.\n\nOnce you have those two files hosted, instead of the COPY and RUN command mentioned in option 1, you'll need to add these new lines to the Dockerfile file in the root of the nitro folder, after all the RUN ./download-machines.sh ... lines:\n\nRUN wasm_module_root=\"<wasm module root>\" && \\\n    mkdir \"$wasm_module_root\" && \\\n    wget <url of replay.wasm> -O \"$wasm_module_root/replay.wasm\" && \\\n    wget <url of machine.wavm.br> -O \"$wasm_module_root/machine.wavm.br\" && \\\n    echo \"$wasm_module_root\" > \"$wasm_module_root/module-root.txt\" && \\\n    ln -sfT \"$wasm_module_root\" latest\n\n\nReplace the <wasm module root> with the WASM module root you got earlier, the <url of replay.wasm> with the direct link to the replay.wasm file (it must be a direct link to the file and not just a download site), and the <url of machine.wavm.br> with the direct link to the machine.wavm.br file.\n\nStep 5. Verify the fraud proofs​\n\nIn theory, fraud proofs should now be working with your newly built Docker images. Make some transactions on your new blockchain, test out your modifications to the State Transition Function, wait for a batch to be posted, and you should be seeing \"validation succeeded\" log lines!\n\nIf you see \"Error during validation\", then the replay binary is likely not up-to-date with your modifications to the State Transition Function. Ensure that the replay binary is freshly built, not missing any modifications, and that the WASM module root set in the rollup contract matches your replay binary.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nCustomize your chain's precompiles\nNext\nConfigure delayed inbox finality\nCustomizations require expertise\nIntroduction\nModification compatibility with Arbitrum Nitro\nBuilding the modified node\nStep 1. Download the Nitro source code\nStep 2. Apply modifications\nStep 3. Run the node without fraud proofs\nStep 4. Enable fraud proofs\nStep 5. Verify the fraud proofs\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/use-a-custom-gas-token",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nCustomize your chain's deployment\nAdditional configuration parameters\nUse a custom gas token\nCustomize your chain's precompiles\nCustomize your chain's behavior\nConfigure delayed inbox finality\nManage the fee collectors\nCustomize ArbOS version\nImplement Circle bridged USDC\nEnable fast withdrawals\nAEP fee router\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to use a custom gas token on your Orbit chain\n\nWhen deploying your AnyTrust Orbit chain you have the option of using a custom gas token, different than ETH, that is natively used for gas payments on the network. When choosing this option, there are certain requirements that the token needs to comply with, as well as certain chain configuration that needs to be adjusted. This guide covers this information.\n\nRequirements of the custom gas token​\n\nThe main requirements for a custom gas token is that it must be an ERC-20 token, and it must be natively deployed on the parent chain. During chain deployment, the gas token is \"natively bridged\" and then properly configured as the native gas token on the Orbit chain.\n\nThere are other important considerations to keep in mind when deciding to use a custom gas token. Restrictions on the ERC-20 token include:\n\nThe token can't be rebasing or have a transfer fee.\nThe token must not revert on transfers of 0 value (as per standard implementations).\nThe token must only be transferrable via a call to the token address itself.\nThe token must only be able to set allowance via a call to the token address itself.\nThe token must not have a callback on transfer, and more generally a user must not be able to make a transfer to themselves revert.\nINFO\n\nWhile certain restrictions are in place today (see above), some of them may be removed in upcoming releases of the custom gas token feature. Please reach out to the Offchain Labs team with any questions or requests for additions to the custom gas token feature.\n\nConfiguration of the Orbit chain when using a custom gas token​\n\nThere are several parameter changes required to ensure proper functioning of an Orbit chain configured to use a custom gas token.\n\nAfter deploying the chain, you must reset the base fees of the parent chain by calling the following functions in the ArbOwner precompile:\n\nSetL1PricePerUnit, setting pricePerUnit to 0\nSetL1PricingRewardRate, setting perUnitReward to 0\n\nNote: these methods use L1 to refer to the parent chain of the Orbit chain.\n\nThese parameter changes are strongly recommended to avoid charging users for a non-existent parent chain's base fee. The impact of not doing this is that Nitro will apply a parent chain's fee to all transactions. As Nitro assumes the native asset is ETH, all fees are expected to be denominated in ETH. This has the consequence of overcharging users for parent chain fees in native tokens that are more expensive than ETH (for example, if you use wrapped BTC as the custom gas token). In the case for tokens with prices much lower than ETH, the impact is far less pronounced.\n\nIn either case we strongly recommend taking these steps to avoid any issues with chain economics. You can read more about how Nitro manages fees in Gas and fees.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nAdditional configuration parameters\nNext\nCustomize your chain's precompiles\nRequirements of the custom gas token\nConfiguration of the Orbit chain when using a custom gas token\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/reference/additional-configuration-parameters",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nCustomize your chain's deployment\nAdditional configuration parameters\nUse a custom gas token\nCustomize your chain's precompiles\nCustomize your chain's behavior\nConfigure delayed inbox finality\nManage the fee collectors\nCustomize ArbOS version\nImplement Circle bridged USDC\nEnable fast withdrawals\nAEP fee router\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nAdditional configuration parameters: Orbit chains\n\nThe following configuration parameters can be used when deploying or managing your Orbit chain:\n\nParameter\tDescription\tHow to set\nExtra challenge period blocks\tAmount of time to wait before a challenge period expires. Like the challenge period parameter, this is measured in blocks on the underlying L1 chain, not the base (L2) chain. The default for this parameter is 200 blocks, or roughly 40 minutes.\tEither in the extraChallengeTimeBlocks field in the RollupCreator config, or by calling Rollup.setExtraChallengeTimeBlocks().\nLoser stake escrow\tThe address where funds staked by a validator that has lost a challenge are sent to be escrowed. It is recommended that this be set to an address that is controlled by the chain owners or to the burn address if the desire is for escrowed funds to be lost.\tEither in the loserStakeEscrow field in the RollupCreator config, or by calling Rollup.setLoserStakeEscrow().\nWASM module root\tHash of the WASM module root to be used when validating. The WASM module root is a 32 byte hash usually expressed in hexadecimal which is a merkelization of the replay binary, which is too large to be posted on-chain. This hash is set in the L1 rollup contract to determine the correct replay binary during fraud proofs. Unless the STF has been customized, the default WASM module root in the latest consensus release should be used.\tEither in the wasmModuleRoot field in the RollupCreator confid, or by calling Rollup.setWasmModuleRoot().\nGas speed limit\tTarget gas usage per second, over which the congestion mechanism activates. This parameter is set to 7 million on Arbitrum One and Nova, and alterations to this should be considered carefully, as setting it too high may resuly in state bloat that impacts the performance of the chain.\tCall ArbOwner.setSpeedLimit() passing in the maximum number of gas units to be executed per second.\nBlock gas limit\tMaximum amount of gas that can be consumed by all of the transactions within a block. On Arbitrum One this is set to 30 million. It can comfortably be set higher, but may harm UX as the processing time of a block will increase correspondingly.\tCall ArbOwner.setMaxTxGasLimit() passing in the maximum number of gas units to be executed per block and transaction.\nGas price floor\tMinimum gas price and is defaulted to 0.1 gwei. This can be set lower or higher as needed, and will impact the willingness of users to transact on the network.\tEither in the minL2BaseFee field in the orbit setup script config or by calling ArbOwner.setMinimumL2BaseFee() passing in the minimum base fee in wei.\nNetwork fee account\tAccount that will receive the L2 surplus fees. It is recommended this is set to an address controlled by the chain owners, or the burn address if fees are intended to be burned. If set to zero, this defaults to the owner address.\tEither in the networkFeeReceiver field in the orbit setup script config or by calling ArbOwner.setNetworkFeeAccount().\nInfrastructure fee account\tAccount that will receive the L2 base fees. It is recommended this is set to an address controlled by the chain owners, or the burn address if fees are intended to be burned. If set to zero, this defaults to the owner address.\tEither in the infrastructureFeeCollector field in the orbit setup script config or by calling ArbOwner.setInfraFeeAccount().\nL1 pricing reward recipient\tAddress that will receive the rewards from the L1 fees. It is recommended this is set to an address controlled by the chain owners, or the burn address if fees are intended to be burned. By default, this is set to the owner address.\tCall ArbOwner.setL1PricingRewardRecipient().\nL1 pricing reward per unit (rate)\tAmount of rewards per unit to send to the L1 pricing reward recipient (multiplied by the unitsAllocated). The default for this parameter is 15 wei.\tCall ArbOwner.setL1PricingRewardRate() passing in the amount of wei per unit to reward.\nSequencer inbox maximum time variation\tBoundaries of the sequencer to manipulate blocks and timestamps. The default values are as follows, and are set as such on Arbitrum One:\ndelayBlocks: 5760\nfutureBlocks: 12\ndelaySeconds: 86400\nfutureSeconds: 3600\n\tEither in the sequencerInboxMaxTimeVariation field in the RollupCreator config or by calling SequencerInbox.setMaxTimeVariation on the parent chain.\nForce-include period\tLength of the period after which a delayed message can be included into the inbox without any action from the sequencer, measured in L1 block time.\tCorresponds to delayBlocks and delaySeconds in the sequencer inbox maximum time variation above.\nBatch posting minimum frequency\tMaximum time to wait after a transaction is sent to post a batch containing it. Note that if no transactions are sent, no batches will be posted, regardless of this setting. The default setting is 1 hour, and can be set lower but may reduce efficiency in the case of low activity on the Orbit chain.\t--node.batch-poster.max-delay in the batch poster config.\nValidator node (branch) creation frequency\tMinimum time to wait since the last assertion to post a new assertion, if configured to post new assertions (”MakeNodes”). This is bypassed if there is an incorrect assertion and a dispute needs to be made by making a new assertion. Note that if no new batches are posted (and no force inclusion happens), no new assertions will be posted, regardless of this setting. The default setting is 1 hour and is alterable but should always be greater than the rollup contract's minimumAssertionPeriod, which is measured in L1 blocks and is defaulted to 75 blocks, or roughly 15 minutes.\t--node.staker.make-assertion-interval in the validator config.\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nCustomize your chain's deployment\nNext\nUse a custom gas token\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/orbit-sdk-configuring-orbit-chain",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nGet started\nDeploy a Rollup chain\nDeploy an AnyTrust chain\nDeploy a custom gas token chain\nConfigure your chain's node\nDeploy a token bridge\nConfigure your chain\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to configure your Orbit chain using the Orbit SDK\n\nIn this how-to, you'll learn how to configure your Orbit chain using the Orbit SDK.\n\nUNDER CONSTRUCTION\n\nThis document is under construction and may change significantly as we incorporate style guidance and feedback from readers. Feel free to request specific clarifications by clicking the Request an update button at the top of this document.\n\nOrbit chains have three areas of configuration:\n\nParent chain configuration\nNode configuration\nChild chain configuration\n1. Parent chain configuration​\n\nConfiguring the parent chain is the initial step to setting up your Orbit chain. Most of the parent chain configurations are specified during the setup phase. Detailed instructions can be found in the Rollup Deployment Parameters section of the Rollup deployment guide.\n\nAfter the initial setup, the chain owner can modify configurations as needed. For instance, the validator set can be updated by invoking the setValidKeyset function with a new set of validators. This adaptability facilitates your chain's optimization and management.\n\n2. Node configuration​\n\nAs a chain deployer, you can configure a node during the node config generation process with the nodeConfig.json file. nodeConfig.json allows you to set up a node as a validator or a sequencer and specify requirements or performance criteria. For more information, refer to the Node Configuration Preparation documentation.\n\n3. Child chain parameter configuration​\n\nThe child chain configuration can be performed after the chain has been initialized and the token bridge has been deployed. Child chains' parameters are configurable via setter functions in the ArbOwner precompile. Additionally, there are various getter functions in the ArbOwner precompile that you can use to read the current configuration.\n\nBelow, we explain several methods in the ArbOwner precompile that you can use to configure the parameters or read their current state.\n\nSetter functions​\n\nYou can use these setter functions to configure the child chain parameters:\n\nParameter\tDescription\naddChainOwner\tAdds a new chain owner to your Orbit chain.\nremoveChainOwner\tRemoves an existing owner from the list of chain owners.\nsetMinimumL2BaseFee\tSets the minimum base fee on the child chain. The minimum base fee is the lowest amount that the base fee on the child chain can ever be. For example, the current minimum base fee on Arbitrum One and Arbitrum Nova is 0.01 gwei.\nsetSpeedLimit\tThe fee mechanism on the Arbitrum Nitro stack differs from the Ethereum blockchain. The Nitro stack has a parameter called the speed limit, which targets the number of gas consumed on the child chain per second. If the amount of gas per second exceeds this pre-specified amount, the base fee on the child chain will increase, and vice versa. The current speed limit on Arbitrum One is 7 million gas per second, meaning if the Arbitrum One chain consumes more than 7 million gas per second, its base fee will increase. For more information on the speed limit, please refer to this document explaining the concept of speed limit in the Nitro stack.\nsetInfraFeeAccount\tSets the infrastructure fee account address, which receives all fees collected on the child chain. It is meant to receive the minimum base fee, with any amount above that going to the network fee account.\nsetNetworkFeeAccount\tSets the network fee account address. As mentioned, this address collects all fees above the base fee. Note that if you set this amount to the 0 address on your chain, all fees will be deposited into the infrastructure fee account.\nscheduleArbOSUpgrade\tIf you plan to upgrade the ArbOS version of your chain, this method can help you schedule the upgrade. For a complete guide, please refer to the explanation for the arbos upgrade.\nsetChainConfig\tWe discussed the chainConfig in the Rollup deployment guide in detail. If you wish to change any field of the chainConfig, you need to use this method on the child chain.\nGetter functions​\nParameter\tDescription\ngetAllChainOwners\tProvides the list of all current chain owners.\nisChainOwner\tAllows you to check whether an address is on the list of chain owners.\ngetInfraFeeAccount\tReturns the infrastructure fee account address.\ngetNetworkFeeAccount\tReturns the network fee account address.\nConfiguring the child chain using the Orbit SDK​\n\nIn the Orbit SDK, we use the Client Extension feature of Viem to extend the public client. In the Orbit SDK, we defined arbOwnerPublicActions to use it and extend the client on Viem. An example of creating a public client extended with arbOwner public actions is:\n\nimport { createPublicClient, http } from 'viem';\nimport { arbOwnerPublicActions } from '@arbitrum/orbit-sdk';\n\nconst client = createPublicClient({\n  chain: arbitrumLocal,\n  transport: http(),\n}).extend(arbOwnerPublicActions);\n\n\nWith arbOwnerPublicActions and the public client in the Orbit SDK, we've added two new methods to the public clients:\n\n1. arbOwnerReadContract​\n\nThis method can be used to read the parameters of the child chain discussed in the previous section. An example of using this method with the client defined in the previous section is:\n\nconst result = await client.arbOwnerReadContract({\n  functionName: 'getAllChainOwners',\n});\n\n\nThe other parameters can be obtained by changing the function names in the the Getter functions section list.\n\n2. arbOwnerPrepareTransactionRequest​\n\nThis method can be used to configure the parameters on the ArbOwner precompile, which are listed in the Setter functions section. An example of utilizing this method to configure parameters using the client defined in the previous section is:\n\n// Adding a random address as chain owner using the upgrade executor\nconst transactionRequest = await client.arbOwnerPrepareTransactionRequest({\n  functionName: 'addChainOwner',\n  args: [randomAccountAddress],\n  upgradeExecutor: false,\n  account: owner.address,\n});\n\n// Submitting the transaction to add a chain owner\nawait client.sendRawTransaction({\n  serializedTransaction: await owner.signTransaction(transactionRequest),\n});\n\n\nTo use this method, as shown in the example above, some inputs need to be defined:\n\nParameter\tDescription\nfunctionName\tThe name of the method you want to use to set the parameter, which can be found in the Setter functions section.\nargs\tThe arguments for the defined function.\nupgradeExecutor\tSpecifies whether a upgradeExecutor contract governs your chain. If it is not using a upgradeExecutor, you can set it to false, similar to the example above.\naccount\tDefines the chain owner if an upgradeExecutor does not govern the chain.\n\nIf a upgradeExecutor contract governs your chain, then you need to use the arbOwnerPrepareTransactionRequest method, similar to the example below:\n\n// Adding a random address as chain owner using the upgrade executor\nconst transactionRequest = await client.arbOwnerPrepareTransactionRequest({\n  functionName: 'addChainOwner',\n  args: [randomAccountAddress],\n  upgradeExecutor: upgradeExecutorAddress,\n  account: owner.address,\n});\n\n// Submitting the transaction to add a chain owner\nawait client.sendRawTransaction({\n  serializedTransaction: await owner.signTransaction(transactionRequest),\n});\n\n\nIn this example, all the fields are the same as in the first example, except the upgradeExecutor field, which you need to set to the upgradeExecutor address, and the account parameter, which needs to be set to the owner of the upgradeExecutor contract.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nDeploy a token bridge\nNext\nCustomize your chain's deployment\n1. Parent chain configuration\n2. Node configuration\n3. Child chain parameter configuration\nSetter functions\nGetter functions\nConfiguring the child chain using the Orbit SDK\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/orbit-sdk-deploying-token-bridge",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nGet started\nDeploy a Rollup chain\nDeploy an AnyTrust chain\nDeploy a custom gas token chain\nConfigure your chain's node\nDeploy a token bridge\nConfigure your chain\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nDeploy a token bridge using the Orbit SDK\n\nThe Arbitrum Nitro stack doesn't natively support specific token bridging standards at the protocol level. Instead, Offchain Labs designed a \"canonical bridge\" that ensures seamless token transfers between the parent and child chains.\n\nThe token bridge architecture includes contracts deployed on the parent chain and on the child chain. These entities communicate via the Retryable Ticket protocol, ensuring efficient and secure interactions.\n\nUNDER CONSTRUCTION\n\nThis document is under construction and may change significantly as we incorporate style guidance and feedback from readers. Feel free to request specific clarifications by clicking the Request an update button at the top of this document.\n\nINFO\n\nSee the ERC-20 token bridge overview for more information about the token bridge's design and operational dynamics, and the \"create-token-bridge-eth\" example for additional guidance.\n\nPrerequisites​\nA running sequencer node. See steps 1-2 in the orbit-setup-script to start the related Docker containers (note that you don't need the orbitSetupScriptConfig.json file here). Use docker-compose logs -f nitro to verify that your node is running.\nToken Bridge Deployment Steps​\n\nOnce an Orbit chain has been deployed and initialized, the bridge contracts need to be deployed on both the parent and child chains. This process involves several steps:\n\nToken approval\nToken bridge contract deployment\nTransaction recipient and checking for deployment on child chain\nDeployment information and contract addresses\nSetting up the WETH gateway\nINFO\n\nThe token bridge deployment process is the same for all Orbit chains types except for the following:\n\nCustom fee token Orbit chains which require token approval.\nETH-based Orbit chains, for which you need to set up a WETH gateway.\n1. Token approval​\nNOTE\n\nThis step is only required for custom fee token Orbit chains.\n\nInitiating the deployment of a token bridge for Custom Fee Token on orbit chains begins with ensuring the TokenBridgeCreator contract is granted sufficient approvals of the native token. To facilitate this process, the Orbit SDK provides two APIs:\n\ncreateTokenBridgeEnoughCustomFeeTokenAllowance: This method verifies that the deployer's address has enough allowance to pay for the fees associated with the token bridge deployment.\ncreateTokenBridgePrepareCustomFeeTokenApprovalTransactionRequest: This function assists in generating the raw transaction required to approve the native token for the TokenBridgeCreator contract.\n\nThe following example demonstrates how to leverage these APIs effectively to check for and, if necessary, grant approval to the TokenBridgeCreator contract:\n\nconst allowanceParams = {\n  nativeToken,\n  owner: rollupOwner.address,\n  publicClient: parentChainPublicClient,\n};\nif (!(await createTokenBridgeEnoughCustomFeeTokenAllowance(allowanceParams))) {\n  const approvalTxRequest = await createTokenBridgePrepareCustomFeeTokenApprovalTransactionRequest(\n    allowanceParams,\n  );\n}\n\n\nIn this scenario, allowanceParams includes:\n\nThe native token's details: nativeToken.\nThe Rollup owner's address: rollupOwner.address.\nThe parent chain's publicClient: parentChainPublicClient.\n\nFirst, createTokenBridgeEnoughCustomFeeTokenAllowance checks if the deployer has been granted enough allowance.\n\nIf the allowance is insufficient, createTokenBridgePrepareCustomFeeTokenApprovalTransactionRequest is called to create the necessary approval transaction.\n\nPlease note that after generating the raw transaction, the deployer must still sign and broadcast it to the network to finalize the approval process.\n\n2. Token bridge contract deployment​\n\nDeploying token bridge contracts is the first step in creating a bridge between the parent and the Orbit chain.\n\nThe deployment process is the same as Orbit chain contracts', where a primary contract facilitates the deployment of core contracts. The token bridge contracts are deployed on the parent and child chains by TokenBridgeCreator. TokenBridgeCreator does it in a single transaction using the Retryable Tickets protocol .\n\nOrbit SDK provides an API that automates the deployment by interacting with the TokenBridgeCreator contract. The API is createTokenBridgePrepareTransactionRequest, which processes the necessary inputs and generates a transaction request tailored for token bridge deployment.\n\nExample:\n\nconst txRequest = await createTokenBridgePrepareTransactionRequest({\n  params: {\n    rollup: rollupContractAddress,\n    rollupOwner: rollupOwnerAddress,\n  },\n  parentChainPublicClient,\n  orbitChainPublicClient,\n  account: rollupOwnerAddress,\n});\n\n\nHere are the parameters used in the above example:\n\nParameter\tDescription\nrollupContractAddress\tOrbit chain's Rollup contract address.\nrollupOwnerAddress\tRollup owner's address.\nparentChainPublicClient\tParent chain's public client, as defined by Viem.\norbitChainPublicClient\tOrbit chain's public client, as defined by Viem.\n\nFor more insights into these variables and their usage, consider exploring this token bridge deployment example.\n\nFollowing the creation of the raw transaction, the next steps involve signing it and broadcasting it to the relevant blockchain network to complete the deployment process.\n\n3. Transaction recipient and checking for deployment on child chain​\n\nAfter sending the deployment transaction, you will need to retrieve the transaction receipt and verify the successful deployment of the contracts on both the parent and child chains.\n\nOur Orbit SDK includes a dedicated API for this purpose, named createTokenBridgePrepareTransactionReceipt, which simplifies the process of obtaining the deployment transaction's recipient.\n\nExample:\n\nconst txReceipt = createTokenBridgePrepareTransactionReceipt(\n  await parentChainPublicClient.waitForTransactionReceipt({ hash: txHash }),\n);\n\n\nIn this scenario, txHash represents the hash of the deployment transaction initiated in the previous step. The waitForTransactionReceipt API from Viem captures the transaction's recipient on the parent chain. The createTokenBridgePrepareTransactionReceipt API enhances the basic functionality provided by Viem's waitForTransactionReceipt, introducing a specialized method named waitForRetryables to handle the outcome (in this case, txReceipt).\n\nBy employing the waitForRetryables method, you can ensure the success of Retryable Tickets on the parent chain.\n\nExample:\n\nconst orbitChainRetryableReceipts = await txReceipt.waitForRetryables({\n  orbitPublicClient: orbitChainPublicClient,\n});\n\nif (orbitChainRetryableReceipts[0].status !== 'success') {\n  throw new Error(\n    `Retryable status is not success: ${orbitChainRetryableReceipts[0].status}. Aborting...`,\n  );\n}\n\nconsole.log(`Retryable executed successfully`);\n\n\nIn this example, the waitForRetryables method is invoked on the txReceipt to monitor the execution of Retryable Tickets and verify their status. A success status indicates that the Retryable Tickets have been executed successfully, ensuring the contracts' deployment. It's important to note that this process involves two Retryable Tickets. You can check out a more comprehensive walkthrough of the example. This enhanced approach not only simplifies the retrieval of transaction receipts but also provides a reliable method for verifying contract deployment across chains.\n\n4. Deployment information and contract addresses​\n\nOnce you have completed the deployment and are assured that the Retryable Tickets are successful, you can use getTokenBridgeContracts to retrieve the deployment information and all the token bridge contracts' addresses.\n\nHere's an example of how to get the contract addresses from the txReceipt generated in the previous steps:\n\nconst tokenBridgeContracts = await txReceipt.getTokenBridgeContracts({\n  parentChainPublicClient,\n});\n\n5. Setting up the WETH gateway​\n\nThe last step in spinning up the token bridge for an ETH- based Orbit chain is setting up the WETH Gateway.\n\nNOTE\n\nThat step only applies to ETH-based Orbit chains, not Custom fee token orbit chains. Our canonical bridge design has a separate custom gateway for WETH to bridge it in and out of the Orbit chain.\n\nYou can find more info about WETH gateways in our \"other gateways flavors\" documentation.\n\nSo, after the token bridge has been deployed and you have secured a successful deployment on both parent and child chains, it's time to set the WETH gateway on both parent and child chains. To handle that, we have two APIs on our Orbit SDK:\n\n1. createTokenBridgePrepareSetWethGatewayTransactionRequest:​\n\nThis API helps you create the raw transaction which handles the WETH gateway on both parent and child chains.\n\nExample:\n\nconst setWethGatewayTxRequest = await createTokenBridgePrepareSetWethGatewayTransactionRequest({\n  rollup: rollupContractAddress,\n  parentChainPublicClient,\n  orbitChainPublicClient,\n  account: rollupOwnerAddress,\n  retryableGasOverrides: {\n    gasLimit: {\n      percentIncrease: 200n,\n    },\n  },\n});\n\n\nIn this example, rollupContractAddress is the address of Orbit chain's Rollup contract, and rollupOwnerAddress is the address of the Rollup owner. parentChainPublicClient and orbitChainPublicClient are the public clients of the parent and orbit chains. This API also has optional fields to override the Retryable ticket setups. In this example, percentIncrease is the buffer to increase the gas limit, thus securing successful retryable tickets.\n\nAfter creating the raw transaction, you need to use Viem to sign it and broadcast it to the network.\n\n2. createTokenBridgePrepareSetWethGatewayTransactionReceipt​\n\nAfter sending the transaction, you need to assess if the Retryable Tickets you just created have been successful. To do that we are using createTokenBridgePrepareSetWethGatewayTransactionReceipt API and thewaitForRetryables method of it to check for the success status of retryable tickets. For the example in this doc we can use this API as follow:\n\nconst setWethGatewayTxReceipt = createTokenBridgePrepareSetWethGatewayTransactionReceipt(\n  await parentChainPublicClient.waitForTransactionReceipt({\n    hash: setWethGatewayTxHash,\n  }),\n);\nconst orbitChainSetWethGatewayRetryableReceipt = await setWethGatewayTxReceipt.waitForRetryables({\n  orbitPublicClient: orbitChainPublicClient,\n});\nif (orbitChainSetWethGatewayRetryableReceipt[0].status !== 'success') {\n  throw new Error(\n    `Retryable status is not success: ${orbitChainSetWethGatewayRetryableReceipt[0].status}. Aborting...`,\n  );\n}\nconsole.log(`Retryables executed successfully`);\n\n\nIn this example setWethGatewayTxHash is the hash of the transaction you sent, setting the WETH gateway on your Orbit chain.\n\nEdit this page\nLast updated on Nov 22, 2024\nPrevious\nConfigure your chain's node\nNext\nConfigure your chain\nPrerequisites\nToken Bridge Deployment Steps\n1. Token approval\n2. Token bridge contract deployment\n3. Transaction recipient and checking for deployment on child chain\n4. Deployment information and contract addresses\n5. Setting up the WETH gateway\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/orbit-sdk-preparing-node-config",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nGet started\nDeploy a Rollup chain\nDeploy an AnyTrust chain\nDeploy a custom gas token chain\nConfigure your chain's node\nDeploy a token bridge\nConfigure your chain\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to configure your Orbit chain's node using the Orbit SDK\n\nThis guide will walk you through configuring an Orbit node supporting a Rollup or AnyTrust chain.\n\nUNDER CONSTRUCTION\n\nThis document is under construction and may change significantly as we incorporate style guidance and feedback from readers. Feel free to request specific clarifications by clicking the Request an update button at the top of this document.\n\nINFO\n\nSee the \"prepare-node-config\" example in the Orbit SDK repository for additional guidance.\n\nPrerequisite: having deployed an Orbit chain. If you haven't done so yet, you can find detailed instructions in the Rollup Deployment Parameters section of the rollup deployment guide.\n\nOnce you have successfully deployed and initialized the Orbit core contracts, the next step is configuring and running your Orbit chain using a Node Config JSON file describing all the configurations for the Arbitrum Node, including settings for the Batch-poster, Validator, and the chain itself.\n\nExample for a Rollup Orbit Chain:\n\n{\n  'chain': {\n    'info-json': stringifyInfoJson([...]),\n    'name': chainName,\n    // Additional chain-specific configurations\n  },\n  'parent-chain': {\n    connection: {\n      url: parentChainRpcUrl,\n    },\n  },\n  'http': {\n    addr: '0.0.0.0',\n    port: 8449,\n    vhosts: '*',\n    corsdomain: '*',\n    api: ['eth', 'net', 'web3', 'arb', 'debug'],\n  },\n  'node': {\n    // Node-specific settings including sequencer, batch-poster, staker configurations\n  },\n};\n\n\nHere are some inputs details from the example above:\n\nParameters\tDescription\nchain\tDetails about the hosted chain, including chain ID, name, and core contracts.\nparent-chain\tInformation for connecting to the parent chain.\nhttp\tConfiguration parameters for the HTTP server.\nnode\tSpecific node settings, including sequencer and batch-poster configurations.\nAdditional configuration for AnyTrust Orbit chains:​\n\nFor AnyTrust Orbit chains, the Node Config JSON has an additional segment under the node field. This addition includes settings specific to the AnyTrust model, such as:\n\nSequencer's inbox address\nParent chain node URL\nRPC aggregators\n\nExample addition for AnyTrust Node Config:\n\n{\n  ...\n  'node': {\n    ...\n    'sequencer-inbox-address': coreContracts.sequencerInbox,\n    'parent-chain-node-url': parentChainRpcUrl,\n    'rest-aggregator': {\n      enable: true,\n      urls: 'http://localhost:9876',\n    },\n    'rpc-aggregator': {\n      'enable': true,\n      'assumed-honest': 1,\n      'backends': stringifyBackendsJson([...]),\n    },\n  }\n  ...\n};\n\nPreparing your node config file​\n\nThe Node Config file includes three fields types:\n\nInformation from the Orbit deployment chain: Such as the addresses of the core contracts.\nParameters configurable by the chain deployer: These parameters, like max-block-speed, can be adjusted to modify your chain's behavior.\nFields not typically configured: Like the HTTP section, which usually remains standard.\n\nLet's explore the parameters allowing you to set up a stable, and secure Orbit chain tailored to your project's requirements:\n\nNode config generation with Orbit SDK​\n\nGenerating a Node Config JSON file to initiate your Orbit chain is a step in the deployment process. The Orbit SDK simplifies this task with an API named prepareNodeConfig. This API takes specific parameters for your Orbit chain and returns a JSON file that can be used as the Node Config to initiate the chain.\n\nHere’s an example of using the prepareNodeConfig API to generate the node config:\n\nconst nodeConfig = prepareNodeConfig({\n  chainName: 'My Orbit Chain',\n  chainConfig,\n  coreContracts,\n  batchPosterPrivateKey: 'BATCH_POSTER_PRIVATE_KEY_HERE',\n  validatorPrivateKey: 'VALIDATOR_PRIVATE_KEY_HERE',\n  parentChainId: parentChain_chain_id,\n  parentChainRpcUrl: parentChain_RPC_URL,\n});\n\n\nHere are some details about the parameters used in the example above:\n\nParameters\tDescription\nchainName\tThe name you have chosen for your Orbit chain.\nchainConfig\tConfiguration used for chain deployment, returned from the createRollupPrepareTransactionReceipt API.\ncoreContracts\tAddresses of your newly deployed Orbit chain's, also returned from the createRollupPrepareTransactionReceipt API.\nbatchPosterPrivateKey\tPrivate key of the batch-poster account, used for signing batch-posting transactions and related functions.\nvalidatorPrivateKey\tPrivate key of the validator(s), used for validating state, posting Rollup Blocks (RBlocks) to the parent chain, and initiating challenges if necessary.\nparentChainId\tChain ID of the parent chain where your Orbit chain is deployed.\nparentChainRpcUrl\tParent chain's RPC URL.\n\nIf you don't have the chainConfig and coreContracts readily available, you can obtain them using the createRollupPrepareTransaction and createRollupPrepareTransactionReceipt APIs.\n\nHere's an example of how to extract chainConfig and coreContracts using just the transaction hash from your deployment:\n\nimport {\n  ChainConfig,\n  createRollupPrepareTransaction,\n  createRollupPrepareTransactionReceipt,\n} from '@arbitrum/orbit-sdk';\n\nconst tx = createRollupPrepareTransaction({ hash: txHash });\nconst txReceipt = createRollupPrepareTransactionReceipt({ hash: txHash });\nconst chainConfig: ChainConfig = JSON.parse(tx.getInputs()[0].config.chainConfig);\nconst coreContracts = txReceipt.getCoreContracts();\n\n\nThis process ensures that all necessary configurations and contract details are included in your Node Config.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nDeploy a custom gas token chain\nNext\nDeploy a token bridge\nAdditional configuration for AnyTrust Orbit chains:\nPreparing your node config file\nNode config generation with Orbit SDK\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/orbit-sdk-deploying-custom-gas-token-chain",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nGet started\nDeploy a Rollup chain\nDeploy an AnyTrust chain\nDeploy a custom gas token chain\nConfigure your chain's node\nDeploy a token bridge\nConfigure your chain\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to deploy a custom gas token chain using the Orbit SDK\nUNDER CONSTRUCTION\n\nThis document is under construction and may change significantly as we incorporate style guidance and feedback from readers. Feel free to request specific clarifications by clicking the Request an update button at the top of this document.\n\nINFO\n\nSee the \"create a rollup custom fee token\" example in the Orbit SDK repository for additional guidance.\n\nThis guide will help you configure and deploy a custom gas token Orbit chain.\n\nCustom gas token orbit chains let participants pay transaction fees in ERC-20 token instead of ETH, which is ideal for use cases requiring this feature and low transaction fees. You can learn more on our page covering custom gas token requirements and configuration.\n\nDeploying a custom gas token Orbit chain is similar to deploying an AnyTrust Orbit chain but with additional steps. To take advantage of all the chains configurations supported by Orbit, we recommend reading our short guides about Rollup and AnyTrust configuration.\n\nNOTE\nCustom gas tokens are not supported yet on Rollup Orbit chains, only on Orbit AnyTrust chains.\nERC-20 tokens need 18 decimals to operate as gas tokens on Orbit chains.\n1. Custom gas token specification​\n\nThe difference between custom gas token chains and other Orbit chains is the use of an ERC-20 token as the gas token. Enabling this feature requires that you select an existing ERC-20 token or deploy a new one on the parent chain.\n\n2. Chain configuration​\n\nChain configuration is the same as for any other AnyTrust chain. See more here.\n\n3. Token approval before deployment process​\n\nIn Custom gas token Orbit chains, the owner needs to give allowance to the rollupCreator contract before starting the deployment process so that rollupCreator can spend enough tokens for the deployment process. For this purpose, we defined two APIs on the Orbit SDK:\n\nA. createRollupEnoughCustomFeeTokenAllowance​\n\nThis API gets related inputs and checks if the rollupCreator contract has enough token Allowance from the owner:\n\nimport { createRollupEnoughCustomFeeTokenAllowance } from '@arbitrum/orbit-sdk';\n\nconst allowanceParams = {\n  nativeToken,\n  account: deployer.address,\n  publicClient: parentChainPublicClient,\n};\n\nconst enoughAllowance = await createRollupEnoughCustomFeeTokenAllowance(allowanceParams);\n\n\nTo build the allowanceParams object as shown in the example above, you need to provide with the following:\n\nParameter\tType\tDescription\nnativeToken\tAddress\tThe contract address on the parent chain of the ERC-20 token your chain will use for gas fees.\naccount\tAddress\tThe address of the Orbit chain's deployer.\npublicClient\tPublicClient\tThe PublicClient object as defined by the Viem library.\nB. createRollupPrepareCustomFeeTokenApprovalTransactionRequest​\n\nThis API gets related inputs and creates the transaction request to secure enough allowance from the owner to the RollupCreator to spend nativeToken on the deployment process.\n\nExample:\n\nimport { createRollupEnoughCustomFeeTokenAllowance } from '@arbitrum/orbit-sdk';\n\nconst allowanceParams = {\n  nativeToken,\n  account: deployer.address,\n  publicClient: parentChainPublicClient,\n};\n\nconst approvalTxRequest = await createRollupPrepareCustomFeeTokenApprovalTransactionRequest(\n  allowanceParams,\n);\n\n4. Deployment process​\n\nThe overall deployment process, including the use of APIs like createRollupPrepareDeploymentParamsConfig and createRollupPrepareTransactionRequest, remains similar to the AnyTrust deployment process. However, attention must be given to incorporating the ERC-20 token details into these configurations.\n\nNOTE\n\nWhen using the API, you also need to specify nativeToken as a param.\n\nExample:\n\nconst txRequest = await createRollupPrepareTransactionRequest({\n  params: {\n    config,\n    batchPosters: [batchPoster],\n    validators: [validator],\n    nativeToken,\n  },\n  account: deployer.address,\n  publicClient: parentChainPublicClient,\n});\n\n\nAll other parts would be the same as explained in the Rollup Orbit chain deployment page.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nDeploy an AnyTrust chain\nNext\nConfigure your chain's node\n1. Custom gas token specification\n2. Chain configuration\n3. Token approval before deployment process\n4. Deployment process\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to Deploy an AnyTrust chain using the Orbit SDK | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/orbit-sdk-deploying-anytrust-chain",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nGet started\nDeploy a Rollup chain\nDeploy an AnyTrust chain\nDeploy a custom gas token chain\nConfigure your chain's node\nDeploy a token bridge\nConfigure your chain\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to Deploy an AnyTrust chain using the Orbit SDK\n\nThis section explains how to initiate an AnyTrust Orbit chain using Arbitrum's Orbit SDK.\n\nUNDER CONSTRUCTION\n\nThis document is under construction and may change significantly as we incorporate style guidance and feedback from readers. Feel free to request specific clarifications by clicking the Request an update button at the top of this document.\n\nINFO\n\nSee the \"set-valid-keyset\" example in the Orbit SDK repository for additional guidance.\n\nAbout AnyTrust Orbit​\n\nAnyTrust chains implement the Arbitrum AnyTrust protocol, an alternative to the Arbitrum Rollup protocol. AnyTrust reduces transaction fees by introducing a minor trust assumption in the form of a permissioned set of parties responsible for managing data availability. For an overview of Orbit chain types, please refer to the Orbit SDK introduction.\n\nDeployment steps​\n\nThe deployment process of AnyTrust chains is very similar to that of Rollup chains, but with some differences that we'll discuss in this guide.\n\nHere are the steps involved in the deployment process:\n\nSetting up the chain parameters\nDeploying your AnyTrust chain\nGetting the AnyTrust Orbit chain information after deployment\nSetting valid keyset on parent chain\n\nThe deployment of an AnyTrust Orbit chain involves defining and setting up the Data Availability Committee (DAC) keyset. This keyset includes keys from the appointed members of the DAC. They are required to ensure the chain's data availability and integrity. Once you have selected your committee members and gathered their keys, the Orbit SDK helps you configure these keys into a keyset. This keyset is then embedded into the chain, serving as a verification mechanism.\n\nLet's go through each deployment step:\n\n1. Setting up the chain parameters​\n\nSimilarly to the Rollup chain, you'll need to prepare the AnyTrust chain configuration, including the core contracts and operational parameters that govern the chain's functionality, focusing on parameters specific to AnyTrust chains.\n\nstruct Config {\n    uint64 confirmPeriodBlocks;\n    uint64 extraChallengeTimeBlocks;\n    address stakeToken;\n    uint256 baseStake;\n    bytes32 wasmModuleRoot;\n    address owner;\n    address loserStakeEscrow;\n    uint256 chainId;\n\n    string chainConfig;\n\n    uint64 genesisBlockNum;\n    ISequencerInbox.MaxTimeVariation sequencerInboxMaxTimeVariation;\n}\n\n\nYou can create the chainConfig parameter within the Config using prepareChainConfig. You can find more details on that function here.\n\nimport { prepareChainConfig } from '@arbitrum/orbit-sdk';\n\nconst chainConfig = prepareChainConfig({\n  chainId: 123_456,\n  arbitrum: {\n    InitialChainOwner: deployer,\n    DataAvailabilityCommittee: true,\n  },\n});\n\n\nOther than the required chainId and arbitrum.InitialChainOwner params, arbitrum.DataAvailabilityCommittee needs to be set to true for AnyTrust.\n\n2. Deploying your AnyTrust chain​\n\nAfter configuring your chain with the createRollupPrepareDeploymentParamsConfig API, the next step is to use the createRollupPrepareTransactionRequest API. This API is designed to take the parameters defined in the RollupDeploymentParams, along with the configuration generated by the createRollupPrepareDeploymentParamsConfig API, to prepare a transaction request. This request is then used to invoke the createRollup function of the RollupCreator contract, which effectively deploys and initializes the core contracts of your AnyTrust Orbit chain.\n\nFor instance, to deploy using the Orbit SDK with a Config equal to config, a single batch poster in [batchPoster], and a single validator in [validator], the process would look like this:\n\nimport { createRollupPrepareTransactionRequest } from '@arbitrum/orbit-sdk';\n\nconst request = await createRollupPrepareTransactionRequest({\n  params: {\n    config,\n    batchPosters: [batchPoster],\n    validators: [validator],\n  },\n  account: deployer_address,\n  publicClient,\n});\n\n\nAfter creating the raw transaction, you can sign and broadcast it to the network.\n\n3. Getting the AnyTrust Orbit chain information after deployment​\n\nTo extract detailed information about your AnyTrust Orbit chain post-deployment, you can use the same API and steps as you would for a Rollup Orbit chain. Here's a reminder of the example:\n\nimport { createRollupPrepareTransactionReceipt } from '@arbitrum/orbit-sdk';\n\nconst data = createRollupPrepareTransactionReceipt(txReceipt);\n\n\nIn this example, txReceipt refers to the transaction receipt you received after deploying the AnyTrust chain. By inputting this receipt into the createRollupPrepareTransactionReceipt function, you can access comprehensive data about your deployment, including details about the core contracts and configuration settings.\n\n4. Setting valid keyset on parent chain​\n\nThe final step is to set up a valid keyset for your Data Availability Committee (DAC) on the parent chain. See How to configure a DAC for instructions.\n\nOnce created, your keyset needs to be established on your Orbit chain's SequencerInbox contract on the parent chain. To facilitate this, we provide an API in Orbit SDK named setValidKeysetPrepareTransactionRequest. This API requires specific information you can gather at step three. This includes the upgradeExecutor and sequencerInbox addresses of your Orbit chain, the generated keyset for your committee, and the owner's account.\n\nHere's an example of how you can use the Orbit SDK to write your keyset:\n\nconst txRequest = await setValidKeysetPrepareTransactionRequest({\n  coreContracts: {\n    upgradeExecutor: 'upgradeExecutor_address',\n    sequencerInbox: 'sequencerInbox_address',\n  },\n  keyset,\n  account: deployer.address,\n  publicClient: parentChainPublicClient,\n});\n\n\nIn this example, upgradeExecutor_address and sequencerInbox_address are placeholders for the Orbit chain's contract addresses. keyset is the keyset you generated for your committee, and deployer.address refers to the owner's account address.\n\nOnce you've created the transaction request using the above API, the next step is to sign and send the transaction. This transaction writes the keyset to the parent chain, enabling it to recognize and verify the valid keyset for your AnyTrust Orbit chain.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nDeploy a Rollup chain\nNext\nDeploy a custom gas token chain\nAbout AnyTrust Orbit\nDeployment steps\n1. Setting up the chain parameters\n2. Deploying your AnyTrust chain\n3. Getting the AnyTrust Orbit chain information after deployment\n4. Setting valid keyset on parent chain\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/orbit-sdk-deploying-rollup-chain",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nGet started\nDeploy a Rollup chain\nDeploy an AnyTrust chain\nDeploy a custom gas token chain\nConfigure your chain's node\nDeploy a token bridge\nConfigure your chain\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to Deploy a Rollup chain using the Orbit SDK\n\nThis document explains how to use the Orbit SDK to deploy a Rollup Orbit chain.\n\nUNDER CONSTRUCTION\n\nThis document is under construction and may change significantly as we incorporate style guidance and feedback from readers. Feel free to request specific clarifications by clicking the Request an update button at the top of this document.\n\nINFO\n\nSee the \"create-rollup-eth\" example in the Orbit SDK repository for additional guidance.\n\nThe main benefit of the Orbit SDK lies in facilitating the deployment and fine-tuning of Orbit chains core Smart-Contracts.\n\nThese contracts are deployed on parent chains, they are:\n\nRollup contracts\nBridge contracts\nContracts handling fraud proofs\n\nCore contracts are the backbone of Arbitrum's Nitro stack, ensuring its robust and efficient operation. You can explore their code in the nitro-contracts GitHub repository.\n\nRollup deployment parameters​\n\ncreateRollup is the function that will deploy your core contracts on the parent chain. createRollup takes a complex input named deployParams, which defines the characteristics of an Orbit Rollup chain.\n\nThe following will walk you through the methods and properties you will use to configure your chain.\n\n1. RollupDeploymentParams struct​\nstruct RollupDeploymentParams {\n\n    Config config;\n\n    address[] validators;\n\n    uint256 maxDataSize;\n\n    address nativeToken;\n\n    bool deployFactoriesToL2;\n\n    uint256 maxFeePerGasForRetryables;\n\n    address[] batchPosters;\n\n    address batchPosterManager;\n}\n\n\nThis Solidity struct includes key settings like the chain configuration (Config), validator addresses, maximum data size, the native token of the chain, and more.\n\n2. Config struct​\nstruct Config {\n\n    uint64 confirmPeriodBlocks;\n\n    uint64 extraChallengeTimeBlocks;\n\n    address stakeToken;\n\n    uint256 baseStake;\n\n    bytes32 wasmModuleRoot;\n\n    address owner;\n    address loserStakeEscrow;\n    uint256 chainId;\n    string chainConfig;\n    uint64 genesisBlockNum;\n    ISequencerInbox.MaxTimeVariation sequencerInboxMaxTimeVariation;\n}\n\n\nThe Config struct defines the chain's core settings, including block confirmation periods, stake parameters, and the chain ID.\n\n3. MaxTimeVariation struct​\nstruct MaxTimeVariation {\n\n    uint256 delayBlocks;\n\n    uint256 futureBlocks;\n\n    uint256 delaySeconds;\n\n    uint256 futureSeconds;\n}\n\n\nThis nested struct within Config specifies time variations related to block sequencing, providing control over block delay and future block settings.\n\n4. chainConfig​\n\nThe chainConfig parameter within the Config struct allows you to customize your Orbit chain. It's a stringified JSON object containing various configuration options that dictate how the Orbit chain behaves and interacts with the parent chain network.\n\nHere's a brief overview of chainConfig:\n\n{\n\n    chainId: number;\n\n    homesteadBlock: number;\n    daoForkBlock: null;\n    daoForkSupport: boolean;\n    eip150Block: number;\n    eip150Hash: string;\n    eip155Block: number;\n    eip158Block: number;\n    byzantiumBlock: number;\n    constantinopleBlock: number;\n    petersburgBlock: number;\n    istanbulBlock: number;\n    muirGlacierBlock: number;\n    berlinBlock: number;\n    londonBlock: number;\n    clique: {\n        period: number;\n        epoch: number;\n    };\n    arbitrum: {\n        EnableArbOS: boolean;\n        AllowDebugPrecompiles: boolean;\n\n        DataAvailabilityCommittee: boolean;\n\n        InitialArbOSVersion: number;\n\n        InitialChainOwner: Address;\n\n        GenesisBlockNum: number;\n\n        MaxCodeSize: number;\n\n        MaxInitCodeSize: number;\n\n    };\n}\n\n\nOut of chainConfig's parameters, a few are particularly important and are likely to be configured by the chain owner: chainId, arbitrum.InitialChainOwner, arbitrum.InitialArbOSVersion, arbitrum.DataAvailabilityCommittee, arbitrum.MaxCodeSize, and arbitrum.MaxInitCodeSize.\n\n4.1. prepareChainConfig​\n\nFor easier config preparation, the Orbit SDK provides the prepareChainConfig function, which takes config parameters as arguments and returns a full chainConfig. Any parameters not provided will default to standard values, which are detailed here.\n\nHere are the parameters you can use with prepareChainConfig:\n\nParameter\tType\tRequired\tDefault Value\tDescription\nchainId\tNumber\tYes\t/\tYour chain's unique identifier. It differentiates your chain from others in the ecosystem.\narbitrum.InitialChainOwner\tAddress\tYes\t/\tSpecifies who owns and controls the chain.\narbitrum.InitialArbOSVersion\tNumber\tNo\tlatest\tSpecifies which version of ArbOS should the chain run.\narbitrum.DataAvailabilityCommittee\tBoolean\tNo\tfalse\tWhen set to false, your chain will run as a Rollup chain, and when set to true it will run as an AnyTrust chain.\narbitrum.MaxCodeSize\tNumber\tNo\t24,576 (bytes)\tSets the maximum size for contract bytecodes on the chain.\narbitrum.MaxInitCodeSize\tNumber\tNo\t49,152 (bytes)\tSimilar to arbitrum.MaxCodeSize, defines the maximum size for your chain's initialization code.\n\nBelow is an example of how to use prepareChainConfig to set up a Rollup chain with a specific chainId, an InitialChainOwner (named as deployer):\n\nimport { prepareChainConfig } from '@arbitrum/orbit-sdk';\n\nconst chainConfig = prepareChainConfig({\n  chainId: 123_456,\n  arbitrum: {\n    InitialChainOwner: deployer,\n    DataAvailabilityCommittee: false,\n  },\n});\n\nRollup configuration parameters​\n\nIn this section, we'll provide detailed explanations of the various chain configuration parameters used in the deployment of Orbit chains.\n\nParameter\tDescription\nbatchPosters\tArray of batch poster addresses. Batch posters batch and compress transactions on the Orbit chain and transmit them back to the parent chain.\nbatchPosterManager\tAccount address responsible for managing currently active batch posters. Not mandatory, as these actions can also be taken by the chain owner.\nvalidators\tArray of validator addresses. Validators are responsible for validating the chain state and posting Rollup Blocks (RBlocks) back to the parent chain. They also monitor the chain and initiate challenges against potentially faulty RBlocks submitted by other validators.\nnativeToken\tDetermines the token used for paying gas fees on the Orbit chain. It can be set to ETH for regular chains or to any ERC-20 token for gas fee token network Orbit chains.\nconfirmPeriodBlocks\tSets the challenge period in terms of blocks, which is the time allowed for validators to dispute or challenge state assertions. On Arbitrum One and Arbitrum Nova, this is currently set to approximately seven days in block count. confirmPeriodBlocks is measured in L1 blocks, we recommend a value of 45818\nbaseStake\tOrbit chain validator nodes must stake a certain amount to incentivize honest participation. The basestake parameter specifies this amount.\nstakeToken\tToken in which the basestake is required. It represents the token's address on the parent chain. Can be ETH or a ERC-20token. Note that the use of an ERC-20 token as the stakeToken is currently not supported by Nitro, but will be soon.\nowner\tAccount address responsible for deploying, owning, and managing your Orbit chain's base contracts on its parent chain.\nchainId\tSets the unique chain ID of your Orbit chain.\nNOTE\n\nchainId and owner parameters must be equal to the chain ID and InitialOwner defined in the chainConfig section.\n\nWhile other configurable parameters exist, they are set to defaults, and it's generally not anticipated that a chain deployer would need to modify them. However, if you believe there's a need to alter any other parameters not listed here, please feel free to contact us on our Discord server for further details and support.\n\nConfiguration and deployment helpers​\n\nThe Orbit SDK provides two APIs, createRollupPrepareDeploymentParamsConfig and createRollupPrepareTransactionRequest to facilitate the configuration and deployment of Rollup parameters for an Orbit chain. These APIs simplify the process of setting up and deploying the core contracts necessary for an Orbit chain.\n\ncreateRollupPrepareDeploymentParamsConfig API:​\n\nThis API is designed to take parameters defined in the Config struct and fill in the rest with default values. It outputs a complete Config struct that is ready for use.\n\nFor example, to create a Config struct with a specific chain ID (chainId), an owner address (deployer_address), and a chainConfig as described in the previous section, you would use the Orbit SDK as follows:\n\nimport { createPublicClient, http } from 'viem';\nimport { arbitrumSepolia } from 'viem/chains';\nimport { createRollupPrepareDeploymentParamsConfig } from '@arbitrum/orbit-sdk';\n\nconst parentPublicClient = createPublicClient({\n  chain: arbitrumSepolia,\n  transport: http(),\n});\n\nconst config = createRollupPrepareDeploymentParamsConfig(parentPublicClient, {\n  chainId: BigInt(chainId),\n  owner: deployer.address,\n  chainConfig,\n});\n\ncreateRollupPrepareTransactionRequest API:​\n\nThis API accepts parameters defined in the RollupDeploymentParams struct, applying defaults where necessary, and generates the RollupDeploymentParams. This struct is then used to create a raw transaction which calls the createRollup function of the RollupCreator contract. As discussed in previous sections, this function deploys and initializes all core Orbit contracts.\n\nFor instance, to deploy using the Orbit SDK with a Config equal to config, a single batch poster in [batchPoster], and a single validator in [validator], the process would look like this:\n\nimport { createRollupPrepareTransactionRequest } from '@arbitrum/orbit-sdk';\n\nconst request = await createRollupPrepareTransactionRequest({\n  params: {\n    config,\n    batchPosters: [batchPoster],\n    validators: [validator],\n  },\n  account: deployer_address,\n  publicClient,\n});\n\n\nAfter creating the raw transaction, you need to sign and broadcast it to the network.\n\nGetting the Orbit chain information after deployment​\n\nOnce you've successfully deployed your Orbit chain, the next step is to retrieve detailed information about the deployment, which you can do with the createRollupPrepareTransactionReceipt API.\n\nAfter sending the signed transaction and receiving the transaction receipt, you can use the createRollupPrepareTransactionReceipt API to parse this receipt and extract the relevant data. This process will provide comprehensive details about the deployed chain, such as contract addresses, configuration settings, and other information.\n\nHere's an example of how to use the Orbit SDK to get data from a deployed Orbit chain:\n\nimport { createRollupPrepareTransactionReceipt } from '@arbitrum/orbit-sdk';\n\nconst data = createRollupPrepareTransactionReceipt(txReceipt);\n\n\nIn this example, txReceipt refers to the transaction receipt you received after deploying the chain. You can access your Orbit chain's information by passing this receipt to the createRollupPrepareTransactionReceipt function. This feature of the Orbit SDK simplifies the post-deployment process, allowing you to quickly and efficiently gather all necessary details about your chain for further use or reference.\n\nEdit this page\nLast updated on Nov 22, 2024\nPrevious\nGet started\nNext\nDeploy an AnyTrust chain\nRollup deployment parameters\nRollup configuration parameters\nConfiguration and deployment helpers\nGetting the Orbit chain information after deployment\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/orbit-managing-gas-speed-limit",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nManage state growth\nManage gas speed limit\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nGuidance for Orbit chains gas speed limit\nWhat is the speed limit on an Orbit chain?​\n\nThe parameter that governs an Orbit chain's throughput limit is known as the gas speed limit.\n\nThe gas speed limit is measured in gas per second and is used as a threshold for increasing gas prices.\n\nFor example, Arbitrum One and Arbitrum Nova have a gas speed limit of 7 million gas per second. This means that when cumulative usage onchain exceeds 7 million gas per second, the L2 base fee rises to increase the amount of gwei charged per unit of gas. This happens using a similar approach to Ethereum's EIP-1559 pricing algorithm.\n\nWhy do we have throughput limits on blockchains?​\n\nThe effect of raising gas prices at the speed limit is to curb user demand when the chain is congested. Doing so protects the chain's underlying infrastructure from being overloaded.\n\nThis is because blockchain nodes have computation constraints that should not be exceeded. Charging more during congested periods ensures that high-priority transactions can still be processed while deterring users and apps from submitting low-priority transactions until a lower activity period.\n\nThe speed limit, therefore, is fundamentally a protective mechanism. If the chain load exceeds what a Nitro validator node can process, then a chain risks halting due to validator downtime. It's important to note here that the security and liveness of an Orbit chain are always maintained through its parent chain contracts, but undoubtedly, the best user experience requires the validators and sequencer to be online.\n\nWhat is the recommended speed limit for Orbit chains?​\n\nPlease note: We recommend against teams raising their chain's default speed target beyond 7 million gas per second.\n\nWhat are the risks of increasing my gas speed limit?​\n\nAn increase in the speed target allows users and apps to perform more on-chain actions without incurring additional costs. This makes it possible for a chain's nodes to experience higher and unexpected loads. When faced with high, sustained demand, the additional load could eventually lead to undesirable increases in infrastructure costs, cause nodes to lag behind the chain, and risk halting if the demand exceeds the resources of validator nodes.\n\nSee State Growth & Corresponding Issues.\n\nIs Offchain Labs working on software improvements to allow Orbit chain owners to safely raise their chain's speed target?​\n\nYes. Offchain Labs is currently working on several key initiatives to improve the core Nitro node software that would result in a safe and formally endorsed increase in the speed targets for Arbitrum chains. These initiatives include migrations to PathDB and PebbleDB (alongside their respective optimizations for Arbitrum chains) and alternative execution layer client implementations for Nitro (e.g., Reth). We will share updates and news on these initiatives when we have them - stay tuned!\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nManage state growth\nNext\nGet started\nWhat is the speed limit on an Orbit chain?\nWhy do we have throughput limits on blockchains?\nWhat is the recommended speed limit for Orbit chains?\nWhat are the risks of increasing my gas speed limit?\nIs Offchain Labs working on software improvements to allow Orbit chain owners to safely raise their chain's speed target?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/calculate-aep-fees#calculating-aep-fees",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nCustomize your chain's deployment\nAdditional configuration parameters\nUse a custom gas token\nCustomize your chain's precompiles\nCustomize your chain's behavior\nConfigure delayed inbox finality\nManage the fee collectors\nCustomize ArbOS version\nImplement Circle bridged USDC\nEnable fast withdrawals\nAEP fee router\nAEP fee router: overview\nSet up an AEP fee router\nCalculating AEP license fees\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nCalculating AEP license fees\n\nThis document will help you calculate your Orbit chain’s Protocol Net Revenue and AEP license fees.\n\nBefore we define “Protocol Net Revenue,” let's explain how fees work in a standard Orbit chain. From there, we can connect how each fee equates to a revenue or a cost.\n\nSequencing revenue​\n\nIn a vanilla Orbit chain (a chain without customizations, transaction ordering policies, or other add-ons), users and dApps will pay a single gas fee to submit their transactions. Under the hood, however, a user’s fee is allocated across four components used by the network in different ways. These four fee components are split as follows:\n\nl2BaseFee: fees paid to execute a transaction on the Orbit chain.\nl2SurplusFee: surplus fees are charged in addition to the base fee when an Orbit chain is congested.\nl1BaseFee: fees paid to cover the cost of an Orbit chain posting its settlement transaction to the parent chain.\nl1SurplusFee: an additional surplus fee that can be configured to award extra fees to the batch poster.\n\nBased on the above, we interpret that an Orbit chain’s revenue sources include all fee components: l2BaseFee, l2SurplusFee, l1BaseFee, and l1SurplusFee. However, one of these fee components is also a cost: l1BaseFee, as it is used to pay for parent chain settlement.\n\nAssertion costs​\n\nThe above fee system applies to an Orbit chain’s Sequencer and Batch Poster, but there is another important actor that is considered essential to the chain. These are the **validators.**\n\nValidators are responsible for posting assertions on the parent chain, which are disputable claims about the new state of the Rollup. Posting an assertion is what progressed chain state on the parent chain. Validators are also responsible for securing the chain by creating disputes on false assertions.\n\nAs validators are necessary for chain security and chain progression, the gas costs paid by validators are a cost under the AEP license.\n\nThe AEP license permits an Orbit chain to deduct the gas costs of assertion posting and confirming only for validators operated by the chain owner. The AEP Fee Router does not deduct assertion costs from its fees. In a later section, we will explain how chain owners can optionally deduct assertion costs.\n\nAdditional revenue sources​\n\nAs the Orbit license allows chain owners to customize their Rollup, the AEP license accounts for revenue sources that could arise out of innovations. As such, it’s worth noting that the total calculation of revenue will also include:\n\nRevenue from transaction ordering policies.\nRevenue earned through fees on top of the bridge.\nBroadly, any revenue earned in connection with your use of Arbitrum Nitro.\n\nYou can read the relevant legal terminology in Section 2 of the AEP Terms.\n\nCalculating AEP fees​\n\nWe are now in a place where we can precisely define AEP fees. An Orbit chain’s obligation for AEP license is 10% of a chain’s Net Protocol Revenue. Net Protocol Revenue is broadly the difference between (i) gross revenue and (ii) settlement costs.\n\nBased on our understanding above, we can calculate AEP fees as follows.\n\nAEP_FEES = [(gross revenue) - (settlement costs)]*0.1\nAEP_FEES = [(sequencing revenue + additional revenue) - (settlement costs + assertion costs)]*0.1\nAEP_FEES = [(l2BaseFee + l2SurplusFee + l1BaseFee + l1SurplusFee) - (l1BaseFee + assertion costs)]*0.1\n\nOpting in for assertion cost deduction​\n\nThe AEP Fee Router does not deduct assertion costs from the fees it routes. This is because the contract system cannot track the amount of gas validators spend, and it cannot determine the eligibility of a validator.\n\nAs such, Orbit chains can choose to deduct these costs from their fee stream, but this will require Orbit chains to self-report assertion costs and implement an intermediary multisig that sits before the AEP Fee Router system.\n\nInstructions for doing so can be found below.\n\nEligible validators​\n\nOnly validators directly associated with the Orbit chain owner are eligible for assertion cost deductions. By directly associated, we mean a validator operated by the team directly or contracted by an external provider (e.g., a Rollup-as-a-Service team) to act as a validator on behalf of the team. In the event of a contracted validator, only one validator can be eligible.\n\nEligible costs​\n\nThe following costs can be deducted for an eligible validator:\n\nThe cost of posting assertions\nThe cost of confirming assertions\nThe cost of participating in fraud proofs\nDeducting assertion costs​\n\nIf a team elects to deduct their assertion posting costs from eligible validators, they must establish and obey the following process:\n\nCommunicate to the Arbitrum Foundation that they intend to deduct on-chain assertion costs\nAlign on a cadence of disbursal and accounting these costs with the Arbitrum Foundation (e.g., quarterly, annually)\nAt this cadence, Provide on-chain accounting to the Arbitrum Foundation to substantiate deducted costs from the AEP Fee Router stream.\n\nTo implement the deduction, the team should do the following:\n\nConfigure all Orbit chain fee components to send all fees to a secure multisig address.\nFor ease of accounting, it’s strongly recommended that this multisig handle no funds other than the rewards earned from the protocol.\nOn the established regular cadence (e.g., quarterly) deduct all eligible assertion gas costs from the multisig’s balance by transferring it to your preferred fee-collecting address. The remainder of the amount must be forwarded to the RewardDistributor contract (configured as directed previously)\nFollowing this, the RewardDistributor will split the post-deduction funds between the AEP Fee Router contracts and the configured chain-owner controlled addresses.\nSpecial cases and exceptions​\n\nCertain Orbit configurations and customizations require special handling of AEP fees. The following is a non-exhaustive list of applicable scenarios and how to ensure AEP compliance. If any of the following cases apply, the recommended approach for fee handling will require manual handling of a portion of or all AEP Fees.\n\nL2-Based Custom Gas Tokens​\n\nIf you are an L3 or higher chain with a custom gas token, your custom gas token contract might be deployed on L2. If this L2 is not Arbitrum One, then the L2 token can be transferred via the AEP Fee Router, as this would first require bridging down to Ethereum (impossible for L2-based tokens). In this instance, we recommend your chain pay fees in ETH by manually sending fees to an ETH-configured routing system.\n\nNon-Ethereum L1​\n\nIf your Orbit chain is deployed on a non-Ethereum L1 (e.g., Solana, BNB Chain), your fees must be manually transferred to a Foundation-controlled address.\n\nNovel Fee-Earning Customizations​\n\nAs discussed above in Additional revenue sources, if you have customized your Orbit chain to earn revenue through any enshrined component, this revenue must be calculated as part of the AEP fees. In such cases, we recommend engaging with the AF to agree on a revenue model and reporting cadence and then manually send additional fees into the routing system as required.\n\nOther cases​\n\nIf you are still determining if your Orbit configuration applies to the listed or unlisted special cases, we recommend engaging with the Arbitrum Foundation.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nSet up an AEP fee router\nNext\nUpgrade ArbOS\nSequencing revenue\nAssertion costs\nAdditional revenue sources\nCalculating AEP fees\nOpting in for assertion cost deduction\nEligible validators\nEligible costs\nDeducting assertion costs\nSpecial cases and exceptions\nL2-Based Custom Gas Tokens\nNon-Ethereum L1\nNovel Fee-Earning Customizations\nOther cases\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Debugging tools | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/reference/debugging-tools",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nRPC endpoints and providers\nContract addresses\nChain parameters\nDevelopment frameworks\nWeb3 libraries and tools\nMonitoring tools and block explorers\nDebugging tools\nMainnet risks\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nDebugging tools\nKNOW MORE TOOLS?\n\nSee something missing? Let us know on the Arbitrum Discord or by opening an issue on GitHub.\n\nThe following tools will help you debug your decentralized apps (dApps):\n\nTenderly​\n\nTenderly is an all-in-one Web3 development platform that empowers developers to build, test, monitor, and operate smart contracts from inception to mass adoption. Tenderly's debugging options focus on providing developers with efficient and user-friendly tools to identify and fix smart contract bugs and production issues. The Debugger enables developers to inspect smart contracts by analyzing precise lines of code in a human-readable format. With Tenderly's Simulator, developers can play out specific historical transactions and current transaction outcomes before sending them on-chain, allowing them to change relevant parameters and source code to test and debug contracts. The platform streamlines the debugging process, saving time and resources while improving smart contract reliability.\n\nAlthough Tenderly provides great debugging options, there are certain limitations when debugging L1-to-L2 messages (also known as Retryable Tickets), due to the utilization of custom Geth errors. For further information on this constraint, please refer to the following resource.\n\nArbiscan​\n\nArbiscan is a prominent blockchain explorer and analytics platform that allows users to access and analyze public data on the Arbitrum network, such as transactions, wallet addresses, and smart contracts. Arbiscan offers VMTrace and Debug tools to aid developers and users in understanding the execution of transactions on the Ethereum network. VMTrace provides a step-by-step visualization of the EVM execution, enabling developers to trace transaction processing and identify potential issues. Debug tools offer additional information such as input data, logs, and events emitted by the smart contract during execution.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nMonitoring tools and block explorers\nNext\nMainnet risks\nTenderly\nArbiscan\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum: Understanding the risks | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/reference/mainnet-risks",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nRPC endpoints and providers\nContract addresses\nChain parameters\nDevelopment frameworks\nWeb3 libraries and tools\nMonitoring tools and block explorers\nDebugging tools\nMainnet risks\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nArbitrum: Understanding the risks\n\nArbitrum One — the first permissionless Ethereum layer 2 rollup with full Ethereum smart contract functionality — is live on mainnet — as is Nova, our first AnyTrust chain; We're sure you're (almost) as excited as we are! Here are some risks you should know about before using the system:\n\nState Of progressive decentralization​\n\nThe Arbitrum DAO system is the owner of both the Arbitrum One and Arbitrum AnyTrust chains; see “State of Progressive Decentralization” for more.\n\nGeneral words of caution: Software bugs​\n\nOffchain Labs’ implementation of the Arbitrum protocol has been carefully constructed, is perpetually being audited by several independent firms, and is continuously reviewed and tested following best engineering practices. That said, there remains a non-zero chance that our codebase contains some undiscovered vulnerabilities that put user funds at risk. Users should carefully factor this risk into their decision to use Arbitrum One and/or Arbitrum Nova, and in deciding how much of their value to entrust into the system. Note that Offchain Labs also sponsors a multi-million dollar bug bounty program to incentivize any party who funds such a critical bug to disclose it responsibly.\n\nGeneral words of caution: Scams​\n\nArbitrum, like Ethereum, is permissionless; on both platforms, anybody can deploy any smart contract code they want. Users should treat interacting with contracts on Arbitrum exactly as they do with Ethereum, i.e., they should only do so if they have good reason to trust that the application is secure.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nDebugging tools\nNext\nTroubleshooting\nState Of progressive decentralization\nGeneral words of caution: Software bugs\nGeneral words of caution: Scams\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Monitoring tools and block explorers | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/reference/monitoring-tools-block-explorers",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nRPC endpoints and providers\nContract addresses\nChain parameters\nDevelopment frameworks\nWeb3 libraries and tools\nMonitoring tools and block explorers\nDebugging tools\nMainnet risks\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nMonitoring tools and block explorers\nKNOW MORE TOOLS?\n\nSee something missing? Let us know on the Arbitrum Discord or by opening an issue on GitHub.\n\nHere, we offer a compilation of tools and blockchain explorers that enable you to examine and oversee transactions, smart contracts, and overall blockchain activity related to decentralized applications (dApps) on different Arbitrum chains.\n\nTool\tUse-cases\tRelevant links\nArbiscan\tTrack/trace transactions and examine addresses on Arbitrum networks\t\nArbitrum One: https://arbiscan.io/\nArbitrum Nova: https://nova.arbiscan.io/\nArbitrum Sepolia: https://sepolia.arbiscan.io\n\nBlockscout\tTrack/trace transactions and examine addresses on Arbitrum networks\t\nArbitrum One: https://arbitrum.blockscout.com/\nArbitrum Nova: https://arbitrum-nova.blockscout.com/\nArbitrum Sepolia: https://arbitrum-sepolia.blockscout.com/\n\nChainbase\tIndex, transform, and use on-chain data at scale\tChainbase\nDexGuru\tTrack/trace transactions and examine addresses on Arbitrum networks\t\nArbitrum One: https://arbitrum.dex.guru/\nArbitrum Nova: https://nova.dex.guru/\n\nDune\tVisualize and analyze Arbitrum network data\t\nDune\nArbitrum community-created Duune dashboard\n\nOKLINK\tTrack/trace transactions and examine addresses on Arbitrum One network\t\nArbitrum One: https://www.oklink.com/arbitrum\nEdit this page\nLast updated on Nov 21, 2024\nPrevious\nWeb3 libraries and tools\nNext\nDebugging tools\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Web3 libraries and tools | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/reference/web3-libraries-tools",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nRPC endpoints and providers\nContract addresses\nChain parameters\nDevelopment frameworks\nWeb3 libraries and tools\nMonitoring tools and block explorers\nDebugging tools\nMainnet risks\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nWeb3 libraries and tools\nKNOW MORE TOOLS?\n\nSee something missing? Let us know on the Arbitrum Discord or by opening an issue on GitHub.\n\nThe following frameworks will help you build your decentralized apps:\n\nName\tLanguage\tDescription\tDocumentation\nEthers.js\tTypeScript\tEthers.js is a lightweight library for Ethereum and EVM-compatible blockchains. It offers secure key management, node compatibility, ENS integration and supports JSON wallets, mnemonic phrases, and HD wallets. The library is TypeScript-ready and well-documented under the MIT License.\tEthers.js Documentation\nalloy\tRust\tAlloy is a collection of utilities and crates for Ethereum development in Rust. It helps create and manage Rust prototypes that support Ethereum-like smart contract execution. Alloy focuses on interoperability and cross-chain communication..\talloy Documentation\nthirdweb SDK\tTypeScript\tthirdweb SDK offers a comprehensive suite for web3 development on EVM-compatible blockchains. It includes wallet connectivity, blockchain interaction, decentralized storage, and authentication. Gasless transactions, wallet components, FIAT on-ramps, and data APIs are key features.\tthirdweb SDK Portal\nViem\tTypeScript\tViem is a modular tool for Ethereum and EVM-compatible blockchain development. It provides performance-optimized APIs, JSON-RPC API abstractions, and smart contract interaction tools, and it supports environments like Anvil, Hardhat, and Ganache.\tViem\nWeb3.js\tJavaScript\tWeb3.js is a JavaScript library for Ethereum and EVM-compatible node interaction. It enables transactions via HTTP, IPC, or WebSocket. Compatible with web browsers, Node.js, and Electron, it's commonly used with MetaMask.\tWeb3.js GitHub\nWeb3.py\tPython\tWeb3.py is a Python library for interacting with Ethereum and EVM-compatible blockchains. It facilitates transactions, smart contract operations, and blockchain data access. Tailored for Python developers, it's a versatile tool for Ethereum-based applications.\tWeb3.py GitHub\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nDevelopment frameworks\nNext\nMonitoring tools and block explorers\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Development frameworks | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/reference/development-frameworks",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nRPC endpoints and providers\nContract addresses\nChain parameters\nDevelopment frameworks\nWeb3 libraries and tools\nMonitoring tools and block explorers\nDebugging tools\nMainnet risks\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nDevelopment frameworks\nKNOW MORE TOOLS?\n\nSee something missing? Let us know on the Arbitrum Discord or by opening an issue on GitHub.\n\nThe following tools will help you develop and test your decentralized apps (dApps):\n\nHardhat​\n\nHardhat is a comprehensive development environment designed specifically for Ethereum, Arbitrum and, in general, EVM developers. It streamlines the process of creating, compiling, deploying, testing, and debugging smart contracts. By providing a robust and customizable framework, Hardhat makes it easy to manage complex projects and integrate with other tools in the ecosystem. Its features include a built-in console, advanced debugging capabilities, and support for extending functionality through plugins, allowing developers to create efficient and secure decentralized applications.\n\nFoundry​\n\nFoundry is a high-performance, portable, and modular toolkit designed for EVM application development, leveraging the Rust programming language. It offers a comprehensive suite of tools to streamline the process of creating, testing, and deploying smart contracts on the Ethereum, Arbitrum and, in general, any EVM network. Foundry facilitates seamless interaction with EVM smart contracts, transactions, and chain data, while also providing a local node and a user-friendly Solidity REPL environment for efficient development.\n\nTruffle​\n\nTruffle is a comprehensive suite of tools for smart contract development, providing an end-to-end solution for building, testing, debugging, and deploying on Ethereum, Arbitrum and other EVM compatible chains. It features advanced debugging capabilities, fast EVM simulation with Ganache, a user-centered design with a VS Code extension, and robust L1 & L2 support. Truffle prioritizes security and partners with ConsenSys Diligence to bring continuous security to projects, providing a seamless and secure developer experience.\n\nthirdweb​\n\nthirdweb SDK covers all aspects of the web3 development stack, including connecting to user’s wallets, interacting with the blockchain and smart contracts, decentralized storage, authentication, and more; enabling you to build scalable and performant web3 applications on any EVM-compatible blockchain. Out of the box, infrastructure is provided for everything required to create decentralized applications, including connection to the blockchain (RPC), decentralized storage (IPFS + pinning services), and tools to create powerful user experiences; such as gasless transactions, wallet connection components, FIAT on-ramps, data APIs, and more.\n\nBrownie​\n\nBrownie is a Python-based framework designed for developing and testing smart contracts on the Ethereum Virtual Machine. It offers full support for Solidity and Vyper programming languages and utilizes pytest for contract testing. Brownie also incorporates trace-based coverage evaluation, property-based and stateful testing with Hypothesis, and powerful debugging tools, including python-style tracebacks and custom error strings.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nChain parameters\nNext\nWeb3 libraries and tools\nHardhat\nFoundry\nTruffle\nthirdweb\nBrownie\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Smart contract addresses | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/reference/contract-addresses",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nRPC endpoints and providers\nContract addresses\nChain parameters\nDevelopment frameworks\nWeb3 libraries and tools\nMonitoring tools and block explorers\nDebugging tools\nMainnet risks\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nSmart contract addresses\n\nThe following information may be useful to those building on Arbitrum. We list the addresses of the smart contracts related to the protocol, the token bridge and precompiles of the different Arbitrum chains.\n\nProtocol smart contracts​\nCore contracts​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nRollup\t0x5eF0...Ba35\t0xFb20...AD88\t0xd808...81C8\nSequencer Inbox\t0x1c47...82B6\t0x211E...c21b\t0x6c97...be0D\nCoreProxyAdmin\t0x5547...2dbD\t0x71D7...7148\t0x1ed7...0686\nCross-chain messaging contracts​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nDelayed Inbox\t0x4Dbd...AB3f\t0xc444...3949\t0xaAe2...ae21\nBridge\t0x8315...ed3a\t0xC1Eb...76Bd\t0x38f9...33a9\nOutbox\t0x0B98...4840\t0xD4B8...cc58\t0x65f0...B78F\nClassic Outbox***\t0x7607...1A40\n0x667e...337a\t\t\n\n***Migrated Network Only\n\nFraud proof contracts​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nChallengeManager\t0xe589...6f58\t0xA590...af0D\t0x84ED...0700\nOneStepProver0\t0x499A...EfcC\t0x8323...d236\t0xAF57...0ddA\nOneStepProverMemory\t0xb556...B676\t0x7a6C...9979\t0xA6Ac...f0c5\nOneStepProverMath\t0xd315...7970\t0x1efb...f2F5\t0xfEe5...42F4\nOneStepProverHostIo\t0xb965...D13A\t0x9CBC...7613\t0xA53a...752a\nOneStepProofEntry\t0x3E1f...A1DF\t0x7Adc...0Fc5\t0x08a2...5961\nToken bridge smart contracts​\nCore contracts​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nL1 Gateway Router\t0x72Ce...31ef\t0xC840...cD48\t0xcE18...8264\nL1 ERC20 Gateway\t0xa3A7...0EeC\t0xB253...21bf\t0x902b...3aFF\nL1 Arb-Custom Gateway\t0xcEe2...180d\t0x2312...232f\t0xba2F...40F3\nL1 Weth Gateway\t0xd920...e2db\t0xE4E2...0BaE\t0xA8aD...0e1E\nL1 Weth\t0xC02a...6Cc2\t0xC02a...6Cc2\t0x7b79...E7f9\nL1 Proxy Admin\t0x9aD4...0aDa\t0xa8f7...e560\t0xDBFC...44b0\n\nThe following contracts are deployed on the corresponding L2 chain\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nL2 Gateway Router\t0x5288...F933\t0x2190...DFa8\t0x9fDD...43C7\nL2 ERC20 Gateway\t0x09e9...1EEe\t0xcF9b...9257\t0x6e24...b502\nL2 Arb-Custom Gateway\t0x0967...5562\t0xbf54...51F4\t0x8Ca1...42C5\nL2 Weth Gateway\t0x6c41...623B\t0x7626...D9eD\t0xCFB1...556D\nL2 Weth\t0x82aF...Bab1\t0x722E...5365\t0x980B...7c73\nL2 Proxy Admin\t0xd570...2a86\t0xada7...d92C\t0x715D...5FdF\nThird party gateways​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\nL1 Dai Gateway\t0xD3B5...3011\nL1 Livepeer Gateway\t0x6142...0676\n\nThe following contracts are deployed on the corresponding L2 chain\n\n\tArbitrum One\nL2 Dai Gateway\t0x4671...6C65\nL2 Livepeer Gateway\t0x6D24...D318\nPrecompiles​\n\nThe following precompiles are deployed on every L2 chain and always have the same address\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nArbAddressTable\t0x0000...0066\t0x0000...0066\t0x0000...0066\nArbAggregator\t0x0000...006D\t0x0000...006D\t0x0000...006D\nArbFunctionTable\t0x0000...0068\t0x0000...0068\t0x0000...0068\nArbGasInfo\t0x0000...006C\t0x0000...006C\t0x0000...006C\nArbInfo\t0x0000...0065\t0x0000...0065\t0x0000...0065\nArbOwner\t0x0000...0070\t0x0000...0070\t0x0000...0070\nArbOwnerPublic\t0x0000...006b\t0x0000...006b\t0x0000...006b\nArbRetryableTx\t0x0000...006E\t0x0000...006E\t0x0000...006E\nArbStatistics\t0x0000...006F\t0x0000...006F\t0x0000...006F\nArbSys\t0x0000...0064\t0x0000...0064\t0x0000...0064\nArbWasm\t-\t-\t0x0000...0071\nArbWasmCache\t-\t-\t0x0000...0072\nNodeInterface\t0x0000...00C8\t0x0000...00C8\t0x0000...00C8\nMisc​\n\nThe following contracts are deployed on the corresponding L2 chain\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nL2 Multicall\t0x842e...4EB2\t0x5e1e...cB86\t0xA115...d092\n;\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nRPC endpoints and providers\nNext\nChain parameters\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/more-types/run-classic-node",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nRun an archive node\nRun a validator\nRun a Classic node\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to run a Classic node\nDo you need to run a Classic node?​\n\nArbitrum One has been upgraded to Nitro, the latest Arbitrum tech stack. \"Arbitrum Classic\" is our term for the old, pre-Nitro tech stack. The Nitro node databases have the raw data of all blocks, including pre-Nitro blocks. However, Nitro nodes cannot execute anything on pre-Nitro blocks. You need an Arbitrum Classic archive node to execute data on pre-Nitro blocks.\n\nThe following commands are supported when running an Arbitrum Classic archive node:\n\neth_call\neth_estimateGas\neth_getBalance\neth_getCode\neth_getTransactionCount\neth_getStorageAt\n\n🔉 Note that Arbitrum Nova and Arbitrum Sepolia started as a Nitro chain, so they don't have classic blocks.\n\nRequired artifacts​\nLatest Docker Image: offchainlabs/arb-node:v1.4.5-e97c1a4\nLatest classic snapshot for Arbitrum One: https://snapshot.arbitrum.foundation/arb1/classic-archive.tar\nRequired parameters​\n--l1.url=<Layer 1 Ethereum RPC URL>\nMust provide standard Ethereum node RPC endpoint.\n--node.chain-id=<L2 Chain ID>\nMust use 42161 for Arbitrum One\nImportant ports​\nRPC: 8547\nWebSocket: 8548\nPutting it all together​\nWhen running docker image, an external volume should be mounted to persist the database across restarts. The mount point should be /home/user/.arbitrum/mainnet.\nHere is an example of how to run a classic archive node for Arbitrum One (only needed for archive requests on pre-Nitro blocks, so you'll probably want to enable the archive mode in your nitro node as well):\ndocker run --rm -it  -v /some/local/dir/arbitrum-mainnet/:/home/user/.arbitrum/mainnet -p 0.0.0.0:8547:8547 -p 0.0.0.0:8548:8548 offchainlabs/arb-node:v1.4.5-e97c1a4 --l1.url=https://l1-node:8545 --node.chain-id=42161 --l2.disable-upstream\n\nNote on permissions​\nThe Docker image is configured to run as non-root UID 1000. This means if you are running in Linux and you are getting permission errors when trying to run the docker image, run this command to allow all users to update the persistent folders.\nmkdir /some/local/dir/arbitrum-mainnet\nchmod -fR 777 /some/local/dir/arbitrum-mainnet\n\nOptional parameters​\n\nWe show here a list of the parameters that are most commonly used when running a Classic node. You can also use the flag --help for a full comprehensive list of the available parameters.\n\n--core.cache.timed-expire\nDefaults to 20m, or 20 minutes. Age of oldest blocks to hold in cache so that disk lookups are not required\n--node.rpc.max-call-gas\nMaximum amount of gas that a node will use in call, default is 5000000\n--core.checkpoint-gas-frequency\nDefaults to 1000000000. Amount of gas between saving checkpoints to disk. When making archive queries node has to load closest previous checkpoint and then execute up to the requested block. The farther apart the checkpoints, the longer potential execution required. However, saving checkpoints more often slows down the node in general.\n--node.cache.allow-slow-lookup\nWhen this option is present, will load old blocks from disk if not in memory cache\nIf archive support is desired, recommend using --node.cache.allow-slow-lookup --core.checkpoint-gas-frequency=156250000\n--node.rpc.tracing.enable\nNote that you also need to have a database populated with an archive node if you want to trace previous transactions\nThis option enables the ability to call a tracing api which is inspired by the parity tracing API with some differences\nExample: curl http://arbnode -X POST -H \"Content-Type: application/json\" -d '{\"jsonrpc\":\"2.0\",\"method\":\"arbtrace_call\",\"params\":[{\"to\": \"0x6b175474e89094c44da98b954eedeac495271d0f\",\"data\": \"0x70a082310000000000000000000000006E0d01A76C3Cf4288372a29124A26D4353EE51BE\"},[\"trace\"], \"latest\"],\"id\":67}'\nThe trace_* methods are renamed to arbtrace_*, except trace_rawTransaction is not supported\nOnly trace type is supported. vmTrace and stateDiff types are not supported\nThe self-destruct opcode is not included in the trace. To get the list of self-destructed contracts, you can provide the deletedContracts parameter to the method\nFeed relay​\nArbitrum classic does not communicate with Nitro sequencer, so the classic relay is no longer used.\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRun a validator\nNext\nRun a feed relay\nDo you need to run a Classic node?\nRequired artifacts\nRequired parameters\nImportant ports\nPutting it all together\nNote on permissions\nOptional parameters\nFeed relay\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/nitro/build-nitro-locally",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to build Nitro locally (Debian, Ubuntu, MacOS)\n\nArbitrum Nitro is the software that powers all Arbitrum chains. This how-to shows how you can build a Docker image, or binaries, directly from Nitro's source code. If you want to run a node for one of the Arbitrum chains, however, it is recommended that you use the docker image available on DockerHub, as explained in How to run a full node.\n\nThis how-to assumes that you're running one of the following operating systems:\n\nDebian 11.7 (arm64)\nUbuntu 22.04 (amd64)\nMacOS Sonoma 14.3.\nBuild a Docker image​\nStep 1. Configure Docker​\nFor Debian/Ubuntu​\nfor pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done\n# Add Docker's official GPG key:\nsudo apt-get update\nsudo apt-get install ca-certificates curl gnupg\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nsudo chmod a+r /etc/apt/keyrings/docker.gpg\n\n# Add the repository to Apt sources:\necho \\\n  \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian \\\n  \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\nsudo service docker start\n\n\n(Note that if you are running Ubuntu 22.04, you might get an Unable to locate package docker-buildx-plugin error. Try sudo apt install docker-buildx instead.)\n\nFor MacOS​\n\nDepending on whether your Mac has an Intel processor or Apple silicon, download the corresponding disk image from Docker, and move it into your Applications folder.\n\n[Optional] Run docker from a different user​\n\nAfter installing docker, you might want to be able to run it with your current user instead of root. You can run the following commands to do so.\n\nsudo groupadd docker\nsudo usermod -aG docker $USER\nnewgrp docker\n\n\nFor troubleshooting, check Docker's section in their documentation\n\nStep 2. Download the Nitro source code​\ngit clone --branch v3.2.1 https://github.com/OffchainLabs/nitro.git\ncd nitro\ngit submodule update --init --recursive --force\n\nStep 3. Build the Nitro node Docker image​\ndocker build . --tag nitro-node\n\n\nThat command will build a Docker image called nitro-node from the local source.\n\nBuild Nitro's binaries natively​\n\nIf you want to build the node binaries natively, execute steps 1-3 of the Build a Docker image section and continue with the steps described here. Notice that even though we are building the binaries outside of Docker, it is still used to help build some WebAssembly components.\n\nStep 4. Configure prerequisites​\nFor Debian/Ubuntu​\napt install git curl build-essential cmake npm golang clang make gotestsum wabt lld-13 python3\nnpm install --global yarn\nln -s /usr/bin/wasm-ld-13 /usr/local/bin/wasm-ld\n\nFor MacOS​\n\nInstall Homebrew package manager and add it to your PATH environment variable:\n\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\necho \"export PATH=/opt/homebrew/bin:$PATH\" >> ~/.zprofile && source ~/.zprofile\n\n\n(replace ~/.zprofile with ~/.bash_profile if you use bash instead of zsh).\n\nInstall essentials:\n\nbrew install git curl make cmake npm go golangci-lint wabt llvm lld libusb gotestsum\nnpm install --global yarn\nsudo mkdir -p /usr/local/bin\necho \"export PATH=/opt/homebrew/opt/llvm/bin:$PATH\" >> ~/.zprofile && source ~/.zprofile\n\nStep 5. Configure node 18​\nFor Debian/Ubuntu​\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | bash\nsource \"$HOME/.bashrc\"\nnvm install 18\nnvm use 18\n\nFor MacOS​\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | bash\nexport NVM_DIR=\"$HOME/.nvm\"\n[ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\"\nnvm install 18\nnvm use 18\n\nStep 6. Configure Rust 1.80.1​\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsource \"$HOME/.cargo/env\"\nrustup install 1.80.1\nrustup default 1.80.1\nrustup install nightly\nrustup target add wasm32-unknown-unknown --toolchain 1.80.1\nrustup target add wasm32-wasi --toolchain 1.80.1\nrustup target add wasm32-unknown-unknown --toolchain nightly\nrustup target add wasm32-wasi --toolchain nightly\nrustup component add rust-src --toolchain nightly\ncargo install cbindgen\n\nStep 7. Configure Go 1.23​\nInstall Bison​\nFor Debian/Ubuntu​\nsudo apt-get install bison\n\nFor MacOS​\nbrew install bison\n\nInstall and configure Go​\nbash < <(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)\nsource \"$HOME/.gvm/scripts/gvm\"\ngvm install go1.23\ngvm use go1.23 --default\ncurl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b $(go env GOPATH)/bin v1.54.2\n\n\nIf you use zsh, replace bash with zsh.\n\nInstall foundry​\ncurl -L https://foundry.paradigm.xyz | bash\nfoundryup\n\nStep 8. Start build​\nmake\n\nStep 9. Produce binaries​\nmake build\n\nWarnings on MacOS​\n\nIn MacOS with Apple Silicon, warnings like the following might appear but they will not hinder the compilation process.\n\nld: warning: object file was built for newer 'macOS' version (14.4) than being linked (14.0)\n\n\nTo solve these warnings, export the following environment variables before building Nitro.\n\nexport MACOSX_DEPLOYMENT_TARGET=$(sw_vers -productVersion)\nexport CGO_LDFLAGS=-Wl,-no_warn_duplicate_libraries\n\nStep 10. Run your node​\n\nTo run your node using the generated binaries, use the following command from the nitro folder, with your desired parameters\n\n./target/bin/nitro <node parameters>\n\nWASM module root error (v2.3.4 or later)​\n\nSince v2.3.4, the State Transition Function (STF) contains code that is not yet activated on the current mainnet and testnet chains. Because of that, you might receive the following error when connecting your built node to those chains:\n\nERROR[05-21|21:59:17.415] unable to find validator machine directory for the on-chain WASM module root err=\"stat {WASM_MODULE_ROOT}: no such file or directory\"\n\n\nTry add flag:\n\n--validation.wasm.allowed-wasm-module-roots={WASM_MODULE_ROOT}\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRun a Sequencer Coordination Manager (SQM)\nNext\nMigrate to Nitro from Classic\nBuild a Docker image\nStep 1. Configure Docker\nStep 2. Download the Nitro source code\nStep 3. Build the Nitro node Docker image\nBuild Nitro's binaries natively\nStep 4. Configure prerequisites\nStep 5. Configure node 18\nStep 6. Configure Rust 1.80.1\nStep 7. Configure Go 1.23\nStep 8. Start build\nStep 9. Produce binaries\nStep 10. Run your node\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/sequencer/read-sequencer-feed",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nRun a feed relay\nRead the sequencer feed\nRun a Sequencer Coordination Manager (SQM)\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to read the sequencer feed\n\nRunning an Arbitrum relay locally as a feed relay lets you subscribe to an uncompressed sequencer feed for real-time data as the sequencer accepts and orders transactions off-chain.\n\nWhen connected to websocket port 9642 of the local relay, you'll receive a data feed that looks something like this:\n\n{\n  \"version\": 1,\n  \"messages\": [\n    {\n      \"sequenceNumber\": 25757171,\n      \"message\": {\n        \"message\": {\n          \"header\": {\n            \"kind\": 3,\n            \"sender\": \"0xa4b000000000000000000073657175656e636572\",\n            \"blockNumber\": 16238523,\n            \"timestamp\": 1671691403,\n            \"requestId\": null,\n            \"baseFeeL1\": null\n          },\n          \"l2Msg\": \"BAL40oKksUiElQL5AISg7rsAgxb6o5SZbYNoIF2DTixsqDpD2xII9GJLG4C4ZAhh6N0AAAAAAAAAAAAAAAC7EQiq1R1VYgL3/oXgvD921hYRyAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArAAaAkebuEnSAUvrWVBGTxA7W+ZMNn5uyLlbOH7Nrs0bYOv6AOxQPqAo2UB0Z7vqlugjn+BUl0drDcWejBfDiPEC6jQA==\"\n        },\n        \"delayedMessagesRead\": 354560\n      },\n      \"signature\": null\n    }\n  ]\n}\n\n\nBreaking this feed down a bit: the top-level data structure is defined by the BroadcastMessage struct:\n\ntype BroadcastMessage struct {\n\tVersion int `json:\"version\"`\n\t// Note: the \"Messages\" object naming is slightly ambiguous: since there are different types of messages\n\tMessages                       []*BroadcastFeedMessage         `json:\"messages,omitempty\"`\n\tConfirmedSequenceNumberMessage *ConfirmedSequenceNumberMessage `json:\"confirmedSequenceNumberMessage,omitempty\"`\n}\n\n\nThe messages field is the BroadcastFeedMessage struct:\n\ntype BroadcastFeedMessage struct {\n\tSequenceNumber arbutil.MessageIndex         `json:\"sequenceNumber\"`\n\tMessage        arbstate.MessageWithMetadata `json:\"message\"`\n\tSignature      []byte                       `json:\"signature\"`\n}\n\n\nEach message conforms to arbstate.MessageWithMetadata:\n\ntype MessageWithMetadata struct {\n\tMessage             *arbos.L1IncomingMessage `json:\"message\"`\n\tDelayedMessagesRead uint64                   `json:\"delayedMessagesRead\"`\n}\n\n\nFinally, we get the transaction's information in the message subfield as an L1IncomingMessage:\n\ntype L1IncomingMessage struct {\n\tHeader *L1IncomingMessageHeader `json:\"header\"`\n\tL2msg  []byte                   `json:\"l2Msg\"`\n\t// Only used for `L1MessageType_BatchPostingReport`\n\tBatchGasCost *uint64 `json:\"batchGasCost,omitempty\" rlp:\"optional\"`\n}\n\n\nYou can use the ParseL2Transactions function to decode the message.\n\nUsing the feed relay, you can also retrieve the L2 block number of a message:\n\nOn Arbitrum One, this can be done by adding the Arbitrum One genesis block number (22207817) to the sequence number of the feed message.\nNote that in the case of Arbitrum Nova, the Nitro genesis number is 0, so it doesn't need to be included when adding to the feed message's sequence number.\nINFO\n\nNote that the messagess[0].message.message.header.blockNumber is L1 block number instead of L2 block number\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRun a feed relay\nNext\nRun a Sequencer Coordination Manager (SQM)\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/token-bridging/bridge-tokens-programmatically/how-to-bridge-tokens-custom-gateway",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nOverview\nETH bridging\nERC-20 token bridging\nBridge tokens programmatically\nGet started\nUse the standard gateway\nUse the generic-custom gateway\nUse the custom gateway\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to bridge tokens via a custom gateway\nDO YOU REALLY NEED A CUSTOM GATEWAY?\n\nBefore starting to implement and deploy a custom gateway, it is strongly encouraged to analyze the current solutions that Arbitrum’s token bridge provides: the standard gateway and the generic-custom gateway. These solutions provide enough functionality to solve the majority of bridging needs from projects. And if you are in doubt about your current approach, you can always ask for assistance on our Discord server.\n\nIn this how-to you’ll learn how to bridge your own token between Ethereum (Layer 1 or L1) and Arbitrum (Layer 2 or L2), using a custom gateway. For alternative ways of bridging tokens, don’t forget to check out this overview.\n\nFamiliarity with Arbitrum’s token bridge system, smart contracts, and blockchain development is expected. If you’re new to blockchain development, consider reviewing our Quickstart: Build a dApp with Arbitrum (Solidity, Hardhat) before proceeding. We will use Arbitrum’s SDK throughout this how-to, although no prior knowledge is required.\n\nWe will go through all steps involved in the process. However, if you want to jump straight to the code, we have created this script in our tutorials repository that encapsulates the entire process.\n\nStep 0: Review the prerequisites (a.k.a. do I really need a custom gateway?)​\n\nBefore starting to implement and deploy a custom gateway, it is strongly encouraged to analyze the current solutions that Arbitrum’s token bridge provides: the standard gateway and the generic-custom gateway. These solutions provide enough functionality to solve the majority of bridging needs from projects. And if you are in doubt about your current approach, you can always ask for assistance on our Discord server.\n\nHaving said that, there are multiple prerequisites to keep in mind when deploying your own custom gateway.\n\nFirst of all, the L1 counterpart of the gateway, must conform to the IL1ArbitrumGateway and the ITokenGateway interfaces. This means that it must have, at least:\n\nA method outboundTransferCustomRefund, to handle forwarded calls from L1GatewayRouter.outboundTransferCustomRefund. It should only allow calls from the router.\nA method outboundTransfer, to handle forwarded calls from L1GatewayRouter.outboundTransfer. It should only allow calls from the router.\nA method finalizeInboundTransfer, to handle messages coming ONLY from L2’s gateway.\nTwo methods calculateL2TokenAddress and getOutboundCalldata to handle other bridging operations.\nMethods to send cross-chain messages through the inbox contract. An example implementation can be found in sendTxToL2 and sendTxToL2CustomRefund on L1ArbitrumMessenger.\n\nFurthermore, if you plan on having permissionless registration of tokens in your gateway, your L1 gateway should also have a registerCustomL2Token method, similar to the one being used in Arbitrum’s generic-custom gateway.\n\nOn the other hand, the L2 counterpart of the gateway, must conform to the ITokenGateway interface. This means that it must have, at least:\n\nA method outboundTransfer, to handle external calls, and forwarded calls from L2GatewayRouter.outboundTransfer.\nA method finalizeInboundTransfer, to handle messages coming ONLY from L1’s gateway.\nTwo methods calculateL2TokenAddress and getOutboundCalldata to handle other bridging operations.\nMethods to send cross-chain messages through the ArbSys precompile. An example implementation can be found in sendTxToL1 on L2ArbitrumMessenger.\nWhat about my custom tokens?​\n\nIf you are deploying custom gateways, you will probably want to support your custom tokens on L1 and L2 too. They also have several requirements they must comply with. You can find more information about it in How to bridge tokens via Arbitrum’s generic-custom gateway.\n\nStep 1: Create a gateway and deploy it on L1​\nTHIS CODE IS FOR TESTING PURPOSES\n\nThe code contained within the following sections is meant for testing purposes only and does not guarantee any level of security. It has not undergone any formal audit or security analysis, so it is not ready for production use. Please exercise caution and due diligence while using this code in any environment.\n\nWe‘ll begin the process by creating our custom gateway and deploying it on L1. A good example of a custom gateway is Arbitrum’s generic-custom gateway. It includes all methods required plus some more to support the wide variety of tokens that can be bridged through it.\n\nIn this case, we’ll use a simpler approach. We’ll create a gateway that supports only one token and has the ability to be disabled/enabled by the owner of the contract. It will also implement all necessary methods. To simplify the deployment process even further, we won’t worry about setting the addresses of the counterpart gateway and the custom tokens at deployment time. Instead, we will use a function setTokenBridgeInformation that will be called by the owner of the contract to initialize the gateway.\n\n// SPDX-License-Identifier: Apache-2.0\npragma solidity ^0.8.0;\n\nimport \"./interfaces/ICustomGateway.sol\";\nimport \"./CrosschainMessenger.sol\";\nimport \"@openzeppelin/contracts/token/ERC20/IERC20.sol\";\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\n\n/**\n * @title Example implementation of a custom gateway to be deployed on L1\n * @dev Inheritance of Ownable is optional. In this case we use it to call the function setTokenBridgeInformation\n * and simplify the test\n */\ncontract L1CustomGateway is IL1CustomGateway, L1CrosschainMessenger, Ownable {\n\n    // Token bridge state variables\n    address public l1CustomToken;\n    address public l2CustomToken;\n    address public l2Gateway;\n    address public router;\n\n    // Custom functionality\n    bool public allowsDeposits;\n\n    /**\n     * Contract constructor, sets the L1 router to be used in the contract's functions and calls L1CrosschainMessenger's constructor\n     * @param router_ L1GatewayRouter address\n     * @param inbox_ Inbox address\n     */\n    constructor(\n        address router_,\n        address inbox_\n    ) L1CrosschainMessenger(inbox_) {\n        router = router_;\n        allowsDeposits = false;\n    }\n\n    /**\n     * Sets the information needed to use the gateway. To simplify the process of testing, this function can be called once\n     * by the owner of the contract to set these addresses.\n     * @param l1CustomToken_ address of the custom token on L1\n     * @param l2CustomToken_ address of the custom token on L2\n     * @param l2Gateway_ address of the counterpart gateway (on L2)\n     */\n    function setTokenBridgeInformation(\n        address l1CustomToken_,\n        address l2CustomToken_,\n        address l2Gateway_\n    ) public onlyOwner {\n        require(l1CustomToken == address(0), \"Token bridge information already set\");\n        l1CustomToken = l1CustomToken_;\n        l2CustomToken = l2CustomToken_;\n        l2Gateway = l2Gateway_;\n\n        // Allows deposits after the information has been set\n        allowsDeposits = true;\n    }\n\n    /// @dev See {ICustomGateway-outboundTransfer}\n    function outboundTransfer(\n        address l1Token,\n        address to,\n        uint256 amount,\n        uint256 maxGas,\n        uint256 gasPriceBid,\n        bytes calldata data\n    ) public payable override returns (bytes memory) {\n        return outboundTransferCustomRefund(l1Token, to, to, amount, maxGas, gasPriceBid, data);\n    }\n\n    /// @dev See {IL1CustomGateway-outboundTransferCustomRefund}\n    function outboundTransferCustomRefund(\n        address l1Token,\n        address refundTo,\n        address to,\n        uint256 amount,\n        uint256 maxGas,\n        uint256 gasPriceBid,\n        bytes calldata data\n    ) public payable override returns (bytes memory res) {\n        // Only execute if deposits are allowed\n        require(allowsDeposits == true, \"Deposits are currently disabled\");\n\n        // Only allow calls from the router\n        require(msg.sender == router, \"Call not received from router\");\n\n        // Only allow the custom token to be bridged through this gateway\n        require(l1Token == l1CustomToken, \"Token is not allowed through this gateway\");\n\n        address from;\n        uint256 seqNum;\n        {\n            bytes memory extraData;\n            uint256 maxSubmissionCost;\n            (from, maxSubmissionCost, extraData) = _parseOutboundData(data);\n\n            // The inboundEscrowAndCall functionality has been disabled, so no data is allowed\n            require(extraData.length == 0, \"EXTRA_DATA_DISABLED\");\n\n            // Escrowing the tokens in the gateway\n            IERC20(l1Token).transferFrom(from, address(this), amount);\n\n            // We override the res field to save on the stack\n            res = getOutboundCalldata(l1Token, from, to, amount, extraData);\n\n            // Trigger the crosschain message\n            seqNum = _sendTxToL2CustomRefund(\n                l2Gateway,\n                refundTo,\n                from,\n                msg.value,\n                0,\n                maxSubmissionCost,\n                maxGas,\n                gasPriceBid,\n                res\n            );\n        }\n\n        emit DepositInitiated(l1Token, from, to, seqNum, amount);\n        res = abi.encode(seqNum);\n    }\n\n    /// @dev See {ICustomGateway-finalizeInboundTransfer}\n    function finalizeInboundTransfer(\n        address l1Token,\n        address from,\n        address to,\n        uint256 amount,\n        bytes calldata data\n    ) public payable override onlyCounterpartGateway(l2Gateway) {\n        // Only allow the custom token to be bridged through this gateway\n        require(l1Token == l1CustomToken, \"Token is not allowed through this gateway\");\n\n        // Decoding exitNum\n        (uint256 exitNum, ) = abi.decode(data, (uint256, bytes));\n\n        // Releasing the tokens in the gateway\n        IERC20(l1Token).transfer(to, amount);\n\n        emit WithdrawalFinalized(l1Token, from, to, exitNum, amount);\n    }\n\n    /// @dev See {ICustomGateway-getOutboundCalldata}\n    function getOutboundCalldata(\n        address l1Token,\n        address from,\n        address to,\n        uint256 amount,\n        bytes memory data\n    ) public pure override returns (bytes memory outboundCalldata) {\n        bytes memory emptyBytes = \"\";\n\n        outboundCalldata = abi.encodeWithSelector(\n            ICustomGateway.finalizeInboundTransfer.selector,\n            l1Token,\n            from,\n            to,\n            amount,\n            abi.encode(emptyBytes, data)\n        );\n\n        return outboundCalldata;\n    }\n\n    /// @dev See {ICustomGateway-calculateL2TokenAddress}\n    function calculateL2TokenAddress(address l1Token) public view override returns (address) {\n        if (l1Token == l1CustomToken) {\n            return l2CustomToken;\n        }\n\n        return address(0);\n    }\n\n    /// @dev See {ICustomGateway-counterpartGateway}\n    function counterpartGateway() public view override returns (address) {\n        return l2Gateway;\n    }\n\n    /**\n     * Parse data received in outboundTransfer\n     * @param data encoded data received\n     * @return from account that initiated the deposit,\n     *         maxSubmissionCost max gas deducted from user's L2 balance to cover base submission fee,\n     *         extraData decoded data\n     */\n    function _parseOutboundData(bytes memory data)\n    internal\n    pure\n    returns (\n        address from,\n        uint256 maxSubmissionCost,\n        bytes memory extraData\n    )\n    {\n        // Router encoded\n        (from, extraData) = abi.decode(data, (address, bytes));\n\n        // User encoded\n        (maxSubmissionCost, extraData) = abi.decode(extraData, (uint256, bytes));\n    }\n\n    // --------------------\n    // Custom methods\n    // --------------------\n    /**\n     * Disables the ability to deposit funds\n     */\n    function disableDeposits() external onlyOwner {\n        allowsDeposits = false;\n    }\n\n    /**\n     * Enables the ability to deposit funds\n     */\n    function enableDeposits() external onlyOwner {\n        require(l1CustomToken != address(0), \"Token bridge information has not been set yet\");\n        allowsDeposits = true;\n    }\n}\n\n\nIL1CustomGateway is an interface very similar to ICustomGateway, and L1CrosschainMessenger implements a method to send the cross-chain message to L2 through the Inbox.\n\n/**\n * @title Minimum expected implementation of a crosschain messenger contract to be deployed on L1\n */\nabstract contract L1CrosschainMessenger {\n    IInbox public immutable inbox;\n\n    /**\n     * Emitted when calling sendTxToL2CustomRefund\n     * @param from account that submitted the retryable ticket\n     * @param to account recipient of the retryable ticket\n     * @param seqNum id for the retryable ticket\n     * @param data data of the retryable ticket\n     */\n    event TxToL2(\n        address indexed from,\n        address indexed to,\n        uint256 indexed seqNum,\n        bytes data\n    );\n\n    constructor(address inbox_) {\n        inbox = IInbox(inbox_);\n    }\n\n    modifier onlyCounterpartGateway(address l2Counterpart) {\n        // A message coming from the counterpart gateway was executed by the bridge\n        IBridge bridge = inbox.bridge();\n        require(msg.sender == address(bridge), \"NOT_FROM_BRIDGE\");\n\n        // And the outbox reports that the L2 address of the sender is the counterpart gateway\n        address l2ToL1Sender = IOutbox(bridge.activeOutbox()).l2ToL1Sender();\n        require(l2ToL1Sender == l2Counterpart, \"ONLY_COUNTERPART_GATEWAY\");\n\n        _;\n    }\n\n    /**\n     * Creates the retryable ticket to send over to L2 through the Inbox\n     * @param to account to be credited with the tokens in the destination layer\n     * @param refundTo account, or its L2 alias if it have code in L1, to be credited with excess gas refund in L2\n     * @param user account with rights to cancel the retryable and receive call value refund\n     * @param l1CallValue callvalue sent in the L1 submission transaction\n     * @param l2CallValue callvalue for the L2 message\n     * @param maxSubmissionCost max gas deducted from user's L2 balance to cover base submission fee\n     * @param maxGas max gas deducted from user's L2 balance to cover L2 execution\n     * @param gasPriceBid gas price for L2 execution\n     * @param data encoded data for the retryable\n     * @return seqnum id for the retryable ticket\n     */\n    function _sendTxToL2CustomRefund(\n        address to,\n        address refundTo,\n        address user,\n        uint256 l1CallValue,\n        uint256 l2CallValue,\n        uint256 maxSubmissionCost,\n        uint256 maxGas,\n        uint256 gasPriceBid,\n        bytes memory data\n    ) internal returns (uint256) {\n        uint256 seqNum = inbox.createRetryableTicket{ value: l1CallValue }(\n            to,\n            l2CallValue,\n            maxSubmissionCost,\n            refundTo,\n            user,\n            maxGas,\n            gasPriceBid,\n            data\n        );\n\n        emit TxToL2(user, to, seqNum, data);\n        return seqNum;\n    }\n}\n\n\nWe now deploy that gateway to L1.\n\nconst { ethers } = require('hardhat');\nconst { providers, Wallet, BigNumber } = require('ethers');\nconst { getArbitrumNetwork, ParentToChildMessageStatus } = require('@arbitrum/sdk');\nconst {\n  AdminErc20Bridger,\n  Erc20Bridger,\n} = require('@arbitrum/sdk/dist/lib/assetBridger/erc20Bridger');\nrequire('dotenv').config();\n\n/**\n * Set up: instantiate L1 / L2 wallets connected to providers\n */\nconst walletPrivateKey = process.env.DEVNET_PRIVKEY;\nconst l1Provider = new providers.JsonRpcProvider(process.env.L1RPC);\nconst l2Provider = new providers.JsonRpcProvider(process.env.L2RPC);\nconst l1Wallet = new Wallet(walletPrivateKey, l1Provider);\nconst l2Wallet = new Wallet(walletPrivateKey, l2Provider);\n\nconst main = async () => {\n  /**\n   * Use l2Network to create an Arbitrum SDK AdminErc20Bridger instance\n   * We'll use AdminErc20Bridger for its convenience methods around registering tokens to a custom gateway\n   */\n  const l2Network = await getArbitrumNetwork(l2Provider);\n  const erc20Bridger = new Erc20Bridger(l2Network);\n  const adminTokenBridger = new AdminErc20Bridger(l2Network);\n  const l1Router = l2Network.tokenBridge.parentGatewayRouter;\n  const l2Router = l2Network.tokenBridge.childGatewayRouter;\n  const inbox = l2Network.ethBridge.inbox;\n\n  /**\n   * Deploy our custom gateway to L1\n   */\n  const L1CustomGateway = await await ethers.getContractFactory('L1CustomGateway', l1Wallet);\n  console.log('Deploying custom gateway to L1');\n  const l1CustomGateway = await L1CustomGateway.deploy(l1Router, inbox);\n  await l1CustomGateway.deployed();\n  console.log(`Custom gateway is deployed to L1 at ${l1CustomGateway.address}`);\n  const l1CustomGatewayAddress = l1CustomGateway.address;\n};\n\nmain()\n  .then(() => process.exit(0))\n  .catch((error) => {\n    console.error(error);\n    process.exit(1);\n  });\n\nStep 2: Create a gateway and deploy it on L2​\n\nWe’ll now create the counterpart of the gateway we created on L1 and deploy it on L2. A good example of a custom gateway on L2 is Arbitrum’s generic-custom gateway on L2.\n\nAs we did with the L1 gateway, we’ll use a simpler approach with the same characteristics of that in L1: supports only one token and has the ability to be disabled/enabled by the owner of the contract. It will also have a setTokenBridgeInformation to be called by the owner of the contract to initialize the gateway.\n\n// SPDX-License-Identifier: Apache-2.0\npragma solidity ^0.8.0;\n\nimport \"./interfaces/ICustomGateway.sol\";\nimport \"./CrosschainMessenger.sol\";\nimport \"./interfaces/IArbToken.sol\";\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\n\n/**\n * @title Example implementation of a custom gateway to be deployed on L2\n * @dev Inheritance of Ownable is optional. In this case we use it to call the function setTokenBridgeInformation\n * and simplify the test\n */\ncontract L2CustomGateway is IL2CustomGateway, L2CrosschainMessenger, Ownable {\n    // Exit number (used for tradeable exits)\n    uint256 public exitNum;\n\n    // Token bridge state variables\n    address public l1CustomToken;\n    address public l2CustomToken;\n    address public l1Gateway;\n    address public router;\n\n    // Custom functionality\n    bool public allowsWithdrawals;\n\n    /**\n     * Contract constructor, sets the L2 router to be used in the contract's functions\n     * @param router_ L2GatewayRouter address\n     */\n    constructor(address router_) {\n        router = router_;\n        allowsWithdrawals = false;\n    }\n\n    /**\n     * Sets the information needed to use the gateway. To simplify the process of testing, this function can be called once\n     * by the owner of the contract to set these addresses.\n     * @param l1CustomToken_ address of the custom token on L1\n     * @param l2CustomToken_ address of the custom token on L2\n     * @param l1Gateway_ address of the counterpart gateway (on L1)\n     */\n    function setTokenBridgeInformation(\n        address l1CustomToken_,\n        address l2CustomToken_,\n        address l1Gateway_\n    ) public onlyOwner {\n        require(l1CustomToken == address(0), \"Token bridge information already set\");\n        l1CustomToken = l1CustomToken_;\n        l2CustomToken = l2CustomToken_;\n        l1Gateway = l1Gateway_;\n\n        // Allows withdrawals after the information has been set\n        allowsWithdrawals = true;\n    }\n\n    /// @dev See {ICustomGateway-outboundTransfer}\n    function outboundTransfer(\n        address l1Token,\n        address to,\n        uint256 amount,\n        bytes calldata data\n    ) public payable returns (bytes memory) {\n        return outboundTransfer(l1Token, to, amount, 0, 0, data);\n    }\n\n    /// @dev See {ICustomGateway-outboundTransfer}\n    function outboundTransfer(\n        address l1Token,\n        address to,\n        uint256 amount,\n        uint256, /* _maxGas */\n        uint256, /* _gasPriceBid */\n        bytes calldata data\n    ) public payable override returns (bytes memory res) {\n        // Only execute if deposits are allowed\n        require(allowsWithdrawals == true, \"Withdrawals are currently disabled\");\n\n        // The function is marked as payable to conform to the inheritance setup\n        // This particular code path shouldn't have a msg.value > 0\n        require(msg.value == 0, \"NO_VALUE\");\n\n        // Only allow the custom token to be bridged through this gateway\n        require(l1Token == l1CustomToken, \"Token is not allowed through this gateway\");\n\n        (address from, bytes memory extraData) = _parseOutboundData(data);\n\n        // The inboundEscrowAndCall functionality has been disabled, so no data is allowed\n        require(extraData.length == 0, \"EXTRA_DATA_DISABLED\");\n\n        // Burns L2 tokens in order to release escrowed L1 tokens\n        IArbToken(l2CustomToken).bridgeBurn(from, amount);\n\n        // Current exit number for this operation\n        uint256 currExitNum = exitNum++;\n\n        // We override the res field to save on the stack\n        res = getOutboundCalldata(l1Token, from, to, amount, extraData);\n\n        // Trigger the crosschain message\n        uint256 id = _sendTxToL1(\n            from,\n            l1Gateway,\n            res\n        );\n\n        emit WithdrawalInitiated(l1Token, from, to, id, currExitNum, amount);\n        return abi.encode(id);\n    }\n\n    /// @dev See {ICustomGateway-finalizeInboundTransfer}\n    function finalizeInboundTransfer(\n        address l1Token,\n        address from,\n        address to,\n        uint256 amount,\n        bytes calldata data\n    ) public payable override onlyCounterpartGateway(l1Gateway) {\n        // Only allow the custom token to be bridged through this gateway\n        require(l1Token == l1CustomToken, \"Token is not allowed through this gateway\");\n\n        // Abi decode may revert, but the encoding is done by L1 gateway, so we trust it\n        (, bytes memory callHookData) = abi.decode(data, (bytes, bytes));\n        if (callHookData.length != 0) {\n            // callHookData should always be 0 since inboundEscrowAndCall is disabled\n            callHookData = bytes(\"\");\n        }\n\n        // Mints L2 tokens\n        IArbToken(l2CustomToken).bridgeMint(to, amount);\n\n        emit DepositFinalized(l1Token, from, to, amount);\n    }\n\n    /// @dev See {ICustomGateway-getOutboundCalldata}\n    function getOutboundCalldata(\n        address l1Token,\n        address from,\n        address to,\n        uint256 amount,\n        bytes memory data\n    ) public view override returns (bytes memory outboundCalldata) {\n        outboundCalldata = abi.encodeWithSelector(\n            ICustomGateway.finalizeInboundTransfer.selector,\n            l1Token,\n            from,\n            to,\n            amount,\n            abi.encode(exitNum, data)\n        );\n\n        return outboundCalldata;\n    }\n\n    /// @dev See {ICustomGateway-calculateL2TokenAddress}\n    function calculateL2TokenAddress(address l1Token) public view override returns (address) {\n        if (l1Token == l1CustomToken) {\n            return l2CustomToken;\n        }\n\n        return address(0);\n    }\n\n    /// @dev See {ICustomGateway-counterpartGateway}\n    function counterpartGateway() public view override returns (address) {\n        return l1Gateway;\n    }\n\n    /**\n     * Parse data received in outboundTransfer\n     * @param data encoded data received\n     * @return from account that initiated the deposit,\n     *         extraData decoded data\n     */\n    function _parseOutboundData(bytes memory data)\n    internal\n    view\n    returns (\n        address from,\n        bytes memory extraData\n    )\n    {\n        if (msg.sender == router) {\n            // Router encoded\n            (from, extraData) = abi.decode(data, (address, bytes));\n        } else {\n            from = msg.sender;\n            extraData = data;\n        }\n    }\n\n    // --------------------\n    // Custom methods\n    // --------------------\n    /**\n     * Disables the ability to deposit funds\n     */\n    function disableWithdrawals() external onlyOwner {\n        allowsWithdrawals = false;\n    }\n\n    /**\n     * Enables the ability to deposit funds\n     */\n    function enableWithdrawals() external onlyOwner {\n        require(l1CustomToken != address(0), \"Token bridge information has not been set yet\");\n        allowsWithdrawals = true;\n    }\n}\n\n\nIL2CustomGateway is also an interface very similar to ICustomGateway, and L2CrosschainMessenger implements a method to send the cross-chain message to L1 through ArbSys.\n\n/**\n * @title Minimum expected implementation of a crosschain messenger contract to be deployed on L2\n */\nabstract contract L2CrosschainMessenger {\n    address internal constant ARB_SYS_ADDRESS = address(100);\n\n    /**\n     * Emitted when calling sendTxToL1\n     * @param from account that submits the L2-to-L1 message\n     * @param to account recipient of the L2-to-L1 message\n     * @param id id for the L2-to-L1 message\n     * @param data data of the L2-to-L1 message\n     */\n    event TxToL1(\n        address indexed from,\n        address indexed to,\n        uint256 indexed id,\n        bytes data\n    );\n\n    modifier onlyCounterpartGateway(address l1Counterpart) {\n        require(\n            msg.sender == AddressAliasHelper.applyL1ToL2Alias(l1Counterpart),\n            \"ONLY_COUNTERPART_GATEWAY\"\n        );\n\n        _;\n    }\n\n    /**\n     * Creates an L2-to-L1 message to send over to L1 through ArbSys\n     * @param from account that is sending funds from L2\n     * @param to account to be credited with the tokens in the destination layer\n     * @param data encoded data for the L2-to-L1 message\n     * @return id id for the L2-to-L1 message\n     */\n    function _sendTxToL1(\n        address from,\n        address to,\n        bytes memory data\n    ) internal returns (uint256) {\n        uint256 id = ArbSys(ARB_SYS_ADDRESS).sendTxToL1(to, data);\n\n        emit TxToL1(from, to, id, data);\n        return id;\n    }\n}\n\n\nWe now deploy that gateway to L2.\n\nconst { ethers } = require('hardhat');\nconst { providers, Wallet, BigNumber } = require('ethers');\nconst {\n  getArbitrumNetwork,\n  ParentToChildMessageStatus,\n  AdminErc20Bridger,\n  Erc20Bridger,\n} = require('@arbitrum/sdk');\nrequire('dotenv').config();\n\n/**\n * Set up: instantiate L1 / L2 wallets connected to providers\n */\nconst walletPrivateKey = process.env.DEVNET_PRIVKEY;\nconst l1Provider = new providers.JsonRpcProvider(process.env.L1RPC);\nconst l2Provider = new providers.JsonRpcProvider(process.env.L2RPC);\nconst l1Wallet = new Wallet(walletPrivateKey, l1Provider);\nconst l2Wallet = new Wallet(walletPrivateKey, l2Provider);\n\nconst main = async () => {\n  /**\n   * Use l2Network to create an Arbitrum SDK AdminErc20Bridger instance\n   * We'll use AdminErc20Bridger for its convenience methods around registering tokens to a custom gateway\n   */\n  const l2Network = await getArbitrumNetwork(l2Provider);\n  const erc20Bridger = new Erc20Bridger(l2Network);\n  const adminTokenBridger = new AdminErc20Bridger(l2Network);\n  const l1Router = l2Network.tokenBridge.l1GatewayRouter;\n  const l2Router = l2Network.tokenBridge.l2GatewayRouter;\n  const inbox = l2Network.ethBridge.inbox;\n\n  /**\n   * Deploy our custom gateway to L2\n   */\n  const L2CustomGateway = await await ethers.getContractFactory('L2CustomGateway', l2Wallet);\n  console.log('Deploying custom gateway to L2');\n  const l2CustomGateway = await L2CustomGateway.deploy(l2Router);\n  await l2CustomGateway.deployed();\n  console.log(`Custom gateway is deployed to L2 at ${l2CustomGateway.address}`);\n  const l2CustomGatewayAddress = l2CustomGateway.address;\n};\n\nmain()\n  .then(() => process.exit(0))\n  .catch((error) => {\n    console.error(error);\n    process.exit(1);\n  });\n\nStep 3: Deploy the custom tokens on L1 and L2​\n\nThis step will depend on your setup. In this case, as our simplified gateway supports only one token, we will deploy those on L1 and L2 to be able to call the setTokenBridgeInformation method on both gateways afterwards.\n\nWe won’t go through the process of deploying custom tokens in this How-to, but you can see a detailed explanation of the steps to take in the page How to bridge tokens via Arbitrum’s generic-custom gateway\n\nStep 4: Configure your custom tokens on your gateways​\n\nThis step will also depend on your setup. In this case, our simplified gateway requires method setTokenBridgeInformation to be called on both gateways to set the addresses of the counterpart gateway and both custom tokens.\n\n/**\n * Set the token bridge information on the custom gateways\n * (This is an optional step that depends on your configuration. In this example, we've added one-shot\n * functions on the custom gateways to set the token bridge addresses in a second step. This could be\n * avoided if you are using proxies or the opcode CREATE2 for example)\n */\nconsole.log('Setting token bridge information on L1CustomGateway:');\nconst setTokenBridgeInfoOnL1 = await l1CustomGateway.setTokenBridgeInformation(\n  l1CustomToken.address,\n  l2CustomToken.address,\n  l2CustomGatewayAddress,\n);\n\nconst setTokenBridgeInfoOnL1Rec = await setTokenBridgeInfoOnL1.wait();\nconsole.log(\n  `Token bridge information set on L1CustomGateway! L1 receipt is: ${setTokenBridgeInfoOnL1Rec.transactionHash}`,\n);\n\nconsole.log('Setting token bridge information on L2CustomGateway:');\nconst setTokenBridgeInfoOnL2 = await l2CustomGateway.setTokenBridgeInformation(\n  l1CustomToken.address,\n  l2CustomToken.address,\n  l1CustomGatewayAddress,\n);\n\nconst setTokenBridgeInfoOnL2Rec = await setTokenBridgeInfoOnL2.wait();\nconsole.log(\n  `Token bridge information set on L2CustomGateway! L2 receipt is: ${setTokenBridgeInfoOnL2Rec.transactionHash}`,\n);\n\nStep 5: Register the custom token to your custom gateway​\n\nOnce all contracts are deployed on their respective chains, and they all have the information of the gateways and tokens, it’s time to register the token in your custom gateway.\n\nAs mentioned in How to bridge tokens via Arbitrum’s generic-custom gateway, this action needs to be done by the L1 token, and we’ve implemented the function registerTokenOnL2 to do it. So now we only need to call that function.\n\nIn this case, when using this function only one action will be performed:\n\nCall function setGateway of L1GatewayRouter. This will change the l1TokenToGateway internal mapping it holds and will send a retryable ticket to the counterpart L2GatewayRouter contract in L2, to also set its mapping to the new values.\n\nTo simplify the process, we’ll use Arbitrum’s SDK and call the method registerCustomToken of the AdminErc20Bridger class, which will call the registerTokenOnL2 method of the token passed by parameter.\n\n/**\n * Register the custom gateway as the gateway of our custom token\n */\nconsole.log('Registering custom token on L2:');\nconst registerTokenTx = await adminTokenBridger.registerCustomToken(\n  l1CustomToken.address,\n  l2CustomToken.address,\n  l1Wallet,\n  l2Provider,\n);\n\nconst registerTokenRec = await registerTokenTx.wait();\nconsole.log(\n  `Registering token txn confirmed on L1! 🙌 L1 receipt is: ${registerTokenRec.transactionHash}.`,\n);\nconsole.log(\n  `Waiting for L2 retryable (takes 10-15 minutes); current time: ${new Date().toTimeString()})`,\n);\n\n/**\n * The L1 side is confirmed; now we listen and wait for the L2 side to be executed; we can do this by computing the expected txn hash of the L2 transaction.\n * To compute this txn hash, we need our message's \"sequence numbers\", unique identifiers of each L1 to L2 message.\n * We'll fetch them from the event logs with a helper method.\n */\nconst l1ToL2Msgs = await registerTokenRec.getParentToChildMessages(l2Provider);\n\n/**\n * In this case, the registerTokenOnL2 method creates 1 L1-to-L2 messages to set the L1 token to the Custom Gateway via the Router\n * Here, We check if that message is redeemed on L2\n */\nexpect(l1ToL2Msgs.length, 'Should be 1 message.').to.eq(1);\n\nconst setGateways = await l1ToL2Msgs[0].waitForStatus();\nexpect(setGateways.status, 'Set gateways not redeemed.').to.eq(ParentToChildMessageStatus.REDEEMED);\n\nconsole.log('Your custom token and gateways are now registered on the token bridge 🥳!');\n\nConclusion​\n\nOnce this step is done, your L1 and L2 gateways will be registered in the token bridge and both tokens will be connected through your custom gateway.\n\nYou can bridge tokens between L1 and L2 using the custom tokens, along with the router and gateway contracts from each layer.\n\nIf you want to see an example of bridging a token from L1 to L2 using Arbitrum’s SDK, you can check out How to bridge tokens via Arbitrum’s standard ERC20 gateway, where the process is described in steps 2-5.\n\nThe full code of this how-to and a more extensive deployment and testing script can be found in this package of our tutorials repository.\n\nResources​\nConcept page: Token Bridge\nArbitrum SDK\nToken bridge contract addresses\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nUse the generic-custom gateway\nNext\nRPC endpoints and providers\nStep 0: Review the prerequisites (a.k.a. do I really need a custom gateway?)\nWhat about my custom tokens?\nStep 1: Create a gateway and deploy it on L1\nStep 2: Create a gateway and deploy it on L2\nStep 3: Deploy the custom tokens on L1 and L2\nStep 4: Configure your custom tokens on your gateways\nStep 5: Register the custom token to your custom gateway\nConclusion\nResources\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to run a feed relay | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/sequencer/run-feed-relay",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nRun a feed relay\nRead the sequencer feed\nRun a Sequencer Coordination Manager (SQM)\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to run a feed relay\nCAUTION\n\nIf running a single node, there is no need to run a feed relay. When running more that one node, it is strongly suggested to run a single feed relay per datacenter, which will reduce ingress fees and improve stability.\n\nCAUTION\n\nFeed endpoints will soon require compression with a custom dictionary, so if connecting to feed with anything other than a standard node, it is strongly suggested to run a local feed relay which will provide an uncompressed feed by default.\n\nThe feed relay is in the same docker image as the Nitro node.\n\nHere is an example of how to run the feed relay for Arbitrum One:\ndocker run --rm -it  -p 0.0.0.0:9642:9642 --entrypoint relay offchainlabs/nitro-node:v3.2.1-d81324d --node.feed.output.addr=0.0.0.0 --node.feed.input.url=wss://arb1.arbitrum.io/feed --chain.id=42161\n\nHere is an example of how to run nitro-node for Arbitrum One with custom relay:\ndocker run --rm -it  -v /some/local/dir/arbitrum:/home/user/.arbitrum -p 0.0.0.0:8547:8547 -p 0.0.0.0:8548:8548 offchainlabs/nitro-node:v3.2.1-d81324d --parent-chain.connection.url=https://l1-mainnet-node:8545 --chain.id=42161 --http.api=net,web3,eth --http.corsdomain=* --http.addr=0.0.0.0 --http.vhosts=* --node.feed.input.url=ws://local-relay-address:9642\n\n\nNote that Arbitrum classic does not communicate with Nitro sequencer, so classic relay is no longer used.\n\nHelm charts (Kubernetes)​\n\nIf you are using Kubernetes to run your feed relay, a helm chart is available at ArtifactHUB. It supports running a Nitro relay by providing the feed input URL. Find more information in the OCL community Helm charts repository.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRun a Classic node\nNext\nRead the sequencer feed\nHelm charts (Kubernetes)\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/token-bridging/bridge-tokens-programmatically/how-to-bridge-tokens-generic-custom",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nOverview\nETH bridging\nERC-20 token bridging\nBridge tokens programmatically\nGet started\nUse the standard gateway\nUse the generic-custom gateway\nUse the custom gateway\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nBridge tokens via Arbitrum’s generic-custom gateway\n\nIn this how-to you’ll learn how to bridge your own token between Ethereum (Layer 1 or L1) and Arbitrum (Layer 2 or L2), using Arbitrum’s generic-custom gateway. For alternative ways of bridging tokens, don’t forget to check out this overview.\n\nFamiliarity with Arbitrum’s token bridge system, smart contracts, and blockchain development is expected. If you’re new to blockchain development, consider reviewing our Quickstart: Build a dApp with Arbitrum (Solidity, Hardhat) before proceeding. We will use Arbitrum’s SDK throughout this how-to, although no prior knowledge is required.\n\nWe will go through all steps involved in the process. However, if you want to jump straight to the code, we have created this script in our tutorials repository that encapsulates the entire process.\n\nStep 0: Review the prerequisites​\n\nAs stated in the token bridge conceptual page, there are a few prerequisites to keep in mind while using this method to make a token bridgeable.\n\nFirst of all, the L1 counterpart of the token, must conform to the ICustomToken interface. This means that:\n\nIt must have a isArbitrumEnabled method that returns 0xb1\nIt must have a method that makes an external call to L1CustomGateway.registerCustomL2Token specifying the address of the L2 contract, and to L1GatewayRouter.setGateway specifying the address of the custom gateway. These calls should be made only once to configure the gateway.\n\nThese methods are needed to register the token via the gateway contract. If your L1 contract does not include these methods and it is not upgradeable, registration could alternatively be performed in one of these ways:\n\nAs a chain-owner registration via an Arbitrum DAO proposal.\nBy wrapping your L1 token and registering the wrapped version of your token.\n\nKeep in mind that this registration can only be done once.\n\nAlso, the L2 counterpart of the token, must conform to the IArbToken interface. This means that:\n\nIt must havebridgeMint and bridgeBurn methods only callable by the L2CustomGateway contract\nIt must have an l1Address view method that returns the address of the token in L1\nTOKEN COMPATIBILITY WITH AVAILABLE TOOLING\n\nIf you want your token to be compatible out of the box with all the tooling available (e.g., the Arbitrum bridge), we recommend that you keep the implementation of the IArbToken interface as close as possible to the L2GatewayToken implementation example.\n\nFor example, if an allowance check is added to the bridgeBurn() function, the token will not be easily withdrawable through the Arbitrum bridge UI, as the UI does not prompt an approval transaction of tokens by default (it expects the tokens to follow the recommended L2GatewayToken implementation).\n\nStep 1: Create a token and deploy it on L1​\n\nWe‘ll begin the process by creating and deploying on L1 a sample token to bridge. If you already have a token contract on L1, you don’t need to perform this step.\n\nHowever, you will need to upgrade the contract if it doesn’t include the required methods described in the previous step.\n\nWe first create a standard ERC20 contract using OpenZeppelin’s implementation. We make only 1 adjustment to that implementation, for simplicity, although it is not required: we specify an initialSupply to be pre-minted and sent to the deployer address upon creation.\n\nWe’ll also add the required methods to make our token bridgeable via the generic-custom gateway.\n\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n\nimport \"./interfaces/ICustomToken.sol\";\nimport \"@openzeppelin/contracts/token/ERC20/ERC20.sol\";\nimport \"@openzeppelin/contracts/access/Ownable.sol\";\n\n/**\n * @title Interface needed to call function registerTokenToL2 of the L1CustomGateway\n */\ninterface IL1CustomGateway {\n    function registerTokenToL2(\n        address _l2Address,\n        uint256 _maxGas,\n        uint256 _gasPriceBid,\n        uint256 _maxSubmissionCost,\n        address _creditBackAddress\n    ) external payable returns (uint256);\n}\n\n/**\n * @title Interface needed to call function setGateway of the L2GatewayRouter\n */\ninterface IL2GatewayRouter {\n    function setGateway(\n        address _gateway,\n        uint256 _maxGas,\n        uint256 _gasPriceBid,\n        uint256 _maxSubmissionCost,\n        address _creditBackAddress\n    ) external payable returns (uint256);\n}\n\ncontract L1Token is Ownable, ICustomToken, ERC20 {\n    address private customGatewayAddress;\n    address private routerAddress;\n    bool private shouldRegisterGateway;\n\n    /**\n     * @dev See {ERC20-constructor} and {Ownable-constructor}\n     *\n     * An initial supply amount is passed, which is preminted to the deployer.\n     */\n    constructor(address _customGatewayAddress, address _routerAddress, uint256 _initialSupply) ERC20(\"L1CustomToken\", \"LCT\") {\n        customGatewayAddress = _customGatewayAddress;\n        routerAddress = _routerAddress;\n        _mint(msg.sender, _initialSupply * 10 ** decimals());\n    }\n\n    /// @dev we only set shouldRegisterGateway to true when in `registerTokenOnL2`\n    function isArbitrumEnabled() external view override returns (uint8) {\n        require(shouldRegisterGateway, \"NOT_EXPECTED_CALL\");\n        return uint8(0xb1);\n    }\n\n    /// @dev See {ICustomToken-registerTokenOnL2}\n    function registerTokenOnL2(\n        address l2CustomTokenAddress,\n        uint256 maxSubmissionCostForCustomGateway,\n        uint256 maxSubmissionCostForRouter,\n        uint256 maxGasForCustomGateway,\n        uint256 maxGasForRouter,\n        uint256 gasPriceBid,\n        uint256 valueForGateway,\n        uint256 valueForRouter,\n        address creditBackAddress\n    ) public override payable onlyOwner {\n        // we temporarily set `shouldRegisterGateway` to true for the callback in registerTokenToL2 to succeed\n        bool prev = shouldRegisterGateway;\n        shouldRegisterGateway = true;\n\n        IL1CustomGateway(customGatewayAddress).registerTokenToL2{ value: valueForGateway }(\n            l2CustomTokenAddress,\n            maxGasForCustomGateway,\n            gasPriceBid,\n            maxSubmissionCostForCustomGateway,\n            creditBackAddress\n        );\n\n        IL2GatewayRouter(routerAddress).setGateway{ value: valueForRouter }(\n            customGatewayAddress,\n            maxGasForRouter,\n            gasPriceBid,\n            maxSubmissionCostForRouter,\n            creditBackAddress\n        );\n\n        shouldRegisterGateway = prev;\n    }\n\n    /// @dev See {ERC20-transferFrom}\n    function transferFrom(\n        address sender,\n        address recipient,\n        uint256 amount\n    ) public override(ICustomToken, ERC20) returns (bool) {\n        return super.transferFrom(sender, recipient, amount);\n    }\n\n    /// @dev See {ERC20-balanceOf}\n    function balanceOf(address account) public view override(ICustomToken, ERC20) returns (uint256) {\n        return super.balanceOf(account);\n    }\n}\n\n\nWe now deploy that token to L1.\n\nconst { ethers } = require('hardhat');\nconst { providers, Wallet } = require('ethers');\nconst { getArbitrumNetwork } = require('@arbitrum/sdk');\nrequire('dotenv').config();\n\nconst walletPrivateKey = process.env.DEVNET_PRIVKEY;\nconst l1Provider = new providers.JsonRpcProvider(process.env.L1RPC);\nconst l2Provider = new providers.JsonRpcProvider(process.env.L2RPC);\nconst l1Wallet = new Wallet(walletPrivateKey, l1Provider);\n\n/**\n * For the purpose of our tests, here we deploy an standard ERC20 token (L1Token) to L1\n * It sends its deployer (us) the initial supply of 1000\n */\nconst main = async () => {\n  /**\n   * Use l2Network to get the token bridge addresses needed to deploy the token\n   */\n  const l2Network = await getArbitrumNetwork(l2Provider);\n\n  const l1Gateway = l2Network.tokenBridge.l1CustomGateway;\n  const l1Router = l2Network.tokenBridge.l1GatewayRouter;\n\n  /**\n   * Deploy our custom token smart contract to L1\n   * We give the custom token contract the address of l1CustomGateway and l1GatewayRouter as well as the initial supply (premine)\n   */\n  console.log('Deploying the test L1Token to L1:');\n  const L1Token = await (await ethers.getContractFactory('L1Token')).connect(l1Wallet);\n  const l1Token = await L1Token.deploy(l1Gateway, l1Router, 1000);\n\n  await l1Token.deployed();\n  console.log(`L1Token is deployed to L1 at ${l1Token.address}`);\n\n  /**\n   * Get the deployer token balance\n   */\n  const tokenBalance = await l1Token.balanceOf(l1Wallet.address);\n  console.log(`Initial token balance of deployer: ${tokenBalance}`);\n};\n\nmain()\n  .then(() => process.exit(0))\n  .catch((error) => {\n    console.error(error);\n    process.exit(1);\n  });\n\nStep 2: Create a token and deploy it on L2​\n\nWe’ll now create and deploy on L2 the counterpart of the token we created on L1.\n\nWe’ll create a standard ERC20 contract using OpenZeppelin’s implementation, and add the required methods from IArbToken.\n\n// SPDX-License-Identifier: Apache-2.0\npragma solidity ^0.8.0;\n\nimport \"./interfaces/IArbToken.sol\";\nimport \"@openzeppelin/contracts/token/ERC20/ERC20.sol\";\n\ncontract L2Token is ERC20, IArbToken {\n    address public l2Gateway;\n    address public override l1Address;\n\n    modifier onlyL2Gateway() {\n        require(msg.sender == l2Gateway, \"NOT_GATEWAY\");\n        _;\n    }\n\n    constructor(address _l2Gateway, address _l1TokenAddress) ERC20(\"L2CustomToken\", \"LCT\") {\n        l2Gateway = _l2Gateway;\n        l1Address = _l1TokenAddress;\n    }\n\n    /**\n     * @notice should increase token supply by amount, and should only be callable by the L2Gateway.\n     */\n    function bridgeMint(address account, uint256 amount) external override onlyL2Gateway {\n        _mint(account, amount);\n    }\n\n    /**\n     * @notice should decrease token supply by amount, and should only be callable by the L2Gateway.\n     */\n    function bridgeBurn(address account, uint256 amount) external override onlyL2Gateway {\n        _burn(account, amount);\n    }\n\n\t\t// Add any extra functionality you want your token to have.\n}\n\n\nWe now deploy that token to L2.\n\nconst { ethers } = require('hardhat');\nconst { providers, Wallet } = require('ethers');\nconst { getArbitrumNetwork } = require('@arbitrum/sdk');\nrequire('dotenv').config();\n\nconst walletPrivateKey = process.env.DEVNET_PRIVKEY;\nconst l2Provider = new providers.JsonRpcProvider(process.env.L2RPC);\nconst l2Wallet = new Wallet(walletPrivateKey, l2Provider);\n\nconst l1TokenAddress = '<address of the l1 token deployed in the previous step>';\n\n/**\n * For the purpose of our tests, here we deploy an standard ERC20 token (L2Token) to L2\n */\nconst main = async () => {\n  /**\n   * Use l2Network to get the token bridge addresses needed to deploy the token\n   */\n  const l2Network = await getArbitrumNetwork(l2Provider);\n  const l2Gateway = l2Network.tokenBridge.childCustomGateway;\n\n  /**\n   * Deploy our custom token smart contract to L2\n   * We give the custom token contract the address of childCustomGateway as well as the address of the counterpart L1 token\n   */\n  console.log('Deploying the test L2Token to L2:');\n  const L2Token = await (await ethers.getContractFactory('L2Token')).connect(l2Wallet);\n  const l2Token = await L2Token.deploy(l2Gateway, l1TokenAddress);\n\n  await l2Token.deployed();\n  console.log(`L2Token is deployed to L2 at ${l2Token.address}`);\n};\n\nmain()\n  .then(() => process.exit(0))\n  .catch((error) => {\n    console.error(error);\n    process.exit(1);\n  });\n\nStep 3: Register the custom token to the generic-custom gateway​\n\nOnce both our contracts are deployed in their respective chains, it’s time to register the token in the generic-custom gateway.\n\nAs mentioned before, this action needs to be done by the L1 token, and we’ve implemented the function registerTokenOnL2 to do it. So now we only need to call that function.\n\nWhen using this function two actions will be performed:\n\nCall function registerTokenToL2 of L1CustomGateway. This will change the l1ToL2Token internal mapping it holds and will send a retryable ticket to the counterpart L2CustomGateway contract in L2, to also set its mapping to the new values.\nCall function setGateway of L1GatewayRouter. This will change the l1TokenToGateway internal mapping it holds and will send a retryable ticket to the counterpart L2GatewayRouter contract in L2, to also set its mapping to the new values.\n\nTo simplify the process, we’ll use Arbitrum’s SDK. We’ll call the method registerCustomToken of the AdminErc20Bridger class, which will call the registerTokenOnL2 method of the token passed by parameter.\n\n/**\n * Register custom token on our custom gateway\n */\nconst adminTokenBridger = new AdminErc20Bridger(l2Network);\nconst registerTokenTx = await adminTokenBridger.registerCustomToken(\n  l1CustomToken.address,\n  l2CustomToken.address,\n  l1Wallet,\n  l2Provider,\n);\n\nconst registerTokenRec = await registerTokenTx.wait();\nconsole.log(\n  `Registering token txn confirmed on L1! 🙌 L1 receipt is: ${registerTokenRec.transactionHash}`,\n);\n\n/**\n * The L1 side is confirmed; now we listen and wait for the L2 side to be executed; we can do this by computing the expected txn hash of the L2 transaction.\n * To compute this txn hash, we need our message's \"sequence numbers\", unique identifiers of each L1 to L2 message.\n * We'll fetch them from the event logs with a helper method.\n */\nconst l1ToL2Msgs = await registerTokenRec.getParentToChildMessages(l2Provider);\n\n/**\n * In principle, a single L1 txn can trigger any number of L1-to-L2 messages (each with its own sequencer number).\n * In this case, the registerTokenOnL2 method created 2 L1-to-L2 messages;\n * - (1) one to set the L1 token to the Custom Gateway via the Router, and\n * - (2) another to set the L1 token to its L2 token address via the Generic-Custom Gateway\n * Here, We check if both messages are redeemed on L2\n */\nexpect(l1ToL2Msgs.length, 'Should be 2 messages.').to.eq(2);\n\nconst setTokenTx = await l1ToL2Msgs[0].waitForStatus();\nexpect(setTokenTx.status, 'Set token not redeemed.').to.eq(ParentToChildMessageStatus.REDEEMED);\n\nconst setGateways = await l1ToL2Msgs[1].waitForStatus();\nexpect(setGateways.status, 'Set gateways not redeemed.').to.eq(ParentToChildMessageStatus.REDEEMED);\n\nconsole.log(\n  'Your custom token is now registered on our custom gateway 🥳  Go ahead and make the deposit!',\n);\n\nConclusion​\n\nOnce this step is done, your L1 and L2 tokens will be connected through the generic-custom gateway.\n\nYou can bridge tokens between L1 and L2 using the origin L1 token and the custom token deployed on L2, along with the router and gateway contracts from each layer.\n\nIf you want to see an example of bridging a token from L1 to L2 using Arbitrum’s SDK, you can check out How to bridge tokens via Arbitrum’s standard ERC20 gateway, where the process is described in steps 2-5.\n\nFrequently asked questions​\nCan I run the same register token process multiple times for the same L1 token?​\n\nNo, you can only register once an L2 token for the same L1 token. After that, the call to registerTokenToL2 will revert if run again.\n\nWhat can I do if my L1 token is not upgradable?​\n\nAs mentioned in the concept page, the token registration can alternatively be performed as a chain-owner registration via Arbitrum DAO proposal.\n\nCan I set up the generic-custom gateway after a standard ERC20 token exists on L2?​\n\nYes, if your token has a standard ERC20 counterpart on L2, you can go through the process of registering your custom L2 token as outlined in this page. At that moment, your L1 token will have 2 counterpart tokens on L2, but only your new custom L2 token will be minted when depositing tokens from L1 (L1-to-L2 bridging). Both L2 tokens will be withdrawable (L2-to-L1 bridging), so users holding the old standard ERC20 token will be able to withdraw back to L1 (using the L2CustomGateway contract instead of the bridge UI) and then deposit to L2 to get the new custom L2 tokens.\n\nResources​\nConcept page: Token Bridge\nArbitrum SDK\nToken bridge contract addresses )\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nUse the standard gateway\nNext\nUse the custom gateway\nStep 0: Review the prerequisites\nStep 1: Create a token and deploy it on L1\nStep 2: Create a token and deploy it on L2\nStep 3: Register the custom token to the generic-custom gateway\nConclusion\nFrequently asked questions\nCan I run the same register token process multiple times for the same L1 token?\nWhat can I do if my L1 token is not upgradable?\nCan I set up the generic-custom gateway after a standard ERC20 token exists on L2?\nResources\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/token-bridging/bridge-tokens-programmatically/how-to-bridge-tokens-standard",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nOverview\nETH bridging\nERC-20 token bridging\nBridge tokens programmatically\nGet started\nUse the standard gateway\nUse the generic-custom gateway\nUse the custom gateway\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nBridge tokens via Arbitrum's standard ERC20 gateway\n\nIn this how-to you’ll learn how to bridge your own token between Ethereum (Layer 1 or L1) and Arbitrum (Layer 2 or L2), using Arbitrum’s standard ERC20 gateway. For alternative ways of bridging tokens, don’t forget to check out this overview.\n\nFamiliarity with Arbitrum’s token bridge system, smart contracts, and blockchain development is expected. If you’re new to blockchain development, consider reviewing our Quickstart: Build a dApp with Arbitrum (Solidity, Hardhat) before proceeding. We will use Arbitrum’s SDK throughout this how-to, although no prior knowledge is required.\n\nWe will go through all steps involved in the process. However, if you want to jump straight to the code, we have created this script in our tutorials repository that encapsulates the entire process.\n\nStep 1: Create a token and deploy it on L1​\n\nWe‘ll begin the process by creating and deploying on L1 a sample token to bridge. If you already have a token contract on L1, you don’t need to perform this step.\n\nWe first create a standard ERC20 contract using OpenZeppelin’s implementation. We make only 1 adjustment to that implementation, for simplicity, although it is not required: we specify an initialSupply to be pre-minted and sent to the deployer address upon creation.\n\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\n\nimport \"@openzeppelin/contracts/token/ERC20/ERC20.sol\";\n\ncontract DappToken is ERC20 {\n    /**\n     * @dev See {ERC20-constructor}.\n     *\n     * An initial supply amount is passed, which is preminted to the deployer.\n     */\n    constructor(uint256 _initialSupply) ERC20(\"Dapp Token\", \"DAPP\") {\n        _mint(msg.sender, _initialSupply * 10 ** decimals());\n    }\n}\n\n\nWe now deploy that token to L1.\n\nconst { ethers } = require('hardhat');\nconst { providers, Wallet } = require('ethers');\nrequire('dotenv').config();\nconst walletPrivateKey = process.env.DEVNET_PRIVKEY;\nconst l1Provider = new providers.JsonRpcProvider(process.env.L1RPC);\nconst l1Wallet = new Wallet(walletPrivateKey, l1Provider);\n\n/**\n * For the purpose of our tests, here we deploy an standard ERC20 token (DappToken) to L1\n * It sends its deployer (us) the initial supply of 1000\n */\nconst main = async () => {\n  console.log('Deploying the test DappToken to L1:');\n  const L1DappToken = await (await ethers.getContractFactory('DappToken')).connect(l1Wallet);\n  const l1DappToken = await L1DappToken.deploy(1000);\n\n  await l1DappToken.deployed();\n  console.log(`DappToken is deployed to L1 at ${l1DappToken.address}`);\n\n  /**\n   * Get the deployer token balance\n   */\n  const tokenBalance = await l1DappToken.balanceOf(l1Wallet.address);\n  console.log(`Initial token balance of deployer: ${tokenBalance}`);\n};\n\nmain()\n  .then(() => process.exit(0))\n  .catch((error) => {\n    console.error(error);\n    process.exit(1);\n  });\n\nStep 2: Identify the bridge contracts to call (concepts summary)​\n\nAs stated in the token bridge conceptual page, when using Arbitrum’s standard ERC20 gateway, you don’t need to do any pre-configuration process. Your token will be “bridgeable” out of the box.\n\nAs explained in the conceptual page, there are 2 contracts that we need to be aware of when bridging tokens:\n\nRouter contract: this is the contract that we’ll interact with. It keeps a mapping of the gateway contracts assigned to each token, fallbacking to a default gateway for standard ERC20 tokens.\nGateway contract: this is the contract that escrows or burns the tokens in the layer of origin, and sends the message over to the counterpart layer to mint or release the tokens there.\n\nFor simplicity, in this how-to we’ll focus on the first case: bridging from Ethereum (L1) to Arbitrum (L2).\n\nWe’ll explain below what specific contracts and methods need to be called to bridge your token, but you can abstract this whole process of finding the right addresses by using Arbitrum’s SDK. You can use the deposit function of the Erc20Bridger class to bridge your tokens, which will use the appropriate router contract based on the network you’re connected to, and will relay the request to the appropriate gateway contract. You can also use the function getParentGatewayAddress to get the address of the gateway contract that’s going to be used. But don’t worry about any of this yet, we’ll use those functions in the next steps.\n\nNow, here’s an explanation of the contracts and methods that need to be called to manually bridge your token:\n\nWhen bridging from Ethereum (L1) to Arbitrum (L2), you’ll need to interact with the L1GatewayRouter contract, by calling the outboundTransferCustomRefund method. This router contract will relay your request to the appropriate gateway contract, in this case, the L1ERC20Gateway contract. To get the address of the gateway contract that’s going to be used, you can call the getGateway function in the L1GatewayRouter contract.\nWhen bridging from Arbitrum (L2) to Ethereum (L1), you’ll need to interact with the L2GatewayRouter contract, by calling the outBoundTransfer method. This router contract will relay your request to the appropriate gateway contract, in this case, the L2ERC20Gateway contract. To get the address of the gateway contract that’s going to be used, you can call the getGateway function in the L2GatewayRouter contract.\n\nYou can find the addresses of the contracts involved in the process in this page.\n\nStep 3: Approve token allowance for the gateway contract​\n\nThe gateway contract will be the one that will transfer the tokens to be bridged over. So the next step is to allow the gateway contract to do so.\n\nWe typically do that by using the approve method of the token, but you can use Arbitrum’s SDK to abstract this process, by calling the method approveToken of the Erc20Bridger class, which will call the approve method of the token passed by parameter, and set the allowance to the appropriate gateway contract.\n\n/**\n * Use l2Network to create an Arbitrum SDK Erc20Bridger instance\n * We'll use Erc20Bridger for its convenience methods around transferring token to L2\n */\nconst l2Network = await getArbitrumNetwork(l2Provider);\nconst erc20Bridge = new Erc20Bridger(l2Network);\n\n/**\n * The Standard Gateway contract will ultimately be making the token transfer call; thus, that's the contract we need to approve.\n * erc20Bridger.approveToken handles this approval\n * Arguments required are:\n * (1) l1Signer: The L1 address transferring token to L2\n * (2) erc20L1Address: L1 address of the ERC20 token to be deposited to L2\n */\nconsole.log('Approving:');\nconst l1Erc20Address = l1DappToken.address;\nconst approveTx = await erc20Bridger.approveToken({\n  parentSigner: l1Wallet,\n  erc20ParentAddress: l1Erc20Address,\n});\n\nconst approveRec = await approveTx.wait();\nconsole.log(\n  `You successfully allowed the Arbitrum Bridge to spend DappToken ${approveRec.transactionHash}`,\n);\n\n\nAs mentioned before, you can also call the approve method of the token and send as a parameter the address of the gateway contract, which you can find by calling the method getGateway function in the router contract.\n\nStep 4: Start the bridging process through the router contract​\n\nAfter allowing the gateway contract to transfer the tokens, we can now start the bridging process.\n\nYou can use Arbitrum’s SDK to abstract this process, by calling the method deposit of the Erc20Bridger class, which will estimate the gas parameters (_maxGas, _gasPriceBid and maxSubmissionCost, explained below) and call the outboundTransferCustomRefund method of the router contract. You will only need to specify the following parameters:\n\namount: Amount of tokens to bridge\nerc20L1Address: L1 address of the ERC20 token being bridged\nl1Signer: Signer object of the account transferring the tokens, connected to the L1 network\nl2Provider: Provider connected to the L2 network\n/**\n * Deposit DappToken to L2 using erc20Bridger. This will escrow funds in the Gateway contract on L1, and send a message to mint tokens on L2.\n * The erc20Bridge.deposit method handles computing the necessary fees for automatic-execution of retryable tickets — maxSubmission cost & l2 gas price * gas — and will automatically forward the fees to L2 as callvalue\n * Also note that since this is the first DappToken deposit onto L2, a standard Arb ERC20 contract will automatically be deployed.\n * Arguments required are:\n * (1) amount: The amount of tokens to be transferred to L2\n * (2) erc20L1Address: L1 address of the ERC20 token to be depositted to L2\n * (2) l1Signer: The L1 address transferring token to L2\n * (3) l2Provider: An l2 provider\n */\nconst depositTx = await erc20Bridger.deposit({\n  amount: tokenDepositAmount,\n  erc20ParentAddress: l1Erc20Address,\n  parentSigner: l1Wallet,\n  childProvider: l2Provider,\n});\n\n\nAs mentioned before, you can also call the method outboundTransferCustomRefund manually in the router contract and specify the following parameters:\n\naddress _token: L1 address of the ERC20 token being bridged\naddress _refundTo: Account to be credited with the excess gas refund in L2\naddress _to: Account to be credited with the tokens in L2\nuint256 _amount: Amount of tokens to bridge\nuint256 _maxGas: Max gas deducted from user’s L2 balance to cover the execution in L2\nuint256 _gasPriceBid: Gas price for the execution in L2\nbytes _data: 2 pieces of data encoded:\nuint256 maxSubmissionCost: Max gas deducted from user's L2 balance to cover base submission fee\nbytes extraData: “0x”\nStep 5: Wait for execution on L2​\n\nAfter calling the deposit method (or the outboundTransferCustomRefund, if you’re choosing the manual way), you’ll have to wait a bit until the message is executed on L2. We will verify the status of the underlying retryable ticket created to bridge the tokens. Check this page, to know more about L1-to-L2 messages, also known as retryables.\n\nYou can programmatically wait for the execution of the transaction on L2 using Arbitrum’s SDK. You should first wait for the execution of the submission transaction (the one sent to the router contract) and then the execution of the L2 transaction.\n\n/**\n * Now we wait for L1 and L2 side of transactions to be confirmed\n */\nconst depositRec = await depositTx.wait();\nconst l2Result = await depositRec.waitForChildTransactionReceipt(l2Provider);\n\n/**\n * The `complete` boolean tells us if the l1 to l2 message was successful\n */\nl2Result.complete\n  ? console.log(`L2 message successful: status: ${L1ToL2MessageStatus[l2Result.status]}`)\n  : console.log(`L2 message failed: status ${L1ToL2MessageStatus[l2Result.status]}`);\n\n\nIf you’re going the manual way, you can verify if the message has been executed on L2 through the Retryables Dashboard. Just paste the hash of transaction submitted to the router contract and the tool will tell you whether it’s been redeemed or not.\n\nStep 6: Check the new token contract created on L2​\n\nFinally, let’s find the token contract that has been created on L2.\n\nUsing Arbitrum’s SDK, you can call method getChildErc20Address of the Erc20Bridger class, which will return the address of the token contract in L2 that corresponds to the L1 token contract sent as parameter.\n\n/**\n * Check if our l2Wallet DappToken balance has been updated correctly\n * To do so, we use erc20Bridge to get the l2Token address and contract\n */\nconst l2TokenAddress = await erc20Bridger.getChildErc20Address(l1Erc20Address, l1Provider);\nconst l2Token = erc20Bridger.getChildTokenContract(l2Provider, l2TokenAddress);\n\n\nTo do this operation manually, you can call method calculateL2TokenAddress of the router contract.\n\nIf you visit that address in Arbiscan, you’ll notice that it is a copy of the contract StandardArbERC20. This is the standard contract that is automatically created the first time a token that doesn’t exist in Arbitrum is bridged. The token bridge conceptual page has more information about this contract.\n\nConclusion​\n\nAfter finishing this process, you’ll now have a counterpart token contract automatically created on L2. You can bridge tokens between L1 and L2 using the original token contract on L1 and the standard created contract on L2, along with the router and gateway contracts from each layer.\n\nResources​\nConcept page: Token Bridge\nArbitrum SDK\nToken bridge contract addresses\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nGet started\nNext\nUse the generic-custom gateway\nStep 1: Create a token and deploy it on L1\nStep 2: Identify the bridge contracts to call (concepts summary)\nStep 3: Approve token allowance for the gateway contract\nStep 4: Start the bridging process through the router contract\nStep 5: Wait for execution on L2\nStep 6: Check the new token contract created on L2\nConclusion\nResources\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/token-bridging/token-bridge-ether",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nOverview\nETH bridging\nERC-20 token bridging\nBridge tokens programmatically\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nETH bridging\n\nEther (ETH) is the native currency of Ethereum and all Arbitrum chains. It is used to pay the necessary fees to execute a transaction in those chains. Bridging ETH from Ethereum (Layer 1, or L1) to an Arbitrum chain (Layer 2, or L2) follows, thus, a different process than the one followed when bridging other types of asset.\n\nDepositing ether​\n\nTo move ETH from L1 to L2, you execute a deposit transaction via Inbox.depositEth. This transfers funds to the Bridge contract on the L1 and credits the same funds to you inside the Arbitrum chain at the specified address.\n\nfunction depositEth(address destAddr) external payable override returns (uint256)\n\n\nThe following diagram depicts the process that funds follow during a deposit operation.\n\nAs far as the L1 knows, all deposited funds are held by Arbitrum's Bridge contract.\n\nWithdrawing ether​\n\nWithdrawing ether can be done using the ArbSys precompile's withdrawEth method:\n\nArbSys(100).withdrawEth{ value: 2300000 }(destAddress)\n\n\nUpon withdrawing, the Ether balance is burnt on the Arbitrum side, and will later be made available on the Ethereum side.\n\nArbSys.withdrawEth is actually a convenience function which is equivalent to calling ArbSys.sendTxToL1 with empty calldataForL1. Like any other sendTxToL1 call, it will require an additional call to Outbox.executeTransaction on L1 after the dispute period elapses for the user to finalize claiming their funds on L1 (see \"L2 to L1 Messages\"). Once the withdrawal is executed from the Outbox, the user's Ether balance will be credited on L1.\n\nThe following diagram depicts the process that funds follow during a withdraw operation.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nOverview\nNext\nERC-20 token bridging\nDepositing ether\nWithdrawing ether\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Get started with token bridging | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/token-bridging/bridge-tokens-programmatically/get-started",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nOverview\nETH bridging\nERC-20 token bridging\nBridge tokens programmatically\nGet started\nUse the standard gateway\nUse the generic-custom gateway\nUse the custom gateway\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nGet started with token bridging\n\nToken bridging is a fundamental aspect of any Layer 2 (L2) protocol. It allows projects to quickly integrate with the Arbitrum ecosystem by leveraging their existing Layer 1 (L1) tokens.\n\nThis section offers a series of how-tos showcasing the different methods available for making your token bridgeable.\n\nYou have three options to consider when deciding on how to bridge your token:\n\nStandard gateway: opt for this method if you want to have an standard ERC-20 token automatically deployed on Arbitrum, which will act as the L2 counterpart to your L1 token. For additional information, please refer to this section on the standard ERC-20 gateway in the conceptual page.\nGeneric-custom gateway: choose this method if you require custom functionality for your ERC20 token on Arbitrum. You will deploy your counterpart token on Arbitrum equipped with the unique features you wish to implement. For additional information, please refer to this section on the Arbitrum generic custom gateway in the conceptual page.\nCustom gateway: this method is intended for edge cases where a custom ERC20 token is insufficient and you need an additional layer of flexibility with the gateway (for example, your token has the capacity to increase its supply on L2, and you want those L2-minted tokens to be withdrawable back to L1 and recognized by the L1 contract). For additional information, please refer to this section on other types of gateways in the conceptual page.\nWhat if I just want to bridge a token programmatically?​\n\nSection How to bridge tokens via Arbitrum’s standard gateway provides an example of how to deposit your tokens (from L1 to L2) programmatically, specifically in steps 2 to 5.\n\nYou can also find scripts demonstrating L1-to-L2 bridging (deposits) and L2-to-L1 bridging (withdrawals) using the Arbitrum SDK.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nERC-20 token bridging\nNext\nUse the standard gateway\nWhat if I just want to bridge a token programmatically?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/bold/bold-economics-of-disputes",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nThe BoLD dispute protocol\nA gentle introduction\nDeploy a validator on testnet\nBoLD Whitepaper\nTechnical deep dive\nEconomics of Disputes\nSpecification on Github\nAudit Report by Trail of Bits\nAudit Report by Code4rena\nPublic preview\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nEconomics of Disputes in Arbitrum BoLD\n\nThe following document explains the economics and denial-of-service protection mechanisms built into Arbitrum BoLD. It covers trade-offs Arbitrum has to make to enable permissionless validation, explaining the key problems in an accessible way.\n\nBackground​\n\nArbitrum One is currently one of the most widely used Ethereum scaling solutions, with ~$14bn USD in total-value-locked at the time of writing. Not only do its scaling properties, such as its 250ms block times, make it popular, but so do its security properties and approach to decentralization. Currently, Arbitrum One is governed by the Arbitrum DAO, one of the most active and robust on-chain organizations.\n\nHowever, Arbitrum technology has not yet achieved its full promise of being fully decentralized. Currently, withdrawals from Arbitrum One back to Ethereum are verified by a permissioned list of validators. These validators can still challenge invalid withdrawals, but the system prevents anyone outside this list from holding them accountable. This permissioned list of validators limits Arbitrum One and Arbitrum Nova to being categorized as a Stage 1 Rollup on the L2Beat website, meaning it still has training wheels preventing it from reaching its full potential.\n\nThe rollup technology powering Arbitrum One is called \"optimistic\" because claims about its state settled to and confirmed on Ethereum after a period of approximately seven days. During those 7 days, the claimed states can be disputed. To make an analogy, a check can be cashed immediately but can be taken to court to dispute if there is a problem within a specific time frame. Because Arbitrum's state is deterministic, a validator that is running a node and following the chain will always know if a posted claim is invalid. A key decentralization property allows anyone who knows the correct claim to challenge invalid claims and win the challenge. This preserves the accurate history of Arbitrum settling to Ethereum and protects the integrity of users' funds and withdrawals using a \"single honest party\" property. As long as there is a single entity following the chain and willing to dispute a claim, Arbitrum's security guarantees are maintained.\n\nToday, Arbitrum One's security properties are defined by the size of its permissioned set of validators. Validators could collude or finalize/confirm an incorrect state, and users have no recourse aside from the Arbitrum One security council stepping in. Elevating Arbitrum One's decentralization requires a different approach.\n\nIn the Fall of 2023, Offchain Labs announced Arbitrum BoLD, a new dispute resolution protocol built from the ground up that will bring Arbitrum chains to the next level of decentralization. BoLD, which is an acryonym for Bounded Liquidity Delay, allows permissionless validation of Arbitrum chains. This means that chain owners can remove the list of permissioned validators for their chains to allow anyone to challenge invalid claims made about Arbitrum states on their parent chain and win.\n\nIn this document, we'll explore the economics and trade-offs enabling permissionless validation.\n\nSettling Arbitrum states to Ethereum​\n\nWe frequently state that \"Arbitrum chains settles their states to a parent chain\", and we'll elaborate on what that means. All Arbitrum One transactions can be recreated by reading data from Ethereum L1, as compressed batches of all L2 transactions are frequently posted to Ethereum. Once a batched transaction is included in a finalized block on Ethereum, its history will never be reverted on Arbitrum One. Ethereum, however, does not know if a batch posted to it refers to a correct version of Arbitrum One's history. To verify batch integrity, there is a separate process that confirms batch correctness on Ethereum: it is called the \"assertion.\"\n\nFor Arbitrum One specifically, approximately every hour, entities known as validators check the correctness of batches by following the Arbitrum chain. Validators then post something called an \"assertion\", which attests to the validity of a batch, saying, \"I have verified this batch\". As Ethereum does not know what is correct on Arbitrum One, it allows about seven days for anyone to dispute one of these assertions. Currently, there is a permissioned list of validators who can post assertions and challenge assertion for all Arbitrum chains. Arbitrum BoLD will enable any chain owner, such as the ArbitrumDAO, to remove this permissioned list. Note that validators who opt to posting assertions are otherwise known as a \"assertion proposers\".\n\nWithdrawing assets back to Ethereum from Arbitrum​\n\nUsers of Arbitrum One that have bridged assets from Ethereum can withdraw said assets at any time. However, for this withdrawal to be fully executed, its corresponding claim must match a confirmed assertion on Ethereum. For instance, if Alice starts a withdrawal transaction on Arbitrum One, it gets posted in a batch on Ethereum. Then, a validator will post an assertion about that batch on Ethereum an hour later. The assertion has a seven-day window in which anyone can dispute it. If this assertion isn't disputed within that time frame, it gets confirmed. After that window passes, Alice will receive her withdrawn assets on Ethereum and is free to use them as she pleases.\n\n\"Settling states\" and having a seven-day dispute window is crucial to ensuring assets can be withdrawn safely. Allowing anyone to dispute invalid claims and win keeps withdrawals protected by strong security guarantees without needing to trust a group of validators. This \"permissionless validation\" separates Optimistic Rollups from side chains.\n\nThe dispute period​\n\nThe reason there is a dispute window for assertions about Arbitrum One on Ethereum is because Ethereum itself has no knowledge about what is correct on Arbitrum One. The two blockchains are different domains with different states. Ethereum, however, can be used as a neutral referee for parties to dispute claims about Arbitrum One. The dispute period is seven days because it is seen as the maximum period of time an adversary could delay Ethereum before social intervention, originally proposed by Vitalik Buterin. This window gives enough time for parties to catch invalid claims and challenge them accordingly.\n\nDispute resolution times​\n\nAn actual dispute occurs if a party disagrees with an assertion on Ethereum and posts an assertion they know to be correct as a counter-claim. This creates a \"fork\" in the chain of assertions, requiring a resolution process. We'll get into the high-level details of how disputes are resolved later in this document.\n\nOnce an actual dispute is ongoing, it will also take time to resolve, as, once again, Ethereum has no knowledge of the correctness of Arbitrum One states. Ethereum must then give sufficient time for parties to submit their proofs and declare a winner. The new Arbitrum BoLD protocol guarantees that a dispute will be resolved within seven days so long as an honest party is present to defend against invalid claims.\n\nAs assertions have a dispute window of seven days, and disputes require an additional seven days to resolve, a dispute made at the last second would delay assertion confirmation to a maximum of 14 days, or two weeks. BoLD is the only dispute protocol we are aware of that guarantees this bound.\n\nThe cost of delaying withdrawals​\n\nDelaying withdrawals incurs opportunity costs and impacts user experience for users who want to withdraw their assets. In the happy case of no disputes, withdrawals already have a baked-in, seven-day delay. A dispute adds seven days to that delay. The problem is that disputes delay all pending withdrawals from Arbitrum One back to Ethereum, not just a single claim. As such, disputing a claim must have a cost for the initiator proportional to the opportunity cost they impose on Arbitrum users.\n\nRequiring a bond to become a validator​\n\nBy default, all Arbitrum nodes act as validators, monitoring the chain to verify assertions posted to the parent chain and flagging any invalid assertions. On Arbitrum One, running a validator, known as a “watchtower” node, is permissionless and requires no additional cost other than the infrastructure for the node.\n\nAnother type of validator, called a \"proposer,\" performs additional tasks on top of their regular duties as a regular validator. Proposers compute Arbitrum states and propose assertions to the parent chain. To prevent abuse and delays in withdrawals, proposers must make a security deposit or \"bond\" to gain the privilege of proposing assertions. This bond can be withdrawn once their latest assertion is confirmed, ending their responsibilities as a proposer.\n\nArbitrum BoLD allows validators to become proposers and challengers without permission. Proposers must bond ETH to propose state assertions to the parent chain. Only one proposer is needed for chain progress, allowing most validators to simply verify assertions. In case of disputes over state assertions, BoLD enables anyone to put up a \"challenge bond\" of ETH to dispute invalid assertions, acting as a challenger in defense of an Arbitrum chain.\n\nPricing bonds​\n\nEnsuring assertions are frequently posted is a requirement for Arbitrum, but at the same time, it should not be a privilege that is easily obtained, which is why the pricing of this \"security deposit\" is based on opportunity cost.\n\nTo be highly conservative, in a \"bank run\"-like scenario, the Arbitrum One bridge contains approximately $3.4B USD worth of assets at the time of writing on Oct 23rd, 2024. Assuming funds could earn a 5% APY if invested elsewhere, the opportunity cost of 1 extra week of delay is approximately $3.27M USD. Given this scenario, we recommend a bond for assertion posters to be greater than $3.7M USD.\n\nHonest proposers can always withdraw their bond once their assertions are confirmed. However, adversaries stand to lose the entirety of their bond if they propose invalid assertions. A large bond size drastically improves the economic security of the system based on these two axes by making the cost to propose high and by guaranteeing that malicious actors will lose their entire bond when they are proven wrong by the protocol.\n\nGiven that participation in BoLD is permissionless, we recommend that the size of bonds required to participate be high enough to disincentivize malicious actors from attacking Arbitrum One and to mitigate against spam (that would otherwise delay confirmations up to 1 challenge period). High bonding values do not harm decentralization because (1) trustless bonding (or staking) pools can be deployed permissionlessly to open challenges and post assertions, and (2) any number of honest parties of unknown identities can emerge to bond their funds to the correct assertion and participate in the defense of Arbitrum at any time within a challenge. As with the current dispute resolution protocol, there are no protocol level incentives for parties who opt in to participate in validating Arbitrum One with BoLD.\n\nWhile both of these bonds can be any ERC20 token and be set to any size, we recommend the use of the WETH ERC20 token & the following bond sizes for Arbitrum One:\n\nAssertion bonds: 3600 ETH - required from validators to bond their funds to an assertion in the eventual hopes of having that assertion be confirmed by the rollup protocol. This is a one-time bond required to be able to start posting assertions. This bond can be withdrawn once a validator’s assertion is confirmed and can alternatively be put together via a trustless bonding pool.\nChallenge-bonds, per level: 555/79 ETH - required from validators to open challenges against an assertion observed on the parent chain (Ethereum, in the case for Arbitrum One), for each level. Note that “level” corresponds to the level of granularity over which the interactive dissection game gets played, starting at the block level, moving on to a range of WASM execution steps, and then finally to the level of a single step of execution.\n\nThese values were carefully calculated to optimize for the resource ratio (explained later) and gas costs in the event of an attack, as explained in BoLD whitepaper. This effectively means that an entity that has already put up a bond to propose an assertion does not need to put up a separate assertion bond to challenge an invalid state assertion that they observe. To be explicitly clear, the validator would still require 555 ETH and 79 ETH for ongoing challenges. These additional challenge bond amounts are needed to participate in the interactive dispute game (back and forth) and narrows down the disagreement to a single step of execution that is then proven on Ethereum. The 555 ETH and 79 ETH challenge bonds can be put together via a trustless bonding pool, and do not all have to be put up by the validator that opened the challenge. These bonds can be refunded at the end of a challenge and can also alternatively be put together by the community using a trustless bonding pool.\n\nCentralization concerns​\n\nRequiring a high bond to post assertions about Arbitrum seems centralizing, as we are replacing an allowlist of validators with a system that requires substantial funds to participate. However, BoLD ships with a trustless bonding pool for assertion posting. That is, any group of honest parties can pool funds into a simple contract that will post an assertion to Ethereum without needing to trust each other. We believe that making it easy to pool the funds to become an assertion poster without needing trust to dispute invalid claims does not affect the safety or decentralization of BoLD.\n\nWe claim optimizing for the unhappy case is more important than the happy case. As there only needs to be one honest assertion poster, we believe it falls into the security budget of the chain to set a high bond fee in order to become a proposer. It should be expensive to delay Arbitrum One withdrawals, and it should also have a high barrier to entry to perform a key responsibility. As long as disputes can be made in a trustless manner, and trustless pools are available in production, we claim the security properties of assertion posting hold equally.\n\nResolving disputes​\n\nOne of the core properties BoLD achieves is providing a fixed upper bound for dispute resolution times. This section will discuss the constraints required to achieve this from first principles.\n\nDispute game overview​\n\nEvery game between adversarial parties needs a referee: a neutral party that can enforce the rules to declare a fair winner. Arbitrum BoLD relies on Ethereum as its referee because of its properties as the most decentralized, censorship-resistant smart contract chain in the world.\n\nWhen a dispute happens about Arbitrum One assertions on Ethereum, there is a protocol for resolving them. At its core, a dispute is about the blockhash of an Arbitrum One block at a given height. Ethereum does not know which claim is correct and, instead, relies on a dispute game to be played out. The game involves different parties making claims with proof to eventually narrow down their disagreement to a single step of execution within the execution of a block, called a one-step proof (OSP). Ethereum can then verify this OSP by itself and, as the neutral referee, declare a winner.\n\nThe \"rules\" of the dispute involve parties making claims with proof to reach the single point of disagreement. Parties \"narrow down\" their claims via moves called bisections. After a party has made a bisection, there is nothing else left to do until another party comes in and counters it. The core of the system is that an honest party winning a one-step proof leaves the malicious party with no other moves to make. Once the honest party has accumulated enough time without being countered, it is declared the winner.\n\nCompared to other dispute protocols, however, BoLD is not a dispute between two specific Ethereum addresses, such as Alice and Bob. Instead, it is a dispute between an absolute, correct history vs. an incorrect one. Claims in BoLD are not attached to a particular address or validator but instead to Merkle commitments of an Arbitrum chain's history. If Alice and Charlie are both honest, and Bob is malicious, Alice and Charlie can play the game as part of a single \"team\". If Alice goes offline in the middle of a dispute-game, Charlie can continue resolving the game on behalf of the honest team because Charlie and Alice claim and make moves on the correct history. This is why we say BoLD enables \"trustless cooperation,\" as there is no need for communication between honest parties. We believe committing a set of chain history hashes instead of a specific hash at a moment in time is crucial for securing dispute protocols.\n\nSpamming the dispute game​\n\nBoLD is a dispute-game in which the party that has accumulated seven days \"not-countered\" wins. That is, parties are incentivized to counter any new claims as soon as they appear to \"block\" their rivals from increasing their timers. For honest parties, responding to claims may sometimes require offchain computational work and, therefore, resources such as CPUs. However, malicious parties can make claims that are eventually found to be junk while making honest parties do actual work.\n\nBecause malicious parties can submit incorrect claims that make honest parties do work, there has to be an economic cost associated with making moves in the dispute-game. Said differently, we need a way to prevent spam attacks in dispute games.\n\nThe cost of moves​\n\nWhen pricing the bonds required to make claims within disputes, we consider the marginal costs that the honest party incurs for each claim a malicious party makes. The BoLD research paper includes information such as the number of adversary moves multiplied by the gas cost of making bisections and claims and some estimates of the offchain computational costs. We deem this the marginal cost of a party in a dispute.\n\nWith BoLD, the space of disagreements between parties is of max size 2^69. As such, the dispute game has to be played at different levels of granularity to make it computationally feasible.\n\nLet's use an analogy: say we have two one-meter sticks that seem identical, and we want to determine where they differ. They appear identical at the centimeter level, so we need to go down to the millimeter level, then the micrometer level, and then figure out where they differ at the nanometer level.\n\nThis is what BoLD does over the space of disputes. Parties play the same game at different levels of granularity. At the centimeter level, each centimeter could trigger a millimeter dispute, and each millimeter dispute could have many micrometer disputes, etc. This dispute pattern could be abused unless spam is discouraged.\n\nPreventing spam​\n\nSince Ethereum knows nothing about which claims are honest or malicious until a one-step proof is provided, how can the protocol detect and discourage spam? A key insight is that honest parties only need to make one honest claim. Honest parties will never spam and create thousands of conflicting claims with themselves. Given this, we can put a price tag on making moves by looking at something called the \"resource ratio\" between honest and malicious parties, as defined in the BoLD research paper.\n\nThis ratio is computed as gas plus staking (or bonding) marginal costs of the adversary to the honest party. This means that certain values input into the equations can lead to different ratios. For instance, we can say the adversary has to pay 10x the marginal costs of the honest party. However, aiming to increase this ratio significantly by plugging in different values leads to higher costs for all parties.\n\nDispute mini-bonds​\n\nWe require parties to lock up some capital called a \"mini-bond\" when making big claims in a dispute. These bonds are not needed when making bisection moves but are critical for posting an initial claim. Pricing these mini-bonds helps achieve a high resource ratio of dishonest parties to honest parties.\n\nIt is clear that if we can multiply the cost to the malicious party by some multiplier of the honest party, we will get significant security benefits. For instance, imagine if a 1 billion dollar attack can be defended by simply pooling together 10 million dollars. Is it possible to achieve such a ratio?\n\nLet's explore the limitations of making the cost to malicious parties higher than the honest parties'.\n\nIf we aim to have a constant resource ratio > 1, we have to do the following: if the adversary makes N stakes at any level, they can force the honest party to make N stakes at the next level down, where the adversary can choose not to place any stakes at all. Regarding resource ratio, to make the adversary always pay 10x in staking, we need to make the bond amount at one level 10x more than the next. As there are multiple levels, the equations for the bond size include an exponential factor on the desired constant resource ratio > 1.\n\nBelow, we plot the bond size vs. the resource ratio of malicious to honest costs. The source for these equations can be found in the research paper and is represented in this calculator.\n\nIf we desire a constant resource ratio of malicious to honest costs > 1, the required bond size in ETH increases as a polynomial at a particular challenge level.\n\nTrade-offs​\n\nHaving a 1000x resource ratio would be nice in theory, but it would, unfortunately, require a bond of 1M ETH ($2.56B USD at time of writing) to open a challenge in the first place, which is unreasonable. Instead, we can explore a more feasible ratio.\n\nThe resource ratio will drive the price of disputes claims, impacting both honest and malicious parties. However, claims can always be made through a trustless pool. Honest parties can pool together funds to participate in disputes.\n\nThe sweet spot​\n\nSo, now that we've established that a higher resource ratio is better but comes with some trade-offs, what is the sweet spot?\n\nWe propose a resource of ratio of 6.46 for Arbitrum One. While odd, this resource ratio was calculated taking the initial \"bond\" to become a proposer (mentioned earlier) and a worst case scenario of 500 gwei/gas on L1 for posting assertions and making sub-challenge moves (i.e. if an attack were to happen, the malicious actor could choose to perform their attack during a period of elevated gas prices). Again, we should emphasize that the ratio of malicious to honest cost should be high to sufficiently deter attacks. Under our current assumptions (500gwei/gas) and proposed parameters (bond sizes, etc) for every $6.46 spent by malicious parties attacking, only $1 is needed to defend it successfully in BoLD. Here's a direct link to the calculations where the X-axis is L1 gas costs in gwei and the Y-axis is the resource ratio.\n\nUnfortunately, there is no \"one size fits all\" framework for choosing the resource ratio for your chain. Therefore, we recommend teams learn and understand the benefits and trade-offs of operating BoLD in a permissionless format - including performing the same type of economic risk analyses we have performed for Arbitrum One.\n\nThinking about incentives​\n\nAlthough we have made claims with hard numbers about how to price disputes and withdrawal delays in Arbitrum BoLD, we also took a step back and considered the theoretical assumptions we were making. Arbitrum One is a complex protocol used by many groups of people with different incentives. The research team at Offchain Labs has spent considerable effort studying the game theory of validators in Optimistic Rollup. Honest parties represent everyone with funds onchain, and they have a significant amount to gain by winning the challenge - as they can prevent the loss of their assets rather than losing them.\n\nA more complex model is proposed, which considers all parties staking and their associated costs paper \"Incentive Schemes for Rollup Validators\". The paper examines the incentives needed to get parties to check whether assertions are correct. It finds that there is no pure strategy, Nash equilibrium, and only a mixed equilibrium if there is no incentive for honest validators. However, the research showed a pure strategy equilibrium can be reached if honest parties are incentivized to check results. The problem of honest validators' \"free riding\" and not checking is well-documented as the verifier's dilemma. We believe future iterations of BOLD could include \"attention challenges\" that reward honest validators for also doing their job.\n\nService fee for “Active” proposers​\n\nFor Arbitrum BoLD's initial launch, we believe that chain owners should pay a service fee to active, top-level proposers as a way of removing the disincentive for participation by honest parties who bond their own capital and propose assertions for Arbitrum One. The fee should be denominated in ETH and should correlate to the annualized income that Ethereum mainnet validators receive, over the same time period. At the time of writing, the estimated annual income for Ethereum mainnet validators is approximately 3% to 4% of their stake (based on CoinDesk Indices Composite Ether Staking Rate (CESR) benchmark and Rated.Network).\n\nThis service fee can be paid out upon an active proposer’s top-level assertion being confirmed on Ethereum and will be calculated using the duration of time that the proposer was considered active by the protocol. The procedure that calculates this will be handled off-chain, using a procedure that will be published at a later date. BoLD makes it permissionless for any validator to become a proposer and also introduces a way to pay a service fee to honest parties for locking up capital to do so. Validators are not considered active proposers until they successfully propose an assertion with a bond.\n\nIn order to become an active proposer for an Arbitrum chain, post-BoLD, a validator has to propose a state assertion to its parent chain. For Arbitrum One and Nova, the state assertion is posted onto L1 Ethereum. If they do not have an active bond on L1, they then need to attach a bond to their assertion in order to successfully post the assertion. Subsequent assertions posted by the same address will simply move the already-supplied bond to their latest proposed assertion. Meanwhile, if an entity, say Bob, has posted a successor assertion to one previously made by another entity, Alice, then Bob would be considered by the protocol to be the current active proposer. Alice would no longer be considered by the protocol as the active proposer and once Alice’s assertion is confirmed, then Alice gets her assertion bond refunded. There can only be 1 “active” proposer at any point in time.\n\nFor Arbitrum One specifically, all eligible entities who wish to be paid this service fee from the Arbitrum Foundation must undergo the Arbitrum Foundation’s KYC process as no AIP \"may be in violation of applicable laws, in particular sanctions-related regulations\". This is also written in the ArbitrumDAO's Constitution.\n\nRewards and Reimbursements for Defenders​\n\nThe service fee described above is meant to incentivize or reimburse an honest, active proposer for locking up their capital to propose assertions and advance the chain. Similarly, in the event of an attack, a bounty is proposed to be paid out to honest defenders using confiscated funds from malicious actors (in the event of a challenge).\n\nFor Arbitrum One specifically, 1% (called the “defender’s bounty”) of the confiscated funds from a malicious actor is to be rewarded to honest parties who deposit a challenge bond and post assertions as part of a sub-challenge, proportional to the amount that a defender has put up to defend a correct state assertion during the challenge. This bounty applies for all challenges (block challenges, sub challenges and one step challenges). Note that any gas costs spent by honest parties to defend Arbitrum One during a challenge is 100% refundable by the Arbitrum Foundation. In this model, honest defenders and proposers of Arbitrum One are incentivized to participate while malicious actors stand to lose everything they spent attacking Arbitrum One. We believe chain owners who are interested in adopting BoLD for their own chain should follow a similar approach, described above for Arbitrum One, to incentivize challenge participation (but not necessarily assertion proposing).\n\nIn this design, defenders are only eligible for the defender's bounty if they deposit a challenge bond (for Arbitrum One, this is either 555 or 79 ETH, depending on the level), posted to an on-chain assertion as part of a sub-challenge (i.e., not the top-level assertion), and have had their on-chain sub-challenge assertion get confirmed by the protocol. For Arbitrum One, the calculation for the defender's bounty is conducted off-chain by the Arbitrum Foundation, and payment will be made via an ArbitrumDAO governance vote (since confiscated funds go to an ArbitrumDAO-controlled address). Honest parties are not automatically rewarded with all the funds seized from malicious actors to avoid creating a situation where honest parties wastefully compete to be the first ones to make each honest move in the interactive fraud-proof game. Additionally, BoLD resolves disputes by determining which top-level assertion is correct, without necessarily being able to classify every move as “honest” or “malicious” as part of the interactive fraud-proof game without off-chain knowledge.\n\nOnce all of a validator’s proposed assertions are confirmed, a validator can withdraw their bond in full. Additionally, the protocol will automatically handle refunds of challenge bonds for honest parties and confiscation of bonds from malicious parties in the event of a challenge. In other words, bonds put up by honest parties will always be returned and bonds put up by malicious parties will always be confiscated. For Arbitrum One specifically, L1 gas costs for honest parties defending a challenge will be reimbursed by the Arbitrum Foundation using a procedure that will be published at a later date. The chain owner could therefore consider the cost of incentivizing or lending the assets to a single honest proposer in the happy case as the security budget of the chain.\n\nFor Arbitrum One specifically, all eligible entities who wish to be paid the defender's bounty from the ArbitrumDAO must undergo the Arbitrum Foundation’s KYC process as no AIP \"may be in violation of applicable laws, in particular sanctions-related regulations\". This is also written in the ArbitrumDAO's Constitution.\n\nConclusion​\n\nThis page summarizes the rationale behind choosing bond sizes and the cost of spam prevention in Optimistic Rollup dispute protocols. We recommend that bond sizes be high enough to discourage challenges from being opened, as malicious parties will always stand to lose when playing the game. As Arbitrum BoLD does not tie disputes to specific addresses, honest parties can have trustless cooperation to resolve disputes if desired. We posit that making the cost of the malicious parties 10x that of the honest party leads to nice economic properties that help us reason about how to price bonds. Finally, we look at a high-level game theory discussion of Optimistic Rollups and argue that solving the verifier's dilemma by incentives to honest validators is an important addition to work towards.\n\nThe topic of further improvements and new economic and incentive models for BoLD are valuable and we believe it deserves the full focus and attention of the community in future proposals and discussions. Details around additional or new proposed economic or incentive models for BoLD will need continued research and development work, but the deployment of BoLD as-is represents a substantial improvement to the security of Arbitrum even without economic-related concerns resolved.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nTechnical deep dive\nNext\nPublic preview\nBackground\nSettling Arbitrum states to Ethereum\nWithdrawing assets back to Ethereum from Arbitrum\nThe dispute period\nDispute resolution times\nThe cost of delaying withdrawals\nResolving disputes\nDispute game overview\nSpamming the dispute game\nThinking about incentives\nService fee for “Active” proposers\nRewards and Reimbursements for Defenders\nConclusion\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/bold/concepts/bold-technical-deep-dive",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nThe BoLD dispute protocol\nA gentle introduction\nDeploy a validator on testnet\nBoLD Whitepaper\nTechnical deep dive\nEconomics of Disputes\nSpecification on Github\nAudit Report by Trail of Bits\nAudit Report by Code4rena\nPublic preview\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nBoLD: a technical deep dive\nOverview​\n\nArbitrum's current dispute protocol involves defending against challengers individually in a 1-vs-1 tournament setting. In contrast, BoLD enables an all-vs-all battle royale between Good and Evil, with a single winner always determined. This dynamic is made possible by BoLD's time-bounded, permissionless validation using deterministic Merkle proofs and hashes. This allows any party to bond in the correct state and prove their claim through interactive fraud proofs, ensuring that a single honest party bonding in the correct state will always prevail in disputes.\n\nValidators on Arbitrum can post their claim on the validity of state roots, known as assertions. Ethereum, of course, does not know anything about the validity of these Arbitrum state roots, but it can help prove their correctness. Anyone in the world can then initiate a challenge over any unconfirmed assertion to start the protocol’s game.\n\nThe assertions being disputed concern block hashes of an Arbitrum chain at a given batch/inbox position. Given that Arbitrum chains are deterministic, there is only one correct history for all parties running the standard Nitro software. Using the notion of one-step proof, Ethereum can check whether someone is making a fraudulent assertion after an interactive game is played to narrow down a dispute.\n\nIf a claim is honest, it can be confirmed on Ethereum after a 6.4-day period (although the DAO can change this period). If a claim is malicious, anyone who knows the correct Arbitrum state can successfully challenge it within that 6.4-day window and always win within a challenge period plus some small delta.\n\nThe current implementation of BoLD involves both on-chain and off-chain components:\n\nRollup contracts to be deployed on Ethereum.\n\nNew challenge management contracts to be deployed on Ethereum.\n\nHonest validator software equipped to submit assertions and perform challenge moves on any assertions it disagrees with. The honest validator is robust enough to win against malicious entities and always ensures honest assertions are the only ones confirmed on-chain.\n\nKey terminology​\nArbitrum rollup contracts: The set of smart contracts on Ethereum L1 that serve as both the data availability layer for Arbitrum and for confirming the rollup's state assertions after a challenge period has passed for each assertion made.\nAssertions: A claim posted to the Arbitrum rollup contracts on Ethereum L1 about the Arbitrum L2 execution state. Each claim consumes messages from the Arbitrum rollup inbox contract. Each assertion can be confirmed after a period of 6.4 days, and anyone can challenge it during that period. A BoLD challenge will add an additional upper bound of 6.4 days to confirm an assertion. If an assertion is challenged near the end of 6.4 days, an additional 6.4 days will be needed to complete the challenge. Gaining the right to post assertions requires placing a large, one-time bond, which can get taken away in the case of losing a challenge to a competing assertion. Opening challenges requires posting smaller \"challenge bonds\".\nValidating bridge: The smart contract that leverages Ethereum's security and censorship-resistance to unlock bridged assets from L2 back to L1. Assets can be unlocked after an assertion has been posted and confirmed.\nFraud proofs: Proofs that prove or disprove that an invalid state transition has taken place. These proofs are generated by challenge participants and are submitted to a chain's parent chain. For example, Arbitrum Rollups that settle onto Ethereum will have their proofs submitted to Ethereum and verified via a smart contract. In this case, these proofs allow Ethereum to be the final arbiter of disagreements over assertions in the rollup contracts, which cannot be falsified by any parties as there is only a single, correct result of executing a WASM instruction on a pre-state.\nChallenge protocol: A set of rules through which a disagreement on an assertion is resolved using Ethereum as the final arbiter. Ethereum's VM can verify one-step proofs of deterministic computation that will confirm a challenge winner in Arbitrum's rollup contracts once the challenge period has elapsed.\nBonding of funds: Creating an assertion in the rollup contracts requires the submitter to join the validator set by putting up a large bond in the form of WETH. Subsequent assertions posted by the same party do not require more bonds. Instead, the protocol always considers validators to be bonded to their latest posted assertion. The bonded funds are taken away if another competing assertion is confirmed. When an assertion is confirmed, the associated bonded funds can be withdrawn.\nHonest validator: An entity that knows the correct state of the Arbitrum L2 chain and who may want to participate in creating assertions, confirming assertions, and/or challenging invalid assertions if they exist. More specifically, this entity must run an Arbitrum full node in MakeNodes, Defensive, StakeLatest, or ResolveNodes mode as described in the How to run a validator. Note that there must always be an active proposer to advance the chain and who will need to run a validator in MakeNodes mode.\nChallenge period: Window of time (~6.4 days on Arbitrum One) over which an assertion can be challenged, after which the assertion can be confirmed. This is configurable by the DAO.\nEdge: Edges are a portion of a claim made by a validator about the history of the chain from some end state all the way back to some initial state. Edges are the fundamental unit in a challenge.\nTimers: Each unrivaled edge (that is, an edge without another competing edge) will have a timer that ticks up. Time in the protocol is measured using L1 blocks and block numbers are used. An edge's timer stops ticking when a rival edge is created on-chain. Most importantly, timers are used to confirm assertions when an unrivaled edge's timer, and associated assertion, reaches the specified challenge period. See the section on Timers for more details.\nDelay attacks: In a delay attack, a malicious party (or group of parties) acts within the rollup protocol, forcing the honest party to play 1-vs-1 games against them to delay the confirmation of results back to the L1 chain. BoLD has a proven, constant upper bound on confirmation times for assertions in Arbitrum, addressing the biggest flaw of the current challenge mechanism. BoLD validators don’t need to play 1-vs-1 challenges and instead can defend a single challenge against many malicious claims. With delay attacks solved, Arbitrum will be able to allow permissionless validation.\nPermissionless validation: The ability for anyone to interact with the Arbitrum rollup contracts on Ethereum to both post assertions and challenge others' assertions without needing permission. With the release of BoLD, the rollup contracts on Arbitrum will no longer have a permissioned list of validators.\nValidator software: Software that has knowledge of the correct Arbitrum L2 state at any point. It tracks the on-chain rollup contracts for assertions posted and will automatically initiate challenges on malicious assertions if configured to do so by the user. It will participate in new and existing challenges and make moves as required by the protocol to win against any number of malicious entities. Its goal is to ensure only honest assertions about Arbitrum's state are confirmed on Ethereum. All Arbitrum full nodes are watchtower validators by default. This means they do not post claims or assertions unless configured to do so but will warn in case invalid assertions are detected on-chain.\nHow BoLD uses Ethereum​\n\nWhen it comes to implementing the protocol, BoLD needs to be deployed on a credibly-neutral, censorship-resistant backend to be fair to all participants. As such, Ethereum was chosen as the perfect candidate. Ethereum is currently the most decentralized, secure, smart contract blockchain to which the full protocol can be deployed, with challenge moves performed as transactions to the protocol’s smart contracts.\n\nA helpful mental model for understanding the system is that it uses Ethereum itself as the ultimate referee for deciding assertion results. Participants in the challenge protocol can disagree over the results of L2 state transitions and provide proofs to the protocol's smart contracts on Ethereum to determine which result is correct. Because computation is deterministic, there will always be a single correct result.\n\nFrom the Nitro whitepaper. L2 blocks are “settled to L1” after a 6.4 day period has elapsed and nobody has challenged their validity on Ethereum.\n\nIn effect, there is a miniature Arbitrum state-transition VM deployed as an Ethereum smart contract to prove which assertions are correct. However, computation on Ethereum is expensive, which is why this mini-VM is built to handle “one-step proofs” consisting of a single step of WebAssembly code. The Arbitrum state transition logic, written in Golang, is also compiled to an assembly language called WASM and will therefore obtain the same results as the VM found in the on-chain smart contract. The soundness of the protocol depends on the assumptions that computation is deterministic and equivalent between the on-chain VM and the Golang state transition compiled to WASM.\n\nAll actors in the protocol have a local state from which they can produce valid proofs, and all honest parties will have the same local state. Malicious entities, however, can deviate from the honest parties in attempts to confirm invalid states through the protocol. Both the protocol and the honest validator client’s job is then to allow honest parties to always win against any number of malicious participants by always claiming the absolute truth.\n\nOn-chain components​\n\nRollup contract: This is a smart contract that lives on Ethereum and allows validators to bond on state assertions about Arbitrum. This contract, known as RollupCore.sol, is already used by Arbitrum chains to post assertions. BoLD requires several changes to how assertions work in this contract, and it now contains a reference to another contract called a ChallengeManager, new in BoLD.\n\nChallengeManager: This is a contract that allows for initiating challenges on assertions and provides methods for anyone to participate in challenges in a permissionless fashion. BoLD will require a new ChallengeManager written in Solidity and deployed to Ethereum. The challenge manager contains entry points for making challenge moves, opening leaves, creating subchallenges, and confirming challenges.\n\nOneStepProver: A set of contracts that implement a miniature WASM VM capable of executing one-step-proofs of computation of the L2 state transition function. This is implemented in Solidity and already exists on Ethereum. No changes to the OSP contracts are needed for BoLD.\n\nBonding: Participants in the protocol need to bond a certain amount of ETH (WETH is used in the BoLD testnet) to gain the privilege of posting assertions to the Rollup contracts by locking up an ETH bond in the protocol contracts. Whenever someone wants to challenge an assertion, they must also place a smaller bond called a challenge bond in their challenge. Bonds, their rationale, and magnitude will be covered in greater detail in the specifications section.\n\nOff-chain components​\nChain bindings: Software that can interact with an Ethereum node in order to make calls and transactions to the on-chain contracts needed for participating in the protocol. We utilize go-ethereum’s abigen utilities to create Go bindings to interact with the contracts above, with a few more developer-friendly wrappers.\nState manager backend: Software that can retrieve L2 chain states and produce commitments to WAVM histories for Arbitrum based on an execution server. The validator client, described below, will have access to a state manager backend in order to make moves on challenge vertices.\nValidator client: A validator client is software that knows the correct history of the Arbitrum L2 chain via a state manager backend and can create assertions on L1 about them by bonding a claim. A validator is also active in ensuring honest assertions get confirmed and participating in challenging those it disagrees with. In BoLD, an honest validator will also participate in challenges other validators are a part of to support other honest participants. It interacts with the on-chain components via chain bindings described above.\nChallenge manager client: Software that can manage the life cycles of challenges that an active validator participates in. Validators need to participate in multiple challenges at once and manage individual challenge vertices correctly to act upon, confirm, or reject them.\nAssertions​\n\nA key responsibility for Arbitrum proposers is to regularly post claims about the Arbitrum chains’ state to Ethereum at certain checkpoints. These are known as assertions (and are sometimes called L2 state roots). Assertions contain information, most critically:\n\nThe L2 block hash being claimed\n\nThe batch number it corresponds to for the Arbitrum chain\n\nThe number of messages in the Arbitrum sequencer inbox at the time the assertion is created\n\nThe following assertion to be posted on-chain must consume the specified number of inbox messages from the previous assertion. There is a required delay in L1 blocks for assertion posting. Currently, this value is set to equal 1 hour for BoLD.\n\nAnyone can confirm assertions after a period of 6.4 days if they have not been challenged. In particular, assertions facilitate the process of withdrawing from Arbitrum back to Ethereum. Arbitrum withdrawals require specifying a blockhash, which must be confirmed as an assertion on-chain. This is why withdrawals have a delay of 6.4 days if they are not actively challenged.\n\nValidators must become proposers in the Rollup contract before being allowed to post assertions. For Arbitrum One and Arbitrum Nova, this involves placing a one-time bond of 3600 WETH that is locked in the contract until they choose to withdraw. Validators can only withdraw their bond if their latest posted assertion gets confirmed. Every assertion a validator posts will become their latest bonded assertion. Subsequent bonds are not needed to post more assertions, instead, the protocol “moves” a validator’s bonds to their latest posted assertion.\n\nAssertions form a chain in which there can be forks. For instance, a validator might disagree on the history committment of block state hashes, which an assertion contains. All Arbitrum Nitro nodes are configured to warn users if they observe an assertion they disagree with posted on-chain. However, if a node is configured as a validator and has deposited a bond to the Rollup contract, then that validator post the correct, rival assertion to any invalid one it just observed. The validator will also be able to initiate a challenge by posting a challenge bond and other data to the ChallengeManager, signaling it is disputing an assertion.\n\nOverflow assertions​\n\nGiven the mandatory delay of one hour between assertions posted on-chain, and each assertion is a claim to a specific Arbitrum batch, there could be a very large number of blocks in between assertions. However, a single assertion only supports a maximum of 2^26 Arbitrum blocks since the previous assertion. If this value is overflowed, one or more follow-up overflow assertions needs to be posted to consume the rest of the blocks above the maximum. This overflow assertion will not be subject to the mandatory 1-hour delay between assertions.\n\nTrustless bonding pools​\n\nA large upfront assertion bond is critical for discouraging malicious actors from attacking Arbitrum and spamming the network (e.g., delay attacks), especially because malicious actors will always lose challenges and their entire bond. On the other hand, requiring such a high upfront assertion bond may be prohibitive for a single honest entity to put up—especially since the cost to defend Arbitrum is proportional to the number of malicious entities and ongoing challenges at any given point in time.\n\nTo address this, there is a contract that anyone can use to deploy a trustless, bonding (or staking) pool as a way of crowdsourcing funds from others who wish to help defend Arbitrum, but who may otherwise not individually be able to put up the sizeable upfront bond itself.\n\nAnyone can deploy an assertion bonding pool using the AssertionStakingPoolCreator.sol contract as a means to crowdsource funds for bonding funds to an assertion. To defend Arbitrum using one of these pools, an entity would first deploy this pool with the assertion they believe is correct and wish to bond on to challenge an adversary's assertion. Then, anyone can verify that the claimed assertion is correct by running the inputs through their node's State Transition Function (STF). If other parties agree that the assertion is correct, they can deposit their funds into the contract. When enough funds have been deposited, anyone can trigger the creation of the assertion on-chain to start the challenge in a trustless manner. Finally, once the dispute protocol confirms the honest parties' assertion, all involved entities will get their funds reimbursed and can withdraw.\n\nNote that with bonding pools, there is no minimum WETH requirement and once the entire bond amount is raised (either 3600, 555, or 79 ETH for Arbitrum One), then the assertion can be posted by anyone trustlessly. Additionally, there is an optional feature in the Nitro node validator software that enables both the automatic deployment of a bonding pool contract and depositing of funds to challenge an observed invalid assertion.\n\nTrustless bonding pools can also be created to open challenges and make moves on challenges without sacrificing decentralization.\n\nOpening challenges​\n\nTo initiate a challenge, there must first be a fork in the assertion chain within the Arbitrum Rollup contracts. However, a challenge's actual start involves creating an edge claim and posting it to the ChallengeManager contract on the parent chain. Additionally, the validator posting the edge must attach a bond called a challenge bond to it (denominated in WETH for the BoLD testnet and for Arbitrum One and Arbitrum Nova). This bond is much lower than the one required to become an assertion proposer.\n\nAnyone can open a challenge on an assertion without needing to be a bonder in the Rollup contract, so long as they post a challenge bond and an edge claiming intent to start the challenge. Challenges are not tied to specific addresses or parties – instead, anyone can participate.\n\nRecall that a challenge is a fundamental disagreement about an assertion posted to the Arbitrum chain. At its core, validators disagree about the blockhash at a certain block number, essentially, and the BoLD protocol allows them to interactively narrow down their disagreement via fraud proofs such that Ethereum can be the final referee and claim a winner.\n\nAt its core, the disagreement between validators looks something like this:\n\nCommon parent assertion: batch 5, blockhash 0xabc\n\nAlice’s assertion: batch 10, blockhash 0x123\n\nBob’s assertion: batch 10, blockhash 0x456\n\nTheir disagreement is about an Arbitrum block somewhere between batch 5 and batch 10. Here’s how the actual challenge begins in this example:\n\nValidators have to fetch all blocks between batch 5 and batch 10 and create a Merkle commitment out of them as a Merkle tree with 2^26+1 leaves. If there are fewer than 2^26 blocks in between the assertions, the last block is repeated to pad the leaves of the tree to that value. Validators then create an “edge” data structure, which contains the following fields:\n\nstart_hash: the start_hash of the claimed assertion and is also the end_hash of the previous assertion\n\nend_hash: the end hash of the last block in the child assertion that a validator claims is correct.\n\nmerkle_root: the Merkle root that results from committing to a Merkle tree from the start block hash to the end block hash\n\ninclusion_proofs: Merkle proofs that the end hashes are indeed leaves of the Merkle tree committing to a root\n\nThe concept of a history commitment is at the core of challenges and BoLD itself.\n\nThe validators above provide a Merkle proof of their commitment to some history. In this case, all the Arbitrum block hashes from batch 5 to batch 10. Using this tree, validators can narrow their disagreement to a single block using Merkle proofs by iteratively bisecting the set of leaves and creating sub-challenge edges which have their own history commitments to each half of the tree.\n\nChallenge resolution​\n\nThe fundamental unit in a challenge is an edge data structure.\n\nInitiation​\n\nThe first validator to create an edge initiates a challenge. The smart contracts validate the Merkle inclusion proofs and hashes provided to prove this challenge is about a specific fork in the assertion chain in the Rollup contract.\n\nBisections​\n\nWhen an edge is created, it claims some history from point A to B, with which validators can agree or disagree. Other validators can claim some history from point A to B’, where B’ is a different end state. A history commitment is a Merkle commitment to a list of hashes.\n\nTo narrow down a disagreement, validators have to figure out what exact hash they disagree with. To do this, the game essentially takes turns between validators playing binary search. Each move here is known as a “bisection” because each move splits a history commitment in half.\n\nFor instance:\n\nAlice commits to 33 hashes with start = A, end = B\n\nBob commits to 33 hashes with start = A, end = B’\n\nEither of them can perform a “bisection” move on their edge. For instance, if Alice “bisects” her edge E, the bisection transaction will produce two children, E_1 and E_2. E_1 commits to 17 hashes from height A to B/2, and E_2 commits to 17 hashes from height B/2 to B.\n\nA validator can make a move on an edge as long as that edge is “rivaled”. That is, the children just created due to Alice’s bisection will have increasing timers until Bob also bisects and possibly creates rivals for Alice’s edges (see timers for more details).\n\nSubchallenges​\n\nThe number of steps of execution at which validators could disagree within a single Arbitrum block has a max of 2^42. To play a game of bisections on this amount of hashes would be unreasonable from a space requirement, as each history commitment would require 4.35Tb worth of hashes. Instead, BoLD plays the bisection game over different levels of granularity of this space of 2^42 hashes that we call \"subchallenges\" that can be viewed as \"phases\" of the dispute resolution process.\n\nAs a reminder, the bisection game is an iterative process. The first subchallenge is at the block level and is where validators disagree over Arbitrum blocks between two assertions. The disagreeing validators) create “edges” containing history commitments to all the blocks in between those two assertions, which is a max of 2^26 L2 blocks, and commence the bisection game. As they progressively narrow down to a single block of disagreement, the validators then begin the next phase of the challenge process by opening a subchallenge over up to 2^19 BigSteps, which are each 2^23 steps of WASM execution. Once they reach a single disagreement at the BigStep level, they open a final subchallenge over a maximum of 2^23 SmallSteps, which are each a single step of WASM execution. The bisection game is the same at each subchallenge level, and opening a subchallenge requires placing another “challenge bond”. The magnitudes of challenge bonds are different at each subchallenge level.\n\nOne step proof​\n\nOnce validators reach a single step of disagreement after reaching the deepest subchallenge level, they need to provide something called a one step proof, or OSP for short. This is a fraud proof of WASM execution showing that executing the Arbitrum state transition function at machine hash A leads to machine hash B. The parent chain, like Ethereum is for Arbitrum One, then actually runs a WASM emulator using a smart contract for this step and will declare a winner. An evil party cannot forge a one-step proof, and unless there is a critical bug in the smart contract, the honest party will always win. At this point, the honest party’s one-step proven edge will be confirmed, and the evil party has no more moves to make. Next, the honest party’s “branch” of edges all the way from the top to the one-step proven edge will have an ever-increasing timer until the top edge can be confirmed by time.\n\nTimers​\n\nOnce a validator creates an edge, and if it does not have any rival edge contesting it, that edge will have a timer that ticks up called its unrivaled timer. Time in the protocol is measured in L1 blocks, and block numbers are used. An edge's timer stops ticking when a rival edge is created on-chain.\n\nEdges also have an inherited timer, which is the sum of its unrivaled timer + the minimum inherited timer of an edge's children (recursive definition). Once one of the top-level edges that initiated a challenge has achieved an inherited timer >= a CHALLENGE_PERIOD (6.4 days), it can be confirmed. At this point, its assertion can also be confirmed as its associated challenge has completed. A minor but important detail is that edges also inherit the time their claimed assertion was unrivaled.\n\nFeel free to read the BoLD whitepaper for more details around how timers are tracked.\n\nCached timer updates​\n\nAn edge's \"inherited timer\" value exists on-chain and can be updated via a transaction. Given it is a recursive definition, it can be updated via multiple transactions. First, the lowermost edges have their timers updated, then their parents, etc., up to the top. Validators can track information locally to avoid sending wasteful transactions and only propagate updates once they are confident their edge is confirmable by time.\n\nConfirmation​\n\nOnce an edge has a total on-chain timer greater than or equal to a challenge period, it can be confirmed via a transaction. Not all edges need to be confirmed on-chain, as simply the top-level block challenge edge is enough to confirm the claimed assertion and resolve a dispute. A challenge is not complete at the one-step proof. It is only complete once the claimed assertion of a challenge is confirmed by time.\n\nBonding in challenges​\n\nTo create a challenge, there must be a fork in the Arbitrum assertion chain smart contract. A validator that wishes to initiate a challenge must then post an “edge” claiming a history of block hashes from the previous assertion to the claimed assertion they believe is correct. To do so, they need to put up some value called a \"challenge bond\". Note that to open a new assertion-level challenge, the challenge bond is equal to the assertion bond for Arbitrum One.\n\nChallenge bonds are named as such because they are bonds required for opening challenges. The mechanism of how challenge bond economics are decided is contained in the Economics of Disputes, which also explains the cost profile and spam prevention in BoLD. In short, the actual cost of a bond encompasses many costs associated with participating in the dispute game. More information on the bond sizes and how they were calculated can be found in the Economics of Disputes document mentioned above.\n\nEach subchallenge that is created requires depositing a challenge bond. For Arbitrum One, the first unrivaled edge’s bond is kept in the challenge manager contract on Ethereum, while any subsequent rival bonds are kept in an excess bond receiver address. Once a challenge is complete, all bonds for an honest party are automatically refunded in-protocol while all confiscated bonds are sent to the ArbitrumDAO treasury. It is important to not offer the majority of the bonds confiscated from dishonest parties to honest parties to avoid perverse incentives, such as grieving attacks in self-challenges or to discourage needless competition between honest parties.\n\nReimbursements of bonds​\n\nThe reimbursement of assertion bonds and challenge bonds for honest parties will be handled “in-band” by the protocol. Please see Economics of Disputes for more information about this topic.\n\nUpgrade mechanism​\n\nFor BoLD to be deployed on an Arbitrum chain, an upgrade admin action needs to be taken using an UpgradeExecutor pattern. This is a smart contract that executes actions as the Rollup owner. At the upgrade, the RollupCore.sol contract will be updated to a new BoLD one, and additional contracts needed for BoLD challenges, such as an EdgeChallengeManager.sol, will also be deployed to the parent chain.\n\nNext, assertions will then be posted to the new Rollup contract. During the upgrade period, there could have been a very large number of blocks posted in Arbitrum batches. For this purpose, BoLD assertions support the concept of an overflow, allowing us to efficiently handle this situation.\n\nWITHDRAWALS LEADING UP TO A BOLD UPGRADE\n\nThe confirmation timing on any withdrawal that is in-flight when the BoLD upgrade is activated will be delayed until the first BoLD assertion is confirmed. This means that for any Arbitrum chain that upgrades to use BoLD, including Arbitrum One and Arbitrum Nova, all pending withdrawals to L1 Ethereum that were initiated before the upgrade will be delayed by 1 challenge period, plus the time between the withdrawal was initiated and the time that the BOLD upgrade takes place. This is because the upgrade effectively \"resets\" the challenge period for that are not yet finalized.\n\nFor example, if the upgrade happened at time t, then a withdrawal initiated at a time t-2 days will need to wait an additional 6.4 days for their withdrawal to be finalized, totaling 8.4 days of maximum delay. Withdrawals that finalize before the upgrade takes place at time t will be unaffected. In other words, the maximum delay a withdrawal will experience leading up to the upgrade is 12.8 days (two challenge periods).\n\nThe upgrade pattern for an existing Arbitrum Rollup to a BoLD-enabled one is tested extensively and run as part of each of our pull requests in the BoLD repository upgrade workflow on GitHub.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nA gentle introduction\nNext\nEconomics of Disputes\nOverview\nKey terminology\nHow BoLD uses Ethereum\nOn-chain components\nOff-chain components\nAssertions\nOpening challenges\nChallenge resolution\nBonding in challenges\nReimbursements of bonds\nUpgrade mechanism\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Chain parameters | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/reference/chain-params",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nRPC endpoints and providers\nContract addresses\nChain parameters\nDevelopment frameworks\nWeb3 libraries and tools\nMonitoring tools and block explorers\nDebugging tools\nMainnet risks\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nChain parameters\nParam\tDescription\tArbitrum One\tArbitrum Nova\tArb Sepolia\nDispute window\tTime for assertions to get confirmed during which validators can issue a challenge\t45818 blocks (~ 6.4 days )\t45818 blocks (~ 6.4 days)\t20 blocks (~ 4.0 minutes)\nBase stake\tAmount of stake required for a validator to make an assertion\t1 ETH\t1 ETH\t1 Sepolia ETH\nForce-include period\tPeriod after which a delayed message can be included into the inbox without any action from the Sequencer\t5760 blocks / 24 hours\t5760 blocks / 24 hours\t5760 blocks / 24 hours\nGas speed limit\tTarget gas/sec, over which the congestion mechanism activates\t7,000,000 gas/sec\t7,000,000 gas/sec\t7,000,000 gas/sec\nGas price floor\tMinimum gas price\t0.01 gwei\t0.01 gwei\t0.1 gwei\nBlock gas limit\tMaximum amount of gas that all the transactions inside a block are allowed to consume\t32,000,000\t32,000,000\t32,000,000\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nContract addresses\nNext\nDevelopment frameworks\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Solidity support | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/arbitrum-vs-ethereum/solidity-support",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nComparison overview\nBlock gas limit, numbers and time\nRPC methods\nSolidity support\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nSolidity support\n\nArbitrum chains are Ethereum compatible, and therefore allow you to trustlessly deploy Solidity smart contracts, as well as contracts written in Vyper or any other language that compiles to EVM bytecode. However, when calling certain properties and functions on a Solidity smart contract, there might be some differences between the result you'd obtain if that contract was on Ethereum, and the result on Arbitrum.\n\nThis page compiles a list of functions and properties that return a different result when called in Arbitrum.\n\nDifferences from Solidity on Ethereum​\n\nAlthough Arbitrum supports Solidity code, there are differences in the effects of a few operations, including language features that don't make much sense in the Layer 2 context.\n\nOperation\tDescription\nblockhash(x)\tReturns a cryptographically insecure, pseudo-random hash for x within the range block.number - 256 <= x < block.number. If x is outside of this range, blockhash(x) will return 0. This includes blockhash(block.number), which always returns 0 just like on Ethereum. The hashes returned do not come from L1. ⚠️ Arbitrum's L2 block hashes should not be relied on as a secure source of randomness.\nblock.coinbase\tReturns the designated internal address 0xA4b000000000000000000073657175656e636572 if the message was posted by a sequencer. If it's a delayed message, it returns the address of the delayed message's poster (Note: the handling of delayed message's block.coinbase will likely be changed in a future ArbOS version).\nblock.difficulty\tReturns the constant 1.\nblock.prevrandao\tReturns the constant 1.\nblock.number\tReturns an \"estimate\" of the L1 block number at which the sequencer received the transaction. For more information, see Block numbers and time.\nmsg.sender\tWorks the same way it does on Ethereum for regular L2 to L2 transactions. For transactions submitted via the delayed inbox, it will return the L2 address alias of the L1 contract that triggered the message. For more information, see address aliasing.\nOPCODE PUSH0\tThis OPCODE was added as part of ArbOS 11 and is now supported.\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRPC methods\nNext\nOracles\nDifferences from Solidity on Ethereum\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Block gas limit, numbers and time | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/arbitrum-vs-ethereum/block-numbers-and-time",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nComparison overview\nBlock gas limit, numbers and time\nRPC methods\nSolidity support\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nBlock gas limit, numbers and time\nARBITRUM CHAINS AND THEIR PARENT CHAINS\n\nWith the release of Arbitrum Orbit, Arbitrum chains can now be L2s that settle to Ethereum (or one of their testnets), or L3s that settle to one of the Arbitrum L2 chains. For simplicity, in this page we speak in terms of Arbitrum One (L2) and Ethereum (L1), but the same logic can be applied to any chain and its parent chain.\n\nAs in Ethereum, Arbitrum clients submit transactions, and the system executes those transactions at some later time. In Arbitrum, clients submit transactions by posting messages to the Ethereum chain, either through the sequencer or via the chain's delayed inbox.\n\nOnce in the chain's core inbox contract, transactions are processed in order. Generally, some time will elapse between when a message is put into the inbox (and timestamped) and when the contract processes the message and carries out the transaction requested by the message.\n\nAdditionally, since the calldata of Arbitrum transactions (or the DAC certificate on AnyTrustchains) is posted to Ethereum, the gas paid when executing them includes an L1 component to cover the costs of the batch poster.\n\nThis page describes what this mechanism means for the block gas limit, block numbers, and the time assumptions of the transactions submitted to Arbitrum.\n\nBlock gas limit​\n\nWhen submitting a transaction to Arbitrum, users are charged for both the execution cost on Arbitrum and the cost of posting its calldata to Ethereum. This dual cost structure is managed by adjusting the transaction's gas limit to reflect these two dimensions, resulting in a higher gas limit value than what would be seen for pure execution.\n\nThe gas limit of an Arbitrum block is set as the sum of all transaction gas limits, including the costs related to L1 data posting. To accommodate potential variations in L1 costs, Arbitrum assigns an artificially large gas limit (1,125,899,906,842,624) for each block. However, the effective execution gas limit is capped at 32 million. This means that while the visible gas limit might appear very high, the actual execution costs are constrained within this limit. Understanding this distinction helps clarify why querying a block might show an inflated gas limit that doesn’t match the effective execution costs.\n\nFor a more detailed breakdown of the gas model, refer to this article on Arbitrum's 2-dimensional fee structure.\n\nBlock numbers: Arbitrum vs. Ethereum​\n\nArbitrum blocks are assigned their own L2 block numbers, distinct from Ethereum's block numbers.\n\nA single Ethereum block could include multiple Arbitrum blocks within it; however, an Arbitrum block cannot span across multiple Ethereum blocks. Thus, any given Arbitrum transaction is associated with exactly one Ethereum block and one Arbitrum block.\n\nEthereum block numbers within Arbitrum​\n\nAccessing block numbers within an Arbitrum smart contract (i.e., block.number in Solidity) will return a value close to (but not necessarily exactly) the L1 block number at which the sequencer received the transaction.\n\n// some Arbitrum contract:\nblock.number // => returns L1 block number (\"ish\")\n\n\nAs a general rule, any timing assumptions a contract makes about block numbers and timestamps should be considered generally reliable in the longer term (i.e., on the order of at least several hours) but unreliable in the shorter term (minutes). (It so happens these are generally the same assumptions one should operate under when using block numbers directly on Ethereum!)\n\nArbitrum block numbers​\n\nArbitrum blocks have their own block numbers, starting at 0 at the Arbitrum genesis block and updating sequentially.\n\nArbOS and the sequencer are responsible for delineating when one Arbitrum block ends and the next one begins. However, block creation depends entirely on chain usage, meaning that blocks are only produced when there are transactions to sequence. In active chains, one can expect to see Arbitrum blocks produced at a relatively steady rate. In more quiet chains, block production might be sporadic depending on the rate at which transactions are received.\n\nA client that queries an Arbitrum node's RPC interface (for, e.g., transaction receipts) will receive the transaction's Arbitrum block number as the standard block number field. The L1 block number will also be included in the added l1BlockNumber field.\n\nconst txnReceipt = await arbitrumProvider.getTransactionReceipt('0x...');\n/** \n    txnReceipt.blockNumber => Arbitrum block number\n    txnReceipt.l1BlockNumber => L1 block number (\"ish\")\n*/\n\n\nThe Arbitrum block number can also be retrieved within an Arbitrum contract via ArbSys precompile:\n\n ArbSys(100).arbBlockNumber() // returns Arbitrum block number\n\nExample​\nWall Clock time\t12:00 am\t12:00:15 am\t12:00:30 am\t12:00:45 am\t12:01 am\t12:01:15 am\nL1 block.number\t1000\t1001\t1002\t1003\t1004\t1005\nL2 block.number *\t1000\t1000\t1000\t1000\t1004\t1004\nArbitrum Block number (from RPCs) **\t370000\t370005\t370006\t370008\t370012\t370015\n\n* L2 block.number: updated to sync with L1 block.number approximately every minute. Thus, over time, it will, like the L1 block.number, average to ~12 seconds per block.\n\n** Arbitrum block number from RPCs: note that this can be updated multiple times per L1 block (this lets the sequencer give sub-L1-block-time transaction receipts.)\n\nCase study: the Multicall contract​\n\nThe Multicall contract offers a great case study for the differences between L1 and L2 block numbers.\n\nThe canonical implementation of Multicall returns the value of block.number. If attempting to use out-of-the-box, some applications might face unintended behaviour.\n\nYou can find a version of the adapted Multicall2 deployed on Arbitrum One at 0x7eCfBaa8742fDf5756DAC92fbc8b90a19b8815bF.\n\nBy default the getBlockNumber, tryBlockAndAggregate, and aggregate functions return the L2 block number. This allows you to use this value to compare your state against the tip of the chain.\n\nThe getL1BlockNumber function can be queried if applications need to surface the L1 block number.\n\nBlock timestamps: Arbitrum vs. Ethereum​\n\nBlock timestamps on Arbitrum are not linked to the timestamp of the L1 block. They are updated every L2 block based on the sequencer's clock. These timestamps must follow these two rules:\n\nMust be always equal or greater than the previous L2 block timestamp\nMust fall within the established boundaries (24 hours earlier than the current time or 1 hour in the future). More on this below.\n\nFurthermore, for transactions that are force-included from L1 (bypassing the sequencer), the block timestamp will be equal to either the L1 timestamp when the transaction was put in the delayed inbox on L1 (not when it was force-included), or the L2 timestamp of the previous L2 block, whichever of the two timestamps is greater.\n\nTimestamp boundaries of the sequencer​\n\nAs mentioned, block timestamps are usually set based on the sequencer's clock. Because there's a possibility that the sequencer fails to post batches on the parent chain (for example, Ethereum) for a period of time, it should have the ability to slightly adjust the timestamp of the block to account for those delays and prevent any potential reorganisations of the chain. To limit the degree to which the sequencer can adjust timestamps, some boundaries are set, currently to 24 hours earlier than the current time, and 1 hour in the future.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nComparison overview\nNext\nRPC methods\nBlock gas limit\nBlock numbers: Arbitrum vs. Ethereum\nEthereum block numbers within Arbitrum\nArbitrum block numbers\nExample\nCase study: the Multicall contract\nBlock timestamps: Arbitrum vs. Ethereum\nTimestamp boundaries of the sequencer\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/arbitrum-vs-ethereum/rpc-methods#__docusaurus_skipToContent_fallback",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nComparison overview\nBlock gas limit, numbers and time\nRPC methods\nSolidity support\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nRPC methods\n\nAlthough the majority of RPC methods follow the same behavior as in Ethereum, some methods might produce a different result, or add more information, when used on an Arbitrum chain. This page covers the differences in response body fields you'll find when calling RPC methods on an Arbitrum chain vs on Ethereum.\n\nINFO\n\nComprehensive documentation on all generally available JSON-RPC methods for Ethereum can be found at ethereum.org. As Arbitrum has go-ethereum at its core, most of the documented methods there can be used with no modifications.\n\nTransactions​\n\nWhen calling eth_getTransactionByHash and other methods that return a transaction, Arbitrum includes a few additional fields and leverages some existing fields in different ways than Ethereum.\n\nTransaction types​\n\nIn addition to the three transaction types currently supported on Ethereum, Arbitrum adds additional types listed below and documented in full detail here.\n\nOn RPC calls that return transactions, the type field will reflect the custom codes where applicable.\n\nTransaction type code\tTransaction type name\tDescription\n100\tArbitrumDepositTxType\tUsed to deposit ETH from L1 to L2 via the Arbitrum bridge\n101\tArbitrumUnsignedTxType\tUsed to call an L2 contract from L1, originated by a user through the Arbitrum bridge\n102\tArbitrumContractTxType\tUsed to call an L2 contract from L1, originated by a contract through the Arbitrum bridge\n104\tArbitrumRetryTxType\tUsed to manually redeem a retryable ticket on L2 that failed to execute automatically (usually due to low gas)\n105\tArbitrumSubmitRetryableTxType\tUsed to submit a retryable ticket via the Arbitrum bridge on L1\n106\tArbitrumInternalTxType\tInternal transactions created by the ArbOS itself for certain state updates, like the L1 base fee and the block number\nAdditional fields​\n\nOn RPC calls that return transactions, the following fields are added to the returned object.\n\nField name\tDescription\nrequestId\tOn L1 to L2 transactions, this field is added to indicate position in the Inbox queue\nExisting fields with different behavior​\n\nOn RPC calls that return transactions, the following fields will have a different content than what's received on Ethereum.\n\nField name\tDescription\nfrom\tOn L1 to L2 transactions, this field will contain the aliased version of the L1's msg.sender\nTransaction receipts​\n\nWhen calling eth_getTransactionReceipt, Arbitrum includes a few additional fields and leverages some existing fields in different ways than Ethereum.\n\nAdditional fields​\n\nOn RPC calls that return transaction receipts, the following fields are added to the returned object.\n\nField name\tDescription\nl1BlockNumber\tThe L1 block number that would be used for block.number calls. More information in Block numbers and time\ngasUsedForL1\tAmount of gas spent on L1 calldata in units of L2 gas. More information in Gas and fees\nBlocks​\n\nWhen calling eth_getBlockByHash and other methods that return a block, Arbitrum includes a few additional fields and leverages some existing fields in different ways than Ethereum.\n\nAdditional fields​\n\nOn RPC calls that return a block, the following fields are added to the returned object.\n\nField name\tDescription\nl1BlockNumber\tAn approximate L1 block number that occurred before this L2 block. More information in Block numbers and time\nsendCount\tThe number of L2 to L1 messages since Nitro genesis\nsendRoot\tThe Merkle root of the outbox tree state\nExisting fields with different behavior​\n\nOn RPC calls that return a block, the following fields will have a different content than what's received on Ethereum.\n\nField name\tDescription\nextraData\tThis field is equivalent to sendRoot\nmixHash\tFirst 8 bytes is equivalent to sendCount, second 8 bytes is equivalent to l1BlockNumber\ndifficulty\tFixed at 0x1\ngasLimit\tValue is fixed at 0x4000000000000, but it's important to note that Arbitrum One currently has a 32M gas limit per block. See Chain params for the gas limit of other chains\nOther methods that are slightly different​\neth_syncing​\n\nCalling eth_syncing returns false when the node is fully synced (just like on Ethereum). If the node is still syncing, eth_syncing returns an object with data about the synchronization status. Here, we provide more details.\n\nUnderstanding messages, batches, and blocks​\n\nNitro nodes receive transactions from their parent chain and the sequencer feed in the form of messages. These messages may contain multiple transactions that are executed by the node, which then produces blocks. Each message produces exactly one block. In most Nitro chains, the message number and the block number are the same. However, Arbitrum One has pre-Nitro (classic) blocks, so for that chain, message 0 produced block 22207818 (blocks prior to that one are 'classic' blocks). Keep in mind that the offset between message and block number is constant in the chain.\n\nOn the parent chain, messages appear in batches. The number of messages per batch changes between batches.\n\nCustom eth_syncing fields​\nINFO\n\nNote that the exact output for the eth_syncing RPC call of an out-of-sync Nitro node is not considered a stable API. It is still being actively developed and can be modified without notice between versions.\n\nField name\tDescription\nbatchSeen\tLast batch number observed on the parent chain\nbatchProcessed\tLast batch that was processed on the parent chain. Processing means dividing the batch into messages\nmessageOfProcessedBatch\tLast message in the last processed batch\nmsgCount\tNumber of messages known/queued by the Nitro node\nblockNum\tLast block created by the Nitro node (up-to-date L2 block the node is synced to)\nmessageOfLastBlock\tMessage that was used to produce the block above\nbroadcasterQueuedMessagesPos\tIf different than 0, this is expected to be greater than msgCount. This field notes a message that was read from the feed but not processed because earlier messages are still missing\nlastL1BlockNum\tLast block number from the parent chain that Nitro sees. This is used to debug the connection with the parent chain\nlastl1BlockHash\tLast block hash from the parent chain that Nitro sees. This is used to debug the connection with the parent chain\nINFO\n\nNote that if the sync process encounters an error while trying to collect the data above (not expected) this error will be added to the response.\n\nUnderstanding common scenarios​\nIf batchSeen > batchProcessed, some batches have still not been processed\nIf msgCount > messageOfLastBlock, some messages have been processed, but not all relevant blocks have been built (this is usually the longest stage while syncing a new node)\nIf broadcasterQueuedMessagesPos > msgCount, the feed is ahead of the last message known to the node\ndebug_traceTransaction​\n\nThe Nitro node provides a native tracer for debugging Stylus contracts called stylusTracer, which returns a JSON array with objects containing the metadata for each executed HostIO. HostIOs are calls the WasmVM makes to read and write data in the EVM. With the result of this tracer and the code for the Stylus contract, you have all the data to understand what happened in a Stylus transaction.\n\nINFO\n\nThe cargo-stylus command-line tool uses the stylusTracer to replay transactions locally inside a debugger. More information can be found on How to debug Stylus transactions using Cargo Stylus Replay.\n\nThe table below describes each field of the stylusTracer return value.\n\nField Name\tDescription\nname\tName of the execute HostIO.\nargs\tArguments of the HostIO encoded as hex.\nouts\tOutputs of the HostIO encoded as hex.\nstartInk\tAmount of Ink before executing the HostIO.\nendInk\tAmount of Ink after executing the HostIO.\naddress\tFor *call HostIOs, the address of the called contract.\nsteps\tFor *call HostIOs, the steps performed by the called contract.\n\nFor example, the command below illustrates how to call this tracer for a transaction.\n\ncurl -s \\\n    -X POST \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"jsonrpc\":\"2.0\",\"method\":\"debug_traceTransaction\",\"params\":[\"<transaction-hash>\", {\"tracer\": \"stylusTracer\"}],\"id\":1}' \\\n    <nitro-node-rpc>\n\n\nThe result of this call will be something along the lines of.\n\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": [\n    {\n      \"args\": \"0x00000024\",\n      \"endInk\": 116090000,\n      \"name\": \"user_entrypoint\",\n      \"outs\": \"0x\",\n      \"startInk\": 116090000\n    },\n    {\n      \"args\": \"0x\",\n      \"endInk\": 116057558,\n      \"name\": \"msg_reentrant\",\n      \"outs\": \"0x00000000\",\n      \"startInk\": 116065958\n    },\n    {\n      \"args\": \"0x\",\n      \"endInk\": 115937952,\n      \"name\": \"read_args\",\n      \"outs\": \"0x6c5283490000000000000000000000003bdff922e18bc03f1cf7b2a8b65a070cbec944f2\",\n      \"startInk\": 115951512\n    },\n    ...\n  ]\n}\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nBlock gas limit, numbers and time\nNext\nSolidity support\nTransactions\nTransaction types\nAdditional fields\nExisting fields with different behavior\nTransaction receipts\nAdditional fields\nBlocks\nAdditional fields\nExisting fields with different behavior\nOther methods that are slightly different\neth_syncing\ndebug_traceTransaction\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Gas and Fees | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/gas-fees",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nTransaction lifecycle\nSequencer\nAnyTrust protocol\nGas / fees\nL2 gas and fees\nL1 pricing\nAdvanced concepts\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nGas and Fees\n\nThere are two parties a user pays when submitting a tx:\n\nthe poster, if reimbursable, for L1 resources such as the L1 calldata needed to post the tx\nthe network fee account for L2 resources, which include the computation, storage, and other burdens L2 nodes must bear to service the tx\n\nThe L1 component is the product of the transaction's estimated contribution to its batch's size — computed using Brotli on the transaction by itself — and the L2's view of the L1 data price, a value which dynamically adjusts over time to ensure the batch-poster is ultimately fairly compensated. For details, see L1 Pricing.\n\nThe L2 component consists of the traditional fees Geth would pay to stakers in a vanilla L1 chain, such as the computation and storage charges applying the state transition function entails. ArbOS charges additional fees for executing its L2-specific precompiles, whose fees are dynamically priced according to the specific resources used while executing the call.\n\nGas Price Floor​\n\nThe L2 gas price on a given Arbitrum chain has a set floor, which can be queried via ArbGasInfo's getMinimumGasPrice method (currently 0.01 gwei on Arbitrum One and 0.01 gwei on Nova).\n\nEstimating Gas​\n\nCalling an Arbitrum Node's eth_estimateGas RPC gives a value sufficient to cover the full transaction fee at the given L2 gas price; i.e., the value returned from eth_estimateGas multiplied by the L2 gas price tells you how much total Ether is required for the transaction to succeed. Note that this means that for a given operation, the value returned by eth_estimateGas will change over time (as the L1 calldata price fluctuates.) (See 2-D fees and How to estimate gas in Arbitrum for more.)\n\nTips in L2​\n\nThe sequencer prioritizes transactions on a first-come first-served basis. Because tips do not make sense in this model, they are ignored. Arbitrum users always just pay the basefee regardless of the tip they choose.\n\nGas Estimating Retryables​\n\nWhen a transaction schedules another, the subsequent transaction's execution will be included when estimating gas via the node's RPC. A transaction's gas estimate, then, can only be found if all the transactions succeed at a given gas limit. This is especially important when working with retryables and scheduling redeem attempts.\n\nBecause a call to redeem donates all of the call's gas, doing multiple requires limiting the amount of gas provided to each subcall. Otherwise the first will take all of the gas and force the second to necessarily fail irrespective of the estimation's gas limit.\n\nGas estimation for Retryable submissions is possible via the NodeInterface and similarly requires the auto-redeem attempt to succeed.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nAnyTrust protocol\nNext\nL1 pricing\nGas Price Floor\nEstimating Gas\nTips in L2\nGas Estimating Retryables\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/l1-gas-pricing",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nTransaction lifecycle\nSequencer\nAnyTrust protocol\nGas / fees\nL2 gas and fees\nL1 pricing\nAdvanced concepts\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nL1 gas pricing\n\nArbOS dynamically prices L1 gas, with the price adjusting to ensure that the amount collected in L1 gas fees is as close as possible to the costs that must be covered, over time.\n\nL1 fee collection​\n\nA transaction is charged for L1 gas if and only if it arrived as part of a sequencer batch. This means that someone would have paid for L1 gas to post the transaction on the L1 chain.\n\nThe estimated cost of posting a transaction on L1 is the product of the transaction's estimated size, and the current L1 Gas Basefee. This estimated cost is divided by the current L2 gas basefee to obtain the amount of L2 gas that corresponds to the L1 operation (more information about this can be found in this article).\n\nThe estimated size is measured in L1 gas and is calculated as follows: first, compress the transaction's data using the brotli-zero algorithm, then multiply the size of the result by 16. (16 is because L1 charges 16 gas per byte. L1 charges less for bytes that are zero, but that doesn't make sense here.) Brotli-zero is used in order to reward users for posting transactions that are compressible. Ideally we would like to reward for posting transactions that contribute to the compressibility (using the brotli compressor) of the entire batch, but that is a difficult notion to define and in any case would be too expensive to compute at L2. Brotli-zero is an approximation that is cheap enough to compute.\n\nL1 gas fee funds that are collected from transactions are transferred to a special L1PricerFundsPool account, so that account's balance represents the amount of funds that have been collected and are available to pay for costs.\n\nThe L1 pricer also records the total number of \"data units\" (the sum of the estimated sizes, after multiplying by 16) that have been received.\n\nL1 costs​\n\nThere are two types of L1 costs: batch posting costs, and rewards.\n\nBatch posting costs reflect the actual cost a batch poster pays to post batch data on L1. Whenever a batch is posted, the L1 contract that records the batch will send a special \"batch posting report\" message to L2 ArbOS, reporting who paid for the batch and what the L1 basefee was at the time. This message is placed in the chain's delayed inbox, so it will be delivered to L2 ArbOS after some delay.\n\nWhen a batch posting report message arrives at L2, ArbOS computes the cost of the referenced batch by multiplying the reported basefee by the batch's data cost. (ArbOS retrieves the batch's data from its inbox state, and computes the L1 gas that the batch would have used by counting the number of zero bytes and non-zero bytes in the batch.) The resulting cost is recorded by the pricer as funds due to the party who is reported to have submitted the batch.\n\nThe second type of L1 cost is an optional (per chain) per-unit reward for handling transaction calldata. In general the reward might be paid to the sequencer, or to members of the Data Availability Committee in an AnyTrust chain, or to anyone else who incurs per-calldata-byte costs on behalf of the chain. The reward is a fixed number of wei per data unit, and is paid to a single address.\n\nThe L1 pricer keeps track of the funds due to the reward address, based on the number of data units handled so far. This amount is updated whenever a batch posting report arrives at L2.\n\nAllocating funds and paying what is owed​\n\nWhen a batch posting report is processed at L2, the pricer allocates some of the collected funds to pay for costs incurred. To allocate funds, the pricer considers three timestamps:\n\ncurrentTime is the current time, when the batch posting report message arrives at L2\nupdateTime is the time at which the reported batch was submitted (which will typically be around 20 minutes before currentTime)\nlastUpdateTime is the time at which the previous reported batch was submitted\n\nThe pricer computes an allocation fraction F = (updateTime-lastUpdateTime) / (currentTime-lastUpdateTime) and allocates a fraction F of funds in the L1PricerFundsPool to the current report. The intuition is that the pricer knows how many funds have been collected between lastUpdateTime and currentTime, and we want to figure out how many of those funds to allocate to the interval between lastUpdateTime and updateTime. The given formula is the correct allocation, if we assume that funds arrived at a uniform rate during the interval between lastUpdateTime and currentTime. The pricer similarly allocates a portion of the total data units to the current report.\n\nNow the pricer pays out the allocated funds to cover the rewards due and the amounts due to batch posters, reducing the balance due to each party as a result. If the allocated funds aren't sufficient to cover everything that is due, some amount due will remain. If all of the amount due can be covered with the allocated funds, any remaining allocated funds are returned to the L1PricerFundsPool.\n\nAdjusting the L1 gas basefee​\n\nAfter allocating funds and paying what is owed, the L1 Pricer adjusts the L1 Gas Basefee. The goal of this process is to find a value that will cause the amount collected to equal the amount owed over time.\n\nThe algorithm first computes the surplus (funds in the L1PricerFundsPool, minus total funds due), which might be negative. If the surplus is positive, the L1 Gas Basefee is reduced, so that the amount collected over a fixed future interval will be reduced by exactly the surplus. If the surplus is negative, the Basefee is increased so that the shortfall will be eliminated over the same fixed future interval.\n\nA second term is added to the L1 Gas Basefee, based on the derivative of the surplus (surplus at present, minus the surplus after the previous batch posting report was processed). This term, which is multiplied by a smoothing factor to reduce fluctuations, will reduce the Basefee if the surplus is increasing, and increase the Basefee if the surplus is shrinking.\n\nGetting L1 fee info​\n\nThe L1 gas basefee can be queried via ArbGasInfo.getL1BaseFeeEstimate. To estimate the L1 fee a transaction will use, the NodeInterface.gasEstimateComponents() or NodeInterface.gasEstimateL1Component() method can be used.\n\nArbitrum transaction receipts include a gasUsedForL1 field, showing the amount of gas used on L1 in units of L2 gas.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nL2 gas and fees\nNext\nDeep dive: Inside Arbitrum\nL1 fee collection\nL1 costs\nAllocating funds and paying what is owed\nAdjusting the L1 gas basefee\nGetting L1 fee info\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/arbitrum-vs-ethereum/comparison-overview",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nComparison overview\nBlock gas limit, numbers and time\nRPC methods\nSolidity support\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nDifferences between Arbitrum and Ethereum: Overview\n\nArbitrum is designed to be as compatible and consistent with Ethereum as possible, from its high-level RPCs to its low-level bytecode and everything in between. Decentralized app (dApp) developers with experience building on Ethereum will likely find that little-to-no new specific knowledge is required to build on Arbitrum.\n\nThis section describes the differences, perks, and gotchas that devs are advised to be aware of when working with Arbitrum. This first page serves as an overview of where you might find these differences, with links to the relevant pages when needed.\n\nBlock numbers and time​\n\nTime in L2s is tricky. The timing assumptions one is used to making about Ethereum blocks don't exactly carry over into the timing of Arbitrum blocks. See Block numbers and time for details about how block numbers and time are handled in Arbitrum.\n\nRPC methods​\n\nAlthough the majority of RPC methods follow the same behavior than in Ethereum, some methods might produce a different result, or add more information, when used on an Arbitrum chain. You can find more information about these differences in RPC methods.\n\nSolidity support​\n\nYou can deploy Solidity contracts onto Arbitrum just like you do Ethereum. There are only a few minor differences in behavior. Find more information about it in Solidity support.\n\nFees​\n\nThe fees an Arbitrum transaction pays for execution essentially work identically to gas fees on Ethereum. Arbitrum transactions must also, however, pay a fee component to cover the cost of posting their calldata to the parent chain (for example, calldata on Arbitrum One, an L2, is posted to Ethereum, an L1). Find more information about the two components of gas fees in Gas and fees and L1 pricing.\n\nCross-chain messaging​\n\nArbitrum chains support arbitrary message passing from a parent chain (for example, a Layer 1 (L1) like Ethereum) to a child chain (for example, a Layer 2 (L2) like Arbitrum One or Arbitrum Nova). These are commonly known as \"L1 to L2 messages\". Developers using this functionality should familiarize themselves with how they work. Find more information about it in L1 to L2 messaging.\n\nSimilarly, Arbitrum chains can also send messages to the parent chain. Find more information about them in L2 to L1 messaging and the outbox.\n\nPrecompiles​\n\nBesides supporting all precompiles available in Ethereum, Arbitrum provides L2-specific precompiles with methods smart contracts can call the same way they can solidity functions. You can find a full reference of them in Precompiles.\n\nNodeInterface​\n\nThe Arbitrum Nitro software includes a special NodeInterface contract available at address 0xc8 that is only accessible via RPCs (it's not actually deployed on-chain, and thus can't be called by smart contracts). Find more information about this interface in NodeInterface.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nCross-chain messaging\nNext\nBlock gas limit, numbers and time\nBlock numbers and time\nRPC methods\nSolidity support\nFees\nCross-chain messaging\nPrecompiles\nNodeInterface\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/how-tos/adding-support-for-new-languages",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nAdd a new smart contract language\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to add a new programming language to Stylus\n\nArbitrum Stylus is a new technology developed for Arbitrum chains which gives smart contract developers superpowers. With Stylus, developers can write EVM-compatible smart contracts in many different programming languages, and reap massive performance gains. Stylus slashes fees, with performance gains ranging from 10-70x, and memory efficiency gains as high as 100-500x.\n\nThis is possible thanks to WebAssembly technology, which all Stylus contracts compile to. Stylus smart contracts live under the same Ethereum state trie in Arbitrum nodes, and can fully interoperate with Solidity or Vyper EVM smart contracts. With Stylus, developers can write smart contracts in Rust that talk to Solidity and vice versa without any limitations.\n\nToday, the Stylus testnet also comes with 2 officially supported SDKs for developers to write contracts in the Rust or C programming languages.\n\nHowever, anyone can add support for new languages in Stylus. As long as a programming language can compile to WebAssembly, Stylus will let you use it to write EVM-compatible smart contracts. Note that in order to be deployed onchain, your compiled program must fit under the 24Kb brotli-compressed limit, and should meet Stylus gas metering requirements.\n\nIn this document, we go over how we added support for the up-and-coming Zig programming language, which is meant to be a spiritual successor to C that comes with great performance and memory safety within 20 lines of code.\n\nWhy Zig?\n\nZig contains memory safety guardrails, requiring developers to think hard about manual memory allocation in a prudent manner\nZig is a C equivalent language, and its tooling is also a C compiler. This means C projects can incrementally adopt Zig when refactoring\nZig is lightning fast and produces small binaries, making it suitable for blockchain applications\n\nPrograms written in Zig and deployed to Stylus have a tiny footprint and will have gas costs comparable, if not equal to, C programs.\n\nRequirements​\nDownload and install Zig 0.11.0\nInstall Rust, which we'll need for the Stylus CLI tool to deploy our program to the Stylus testnet\n\nWe'll also be using Rust to run an example script that can call our Zig contract on the Stylus testnet using the popular ethers-rs library.\n\nOnce Rust is installed, also install the Stylus CLI tool with\n\nRUSTFLAGS=\"-C link-args=-rdynamic\" cargo install --force cargo-stylus\n\nUsing Zig with Stylus​\n\nFirst, let's clone the repository:\n\ngit clone https://github.com/offchainlabs/zig-on-stylus && cd zig-on-stylus\n\n\nthen delete everything inside of main.zig. We'll be filling it out ourselves in this tutorial.\n\nTo support Stylus, your Zig programs need to define a special entrypoint function, which takes in the length of its input args, len, and returns a status code i32, which is either 0 or 1. We won't need the Zig standard library for this.\n\nOne more thing it needs is to use a special function, called memory_grow which can allocate memory for your program. This function is injected into all Stylus contracts as an external import. Internally, we call these vm_hooks, and also refer to them as host-io's, because they give you access to the host, EVM environment.\n\nGo ahead and replace everything in your main.zig function with:\n\npub extern \"vm_hooks\" fn memory_grow(len: u32) void;\n\nexport fn mark_unused() void {\n    memory_grow(0);\n    @panic(\"\");\n}\n\n// The main entrypoint to use for execution of the Stylus WASM program.\nexport fn user_entrypoint(len: usize) i32 {\n    _ = len;\n    return 0;\n}\n\n\nAt the top, we declare the memory_grow external function for use.\n\nNext, we can build our Zig library to a freestanding WASM file for our onchain deployment:\n\nzig build-lib ./src/main.zig -target wasm32-freestanding -dynamic --export=user_entrypoint -OReleaseSmall --export=mark_unused\n\n\nThis is enough for us to deploy on the Stylus testnet! We'll use the Stylus CLI tool, which you installed earlier using cargo install:\n\ncargo stylus deploy --private-key=<YOUR_TESTNET_PRIVKEY> --wasm-file-path=main.wasm\n\n\nThe tool will send two transactions: one to deploy your Zig contract's code onchain, and the other to activate it for usage.\n\nUncompressed WASM size: 112 B\nCompressed WASM size to be deployed onchain: 103 B\n\n\nYou can see that our Zig program is tiny when compiled to WASM. Next, we can call our contract to make sure it works using any of your favorite Ethereum tooling. In this example below, we use the cast CLI tool provided by foundry. The contract above has been deployed to the Stylus testnet at address 0xe0CD04EA8c148C9a5A58Fee1C895bc2cf6896799.\n\nexport ADDR=0xe0CD04EA8c148C9a5A58Fee1C895bc2cf6896799\ncast call --rpc-url 'https://stylus-testnet.arbitrum.io/rpc' $ADDR '0x'\n\n\nCalling the contract via RPC should simply return the value 0 as we programmed it to.\n\n0x\n\nReading input and writing output data​\n\nSmart contracts on Ethereum, at the bare minimum, can take in data and output data as bytes. Stylus contracts are no different, and to do anything useful, we need to be able to read from user input also write our output to the caller. To do this, the Stylus runtime provides all Stylus contracts with two additional, useful host-ios:\n\npub extern \"vm_hooks\" fn read_args(dest: *u8) void;\npub extern \"vm_hooks\" fn write_result(data: *const u8, len: usize) void;\n\n\nAdd these near the top of your main.zig file.\n\nThe first, read_args takes in a pointer to a byte slice where the input arguments will be written to. The length of this byte slice must equal the length of the program args received in the user_entrypoint. We can write a helper function that uses this vm hook and gives us a byte slice in Zig we can then operate on.\n\n// Allocates a Zig byte slice of length=`len` reads a Stylus contract's calldata\n// using the read_args hostio function.\npub fn input(len: usize) ![]u8 {\n    var input = try allocator.alloc(u8, len);\n    read_args(@ptrCast(*u8, input));\n    return input;\n}\n\n\nNext, we implement a helper function that outputs the data bytes to the Stylus contract's caller:\n\n// Outputs data as bytes via the write_result hostio to the Stylus contract's caller.\npub fn output(data: []u8) void {\n    write_result(@ptrCast(*u8, data), data.len);\n}\n\n\nLet's put these together:\n\n// The main entrypoint to use for execution of the Stylus WASM program.\n// It echoes the input arguments to the caller.\nexport fn user_entrypoint(len: usize) i32 {\n    var in = input(len) catch return 1;\n    output(in);\n    return 0;\n}\n\n\nWe're almost good to go, let's try to compile to WASM and deploy to the Stylus testnet. Let's run our build command again:\n\nsrc/main.zig:21:20: error: use of undeclared identifier 'allocator'\n    var data = try allocator.alloc(u8, len);\n                   ^~~~~~~~~\n\n\nOops! Looks like we need an allocator to do our job here. Zig, as a language, requires programmers to think carefully about memory allocation and it's a typical pattern to require them to manually provide an allocator. There are many to choose from, but the Zig standard library already has one built specifically for WASM programs. Memory in WASM programs grows in increments of 64Kb, and the allocator from the stdlib has us covered here.\n\nLet's try to use it by adding the following to the top of our main.zig\n\nconst std = @import(\"std\");\nconst allocator = std.heap.WasmAllocator;\n\n\nOur code compiles, but will it deploy onchain? Run cargo stylus check --wasm-file-path=main.wasm and see:\n\nCaused by:\n    missing import memory_grow\n\n\nWhat's wrong? This means that the WasmAllocator from the Zig standard library should actually be using our special memory_grow hostio function underneath the hood. We can fix this by copying over the WasmAllocator.zig file from the standard library, and modifying a single line to use memory_grow.\n\nYou can find this file under WasmAllocator.zig in the OffchainLabs/zig-on-stylus repository. We can now use it:\n\nconst std = @import(\"std\");\nconst WasmAllocator = @import(\"WasmAllocator.zig\");\n\n// Uses our custom WasmAllocator which is a simple modification over the wasm allocator\n// from the Zig standard library as of Zig 0.11.0.\npub const allocator = std.mem.Allocator{\n    .ptr = undefined,\n    .vtable = &WasmAllocator.vtable,\n};\n\n\nBuilding again and running cargo stylus check should now succeed:\n\nUncompressed WASM size: 514 B\nCompressed WASM size to be deployed onchain: 341 B\nConnecting to Stylus RPC endpoint: https://stylus-testnet.arbitrum.io/rpc\nStylus program with same WASM code is already activated onchain\n\n\nLet's deploy it:\n\ncargo stylus deploy --private-key=<YOUR_TESTNET_PRIVKEY> --wasm-file-path=main.wasm\n\n\nNow if we try to call it, it will output whatever input we send it, like an echo. Let's send it the input 0x123456:\n\nexport ADDR=0x20Aa65a9D3F077293993150C0345f62B50CCb549\ncast call --rpc-url 'https://stylus-testnet.arbitrum.io/rpc' $ADDR '0x123456'\n\n0x123456\n\n\nWorks!\n\nPrime number checker implementation​\n\nLet's build something a little bit fancier: this time we'll implement a primality checker in Zig using an ancient algorithm called the sieve of erathosthenes. Given a number, our contract will output 1 if it is prime, or 0 otherwise. We'll implement in a pretty naive way, but leverage one of Zig's awesome features: comptime.\n\nThe comptime keyword tells the Zig compiler to evaluate the code involved at compile time, allowing you to define computation that would normally make runtime more expensive and do it while your binary is being compiled! Comptime in Zig is extremely flexible. In this example, we use it to define a slice of booleans up to a certain limit at compile time, which we'll use to mark which numbers are prime or not.\n\nfn sieve_of_erathosthenes(comptime limit: usize, nth: u16) bool {\n    var prime = [_]bool{true} ** limit;\n    prime[0] = false;\n    prime[1] = false;\n    var i: usize = 2;\n    while (i * i < limit) : (i += 1) {\n        if (prime[i]) {\n            var j = i * i;\n            while (j < limit) : (j += i)\n                prime[j] = false;\n        }\n    }\n    return prime[nth];\n}\n\n\nChecking if a number N is prime would involve just checking if the value at index N in this prime boolean slice is true. We can then integrate this function into our user_entrypoint:\n\n// The main entrypoint to use for execution of the Stylus WASM program.\nexport fn user_entrypoint(len: usize) i32 {\n    // Expects the input is a u16 encoded as little endian bytes.\n    var input = args(len) catch return 1;\n    var check_nth_prime = std.mem.readIntSliceLittle(u16, input);\n    const limit: u16 = 10_000;\n    if (check_nth_prime > limit) {\n        @panic(\"input is greater than limit of 10,000 primes\");\n    }\n    // Checks if the number is prime and returns a boolean using the output function.\n    var is_prime = sieve_of_erathosthenes(limit, check_nth_prime);\n    var out = input[0..1];\n    if (is_prime) {\n        out[0] = 1;\n    } else {\n        out[0] = 0;\n    }\n    output(out);\n    return 0;\n}\n\n\nLet's check and deploy it:\n\nUncompressed WASM size: 10.8 KB\nCompressed WASM size to be deployed onchain: 525 B\n\n\nOur uncompressed size is big because of that giant array of booleans, but the program is highly compressible because all of them are zeros!\n\nAn instance of this program has been deployed to the Stylus testnet at address 0x0c503Bb757b1CaaD0140e8a2700333C0C9962FE4\n\nInteracting With Stylus contracts Using Ethers-rs​\n\nAn example is included in this repo under rust-example which uses the popular ethers-rs library to interact with our prime sieve contract on the Stylus testnet. To run it, do:\n\nexport STYLUS_PROGRAM_ADDRESS=0x0c503Bb757b1CaaD0140e8a2700333C0C9962FE4\ncargo run\n\n\n...and see:\n\nChecking if 2 is_prime = true, took: 404.146917ms\nChecking if 3 is_prime = true, took: 154.802083ms\nChecking if 4 is_prime = false, took: 123.239583ms\nChecking if 5 is_prime = true, took: 109.248709ms\nChecking if 6 is_prime = false, took: 113.086625ms\nChecking if 32 is_prime = false, took: 280.19975ms\nChecking if 53 is_prime = true, took: 123.667958ms\n\nNext steps​\n\nThe hostios defined in this walkthrough are not the only ones! Check out our stylus-sdk-c to see all the hostios you can use under hostio.h. These include affordances for the EVM, utilities to access storage, and utilities to call other Arbitrum smart contracts.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nOther language frameworks (non-Rust)\nNext\nTroubleshooting\nRequirements\nUsing Zig with Stylus\nReading input and writing output data\nPrime number checker implementation\nInteracting With Stylus contracts Using Ethers-rs\nNext steps\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/how-tos/verify-contracts",
    "html": "Skip to main content\nArbitrum Docs\nPage Not Found\n\nWe could not find what you were looking for.\n\nPlease contact the owner of the site that linked you to the original URL and let them know their link is broken.\n\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/how-tos/debug-stylus-transactions",
    "html": "Skip to main content\nArbitrum Docs\nPage Not Found\n\nWe could not find what you were looking for.\n\nPlease contact the owner of the site that linked you to the original URL and let them know their link is broken.\n\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to verify contracts for Stylus contracts | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/how-tos/verifying-contracts",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nCLI tools (cargo-stylus)\nCLI tools overview\nOptimize WASM binaries\nDebug Stylus transactions\nVerify contracts\ncargo-stylus repository\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nHow to verify contracts for Stylus contracts\nCAUTION\n\nThis page will walk you through how to verify your Stylus contracts locally. Stylus contract verification is also available on Arbiscan. Please note, however, that Stylus contract verification on Arbiscan is only supported for Stylus contracts deployed using cargo-stylus 0.5.0 or higher.\n\nBackground​\n\nStylus contracts written in Rust and deployed onchain can be verified against a local codebase by using the cargo stylus tool.\n\nGoals​\nTo ensure Stylus contract deployments are reproducible by anyone who is running the same architecture as the deployed item\nTo sandbox the reproducible environment and standardize it as much as possible to prevent foot guns\nTo guarantee that programs reproducibly deployed with a cargo stylus version >= 0.4.2 are verifiable\nOpting out​\n\nBy default, cargo stylus deploy is reproducible as it runs in a Docker container. Users can opt-out by specifying --no-verify as a flag.\n\nReproducible deployments​\n\nRequired knowledge and setup:\n\nSystem architecture of your host computer (x86 / ARM)\nThe git commit of your project used for deployment\nA Rust stylus project, such as OffchainLabs/stylus-hello-world which contains a rust-toolchain.toml file\nYour cargo stylus version (run cargo stylus --version to obtain this value)\nDocker installed and running on your machine\n\nYour project's toolchain file must contain the Rust version you wish to use for your deployment, such as major.minor.patch\n\n[toolchain]\nchannel = \"1.79.0\"\n\n\nIt cannot be stable, nightly, or beta by itself, as a specific version must be added. For instance, you can specify nightly-YYYY-MM-DD or major.minor.patch for your channel. This is so that deployments have a very specific version to prevent potential mismatches from being more generic.\n\n# Replace {PRIV_KEY} with your actual private key or set it as a local variable\ncargo stylus deploy --private-key={PRIV_KEY} --verbose\n\n\nUpon completion, you will obtain the deployment transaction hash:\n\ndeployment tx hash: 0x1d8ae97e245e1db21dd188e5b64ad9025c1fb4e5f82a8d38bc8ae2b7a387600b\n\n\nSave this tx hash, as verifiers will need it.\n\nReproducible verification​\n\nTo verify a program, the verifier will need Docker installed and also know:\n\nSystem architecture the deployer used (x86 / ARM). Note: ARM devices that can emulate x86, such as Mac M series via rosetta, can verify x86 Stylus deployments\nThe git commit of the project the deployer used\nYour cargo stylus version the deployer used\nThe deployment transaction hash\n\nNavigate to the project's directory and check out the git commit that was used at deployment. Ensure your cargo stylus --version matches what the deployer used.\n\n# Replace {DEPLOYMENT_TX_HASH} with the actual DEPLOYMENT_TX_HASH or set it as a local variable\ncargo stylus verify --deployment-tx={DEPLOYMENT_TX_HASH}\n\n\nThis command will run the verification pipeline through a Docker environment, recreate the project metadata hash, and verify that the deployed program matches what the command reconstructed locally.\n\nHow it works​\n\nOn deployment, a keccak256 hash is created from the contents of all Rust source files in the project, sorted by file path, along with a rust-toolchain.toml, Cargo.toml and Cargo.lock files by default. This hash is injected in as a custom section of the user wasm's code. This means all data in the source files will be used for reproducible verification of a Stylus contract, including code comments.\n\nThis means the codehash onchain of the program will change due to this deployment metadata hash.\n\nThe verification routine fetches the deployment transaction by hash via RPC, then attempts to build the local project to reconstruct the deployment init code and WASM using cargo build. It then checks that the deployment tx data matches the created init code.\n\nImportant details​\n\nDocker image The Docker container used for reproducibility standardizes all builds to x86, and it looks like this:\n\nFROM --platform=linux/amd64 rust:1.79 as builder\nRUN rustup toolchain install $VERSION-x86_64-unknown-linux-gnu\nRUN rustup default $VERSION-x86_64-unknown-linux-gnu\nRUN rustup target add wasm32-unknown-unknown\nRUN rustup target add wasm32-wasi\nRUN rustup target add x86_64-unknown-linux-gnu\nRUN cargo install cargo-stylus\n\n\nThe docker container uses the rust:1.79 version as a base for all projects. This will install cargo tooling and rust targets, but the toolchain actually used for compilation will be specified by the project being deployed in its rust-toolchain.toml file.\n\nFor instance, a future toolchain can be used despite the base image being 1.79, as when cargo stylus is installed, it will use that particular toolchain. Future cargo stylus updates could update this base image but may not impact the compiled WASM as the image will be using the specified toolchain. However, this is why knowing the specific cargo stylus version used for the reproducible verification from the deployer is important.\n\nThe build toolchain\n\nAll verifiable Stylus contracts in Rust must have a standard rust-toolchain.toml file which specifies the channel for their deployment. It cannot be stable, nightly, or beta by itself, as a specific version must be added. For instance, you can specify nightly-YYYY-MM-DD or major.minor.patch for your channel. This is so that deployments have a very specific version to prevent potential mismatches from being more generic.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nDebug Stylus transactions\nNext\nOther language frameworks (non-Rust)\nBackground\nGoals\nOpting out\nReproducible deployments\nReproducible verification\nHow it works\nImportant details\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/how-tos/debugging-stylus-tx",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nCLI tools (cargo-stylus)\nCLI tools overview\nOptimize WASM binaries\nDebug Stylus transactions\nVerify contracts\ncargo-stylus repository\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to debug Stylus transactions using Cargo Stylus Replay\n\nDebugging smart contracts can be challenging, especially when dealing with complex transactions. The cargo-stylus crate simplifies the debugging process by allowing developers to replay Stylus transactions. This tool leverages GDB to provide an interactive debugging experience, enabling developers to set breakpoints, inspect state changes, and trace the execution flow step-by-step. This capability is crucial for identifying and resolving issues, ensuring that smart contracts function correctly and efficiently.\n\nOverview​\n\nCargo Stylus is a tool designed to simplify the development and debugging process for smart contracts written in Rust for the Stylus execution environment. One of its powerful features is the cargo stylus subcommand, which provides essential functionalities for developers:\n\nTrace transactions: Perform trace calls against Stylus transactions using Ethereum nodes' debug_traceTransaction RPC. This feature enables developers to analyze the execution flow and state changes of their transactions in a detailed manner.\nDebugging with GDB or LLDB: Replay and debug the execution of a Stylus transaction using a debugger. This allows developers to set breakpoints, inspect variables, and step through the transaction execution line by line, providing an in-depth understanding of the transaction's behavior.\nReplaying transactions​\nRequirements​\nRust (version 1.77 or higher)\nCrate: cargo-stylus\nGNU Debugger (GDB) (Linux) or LLDB (MacOS)\nCast (an Ethereum CLI tool)\nArbitrum RPC Provider with tracing endpoints enabled or a local Stylus dev node\n\ncargo stylus replay allows users to debug the execution of a Stylus transaction using GDB or LLDB against the Rust source code.\n\nInstallation and setup​\nInstall the required crates and debugger: First, let's ensure that the following crates are installed:\ncargo install cargo-stylus\n\n\nIf on Linux, install GDB if it's not already installed:\n\nsudo apt-get install gdb\n\n\nIf on MacOS, install LLDB if it's not already installed:\n\nxcode-select --install\n\nDeploy your Stylus contract: For this guide, we demonstrate how to debug the execution of the increment() method in the stylus-hello-world smart contract. In Rust, it looks something like this, within src/lib.rs:\n#[external]\nimpl Counter {\n    ...\n    /// Increments number and updates its value in storage.\n    pub fn increment(&mut self) {\n        let number = self.number.get();\n        self.set_number(number + U256::from(1));\n    }\n    ...\n}\n\n\nSet your RPC endpoint to a node with tracing enabled and your private key:\n\nexport RPC_URL=...\nexport PRIV_KEY=...\n\n\nand deploy your contract:\n\ncargo stylus deploy --private-key=$PRIV_KEY --endpoint=$RPC_URL\n\n\nYou should see an output similar to:\n\ncontract size: 4.0 KB\nwasm size: 12.1 KB\ncontract size: 4.0 KB\ndeployed code at address: 0x2c8d8a1229252b07e73b35774ad91c0b973ecf71\nwasm already activated!\n\nSend a transaction: First, set the address of the deployed contract as an environment variable:\nexport ADDR=0x2c8d8a1229252b07e73b35774ad91c0b973ecf71\n\n\nAnd send a transaction using Cast:\n\ncast send --rpc-url=$RPC_URL --private-key=$PRIV_KEY $ADDR \"increment()\"\n\nReplay the transaction with the debugger: Now, we can replay the transaction with cargo stylus and the debugger to inspect each step of it against our source code. Make sure GDB is installed and that you are on a Linux, x86 system. Also, you should set the transaction hash as an environment variable:\nexport TX_HASH=0x18b241841fa0a59e02d3c6d693750ff0080ad792204aac7e5d4ce9e20c466835\n\n\nAnd replay the transaction:\n\ncargo stylus replay --tx=$TX_HASH --endpoint=$RPC_URL --use-native-tracer\n\n\nOptions:\n\n--tx: Specifies the transaction hash to replay.\n--endpoint: Specifies the RPC endpoint for fetching transaction data.\n--use-native-tracer: Uses the native Stylus tracer instead of the default JS tracer. The native tracer has broader support from RPC providers.\n\n\nNote: The --use-native-tracer flag uses stylusTracer instead of jsTracer, which is required for tracing Stylus transactions on most RPC providers. See more details below.\n\nThe debugger will load and set a breakpoint automatically at the user_entrypoint internal Stylus function. While the examples below showcase GDB commands, you can find the LLDB equivalents here.\n\n[Detaching after vfork from child process 370003]\n\nThread 1 \"cargo-stylus\" hit Breakpoint 1, stylus_hello_world::user_entrypoint (len=4) at src/lib.rs:38\n38\t    #[entrypoint]\n(gdb)\n\nDebugging: Now, set a breakpoint at the increment() method:\n(gdb) b stylus_hello_world::Counter::increment\nBreakpoint 2 at 0x7ffff7e4ee33: file src/lib.rs, line 69.\n\n\nThen, type c to continue the execution and you will reach that line where increment is called:\n\n(gdb) c\n\n\nOnce you reach the increment method, inspect the state:\n\nThread 1 \"cargo-stylus\" hit Breakpoint 2, stylus_hello_world::Counter::increment (self=0x7fffffff9ae8) at src/lib.rs:69\n69\t        let number = self.number.get();\n(gdb) p number\n\nTrace a transaction​\n\nFor traditional tracing, cargo stylus supports calls to debug_traceTransaction. To trace a transaction, you can use the following command:\n\ncargo stylus trace [OPTIONS] --tx <TX> --use-native-tracer\n\n\nOptions:\n\n  -e, --endpoint <ENDPOINT>  RPC endpoint [default: http://localhost:8547]\n  -t, --tx <TX>              Tx to replay\n  -p, --project <PROJECT>    Project path [default: .]\n  -h, --help                 Print help\n  -V, --version              Print version\n      --use-native-tracer    Uses the native Stylus tracer instead of the default JS tracer. The native tracer has broader support from RPC providers.\n\n\nRun the following command to obtain a trace output:\n\ncargo stylus trace --tx=$TX_HASH --endpoint=$RPC_URL --use-native-tracer\n\n\nThis will produce a trace of the functions called and ink left along each method:\n\n[{\"args\":[0,0,0,4],\"endInk\":846200000,\"name\":\"user_entrypoint\",\"outs\":[],\"startInk\":846200000},{\"args\":[],\"endInk\":846167558,\"name\":\"msg_reentrant\",\"outs\":[0,0,0,0],\"startInk\":846175958},{\"args\":[],\"endInk\":846047922,\"name\":\"read_args\",\"outs\":[208,157,224,138],\"startInk\":846061362},{\"args\":[],\"endInk\":845914924,\"name\":\"msg_value\",\"outs\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"startInk\":845928364},{\"args\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"endInk\":227196069,\"name\":\"storage_load_bytes32\",\"outs\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],\"startInk\":844944549},{\"args\":[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1],\"endInk\":226716083,\"name\":\"storage_cache_bytes32\",\"outs\":[],\"startInk\":226734563},{\"args\":[0],\"endInk\":226418732,\"name\":\"storage_flush_cache\",\"outs\":[],\"startInk\":226486805},{\"args\":[],\"endInk\":226362319,\"name\":\"write_result\",\"outs\":[],\"startInk\":226403481},{\"args\":[],\"endInk\":846200000,\"name\":\"user_returned\",\"outs\":[0,0,0,0],\"startInk\":846200000}]\n\nRPC endpoint compatibility​\n\nBoth cargo stylus trace and cargo stylus replay require an RPC endpoint that supports debug_traceTransaction. By default, the jsTracer type is used, which is not supported by most RPC providers. If the --use-native-tracer flag is used, the stylusTracer type is used, which is supported by many RPC providers. Both jsTracer and stylusTracer are available on local nodes, but stylusTracer is more efficient. See this list of RPC providers for tracing support.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nOptimize WASM binaries\nNext\nVerify contracts\nOverview\nReplaying transactions\nInstallation and setup\nTrace a transaction\nRPC endpoint compatibility\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to optimize Stylus WASM binaries | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/how-tos/optimizing-binaries",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nCLI tools (cargo-stylus)\nCLI tools overview\nOptimize WASM binaries\nDebug Stylus transactions\nVerify contracts\ncargo-stylus repository\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to optimize Stylus WASM binaries\n\nTo be deployed onchain, the size of your uncompressed WebAssembly (WASM) file must not exceed 128Kb, while the compressed binary must not exceed 24KB. Stylus conforms with the same contract size limit as the EVM to remain fully interoperable with all smart contracts on Arbitrum chains.\n\ncargo-stylus, the Stylus CLI tool, automatically compresses your WASM programs, but there are additional steps that you can take to further reduce the size of your binaries.\n\nYour options fall into two categories: Rust compiler flags, and third-party optimization tools.\n\nRust compiler flags​\n\nThe Rust compiler supports various config options for shrinking binary sizes.\n\nCargo.toml​\n[profile.release]\ncodegen-units = 1        # prefer efficiency to compile time\npanic = \"abort\"          # use simple panics\nopt-level = \"z\"          # optimize for size (\"s\" may also work)\nstrip = true             # remove debug info\nlto = true               # link time optimization\ndebug = false            # no debug data\nrpath = false            # no run-time search path\ndebug-assertions = false # prune debug assertions\nincremental = false      # no incremental builds\n\nThird-party optimization tooling​\n\nAdditional WASM-specific tooling exists to shrink binaries. Due to being 3rd party, users should use these at their own risk.\n\nwasm-opt​\n\nwasm-opt applies techniques to further reduce binary size, usually netting around 10%.\n\ntwiggy​\n\ntwiggy is a code size profiler for WASM, it can help you estimate the impact of each added component on your binaries' size.\n\nOur team has also curated a list of recommended libraries that are helpful to Stylus development and optimally sized.\n\nFrequently asked questions​\n\nWill future releases of Stylus introduce additional optimizations?\n\nYes! We're actively working on improving WASM sizes generated by Rust code with the Stylus SDK.\n\nWhy don't I have to worry about this type of optimization when I use cargo without using Stylus?\n\nOn modern platforms, tools like cargo don’t have to worry about the size of the binaries they produce. This is because there’s many orders of magnitude more storage available than even the largest of binaries, and for most applications it’s media like images and videos that constitutes the majority of the footprint.\n\nResource constraints when building on blockchains are extremely strict. Hence, while not the default option, tooling often provides mechanisms for reducing binary bloat, such as the options outlined in this document.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nCLI tools overview\nNext\nDebug Stylus transactions\nRust compiler flags\nCargo.toml\nThird-party optimization tooling\nwasm-opt\ntwiggy\nFrequently asked questions\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Stylus caching strategy | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/concepts/stylus-cache-manager",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nOverview\nGas and ink costs\nCaching strategy\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nStylus caching strategy\n\nStylus is designed for fast computation and efficiency. However, the initialization process when entering a contract can be resource-intensive and time-consuming.\n\nThis initialization process, if repeated frequently, may lead to inefficiencies. To address this, we have implemented a caching strategy. By storing frequently accessed contracts in memory, we can avoid repeated initializations. This approach saves resources and time, significantly enhancing the speed and efficiency of contract execution.\n\nNote that Stylus smart contracts will need to be re-activated once per year (365 days) or whenever a upgrade to Stylus (which will always involve an ArbOS upgrade), even if they are in the cache. This re-activation can be done using cargo-stylus, a cargo subcommand for building, verifying, and deploying Arbitrum Stylus WASM contracts in Rust.\n\nCacheManager contract​\n\nThe core component of our caching strategy is the CacheManager contract. This smart contract manages the cache, interacts with precompiles, and determines which contracts should be cached. The CacheManager can hold approximately 4,000 contracts in memory.\n\nThe CacheManager defines how contracts remain in the cache and how they compete with other contracts for cache space. Its primary purpose is to reduce high initialization costs, ensuring efficient contract activation and usage. The contract includes methods for adding and removing cache entries, querying the status of cached contracts, and managing the lifecycle of cached data.\n\nKey features​\n\nThe CacheManager plays a crucial role in our caching strategy by keeping a specific set of contracts in memory rather than retrieving them from disk. This significantly reduces the activation time for frequently accessed contracts. The CacheManager contract is an on-chain contract that accepts bids for inserting contract code into the cache. It then calls a precompile that loads or unloads the contracts in the ArbOS cache, which follows the on-chain cache but operates locally in the client and marks the contract as in or out of the cache in the ArbOS state.\n\nThe cache operates through an auction system where dApp developers submit bids to insert their contracts into the cache. If the cache is at capacity, lower bids are evicted to make space for higher bids. The cache maintains a minimum heap of bids for codeHashes, with bids encoded as bid << 64 + index, where index represents the position in the list of all bids. When an insertion exceeds the cache's maximum size, items are popped off the minimum heap and deleted until there is enough space to insert the new item. Contracts with equal bids will be popped in a random order, while the smallest bid is evicted first.\n\nTo ensure that developers periodically pay to maintain their position in the cache, we use a global decay parameter computed by decay = block.timestamp * _decay. This inflates the value of bids over time, making newer bids more valuable.\n\nCache access and costs​\n\nDuring activation, we compute the contract's initialization costs for both non-cached and cached initialization. These costs take into account factors such as the number of functions, types, code size, data length, and memory usage. It's important to note that accessing an uncached contract does not automatically add it to the CacheManager's cache. Only explicit calls to the CacheManager contract will add a contract to the cache. If a contract is removed from the cache, calling the contract becomes more expensive unless it is re-added.\n\nTo see how much gas contract initialization would cost, you need to call programInitGas(address) from the ArbWasm precompile. This function returns both the initialization cost when the contract is cached and when it is not.\n\nHow to use the CacheManager API​\n\nThis section provides a practical guide for interacting with the CacheManager contract API, either directly or through the cargo stylus command-line tool.\n\nStep 1: Determine the minimum bid​\n\nBefore placing a bid, it's important to know the minimum bid required to cache the Stylys contract. This can be done using the getMinBid function, or using the cargo stylus cache suggest-bid command.\n\nMethod 1: Direct smart contract call\n\nuint192 minBid = cacheManager.getMinBid(contractAddress);\n\n\nMethod 2: Cargo stylus command\n\nNote that here, [contractAddress] is the address of the Stylus contract you want to cache.\n\ncargo stylus cache suggest-bid [contractAddress]\n\nStep 2: Place a bid​\n\nYou can place a bid using either of the following methods:\n\nMethod 1: Direct smart contract call\n\nHere, bidAmount is the amount you want to bid, and contractAddress is the address of the Stylus contract you're bidding for.\n\ncacheManager.placeBid{value: bidAmount}(contractAddress);\n\n\nMethod 2: Cargo stylus command\n\nYou can place a bid using the cargo stylus cache bid command:\n\ncargo stylus cache bid <--private-key-path <PRIVATE_KEY_PATH>|--private-key <PRIVATE_KEY>|--keystore-path <KEYSTORE_PATH>> [contractAddress] [bidAmount]\n\n[contractAddress]: The address of the Stylus contract you want to cache.\n[bidAmount]: The amount you want to bid. If not specified, the default bid is 0.\n\nIf you specify a bid amount using cargo stylus, it will automatically validate that the bid is greater than or equal to the result of the getMinBid function. If the bid is insufficient, the command will fail, ensuring that only valid bids are placed.\n\nStep 3: Check cache status​\n\nTo check if a specific address is cached, you can use the cargo stylus status command:\n\ncargo stylus cache status --address=[contractAddress]\n\nAdditional information​\nPausing Bids: The CacheManager contract has an isPaused state that can be toggled by the owner to prevent or allow new bids.\nChecking Cache Size: You can monitor the current cache size and decay rate using the getCacheSize and getDecayRate functions respectively.\n\nBy following these steps, you can effectively interact with the CacheManager contract, either directly through smart contract calls or using the cargo stylus command-line tool. This ensures that your bids meet the necessary requirements for caching programs on the network, optimizing your contracts for faster and more efficient execution.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nGas and ink costs\nNext\nCLI tools overview\nCacheManager contract\nKey features\nCache access and costs\nHow to use the CacheManager API\nStep 1: Determine the minimum bid\nStep 2: Place a bid\nStep 3: Check cache status\nAdditional information\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/reference/opcode-hostio-pricing",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nOverview\nGas and ink costs\nCaching strategy\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nGas and ink costs\n\nThis reference provides the latest gas and ink costs for specific WASM opcodes and host I/Os when using Stylus. For a conceptual introduction to Stylus gas and ink, see Gas and ink (Stylus).\n\nOpcode costs​\n\nThe Stylus VM charges for WASM opcodes according to the following table, which was determined via a conservative statistical analysis and is expected to change as Stylus matures. Prices may fluctuate across upgrades as our analysis evolves and optimizations are made.\n\nHex\tOpcode\tInk\tGas\tNotes\n0x00\tUnreachable\t1\t0.0001\t\n0x01\tNop\t1\t0.0001\t\n0x02\tBlock\t1\t0.0001\t\n0x03\tLoop\t1\t0.0001\t\n0x04\tIf\t765\t0.0765\t\n0x05\tElse\t1\t0.0001\t\n0x0b\tEnd\t1\t0.0001\t\n0x0c\tBr\t765\t0.0765\t\n0x0d\tBrIf\t765\t0.0765\t\n0x0e\tBrTable\t2400 + 325x\t0.24 + 0.0325x\tCost varies with table size\n0x0f\tReturn\t1\t0.0001\t\n0x10\tCall\t3800\t0.38\t\n0x11\tCallIndirect\t13610 + 650x\t1.361 + 0.065x\tCost varies with no. of args\n0x1a\tDrop\t9\t0.0009\t\n0x1b\tSelect\t1250\t0.125\t\n0x20\tLocalGet\t75\t0.0075\t\n0x21\tLocalSet\t210\t0.0210\t\n0x22\tLocalTee\t75\t0.0075\t\n0x23\tGlobalGet\t225\t0.0225\t\n0x24\tGlobalSet\t575\t0.0575\t\n0x28\tI32Load\t670\t0.067\t\n0x29\tI64Load\t680\t0.068\t\n0x2c\tI32Load8S\t670\t0.067\t\n0x2d\tI32Load8U\t670\t0.067\t\n0x2e\tI32Load16S\t670\t0.067\t\n0x2f\tI32Load16U\t670\t0.067\t\n0x30\tI64Load8S\t680\t0.068\t\n0x31\tI64Load8U\t680\t0.068\t\n0x32\tI64Load16S\t680\t0.068\t\n0x33\tI64Load16U\t680\t0.068\t\n0x34\tI64Load32S\t680\t0.068\t\n0x35\tI64Load32U\t680\t0.068\t\n0x36\tI32Store\t825\t0.0825\t\n0x37\tI64Store\t950\t0.095\t\n0x3a\tI32Store8\t825\t0.0825\t\n0x3b\tI32Store16\t825\t0.0825\t\n0x3c\tI64Store8\t950\t0.095\t\n0x3d\tI64Store16\t950\t0.095\t\n0x3e\tI64Store32\t950\t0.095\t\n0x3f\tMemorySize\t3000\t0.3\t\n0x40\tMemoryGrow\t8050\t0.805\t\n0x41\tI32Const\t1\t0.0001\t\n0x42\tI64Const\t1\t0.0001\t\n0x45\tI32Eqz\t170\t0.017\t\n0x46\tI32Eq\t170\t0.017\t\n0x47\tI32Ne\t170\t0.017\t\n0x48\tI32LtS\t170\t0.017\t\n0x49\tI32LtU\t170\t0.017\t\n0x4a\tI32GtS\t170\t0.017\t\n0x4b\tI32GtU\t170\t0.017\t\n0x4c\tI32LeS\t170\t0.017\t\n0x4d\tI32LeU\t170\t0.017\t\n0x4e\tI32GeS\t170\t0.017\t\n0x4f\tI32GeU\t170\t0.017\t\n0x50\tI64Eqz\t225\t0.0225\t\n0x51\tI64Eq\t225\t0.0225\t\n0x52\tI64Ne\t225\t0.0225\t\n0x53\tI64LtS\t225\t0.0225\t\n0x54\tI64LtU\t225\t0.0225\t\n0x55\tI64GtS\t225\t0.0225\t\n0x56\tI64GtU\t225\t0.0225\t\n0x57\tI64LeS\t225\t0.0225\t\n0x58\tI64LeU\t225\t0.0225\t\n0x59\tI64GeS\t225\t0.0225\t\n0x5a\tI64GeU\t225\t0.0225\t\n0x67\tI32Clz\t210\t0.021\t\n0x68\tI32Ctz\t210\t0.021\t\n0x69\tI32Popcnt\t2650\t0.265\t\n0x6a\tI32Add\t70\t0.007\t\n0x6b\tI32Sub\t70\t0.007\t\n0x6c\tI32Mul\t160\t0.016\t\n0x6d\tI32DivS\t1120\t0.112\t\n0x6e\tI32DivU\t1120\t0.112\t\n0x6f\tI32RemS\t1120\t0.112\t\n0x70\tI32RemU\t1120\t0.112\t\n0x71\tI32And\t70\t0.007\t\n0x72\tI32Or\t70\t0.007\t\n0x73\tI32Xor\t70\t0.007\t\n0x74\tI32Shl\t70\t0.007\t\n0x75\tI32ShrS\t70\t0.007\t\n0x76\tI32ShrU\t70\t0.007\t\n0x77\tI32Rotl\t70\t0.007\t\n0x78\tI32Rotr\t70\t0.007\t\n0x79\tI64Clz\t210\t0.021\t\n0x7a\tI64Ctz\t210\t0.012\t\n0x7b\tI64Popcnt\t6000\t0.6\t\n0x7c\tI64Add\t100\t0.01\t\n0x7d\tI64Sub\t100\t0.01\t\n0x7e\tI64Mul\t160\t0.016\t\n0x7f\tI64DivS\t1270\t0.127\t\n0x80\tI64DivU\t1270\t0.127\t\n0x81\tI64RemS\t1270\t0.127\t\n0x82\tI64RemU\t1270\t0.127\t\n0x83\tI64And\t100\t0.01\t\n0x84\tI64Or\t100\t0.01\t\n0x85\tI64Xor\t100\t0.01\t\n0x86\tI64Shl\t100\t0.01\t\n0x87\tI64ShrS\t100\t0.01\t\n0x88\tI64ShrU\t100\t0.01\t\n0x89\tI64Rotl\t100\t0.01\t\n0x8a\tI64Rotr\t100\t0.01\t\n0xa7\tI32WrapI64\t100\t0.01\t\n0xac\tI64ExtendI32S\t100\t0.01\t\n0xad\tI64ExtendI32U\t100\t0.01\t\n0xc0\tI32Extend8S\t100\t0.01\t\n0xc1\tI32Extend16S\t100\t0.01\t\n0xc2\tI64Extend8S\t100\t0.01\t\n0xc3\tI64Extend16S\t100\t0.01\t\n0xc4\tI64Extend32S\t100\t0.01\t\n0xfc0a\tMemoryCopy\t950 + 100x\t0.095 + 0.01x\tCost varies with no. of bytes\n0xfc0b\tMemoryFill\t950 + 100x\t0.095 + 0.01x\tCost varies with no. of bytes\nHost I/O costs​\n\nCertain operations require suspending WASM execution so that the Stylus VM can perform tasks natively in the host. This costs about 0.84 gas to do. Though we’ll publish a full specification later, the following table details the costs of simple operations that run in the host.\n\nNote that the values in this table were determined via a conservative statistical analysis and are expected to change as Stylus matures. Prices may fluctuate across upgrades as our analysis evolves and optimizations are made.\n\nHost I/O\tInk\tGas\tNotes\nread_args\t8400 + 5040b\t0.84 + 0.504b\tb = bytes after first 32\nwrite_result\t8400 + 16381b\t0.84 + 1.6381b\tb = bytes after first 32\nkeccak\t121800 + 21000w\t12.18 + 2.1w\tw = EVM words\nblock_basefee\t13440\t1.344\t\nblock_coinbase\t13440\t1.344\t\nblock_gas_limit\t8400\t0.84\t\nblock_number\t8400\t0.84\t\nblock_timestmap\t8400\t0.84\t\nchain_id\t8400\t0.84\t\ncontract_address\t13440\t1.344\t\nevm_gas_left\t8400\t0.84\t\nevm_ink_left\t8400\t0.84\t\nmsg_reentrant\t8400\t0.84\t\nmsg_sender\t13440\t1.344\t\nmsg_value\t13440\t1.344\t\nreturn_data_size\t8400\t0.84\t\ntx_ink_price\t8400\t0.84\t\ntx_gas_price\t13440\t1.344\t\ntx_origin\t13440\t1.344\t\nconsole_log_text\t0\t0\tdebug-only\nconsole_log\t0\t0\tdebug-only\nconsole_tee\t0\t0\tdebug-only\nnull_host\t0\t0\tdebug-only\nSee also​\nGas and ink (Stylus): A conceptual introduction to the \"gas\" and \"ink\" primitives\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nOverview\nNext\nCaching strategy\nOpcode costs\nHost I/O costs\nSee also\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/recommended-libraries",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nRecommended libraries\nUsing public Rust crates​\n\nRust provides a package registry at crates.io, which lets developers conveniently access a plethora of open source libraries to utilize as dependencies in their code. Stylus Rust contracts can take advantage of these crates to simplify their development workflow.\n\nWhile crates.io is a fantastic resource, many of these libraries were not designed with the constraints of a blockchain environment in mind. Some produce large binaries that exceed the 24KB compressed size limit of WASM smart contracts on Arbitrum. Many also take advantage of unsupported features such as:\n\nRandom numbers\nMulti threading\nFloating point numbers and operations\n\nUsing the standard Rust library often bloats contract sizes beyond the maximum size. For this reason, libraries designated as no_std are typically much stronger candidates for usage as a smart contract dependency. crates.io has a special tag for marking crates as no_std; however, it's not universally used. Still, it can be a good starting point for locating supported libraries. See \"No standard library\" crates for more details.\n\nCurated crates​\n\nTo save developers time on smart contract development for common dependencies, we've curated a list of crates and utilities that we found helpful. Keep in mind that we have not audited this code, and you should always be mindful about pulling dependencies into your codebase, whether they've been audited or not. We provide this list for you to use at your discretion and risk.\n\nrust_decimal: Decimal number implementation written in pure Rust. Suitable for financial and fixed-precision calculations\nspecial: The package provides special functions, which are mathematical functions with special names due to their common usage, such as sin, ln, tan, etc.\nhashbrown: Rust port of Google's SwissTable hash map\ntime: Date and time library\nhex: Encoding and decoding data into/from hexadecimal representation\n\nWe'll be adding more libraries to this list as we find them. Feel free to suggest an edit if you know of any great crates that would be generally useful here.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nBytes In Bytes Out\nNext\nAdvanced features\nUsing public Rust crates\nCurated crates\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/bytes_in_bytes_out",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nBytes In, Bytes Out\n\nThis is a simple bytes in, bytes out contract that shows a minimal entrypoint function (denoted by the #[entrypoint] proc macro). If your smart contract just has one primary function, like computing a cryptographic hash, this can be a great model because it strips out the SDK and acts like a pure function or Unix-style app.\n\nsrc/main.rs​\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\n#![cfg_attr(not(feature = \"export-abi\"), no_main)]\n\nextern crate alloc;\nuse alloc::vec::Vec;\n\nuse stylus_sdk::stylus_proc::entrypoint;\n\n#[entrypoint]\nfn user_main(input: Vec<u8>) -> Result<Vec<u8>, Vec<u8>> {\n    Ok(input)\n}\n\nCargo.toml​\n[package]\nname = \"bytes_in_bytes_out\"\nversion = \"0.1.7\"\nedition = \"2021\"\n\n[dependencies]\nstylus-sdk = \"0.6.0\"\n\n[features]\nexport-abi = [\"stylus-sdk/export-abi\"]\n\n[profile.release]\ncodegen-units = 1\nstrip = true\nlto = true\npanic = \"abort\"\nopt-level = \"s\"\n\n[workspace]\n\nEdit this page\nPrevious\nHashing\nNext\nRecommended libraries\nsrc/main.rs\nCargo.toml\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Hasing with keccak256 • Stylus by Example | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/hashing",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHasing with keccak256 • Stylus by Example\nHashing with keccak256​\n\nKeccak256 is a cryptographic hash function that takes an input of an arbitrary length and produces a fixed-length output of 256 bits.\n\nKeccak256 is a member of the SHA-3 family of hash functions.\n\nkeccak256 computes the Keccak-256 hash of the input.\n\nSome use cases are:\n\nCreating a deterministic unique ID from a input\nCommit-Reveal scheme\nCompact cryptographic signature (by signing the hash instead of a larger input)\n\nHere we will use stylus-sdk::crypto::keccak to calculate the keccak256 hash of the input data:\n\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\npub fn keccak<T: AsRef<[u8]>>(bytes: T) -> B256\n\nFull Example code:\nsrc/main.rs​\n// Only run this as a WASM if the export-abi feature is not set.\n#![cfg_attr(not(any(feature = \"export-abi\", test)), no_main)]\nextern crate alloc;\n\n/// Import items from the SDK. The prelude contains common traits and macros.\nuse stylus_sdk::{alloy_primitives::{U256, Address, FixedBytes}, abi::Bytes, prelude::*, crypto::keccak};\nuse alloc::string::String;\nuse alloc::vec::Vec;\n// Becauce the naming of alloy_primitives and alloy_sol_types is the same, so we need to re-name the types in alloy_sol_types\nuse alloy_sol_types::{sol_data::{Address as SOLAddress, String as SOLString, Bytes as SOLBytes, *}, SolType};\nuse alloy_sol_types::sol;\n\n// Define error\nsol! {\n    error DecodedFailed();\n}\n\n// Error types for the MultiSig contract\n#[derive(SolidityError)]\npub enum HasherError{\n    DecodedFailed(DecodedFailed)\n}\n\n#[solidity_storage]\n#[entrypoint]\npub struct Hasher {\n}\n/// Declare that `Hasher` is a contract with the following external methods.\n#[public]\nimpl Hasher {\n    \n    // Encode the data and hash it\n    pub fn encode_and_hash(\n        &self, \n        target: Address,\n        value: U256,\n        func: String,\n        data: Bytes,\n        timestamp: U256\n    ) -> FixedBytes<32> {\n        // define sol types tuple\n        type TxIdHashType = (SOLAddress, Uint<256>, SOLString, SOLBytes, Uint<256>);\n        // set the tuple\n        let tx_hash_data = (target, value, func, data, timestamp);\n        // encode the tuple\n        let tx_hash_data_encode = TxIdHashType::abi_encode_sequence(&tx_hash_data);\n        // hash the encoded data\n        keccak(tx_hash_data_encode).into()\n    }\n\n    // This should always return true\n    pub fn encode_and_decode(\n        &self, \n        address: Address, \n        amount: U256\n    ) -> Result<bool, HasherError> {\n        // define sol types tuple\n        type TxIdHashType = (SOLAddress, Uint<256>);\n        // set the tuple\n        let tx_hash_data = (address, amount);\n        // encode the tuple\n        let tx_hash_data_encode = TxIdHashType::abi_encode_sequence(&tx_hash_data);\n\n        let validate = true;\n        \n        // Check the result\n        match TxIdHashType::abi_decode_sequence(&tx_hash_data_encode, validate) {\n            Ok(res) => Ok(res == tx_hash_data),\n            Err(_) => {\n                return Err(HasherError::DecodedFailed(DecodedFailed{}));\n            },\n        }   \n    }\n        \n    // Packed encode the data and hash it, the same result with the following one\n    pub fn packed_encode_and_hash_1(\n        &self, \n        target: Address,\n        value: U256,\n        func: String,\n        data: Bytes,\n        timestamp: U256\n    )-> FixedBytes<32> {\n        // define sol types tuple\n        type TxIdHashType = (SOLAddress, Uint<256>, SOLString, SOLBytes, Uint<256>);\n        // set the tuple\n        let tx_hash_data = (target, value, func, data, timestamp);\n        // encode the tuple\n        let tx_hash_data_encode_packed = TxIdHashType::abi_encode_packed(&tx_hash_data);\n        // hash the encoded data\n        keccak(tx_hash_data_encode_packed).into()\n    }\n\n    // Packed encode the data and hash it, the same result with the above one\n    pub fn packed_encode_and_hash_2(\n        &self, \n        target: Address,\n        value: U256,\n        func: String,\n        data: Bytes,\n        timestamp: U256\n    )-> FixedBytes<32> {\n        // set the data to arrary and concat it directly\n        let tx_hash_data_encode_packed = [&target.to_vec(), &value.to_be_bytes_vec(), func.as_bytes(), &data.to_vec(), &timestamp.to_be_bytes_vec()].concat();\n        // hash the encoded data\n        keccak(tx_hash_data_encode_packed).into()\n    }\n\n\n    // The func example: \"transfer(address,uint256)\"\n    pub fn encode_with_signature(\n        &self, \n        func: String, \n        address: Address, \n        amount: U256\n    ) -> Vec<u8> {\n        type TransferType = (SOLAddress, Uint<256>);\n        let tx_data = (address, amount);\n        let data = TransferType::abi_encode_sequence(&tx_data);\n        // Get function selector\n        let hashed_function_selector: FixedBytes<32> = keccak(func.as_bytes().to_vec()).into();\n        // Combine function selector and input data (use abi_packed way)\n        let calldata = [&hashed_function_selector[..4], &data].concat();\n        calldata\n    }\n\n    // The func example: \"transfer(address,uint256)\"\n    pub fn encode_with_signature_and_hash(\n        &self, \n        func: String, \n        address: Address, \n        amount: U256\n    ) -> FixedBytes<32> {\n        type TransferType = (SOLAddress, Uint<256>);\n        let tx_data = (address, amount);\n        let data = TransferType::abi_encode_sequence(&tx_data);\n        // Get function selector\n        let hashed_function_selector: FixedBytes<32> = keccak(func.as_bytes().to_vec()).into();\n        // Combine function selector and input data (use abi_packed way)\n        let calldata = [&hashed_function_selector[..4], &data].concat();\n        keccak(calldata).into()\n    }\n}\n\nCargo.toml​\n[package]\nname = \"stylus-encode-hashing\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[dependencies]\nalloy-primitives = \"=0.7.6\"\nalloy-sol-types = \"=0.7.6\"\nmini-alloc = \"0.4.2\"\nstylus-sdk = \"0.6.0\"\nhex = \"0.4.3\"\nsha3 = \"0.10.8\"\n\n[features]\nexport-abi = [\"stylus-sdk/export-abi\"]\ndebug = [\"stylus-sdk/debug\"]\n\n[lib]\ncrate-type = [\"lib\", \"cdylib\"]\n\n[profile.release]\ncodegen-units = 1\nstrip = true\nlto = true\npanic = \"abort\"\nopt-level = \"s\"\n\nEdit this page\nPrevious\nAbi Decode\nNext\nBytes In Bytes Out\nHashing with keccak256\nsrc/main.rs\nCargo.toml\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/abi_decode",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nABI Decode\n\nThe decode can not be used for encode_packed data because it ignores padding when encode. (For more information you can refer to ABI Encode)\n\nSo here we show an example for using decode on data encoded with abi_encode_sequence:\n\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\n// This should always return true\npub fn encode_and_decode(\n    &self, \n    target: Address,\n    value: U256,\n    func: String,\n    data: Bytes,\n    timestamp: U256\n) -> Result<bool, HasherError> {\n    // define sol types tuple\n    type TxIdHashType = (SOLAddress, Uint<256>, SOLString, SOLBytes, Uint<256>);\n    // because the abi_encode_sequence will return alloy_primitives::Bytes rather than stylus_sdk::bytes, so we need to make sure the input and return types are the same\n    let primative_data = alloy_primitives::Bytes::copy_from_slice(&data);\n    // set the tuple\n    let tx_hash_data = (target, value, func, primative_data, timestamp);\n    // encode the tuple\n    let tx_hash_data_encode = TxIdHashType::abi_encode_sequence(&tx_hash_data);\n\n    let validate = true;\n    \n    // Check the result\n    match TxIdHashType::abi_decode_sequence(&tx_hash_data_encode, validate) {\n        Ok(res) => Ok(res == tx_hash_data),\n        Err(_) => {\n            return Err(HasherError::DecodedFailed(DecodedFailed{}));\n        },\n    }   \n}\n\nFull Example code:\nsrc/lib.rs​\n\n#![cfg_attr(not(any(feature = \"export-abi\", test)), no_main)]\nextern crate alloc;\n\n\n/// Import items from the SDK. The prelude contains common traits and macros.\nuse stylus_sdk::{alloy_primitives::{U256, Address}, prelude::*};\n// Because the naming of `alloy_primitives` and `alloy_sol_types` is the same, we need to rename the types in `alloy_sol_types`.\nuse alloy_sol_types::{sol_data::{Address as SOLAddress, *}, SolType, sol};\n\n\n// Define error\nsol! {\n    error DecodedFailed();\n}\n\n// Error types for the MultiSig contract\n#[derive(SolidityError)]\npub enum DecoderError{\n    DecodedFailed(DecodedFailed)\n}\n\n#[storage]\n#[entrypoint]\npub struct Decoder;\n\n\n/// Declare that `Decoder` is a contract with the following external methods.\n#[public]\nimpl Decoder {\n    // This should always return true\n    pub fn encode_and_decode(\n        &self, \n        address: Address, \n        amount: U256\n    ) -> Result<bool, DecoderError> {\n        // define sol types tuple\n        type TxIdHashType = (SOLAddress, Uint<256>);\n        // set the tuple\n        let tx_hash_data = (address, amount);\n        // encode the tuple\n        let tx_hash_data_encode = TxIdHashType::abi_encode_params(&tx_hash_data);\n\n        let validate = true;\n        \n        // Check the result\n        match TxIdHashType::abi_decode_params(&tx_hash_data_encode, validate) {\n            Ok(res) => Ok(res == tx_hash_data),\n            Err(_) => {\n                return Err(DecoderError::DecodedFailed(DecodedFailed{}));\n            },\n        }   \n    }\n\n}\n\nCargo.toml​\n[package]\nname = \"stylus-decode-hashing\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[dependencies]\nalloy-primitives = \"=0.7.6\"\nalloy-sol-types = \"=0.7.6\"\nmini-alloc = \"0.4.2\"\nstylus-sdk = \"0.5.1\"\n\n[features]\nexport-abi = [\"stylus-sdk/export-abi\"]\ndebug = [\"stylus-sdk/debug\"]\n\n[lib]\ncrate-type = [\"lib\", \"cdylib\"]\n\n[profile.release]\ncodegen-units = 1\nstrip = true\nlto = true\npanic = \"abort\"\nopt-level = \"s\"\n\n\nEdit this page\nPrevious\nAbi Encode\nNext\nHashing\nsrc/lib.rs\nCargo.toml\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/abi_encode",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nABI Encode\n\nThe ABI Encode has 2 types which are encode and encode_packed.\n\nencode will concatenate all values and add padding to fit into 32 bytes for each values.\nencode_packed will concatenate all values in the exact byte representations without padding. (For example, encode_packed(\"a\", \"bc\") == encode_packed(\"ab\", \"c\"))\n\nSuppose we have a tuple of values: (target, value, func, data, timestamp) to encode, and their alloy primitives type are (Address, U256, String, Bytes, U256).\n\nFirstly we need to import those types we need from alloy_primitives, stylus_sdk::abi and alloc::string:\n\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\n// Import items from the SDK. The prelude contains common traits and macros.\nuse stylus_sdk::{alloy_primitives::{U256, Address, FixedBytes}, abi::Bytes, prelude::*};\n// Import String from alloc\nuse alloc::string::String;\n\n\nSecondly because we will use the method abi_encode_sequence and abi_encode_packed under alloy_sol_types to encode data, we also need to import the types from alloy_sol_types:\n\n// Becauce the naming of alloy_primitives and alloy_sol_types is the same, so we need to re-name the types in alloy_sol_types\nuse alloy_sol_types::{sol_data::{Address as SOLAddress, String as SOLString, Bytes as SOLBytes, *}, SolType};\n\nencode​\n\nThen encode them:\n\n// define sol types tuple\ntype TxIdHashType = (SOLAddress, Uint<256>, SOLString, SOLBytes, Uint<256>);\n// set the tuple\nlet tx_hash_data = (target, value, func, data, timestamp);\n// encode the tuple\nlet tx_hash_bytes = TxIdHashType::abi_encode_sequence(&tx_hash_data);\n\nencode_packed​\n\nThere are 2 methods to encode_packed data:\n\nencode_packed them:\n// define sol types tuple\ntype TxIdHashType = (SOLAddress, Uint<256>, SOLString, SOLBytes, Uint<256>);\n// set the tuple\nlet tx_hash_data = (target, value, func, data, timestamp);\n// encode the tuple\nlet tx_hash_data_encode_packed = TxIdHashType::abi_encode_packed(&tx_hash_data);\n\nWe can also use the following method to encode_packed them:\nlet tx_hash_data_encode_packed = [&target.to_vec(), &value.to_be_bytes_vec(), func.as_bytes(), &data.to_vec(), &timestamp.to_be_bytes_vec()].concat();\n\nFull Example code:\nsrc/main.rs​\n// Allow `cargo stylus export-abi` to generate a main function.\n#![cfg_attr(not(feature = \"export-abi\"), no_main)]\nextern crate alloc;\n\n\n/// Import items from the SDK. The prelude contains common traits and macros.\nuse stylus_sdk::{alloy_primitives::{U256, Address, FixedBytes}, abi::Bytes, prelude::*};\nuse alloc::string::String;\n// Becauce the naming of alloy_primitives and alloy_sol_types is the same, so we need to re-name the types in alloy_sol_types\nuse alloy_sol_types::{sol_data::{Address as SOLAddress, String as SOLString, Bytes as SOLBytes, *}, SolType};\nuse sha3::{Digest, Keccak256};\n\n// Define some persistent storage using the Solidity ABI.\n// `Encoder` will be the entrypoint.\n#[storage]\n#[entrypoint]\npub struct Encoder;\n\nimpl Encoder {\n    fn keccak256(&self, data: Bytes) -> FixedBytes<32> {\n        // prepare hasher\n        let mut hasher = Keccak256::new();\n        // populate the data\n        hasher.update(data);\n        // hashing with keccack256\n        let result = hasher.finalize();\n        // convert the result hash to FixedBytes<32>\n        let result_vec = result.to_vec();\n        FixedBytes::<32>::from_slice(&result_vec)   \n    }\n}\n\n/// Declare that `Encoder` is a contract with the following external methods.\n#[public]\nimpl Encoder {\n\n     // Encode the data and hash it\n     pub fn encode(\n        &self, \n        target: Address,\n        value: U256,\n        func: String,\n        data: Bytes,\n        timestamp: U256\n    ) -> Vec<u8> {\n        // define sol types tuple\n        type TxIdHashType = (SOLAddress, Uint<256>, SOLString, SOLBytes, Uint<256>);\n        // set the tuple\n        let tx_hash_data = (target, value, func, data, timestamp);\n        // encode the tuple\n        let tx_hash_data_encode = TxIdHashType::abi_encode_params(&tx_hash_data);\n        tx_hash_data_encode\n    }\n\n    // Packed encode the data and hash it, the same result with the following one\n    pub fn packed_encode(\n        &self, \n        target: Address,\n        value: U256,\n        func: String,\n        data: Bytes,\n        timestamp: U256\n    )-> Vec<u8> {\n        // define sol types tuple\n        type TxIdHashType = (SOLAddress, Uint<256>, SOLString, SOLBytes, Uint<256>);\n        // set the tuple\n        let tx_hash_data = (target, value, func, data, timestamp);\n        // encode the tuple\n        let tx_hash_data_encode_packed = TxIdHashType::abi_encode_packed(&tx_hash_data);\n        tx_hash_data_encode_packed\n    }\n\n    // Packed encode the data and hash it, the same result with the above one\n    pub fn packed_encode_2(\n        &self, \n        target: Address,\n        value: U256,\n        func: String,\n        data: Bytes,\n        timestamp: U256\n    )-> Vec<u8> {\n        // set the data to arrary and concat it directly\n        let tx_hash_data_encode_packed = [&target.to_vec(), &value.to_be_bytes_vec(), func.as_bytes(), &data.to_vec(), &timestamp.to_be_bytes_vec()].concat();\n        tx_hash_data_encode_packed\n    }\n\n\n    // The func example: \"transfer(address,uint256)\"\n    pub fn encode_with_signature(\n        &self, \n        func: String, \n        address: Address, \n        amount: U256\n    ) -> Vec<u8> {\n        type TransferType = (SOLAddress, Uint<256>);\n        let tx_data = (address, amount);\n        let data = TransferType::abi_encode_params(&tx_data);\n        // Get function selector\n        let hashed_function_selector = self.keccak256(func.as_bytes().to_vec().into());\n        // Combine function selector and input data (use abi_packed way)\n        let calldata = [&hashed_function_selector[..4], &data].concat();\n        calldata\n    }\n\n}\n\nCargo.toml​\n[package]\nname = \"stylus-encode-hashing\"\nversion = \"0.1.7\"\nedition = \"2021\"\nlicense = \"MIT OR Apache-2.0\"\nkeywords = [\"arbitrum\", \"ethereum\", \"stylus\", \"alloy\"]\n\n[dependencies]\nalloy-primitives = \"=0.7.6\"\nalloy-sol-types = \"=0.7.6\"\nmini-alloc = \"0.4.2\"\nstylus-sdk = \"0.6.0\"\nhex = \"0.4.3\"\nsha3 = \"0.10\"\n\n[dev-dependencies]\ntokio = { version = \"1.12.0\", features = [\"full\"] }\nethers = \"2.0\"\neyre = \"0.6.8\"\n\n[features]\nexport-abi = [\"stylus-sdk/export-abi\"]\n\n[lib]\ncrate-type = [\"lib\", \"cdylib\"]\n\n[profile.release]\ncodegen-units = 1\nstrip = true\nlto = true\npanic = \"abort\"\nopt-level = \"s\"\n\nEdit this page\nPrevious\nFunction Selector\nNext\nAbi Decode\nencode\nencode_packed\nsrc/main.rs\nCargo.toml\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Function selector • Stylus by Example | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/function_selector",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nFunction selector\n\nWhen a smart contract is called, the first 4 bytes of the calldata sent as part of the request are called the \"function selector\", and identify which function of the smart contract to call.\n\nYou can compute a specific function selector by using the function_selector! macro.\n\nHere's an example that computes the selector of a function named foo:\n\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\nfunction_selector!(\"foo\") // returns 0xc2985578\n\n\nFunctions usually take a number of arguments that you need to pass in order for the call to be successful. For example, here's the signature of a function that takes 2 arguments, an address and a uint256:\n\nfunction transfer(address recipient, uint256 amount) external returns (bool);\n\n\nTo compute the selector for this function, pass the types of the arguments to the function_selector macro:\n\nfunction_selector!(\"transfer\", Address, U256) // returns 0xa9059cbb\n\n\nfunction_selector will return a byte array containing the encoded function selector.\n\nLearn More​\nstylus_sdk::function_selector\nEdit this page\nPrevious\nSending Ether\nNext\nAbi Encode\nLearn More\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/sending_ether",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nSending Ether\n\nWe have three main ways to send Ether in Rust Stylus: using the transfer_eth method, using low level call method, and sending value while calling an external contract.\n\nIt's important to note that the transfer_eth method in Rust Stylus invokes the recipient contract, which may subsequently call other contracts. All the gas is supplied to the recipient, which it may burn. Conversely, the transfer method in Solidity is capped at 2300 gas. In Rust Stylus, you can cap the gas by using the low-level call method with a specified gas. An example of this is provided in the code on bottom of the page.\n\nThese two methods are exactly equivalent under the hood:\n\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\ntransfer_eth(recipient, value)?;\n\ncall(Call::new_in(self).value(value), recipient, &[])?;\n\nWhere to Send Ether​\n\nExternally Owned Account (EOA) Addresses: Directly send Ether to an EOA address.\n\nSolidity Smart Contracts with Receive Function (No Calldata): Send Ether to a Solidity smart contract that has a receive function without providing any calldata.\n\nSolidity Smart Contracts with Fallback Function (With Calldata): Send Ether to a Solidity smart contract that has a fallback function by providing the necessary calldata.\n\nSmart Contracts with Payable Methods (both Solidity and Stylus): Send Ether to smart contracts that have defined payable methods. Payable methods are identified by the payable modifier in Solidity, and the #[payable] macro in Rust.\n\nBelow you can find examples for each of these methods and how to define them in a Rust Stylus smart contract using the Stylus SDK:\n\nsrc/lib.rs​\n// Only run this as a WASM if the export-abi feature is not set.\n#![cfg_attr(not(any(feature = \"export-abi\", test)), no_main)]\nextern crate alloc;\n\nuse alloy_primitives::Address;\nuse stylus_sdk::{\n    abi::Bytes,\n    call::{call, transfer_eth, Call},\n    msg::{self},\n    prelude::*,\n};\n\nsol_interface! {\n    interface ITarget {\n        function receiveEther() external payable;\n    }\n}\n\n#[storage]\n#[entrypoint]\npub struct SendEther {}\n\n#[public]\nimpl SendEther {\n    // Transfer Ether using the transfer_eth method\n    // This can be used to send Ether to an EOA or a Solidity smart contract that has a receive() function implemented\n    #[payable]\n    pub fn send_via_transfer(to: Address) -> Result<(), Vec<u8>> {\n        transfer_eth(to, msg::value())?;\n        Ok(())\n    }\n\n    // Transfer Ether using a low-level call\n    // This can be used to send Ether to an EOA or a Solidity smart contract that has a receive() function implemented\n    #[payable]\n    pub fn send_via_call(&mut self, to: Address) -> Result<(), Vec<u8>> {\n        call(Call::new_in(self).value(msg::value()), to, &[])?;\n        Ok(())\n    }\n\n    // Transfer Ether using a low-level call with a specified gas limit\n    // This can be used to send Ether to an EOA or a Solidity smart contract that has a receive() function implemented\n    #[payable]\n    pub fn send_via_call_gas_limit(&mut self, to: Address, gas_amount: u64) -> Result<(), Vec<u8>> {\n        call(\n            Call::new_in(self).value(msg::value()).gas(gas_amount),\n            to,\n            &[],\n        )?;\n        Ok(())\n    }\n\n    // Transfer Ether using a low-level call with calldata\n    // This can be used to call a Solidity smart contract's fallback function and send Ether along with calldata\n    #[payable]\n    pub fn send_via_call_with_call_data(\n        &mut self,\n        to: Address,\n        data: Bytes,\n    ) -> Result<(), Vec<u8>> {\n        call(Call::new_in(self).value(msg::value()), to, data.as_slice())?;\n        Ok(())\n    }\n\n    // Transfer Ether to another smart contract via a payable method on the target contract\n    // The target contract can be either a Solidity smart contract or a Stylus contract that has a receiveEther function, which is a payable function\n    #[payable]\n    pub fn send_to_stylus_contract(&mut self, to: Address) -> Result<(), Vec<u8>> {\n        let target = ITarget::new(to);\n        let config = Call::new_in(self).value(msg::value());\n        target.receive_ether(config)?;\n        Ok(())\n    }\n}\n\nCargo.toml​\n[package]\nname = \"stylus_sending_ether_example\"\nversion = \"0.1.7\"\nedition = \"2021\"\nlicense = \"MIT OR Apache-2.0\"\nkeywords = [\"arbitrum\", \"ethereum\", \"stylus\", \"alloy\"]\n\n[dependencies]\nalloy-primitives = \"=0.7.6\"\nalloy-sol-types = \"=0.7.6\"\nmini-alloc = \"0.4.2\"\nstylus-sdk = \"0.6.0\"\nhex = \"0.4.3\"\n\n[dev-dependencies]\ntokio = { version = \"1.12.0\", features = [\"full\"] }\nethers = \"2.0\"\neyre = \"0.6.8\"\n\n[features]\nexport-abi = [\"stylus-sdk/export-abi\"]\n\n[lib]\ncrate-type = [\"lib\", \"cdylib\"]\n\n[profile.release]\ncodegen-units = 1\nstrip = true\nlto = true\npanic = \"abort\"\nopt-level = \"s\"\n\n\nEdit this page\nPrevious\nVm Affordances\nNext\nFunction Selector\nWhere to Send Ether\nsrc/lib.rs\nCargo.toml\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/vm_affordances",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nVM affordances\n\nThe Stylus Rust SDK contains several modules for interacting with the Virtual Machine (VM), which can be imported from stylus_sdk.\n\nLet's see an example:\n\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\nuse stylus_sdk::{msg};\n\nlet callvalue = msg::value();\n\n\nThis page lists the modules that are available, as well as the methods within those modules.\n\nblock​\n\nAllows you to inspect the current block:\n\nbasefee: gets the basefee of the current block\nchainid: gets the unique chain identifier of the Arbitrum chain\ncoinbase: gets the coinbase of the current block, which on Arbitrum chains is the L1 batch poster's address\ngas_limit: gets the gas limit of the current block\nnumber: gets a bounded estimate of the L1 block number at which the sequencer sequenced the transaction. See Block gas limit, numbers and time for more information on how this value is determined\ntimestamp: gets a bounded estimate of the Unix timestamp at which the sequencer sequenced the transaction. See Block gas limit, numbers and time for more information on how this value is determined\nuse stylus_sdk::{block};\n\nlet basefee = block::basefee();\nlet chainid = block::chainid();\nlet coinbase = block::coinbase();\nlet gas_limit = block::gas_limit();\nlet number = block::number();\nlet timestamp = block::timestamp();\n\ncontract​\n\nAllows you to inspect the contract itself:\n\naddress: gets the address of the current program\nargs: reads the invocation's calldata. The entrypoint macro uses this under the hood\nbalance: gets the balance of the current program\noutput: writes the contract's return data. The entrypoint macro uses this under the hood\nread_return_data: copies the bytes of the last EVM call or deployment return result. Note: this function does not revert if out of bounds, but rather will copy the overlapping portion\nreturn_data_len: returns the length of the last EVM call or deployment return result, or 0 if neither have happened during the program's execution\nuse stylus_sdk::{contract};\n\nlet address = contract::address();\ncontract::args();\nlet balance = contract::balance();\ncontract::output();\ncontract::read_return_data();\ncontract::return_data_len();\n\ncrypto​\n\nAllows you to access VM-accelerated cryptographic functions:\n\nkeccak: efficiently computes the keccak256 hash of the given preimage\nuse stylus_sdk::{crypto};\nuse stylus_sdk::alloy_primitives::address;\n\nlet preimage = address!(\"361594F5429D23ECE0A88E4fBE529E1c49D524d8\");\nlet hash = crypto::keccak(&preimage);\n\nevm​\n\nAllows you to access affordances for the Ethereum Virtual Machine:\n\ngas_left: gets the amount of gas remaining. See Ink and Gas for more information on Stylus's compute pricing\nink_left: gets the amount of ink remaining. See Ink and Gas for more information on Stylus's compute pricing\nlog: emits a typed alloy log\npay_for_memory_grow: this function exists to force the compiler to import this symbol. Calling it will unproductively consume gas\nraw_log: emits an EVM log from its raw topics and data. Most users should prefer the alloy-typed raw_log\nuse stylus_sdk::{evm};\n\nlet gas_left = evm::gas_left();\nlet ink_left = evm::ink_left();\nevm::log(...);\nevm::pay_for_memory_grow();\nevm::raw_log(...);\n\n\nHere's an example of how to emit a Transfer log:\n\nsol! {\n    event Transfer(address indexed from, address indexed to, uint256 value);\n    event Approval(address indexed owner, address indexed spender, uint256 value);\n}\n\nfn foo() {\n   ...\n   evm::log(Transfer {\n      from: Address::ZERO,\n      to: address,\n      value,\n   });\n}\n\nmsg​\n\nAllows you to inspect the current call\n\nreentrant: whether the current call is reentrant\nsender: gets the address of the account that called the program. For normal L2-to-L2 transactions the semantics are equivalent to that of the EVM's CALLER opcode, including in cases arising from DELEGATE_CALL\nvalue: gets the ETH value in wei sent to the program\nuse stylus_sdk::{msg};\n\nlet reentrant = msg::reentrant();\nlet sender = msg::sender();\nlet value = msg::value();\n\ntx​\n\nAllows you to inspect the current transaction\n\ngas_price: gets the gas price in wei per gas, which on Arbitrum chains equals the basefee\ngas_to_ink: converts evm gas to ink. See Ink and Gas for more information on Stylus's compute-pricing model\nink_price: gets the price of ink in evm gas basis points. See Ink and Gas for more information on Stylus's compute-pricing model\nink_to_gas: converts ink to evm gas. See Ink and Gas for more information on Stylus's compute-pricing model\norigin: gets the top-level sender of the transaction. The semantics are equivalent to that of the EVM's ORIGIN opcode\nuse stylus_sdk::{tx};\n\nlet gas_price = tx::gas_price();\nlet gas_to_ink = tx::gas_to_ink();\nlet ink_price = tx::ink_price();\nlet ink_to_gas = tx::ink_to_gas();\nlet origin = tx::origin();\n\nLearn More​\nArbitrum documentation\nStylus SDK modules\nEdit this page\nPrevious\nInheritance\nNext\nSending Ether\nblock\ncontract\ncrypto\nevm\nmsg\ntx\nLearn More\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Inheritance • Stylus by Example | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/inheritance",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nInheritance\n\nThe Stylus Rust SDK replicates the composition pattern of Solidity. The #[public] macro provides the Router trait, which can be used to connect types via inheritance, via the #[inherit] macro.\n\nLet's see an example:\n\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\n#[public]\n#[inherit(Erc20)]\nimpl Token {\n    pub fn mint(&mut self, amount: U256) -> Result<(), Vec<u8>> {\n        ...\n    }\n}\n\n#[public]\nimpl Erc20 {\n    pub fn balance_of() -> Result<U256> {\n        ...\n    }\n}\n\n\nIn the above code, we can see how Token inherits from Erc20, meaning that it will inherit the public methods available in Erc20. If someone called the Token contract on the function balanceOf, the function Erc20.balance_of() would be executed.\n\nAdditionally, the inheriting type must implement the Borrow trait for borrowing data from the inherited type. In the case above, Token should implement Borrow<Erc20>. For simplicity, #[storage] and sol_storage! provide a #[borrow] annotation that can be used instead of manually implementing the trait:\n\nsol_storage! {\n    #[entrypoint]\n    pub struct Token {\n        #[borrow]\n        Erc20 erc20;\n        ...\n    }\n\n    pub struct Erc20 {\n        ...\n    }\n}\n\nMethods search order​\n\nA type can inherit multiple other types (as long as they use the #[public] macro). Since execution begins in the type that uses the #[entrypoint] macro, that type will be first checked when searching a specific method. If the method is not found in that type, the search will continue in the inherited types, in order of inheritance. If the method is not found in any of the inherited methods, the call will revert.\n\nLet's see an example:\n\n#[public]\n#[inherit(B, C)]\nimpl A {\n    pub fn foo() -> Result<(), Vec<u8>> {\n        ...\n    }\n}\n\n#[public]\nimpl B {\n    pub fn bar() -> Result<(), Vec<u8>> {\n        ...\n    }\n}\n\n#[public]\nimpl C {\n    pub fn bar() -> Result<(), Vec<u8>> {\n        ...\n    }\n\n    pub fn baz() -> Result<(), Vec<u8>> {\n        ...\n    }\n}\n\n\nIn the code above:\n\ncalling foo() will search the method in A, find it, and execute A.foo()\ncalling bar() will search the method in A first, then in B, find it, and execute B.bar()\ncalling baz() will search the method in A, B and finally C, so it will execute C.baz()\n\nNotice that C.bar() won't ever be reached, since the inheritance goes through B first, which has a method named bar() too.\n\nFinally, since the inherited types can also inherit other types themselves, keep in mind that method resolution finds the first matching method by Depth First Search.\n\nOverriding methods​\n\nBecause methods are checked in the inherited order, if two types implement the same method, the one in the higher level in the hierarchy will override the one in the lower levels, which won’t be callable. This allows for patterns where the developer imports a crate implementing a standard, like ERC-20, and then adds or overrides just the methods they want to without modifying the imported ERC-20 type.\n\nImportant warning: The Stylus Rust SDK does not currently contain explicit override or virtual keywords for explicitly marking override functions. It is important, therefore, to carefully ensure that contracts are only overriding the functions.\n\nLet's see an example:\n\n#[public]\n#[inherit(B, C)]\nimpl A {\n    pub fn foo() -> Result<(), Vec<u8>> {\n        ...\n    }\n}\n\n#[public]\nimpl B {\n    pub fn foo() -> Result<(), Vec<u8>> {\n        ...\n    }\n\n    pub fn bar() -> Result<(), Vec<u8>> {\n        ...\n    }\n}\n\n\nIn the example above, even though B has an implementation for foo(), calling foo() will execute A.foo() since the method is searched first in A.\n\nLearn more​\nArbitrum documentation\ninheritance, #[inherit] and #[borrow]\nRouter trait\nBorrow trait\nBorrowMut trait\nEdit this page\nPrevious\nEvents\nNext\nVm Affordances\nMethods search order\nOverriding methods\nLearn more\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Events • Stylus by Example | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/events",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nEvents\n\nEvents allow for data to be logged publicly to the blockchain. Log entries provide the contract's address, a series of up to four topics, and some arbitrary length binary data. The Stylus Rust SDK provides a few ways to publish event logs described below.\n\nLearn More​\nSolidity docs: Events\nstylus_sdk::evm::log\nalloy_sol_types::SolEvent\nLog​\n\nUsing the evm::log function in the Stylus SDK is the preferred way to log events. It ensures that an event will be logged in a Solidity ABI-compatible format. The log function takes any type that implements Alloy SolEvent trait. It's not recommended to attempt to implement this trait on your own. Instead, make use of the provided sol! macro to declare your Events and their schema using Solidity-style syntax to declare the parameter types. Alloy will create ABI-compatible Rust types which you can instantiate and pass to the evm::log function.\n\nLog Usage​\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\n// sol! macro event declaration\n// Up to 3 parameters can be indexed.\n// Indexed parameters helps you filter the logs efficiently\nsol! {\n    event Log(address indexed sender, string message);\n    event AnotherLog();\n}\n\n#[storage]\n#[entrypoint]\npub struct Events {}\n\n#[public]\nimpl Events {\nfn user_main(_input: Vec<u8>) -> ArbResult {\n    // emits a 'Log' event, defined above in the sol! macro\n    evm::log(Log {\n        sender: Address::from([0x11; 20]),\n        message: \"Hello world!\".to_string(),\n    });\n\n    // no data, but 'AnotherLog' event will still emit to the chain\n    evm::log(AnotherLog {});\n\n    Ok(vec![])\n}\n}\n\nRaw Log​\n\nThe evm::raw_log affordance offers the ability to send anonymous events that do not necessarily conform to the Solidity ABI. Instead, up to four raw 32-byte indexed topics are published along with any arbitrary bytes appended as data.\n\nNOTE: It's still possible to achieve Solidity ABI compatibility using this construct. To do so you'll have to manually compute the ABI signature for the event, following the equation set in the Solidity docs. The result of that should be assigned to TOPIC_0, the first topic in the slice passed to raw_log.\n\nRaw Log Usage​\n// set up local variables\nlet user = Address::from([0x22; 20]);\nlet balance = U256::from(10_000_000);\n\n// declare up to 4 topics\n// topics must be of type FixedBytes<32>\nlet topics = &[user.into_word()];\n\n// store non-indexed data in a byte Vec\nlet mut data: Vec<u8> = vec![];\n// to_be_bytes means 'to big endian bytes'\ndata.extend_from_slice(balance.to_be_bytes::<32>().to_vec().as_slice());\n\n// unwrap() here 'consumes' the Result\nevm::raw_log(topics.as_slice(), data.as_ref()).unwrap();\n\nResult​\n\nCombining the above examples into the boiler plate provided below this section, deploying to a Stylus chain and then invoking the deployed contract will result in the following three events logged to the chain:\n\nlogs​\n[\n  {\n    \"address\": \"0x6cf4a18ac8efd6b0b99d3200c4fb9609dd60d4b3\",\n    \"topics\": [\n      \"0x0738f4da267a110d810e6e89fc59e46be6de0c37b1d5cd559b267dc3688e74e0\",\n      \"0x0000000000000000000000001111111111111111111111111111111111111111\"\n    ],\n    \"data\": \"0x0000000000000000000000000000000000000000000000000000000000000020000000000000000000000000000000000000000000000000000000000000000c48656c6c6f20776f726c64210000000000000000000000000000000000000000\",\n    \"blockHash\": \"0xfef880025dc87b5ab4695a0e1a6955dd7603166ecba79ce0f503a568b2ec8940\",\n    \"blockNumber\": \"0x94\",\n    \"transactionHash\": \"0xc7318dae2164eb441fb80f5b869f844e3e97ae83c24a4639d46ec4d915a30818\",\n    \"transactionIndex\": \"0x1\",\n    \"logIndex\": \"0x0\",\n    \"removed\": false\n  },\n  {\n    \"address\": \"0x6cf4a18ac8efd6b0b99d3200c4fb9609dd60d4b3\",\n    \"topics\": [\"0xfe1a3ad11e425db4b8e6af35d11c50118826a496df73006fc724cb27f2b99946\"],\n    \"data\": \"0x\",\n    \"blockHash\": \"0xfef880025dc87b5ab4695a0e1a6955dd7603166ecba79ce0f503a568b2ec8940\",\n    \"blockNumber\": \"0x94\",\n    \"transactionHash\": \"0xc7318dae2164eb441fb80f5b869f844e3e97ae83c24a4639d46ec4d915a30818\",\n    \"transactionIndex\": \"0x1\",\n    \"logIndex\": \"0x1\",\n    \"removed\": false\n  },\n  {\n    \"address\": \"0x6cf4a18ac8efd6b0b99d3200c4fb9609dd60d4b3\",\n    \"topics\": [\"0x0000000000000000000000002222222222222222222222222222222222222222\"],\n    \"data\": \"0x0000000000000000000000000000000000000000000000000000000000989680\",\n    \"blockHash\": \"0xfef880025dc87b5ab4695a0e1a6955dd7603166ecba79ce0f503a568b2ec8940\",\n    \"blockNumber\": \"0x94\",\n    \"transactionHash\": \"0xc7318dae2164eb441fb80f5b869f844e3e97ae83c24a4639d46ec4d915a30818\",\n    \"transactionIndex\": \"0x1\",\n    \"logIndex\": \"0x2\",\n    \"removed\": false\n  }\n]\n\nBoilerplate​\nsrc/lib.rs​\n// Only run this as a WASM if the export-abi feature is not set.\n#![cfg_attr(not(any(feature = \"export-abi\", test)), no_main)]\nextern crate alloc;\n\nuse alloc::vec::Vec;\nuse alloc::{string::ToString, vec};\n\nuse stylus_sdk::alloy_primitives::U256;\nuse stylus_sdk::{alloy_primitives::Address, alloy_sol_types::sol, evm, prelude::*, ArbResult};\n\n// sol! macro event declaration\n// Up to 3 parameters can be indexed.\n// Indexed parameters helps you filter the logs by the indexed parameter\nsol! {\n    event Log(address indexed sender, string message);\n    event AnotherLog();\n}\n\n#[storage]\n#[entrypoint]\npub struct Events {}\n\n#[public]\nimpl Events {\nfn user_main(_input: Vec<u8>) -> ArbResult {\n    // emits a 'Log' event, defined above in the sol! macro\n    evm::log(Log {\n        sender: Address::from([0x11; 20]),\n        message: \"Hello world!\".to_string(),\n    });\n\n    // no data, but event will still log to the chain\n    evm::log(AnotherLog {});\n\n    // set up local variables\n    let user = Address::from([0x22; 20]);\n    let balance = U256::from(10_000_000);\n\n    // declare up to 4 topics\n    // topics must be of type FixedBytes<32>\n    let topics = &[user.into_word()];\n\n    // store non-indexed data in a byte Vec\n    let mut data: Vec<u8> = vec![];\n    // to_be_bytes means 'to big endian bytes'\n    data.extend_from_slice(balance.to_be_bytes::<32>().to_vec().as_slice());\n\n    // unwrap() here 'consumes' the Result\n    evm::raw_log(topics.as_slice(), data.as_ref()).unwrap();\n\n    Ok(Vec::new())\n}\n}\n\nCargo.toml​\n[package]\nname = \"stylus_events_example\"\nversion = \"0.1.7\"\nedition = \"2021\"\nlicense = \"MIT OR Apache-2.0\"\nkeywords = [\"arbitrum\", \"ethereum\", \"stylus\", \"alloy\"]\n\n[dependencies]\nalloy-primitives = \"=0.7.6\"\nalloy-sol-types = \"=0.7.6\"\nmini-alloc = \"0.4.2\"\nstylus-sdk = \"0.6.0\"\nhex = \"0.4.3\"\n\n[dev-dependencies]\ntokio = { version = \"1.12.0\", features = [\"full\"] }\nethers = \"2.0\"\neyre = \"0.6.8\"\n\n[features]\nexport-abi = [\"stylus-sdk/export-abi\"]\n\n[lib]\ncrate-type = [\"lib\", \"cdylib\"]\n\n[profile.release]\ncodegen-units = 1\nstrip = true\nlto = true\npanic = \"abort\"\nopt-level = \"s\"\n\nEdit this page\nPrevious\nErrors\nNext\nInheritance\nLearn More\nLog\nLog Usage\nRaw Log\nRaw Log Usage\nResult\nlogs\nBoilerplate\nsrc/lib.rs\nCargo.toml\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/errors",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nErrors\n\nIn Rust Stylus contracts, error handling is a crucial aspect of writing robust and reliable smart contracts. Rust differentiates between recoverable and unrecoverable errors. Recoverable errors are represented using the Result type, which can either be Ok, indicating success, or Err, indicating failure. This allows developers to manage errors gracefully and maintain control over the flow of execution. Unrecoverable errors are handled with the panic! macro, which stops execution, unwinds the stack, and returns a dataless error.\n\nIn Stylus contracts, error types are often explicitly defined, providing clear and structured ways to handle different failure scenarios. This structured approach promotes better error management, ensuring that contracts are secure, maintainable, and behave predictably under various conditions. Similar to Solidity and EVM, errors in Stylus will undo all changes made to the state during a transaction by reverting the transaction. Thus, there are two main types of errors in Rust Stylus contracts:\n\nRecoverable Errors: The Stylus SDK provides features that make using recoverable errors in Rust Stylus contracts convenient. This type of error handling is strongly recommended for Stylus contracts.\nUnrecoverable Errors: These can be defined similarly to Rust code but are not recommended for smart contracts if recoverable errors can be used instead.\nLearn More​\nSolidity docs: Expressions and Control Structures\n#[derive(SolidityError)]\nalloy_sol_types::SolError\nError handling: Rust book\nRecoverable Errors​\n\nRecoverable errors are represented using the Result type, which can either be Ok, indicating success, or Err, indicating failure. The Stylus SDK provides tools to define custom error types and manage recoverable errors effectively.\n\nExample: Recoverable Errors​\n\nHere's a simplified Rust Stylus contract demonstrating how to define and handle recoverable errors:\n\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\n#![cfg_attr(not(feature = \"export-abi\"), no_main)]\nextern crate alloc;\n\n\nuse alloy_sol_types::sol;\nuse stylus_sdk::{abi::Bytes, alloy_primitives::{Address, U256}, call::RawCall, prelude::*};\n\n#[storage]\n#[entrypoint]\npub struct MultiCall;\n\n// Declare events and Solidity error types\nsol! {\n    error ArraySizeNotMatch();\n    error CallFailed(uint256 call_index);\n}\n\n#[derive(SolidityError)]\npub enum MultiCallErrors {\n    ArraySizeNotMatch(ArraySizeNotMatch),\n    CallFailed(CallFailed),\n}\n\n#[public]\nimpl MultiCall {\n    pub fn multicall(\n        &self,\n        addresses: Vec<Address>,\n        data: Vec<Bytes>,\n    ) -> Result<Vec<Bytes>, MultiCallErrors> {\n        let addr_len = addresses.len();\n        let data_len = data.len();\n        let mut results: Vec<Bytes> = Vec::new();\n        if addr_len != data_len {\n            return Err(MultiCallErrors::ArraySizeNotMatch(ArraySizeNotMatch {}));\n        }\n        for i in 0..addr_len {\n            let result: Result<Vec<u8>, Vec<u8>> =\n                RawCall::new().call(addresses[i], data[i].to_vec().as_slice());\n            let data = match result {\n                Ok(data) => data,\n                Err(_data) => return Err(MultiCallErrors::CallFailed(CallFailed { call_index: U256::from(i) })),\n            };\n            results.push(data.into())\n        }\n        Ok(results)\n    }\n}\n\nUsing SolidityError Derive Macro: The #[derive(SolidityError)] attribute is used for the MultiCallErrors enum, automatically implementing the necessary traits for error handling.\nDefining Errors: Custom errors ArraySizeNotMatch and CallFailed is declared in MultiCallErrors enum. CallFailed error includes a call_index parameter to indicate which call failed.\nArraySizeNotMatch Error Handling: The multicall function returns ArraySizeNotMatch if the size of addresses and data vectors are not equal.\nCallFailed Error Handling: The multicall function returns a CallFailed error with the index of the failed call if any call fails. Note that we're using match to check if the result of the call is an error or a return data. We'll describe match pattern in the further sections.\nUnrecoverable Errors​\n\nHere are various ways to handle such errors in the multicall function, which calls multiple addresses and panics in different scenarios:\n\nUsing panic!​\n\nDirectly panics if the call fails, including the index of the failed call.\n\n        for i in 0..addr_len {\n            let result = RawCall::new().call(addresses[i], data[i].to_vec().as_slice());\n            let data = match result {\n                Ok(data) => data,\n                Err(_data) => panic!(\"Call to address {:?} failed at index {}\", addresses[i], i),\n            };\n            results.push(data.into());\n}\n\n\nHandling Call Failure with panic!: The function panics if any call fails and the transaction will be reverted without any data.\n\nUsing unwrap​\n\nUses unwrap to handle the result, panicking if the call fails.\n\n        for i in 0..addr_len {\n            let result = RawCall::new().call(addresses[i], data[i].to_vec().as_slice()).unwrap();\n            results.push(result.into());\n}\n\n\nHandling Call Failure with unwrap: The function uses unwrap to panic if any call fails, including the index of the failed call.\n\nUsing match​\n\nUses a match statement to handle the result of call, panicking if the call fails.\n\n        for i in 0..addr_len {\n            let result = RawCall::new().call(addresses[i], data[i].to_vec().as_slice());\n            let data = match result {\n                Ok(data) => data,\n                Err(_data) => return Err(MultiCallErrors::CallFailed(CallFailed { call_index: U256::from(i) })),\n            };\n            results.push(data.into());\n}\n\n\nHandling Call Failure with match: The function uses a match statement to handle the result of call, returning error if any call fails.\n\nUsing the ? Operator​\n\nUses the ? operator to propagate the error if the call fails, including the index of the failed call.\n\n        for i in 0..addr_len {\n            let result = RawCall::new().call(addresses[i], data[i].to_vec().as_slice())\n                .map_err(|_| MultiCallErrors::CallFailed(CallFailed { call_index: U256::from(i) }))?;\n            results.push(result.into());\n}\n\n\nHandling Call Failure with ? Operator: The function uses the ? operator to propagate the error if any call fails, including the index of the failed call.\n\nEach method demonstrates a different way to handle unrecoverable errors in the multicall function of a Rust Stylus contract, providing a comprehensive approach to error management.\n\nNote that as mentioned above, it is strongly recommended to use custom error handling instead of unrecoverable error handling.\n\nBoilerplate​\nsrc/lib.rs​\n\nThe lib.rs code can be found at the top of the page in the recoverable error example section.\n\nCargo.toml​\n[package]\nname = \"stylus-multicall-contract\"\nversion = \"0.1.7\"\nedition = \"2021\"\n\n[dependencies]\nalloy-primitives = \"=0.7.6\"\nalloy-sol-types = \"=0.7.6\"\nstylus-sdk = \"0.6.0\"\nhex = \"0.4.3\"\n\n[dev-dependencies]\ntokio = { version = \"1.12.0\", features = [\"full\"] }\nethers = \"2.0\"\neyre = \"0.6.8\"\n\n[features]\nexport-abi = [\"stylus-sdk/export-abi\"]\n\n[[bin]]\nname = \"stylus-multicall-contract\"\npath = \"src/main.rs\"\n\n[lib]\ncrate-type = [\"lib\", \"cdylib\"]\n\n\nEdit this page\nPrevious\nFunction\nNext\nEvents\nLearn More\nRecoverable Errors\nUnrecoverable Errors\nUsing panic!\nUsing unwrap\nUsing match\nUsing the ? Operator\nBoilerplate\nsrc/lib.rs\nCargo.toml\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Function • Stylus by Example | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/function",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nFunctions\n\nFunctions are a fundamental part of any programming language, including Stylus, enabling you to encapsulate logic into reusable components.\n\nThis guide covers the syntax and usage of functions, including internal and external functions, and how to return multiple values.\n\nLearn More​\nRust docs - Functions\nSolidity docs - Functions\nOverview​\n\nA function in Stylus consists of a name, a set of parameters, an optional return type, and a body.\n\nJust as with storage, Stylus methods are Solidity ABI equivalent. This means that contracts written in different programming languages are fully interoperable.\n\nFunctions are declared with the fn keyword. Parameters allow the function to accept inputs, and the return type specifies the output of the function. If no return type is specified, the function returns void.\n\nFollowing is an example of a function add that takes two uint256 values and returns their sum.\n\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\nfn add(a: uint256, b: uint256) -> uint256 {\n    return a + b;\n}\n\nFunction Parameters​\n\nFunction parameters are the inputs to a function. They are specified as a list of IDENTIFIER: Type pairs, separated by commas.\n\nIn this example, the function add_numbers takes two u32 parameters, a and b and returns the sum of the two numbers.\n\nfn add_numbers(a: u32, b: u32) -> u32 {\n    a + b\n}\n\nReturn Types​\n\nReturn types in functions are an essential part of defining the behavior and expected outcomes of your smart contract methods.\n\nHere, we explain the syntax and usage of return types in Stylus with general examples.\n\nBasic Syntax​\n\nA function with a return type in Stylus follows this basic structure. The return type is specified after the -> arrow. Values are returned using the return keyword or implicitly as the last expression of the function. In Rust and Stylus, the last expression in a function is implicitly returned, so the return keyword is often omitted.\n\npub fn function_name(&self) -> ReturnType {\n    // Function body\n}\n\nExamples​\n\nFunction returning a String: This get_greeting function returns a String. The return type is specified as String after the -> arrow.\n\npub fn get_greeting() -> String {\n    \"Hello, Stylus!\".into()\n}\n\n\nFunction returning an Integer: This get_number function returns an unsigned 32-bit integer (u32).\n\npub fn get_number() -> u32 {\n    42\n}\n\n\nFunction returning a Result with Ok and Err variants: The perform_operation function returns a Result<u32, CustomError>. The Result type is used for functions that can return either a success value (Ok) or an error (Err). In this case, it returns Ok(value) on success and an error variant of CustomError on failure.\n\npub enum CustomError {\n    ErrorVariant,\n}\n\npub fn perform_operation(value: u32) -> Result<u32, CustomError> {\n    if value > 0 {\n        Ok(value)\n    } else {\n        Err(CustomError::ErrorVariant)\n    }\n}\n\nPublic Functions​\n\nPublic functions are those that can be called by other contracts.\n\nTo define a public function in a Stylus contract, you use the #[public] macro. This macro ensures that the function is accessible from outside the contract.\n\nPreviously, all public methods were required to return a Result type with Vec<u8> as the error type. This is now optional. Specifically, if a method is \"infallible\" (i.e., it cannot produce an error), it does not need to return a Result type. Here's what this means:\n\nInfallible methods: Methods that are guaranteed not to fail (no errors possible) do not need to use the Result type. They can return their result directly without wrapping it in Result.\n\nOptional error handling: The Result type with Vec<u8> as the error type is now optional for methods that cannot produce an error.\n\nIn the following example, owner is a public function that returns the contract owner's address. Since this function is infallible (i.e., it cannot produce an error), it does not need to return a Result type.\n\n#[external]\nimpl Contract {\n    // Define an external function to get the owner of the contract\n    pub fn owner(&self) -> Address {\n        self.owner.get()\n    }\n}\n\nInternal Functions​\n\nInternal functions are those that can only be called within the contract itself. These functions are not exposed to external calls.\n\nTo define an internal function, you simply include it within your contract's implementation without the #[public] macro.\n\nThe choice between public and internal functions depends on the desired level of accessibility and interaction within and across contracts.\n\nIn the followinge example, set_owner is an internal function that sets a new owner for the contract. It is only callable within the contract itself.\n\nimpl Contract {\n    // Define an internal function to set a new owner\n    pub fn set_owner(&mut self, new_owner: Address) {\n        self.owner.set(new_owner);\n    }\n}\n\n\nTo mix public and internal functions within the same contract, you should use two separate impl blocks with the same contract name. Public functions are defined within an impl block annotated with the #[public] attribute, signifying that these functions are part of the contract's public interface and can be invoked from outside the contract. In contrast, internal functions are placed within a separate impl block that does not have the #[public] attribute, making them internal to the contract and inaccessible to external entities.\n\nsrc/lib.rs​\n// Only run this as a WASM if the export-abi feature is not set.\n#![cfg_attr(not(any(feature = \"export-abi\", test)), no_main)]\nextern crate alloc;\n\nuse alloc::vec;\nuse stylus_sdk::alloy_primitives::Address;\nuse stylus_sdk::prelude::*;\nuse stylus_sdk::storage::StorageAddress;\n\nuse stylus_sdk::alloy_primitives::U256;\nuse stylus_sdk::storage::StorageU256;\nuse stylus_sdk::console;\n\n\n#[storage]\n#[entrypoint]\npub struct ExampleContract {\n    owner: StorageAddress,\n    data: StorageU256,\n}\n\n#[public]\nimpl ExampleContract {\n    // External function to set the data\n    pub fn set_data(&mut self, value: U256) {\n        self.data.set(value);\n    }\n\n    // External function to get the data\n    pub fn get_data(&self) -> U256 {\n        self.data.get()\n    }\n\n    // External function to get the contract owner\n    pub fn get_owner(&self) -> Address {\n        self.owner.get()\n    }\n}\n\nimpl ExampleContract {\n    // Internal function to set a new owner\n    pub fn set_owner(&mut self, new_owner: Address) {\n        self.owner.set(new_owner);\n    }\n\n    // Internal function to log data\n    pub fn log_data(&self) {\n        let _data = self.data.get();\n        console!(\"Current data is: {:?}\", _data);\n    }\n}\n\nCargo.toml​\n[package]\nname = \"stylus-functions\"\nversion = \"0.1.0\"\nedition = \"2021\"\n\n[dependencies]\nalloy-primitives = \"=0.7.6\"\nalloy-sol-types = \"=0.7.6\"\nmini-alloc = \"0.4.2\"\nstylus-sdk = \"0.6.0\"\nhex = \"0.4.3\"\nsha3 = \"0.10.8\"\n\n[features]\nexport-abi = [\"stylus-sdk/export-abi\"]\ndebug = [\"stylus-sdk/debug\"]\n\n[lib]\ncrate-type = [\"lib\", \"cdylib\"]\n\n[profile.release]\ncodegen-units = 1\nstrip = true\nlto = true\npanic = \"abort\"\nopt-level = \"s\"\n\nEdit this page\nPrevious\nConstants\nNext\nErrors\nLearn More\nOverview\nFunction Parameters\nReturn Types\nBasic Syntax\nExamples\nPublic Functions\nInternal Functions\nsrc/lib.rs\nCargo.toml\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Constants • Stylus by Example | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/constants",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nConstants\n\nConstants are values that are bound to a name and cannot change. They are always immutable. In Rust, constants are declared with the const keyword. Unlike variables declared with the let keyword, constants must be annotated with their type.\n\nConstants are valid for the entire length of the transaction. They are essentially inlined wherever they are used, meaning that their value is copied directly into whatever context invokes them.\n\nSince their value is hardcoded, they can save on gas cost as their value does not need to be fetched from storage.\n\nLearn More​\nRust docs - Constant items\nSolidity docs - Constant variables\nsrc/lib.rs​\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\n// Only run this as a WASM if the export-abi feature is not set.\n#![cfg_attr(not(any(feature = \"export-abi\", test)), no_main)]\nextern crate alloc;\n\nuse alloc::vec;\nuse alloc::vec::Vec;\n\nuse stylus_sdk::alloy_primitives::Address;\nuse stylus_sdk::prelude::*;\nuse stylus_sdk::storage::StorageAddress;\n\nconst OWNER: &str = \"0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045\";\n\n#[storage]\n#[entrypoint]\npub struct Contract {\n    owner: StorageAddress,\n}\n\n#[public]\nimpl Contract {\n    pub fn init(&mut self) -> Result<(), Vec<u8>> {\n        // Parse the const &str as a local Address variable\n        let owner_address = Address::parse_checksummed(OWNER, None).expect(\"Invalid address\");\n\n        // Save the result as the owner\n        self.owner.set(owner_address);\n\n        Ok(())\n    }\n    pub fn owner(&self) -> Result<Address, Vec<u8>> {\n        let owner_address = self.owner.get();\n\n        Ok(owner_address)\n    }\n}\n\n\nCargo.toml​\n[package]\nname = \"stylus_constants_example\"\nversion = \"0.1.7\"\nedition = \"2021\"\nlicense = \"MIT OR Apache-2.0\"\nkeywords = [\"arbitrum\", \"ethereum\", \"stylus\", \"alloy\"]\n\n[dependencies]\nalloy-primitives = \"=0.7.6\"\nalloy-sol-types = \"=0.7.6\"\nmini-alloc = \"0.4.2\"\nstylus-sdk = \"0.6.0\"\nhex = \"0.4.3\"\n\n[dev-dependencies]\ntokio = { version = \"1.12.0\", features = [\"full\"] }\nethers = \"2.0\"\neyre = \"0.6.8\"\n\n[features]\nexport-abi = [\"stylus-sdk/export-abi\"]\n\n[lib]\ncrate-type = [\"lib\", \"cdylib\"]\n\n[profile.release]\ncodegen-units = 1\nstrip = true\nlto = true\npanic = \"abort\"\nopt-level = \"s\"\n\n\nEdit this page\nPrevious\nVariables\nNext\nFunction\nLearn More\nsrc/lib.rs\nCargo.toml\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Variables • Stylus by Example | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/variables",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nVariables\n\nIn Solidity, there are 3 types of variables: local, state, and global. Local variables are not stored on the blockchain, while state variables are (and incur a much higher cost as a result). This is true of Arbitrum Stylus Rust smart contracts as well, although how they're defined is quite different.\n\nIn Rust, local variables are just ordinary variables you assign with let or let mut statements. Local variables are far cheaper than state variables, even on the EVM, however, Stylus local variables are more than 100x cheaper to allocate in memory than their Solidity equivalents.\n\nUnlike Solidity, Rust was not built inherently with the blockchain in mind. It is a general purpose programming language. We therefore define specific storage types to explicitly denote values intended to be stored permanently as part of the contract's state. State variables cost the same to store as their Solidity equivalents.\n\nGlobal variables in Solidity, such as msg.sender and block.timestamp, are available as function calls pulled in from the stylus_sdk with their Rust equivalents being msg::sender() and block::timestamp(), respectively. These variables provide information about the blockchain or the active transaction.\n\nLearn more​\nRust Docs - Variables and Mutability\nStylus SDK Rust Docs - Storage\nStylus SDK Guide - Storage\nSolidity docs - state variables\nSolidity docs - global variables\nsrc/lib.rs​\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\n// Only run this as a WASM if the export-abi feature is not set.\n#![cfg_attr(not(any(feature = \"export-abi\", test)), no_main)]\nextern crate alloc;\n\nuse stylus_sdk::alloy_primitives::{U16, U256};\nuse stylus_sdk::prelude::*;\nuse stylus_sdk::storage::{StorageAddress, StorageBool, StorageU256};\nuse stylus_sdk::{block, console, msg};\n\n#[storage]\n#[entrypoint]\npub struct Contract {\n    initialized: StorageBool,\n    owner: StorageAddress,\n    max_supply: StorageU256,\n}\n\n#[public]\nimpl Contract {\n    // State variables are initialized in an `init` function.\n    pub fn init(&mut self) -> Result<(), Vec<u8>> {\n        // We check if contract has been initialized before.\n        // We return if so, we initialize if not.\n        let initialized = self.initialized.get();\n        if initialized {\n            return Ok(());\n        }\n        self.initialized.set(true);\n\n        // We set the contract owner to the caller,\n        // which we get from the global msg module\n        self.owner.set(msg::sender());\n        self.max_supply.set(U256::from(10_000));\n\n        Ok(())\n    }\n\n    pub fn do_something() -> Result<(), Vec<u8>> {\n        // Local variables are not saved to the blockchain\n        // 16-bit Rust integer\n        let _i = 456_u16;\n        // 16-bit int inferred from U16 Alloy primitive\n        let _j = U16::from(123);\n\n        // Here are some global variables\n        let _timestamp = block::timestamp();\n        let _amount = msg::value();\n\n        console!(\"Local variables: {_i}, {_j}\");\n        console!(\"Global variables: {_timestamp}, {_amount}\");\n\n        Ok(())\n    }\n}\n\n\nCargo.toml​\n[package]\nname = \"stylus_variable_example\"\nversion = \"0.1.7\"\nedition = \"2021\"\nlicense = \"MIT OR Apache-2.0\"\nkeywords = [\"arbitrum\", \"ethereum\", \"stylus\", \"alloy\"]\n\n[dependencies]\nalloy-primitives = \"=0.7.6\"\nalloy-sol-types = \"=0.7.6\"\nmini-alloc = \"0.4.2\"\nstylus-sdk = \"0.6.0\"\nhex = \"0.4.3\"\n\n[dev-dependencies]\ntokio = { version = \"1.12.0\", features = [\"full\"] }\nethers = \"2.0\"\neyre = \"0.6.8\"\n\n[features]\nexport-abi = [\"stylus-sdk/export-abi\"]\n\n[lib]\ncrate-type = [\"lib\", \"cdylib\"]\n\n[profile.release]\ncodegen-units = 1\nstrip = true\nlto = true\npanic = \"abort\"\nopt-level = \"s\"\n\n\nEdit this page\nPrevious\nPrimitive Data Types\nNext\nConstants\nLearn more\nsrc/lib.rs\nCargo.toml\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Primitive Data Types • Stylus by Example | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/primitive_data_types",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nPrimitive Data Types\n\nThe Stylus SDK makes use of the popular Alloy library (from the developers of ethers-rs and Foundry) to represent various native Solidity types as Rust types and to seamlessly convert between them when needed. These are needed since there are a number of custom types (like address) and large integers that are not natively supported in Rust.\n\nIn this section, we'll focus on the following types:\n\nU256\nI256\nAddress\nbool\n\nMore in-depth documentation about the available methods and types in the Alloy library can be found in their docs. It also helps to cross-reference with Solidity docs if you don't already have a solid understanding of those types.\n\nLearn More​\nAlloy docs (v0.3.2)\nAddress\nSigned\nUint\nSolidity docs (v0.8.19)\nIntegers​\n\nAlloy defines a set of convenient Rust types to represent the typically sized integers used in Solidity. The type U256 represents a 256-bit unsigned integer, meaning it cannot be negative. The range for a U256 number is 0 to 2^256 - 1.\n\nNegative numbers are allowed for I types, such as I256. These represent signed integers.\n\nU256 maps to uint256 ... I256 maps to int256\nU128 maps to uint128 ... I128 maps to int128\n...\nU8 maps to uint8 ... I8 maps to int8\nInteger Usage​\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\n// Unsigned\nlet eight_bit: U8 = U8::from(1);\nlet two_fifty_six_bit: U256 = U256::from(0xff_u64);\n\n// Out: Stylus says: '8-bit: 1 | 256-bit: 255'\nconsole!(\"8-bit: {} | 256-bit: {}\", eight_bit, two_fifty_six_bit);\n\n// Signed\nlet eight_bit: I8 = I8::unchecked_from(-1);\nlet two_fifty_six_bit: I256 = I256::unchecked_from(0xff_u64);\n\n// Out: Stylus says: '8-bit: -1 | 256-bit: 255'\nconsole!(\"8-bit: {} | 256-bit: {}\", eight_bit, two_fifty_six_bit);\n\nExpanded Integer Usage​\n// Use `try_from` if you're not sure it'll fit\nlet a = I256::try_from(20003000).unwrap();\n// Or parse from a string\nlet b = \"100\".parse::<I256>().unwrap();\n// With hex characters\nlet c = \"-0x138f\".parse::<I256>().unwrap();\n// Underscores are ignored\nlet d = \"1_000_000\".parse::<I256>().unwrap();\n\n// Math works great\nlet e = a * b + c - d;\n// Out: Stylus says: '20003000 * 100 + -5007 - 1000000 = 1999294993'\nconsole!(\"{} * {} + {} - {} = {}\", a, b, c, d, e);\n\n// Useful constants\nlet f = I256::MAX;\nlet g = I256::MIN;\nlet h = I256::ZERO;\nlet i = I256::MINUS_ONE;\n\n// Stylus says: '5789...9967, -5789...9968, 0, -1'\nconsole!(\"{f}, {g}, {h}, {i}\");\n// As hex: Stylus says: '0x7fff...ffff, 0x8000...0000, 0x0, 0xffff...ffff'\nconsole!(\"{:#x}, {:#x}, {:#x}, {:#x}\", f, g, h, i);\n\nAddress​\n\nEthereum addresses are 20 bytes in length, or 160 bits. Alloy provides a number of helper utilities for converting to addresses from strings, bytes, numbers, and addresses.\n\nAddress Usage​\n// From a 20 byte slice, all 1s\nlet addr1 = Address::from([0x11; 20]);\n// Out: Stylus says: '0x1111111111111111111111111111111111111111'\nconsole!(\"{addr1}\");\n\n// Use the address! macro to parse a string as a checksummed address\nlet addr2 = address!(\"d8da6bf26964af9d7eed9e03e53415d37aa96045\");\n// Out: Stylus says: '0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045'\nconsole!(\"{addr2}\");\n\n// Format compressed addresses for output\n// Out: Stylus says: '0xd8dA…6045'\nconsole!(\"{addr2:#}\");\n\nBoolean​\n\nUse native Rust primitives where it makes sense and where no equivalent Alloy primitive exists.\n\nBoolean Usage​\nlet frightened: bool = true;\n// Out: Stylus says: 'Boo! Did I scare you?'\nconsole!(\"Boo! Did I scare you?\");\n\nlet response = match frightened {\n    true => \"Yes!\".to_string(),\n    false => \"No!\".to_string(),\n};\n\n// Out: Stylus says: 'Yes!'\nconsole!(\"{response}\");\n\nBoilerplate​\nsrc/lib.rs​\n#![cfg_attr(not(any(feature = \"export-abi\", test)), no_main)]\nextern crate alloc;\nuse alloc::{string::ToString, vec::Vec};\n\nuse stylus_sdk::{\n    alloy_primitives::{address, Address, I256, I8, U256, U8}, console, prelude::*, ArbResult\n};\n\n#[storage]\n#[entrypoint]\npub struct Data {\n    \n}\n\n\n#[public]\nimpl Data {\nfn user_main(_input: Vec<u8>) -> ArbResult {\n    // Use native Rust primitives where they make sense\n    // and where no equivalent Alloy primitive exists\n    let frightened: bool = true;\n    // Out: Stylus says: 'Boo! Did I scare you?'\n    console!(\"Boo! Did I scare you?\");\n\n    let _response = match frightened {\n        true => \"Yes!\".to_string(),\n        false => \"No!\".to_string(),\n    };\n\n    // Out: Stylus says: 'Yes!'\n    console!(\"{_response}\");\n\n    // U256 stands for a 256-bit *unsigned* integer, meaning it cannot be\n    // negative. The range for a U256 number is 0 to 2^256 - 1. Alloy provides\n    // a set of unsigned integer types to represent the various sizes available\n    // in the EVM.\n    //    U256 maps to uint256\n    //    U128 maps to uint128\n    //    ...\n    //    U8 maps to uint8\n    let _eight_bit: U8 = U8::from(1);\n    let _two_fifty_six_bit: U256 = U256::from(0xff_u64);\n\n    // Out: Stylus says: '8-bit: 1 | 256-bit: 255'\n    console!(\"8-bit: {} | 256-bit: {}\", _eight_bit, _two_fifty_six_bit);\n\n    // Negative numbers are allowed for I types. These represent signed integers.\n    //    I256 maps to int256\n    //    I128 maps to int128\n    //    ...\n    //    I8 maps to int8\n    let _eight_bit: I8 = I8::unchecked_from(-1);\n    let _two_fifty_six_bit: I256 = I256::unchecked_from(0xff_u64);\n\n    // Out: Stylus says: '8-bit: -1 | 256-bit: 255'\n    console!(\"8-bit: {} | 256-bit: {}\", _eight_bit, _two_fifty_six_bit);\n\n    // Additional usage of integers\n\n    // Use `try_from` if you're not sure it'll fit\n    let a = I256::try_from(20003000).unwrap();\n    // Or parse from a string\n    let b = \"100\".parse::<I256>().unwrap();\n    // With hex characters\n    let c = \"-0x138f\".parse::<I256>().unwrap();\n    // Underscores are ignored\n    let d = \"1_000_000\".parse::<I256>().unwrap();\n\n    // Math works great\n    let _e = a * b + c - d;\n    // Out: Stylus says: '20003000 * 100 + -5007 - 1000000 = 1999294993'\n    console!(\"{} * {} + {} - {} = {}\", a, b, c, d, _e);\n\n    // Useful constants\n    let _f = I256::MAX;\n    let _g = I256::MIN;\n    let _h = I256::ZERO;\n    let _i = I256::MINUS_ONE;\n\n    // Stylus says: '5789...9967, -5789...9968, 0, -1'\n    console!(\"{_f}, {_g}, {_h}, {_i}\");\n    // As hex: Stylus says: '0x7fff...ffff, 0x8000...0000, 0x0, 0xffff...ffff'\n    console!(\"{:#x}, {:#x}, {:#x}, {:#x}\", _f, _g, _h, _i);\n\n    // Ethereum addresses are 20 bytes in length, or 160 bits. Alloy provides a number of helper utilities for converting to addresses from strings, bytes, numbers, and addresses\n\n    // From a 20 byte slice, all 1s\n    let _addr1 = Address::from([0x11; 20]);\n    // Out: Stylus says: '0x1111111111111111111111111111111111111111'\n    console!(\"{_addr1}\");\n\n    // Use the address! macro to parse a string as a checksummed address\n    let _addr2 = address!(\"d8da6bf26964af9d7eed9e03e53415d37aa96045\");\n    // Out: Stylus says: '0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045'\n    console!(\"{_addr2}\");\n\n    // Format compressed addresses for output\n    // Out: Stylus says: '0xd8dA…6045'\n    console!(\"{_addr2:#}\");\n\n    Ok(Vec::new())\n}\n}\n\nCargo.toml​\n[package]\nname = \"stylus_data_example\"\nversion = \"0.1.7\"\nedition = \"2021\"\nlicense = \"MIT OR Apache-2.0\"\nkeywords = [\"arbitrum\", \"ethereum\", \"stylus\", \"alloy\"]\n\n[dependencies]\nalloy-primitives = \"=0.7.6\"\nalloy-sol-types = \"=0.7.6\"\nmini-alloc = \"0.4.2\"\nstylus-sdk = \"0.6.0\"\nhex = \"0.4.3\"\n\n[dev-dependencies]\ntokio = { version = \"1.12.0\", features = [\"full\"] }\nethers = \"2.0\"\neyre = \"0.6.8\"\n\n[features]\nexport-abi = [\"stylus-sdk/export-abi\"]\n\n[lib]\ncrate-type = [\"lib\", \"cdylib\"]\n\n[profile.release]\ncodegen-units = 1\nstrip = true\nlto = true\npanic = \"abort\"\nopt-level = \"s\"\n\n\nEdit this page\nPrevious\nHello World\nNext\nVariables\nLearn More\nIntegers\nInteger Usage\nExpanded Integer Usage\nAddress\nAddress Usage\nBoolean\nBoolean Usage\nBoilerplate\nsrc/lib.rs\nCargo.toml\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus-by-example/hello_world",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHello World\n\nUsing the console! macro from the stylus_sdk allows you to print output to the terminal for debugging purposes. To view the output, you'll need to run a local Stylus dev node as described in the Arbitrum docs and set the debug feature flag as shown in line 7 of the Cargo.toml file below.\n\nThe console! macro works similar to the built-in println! macro that comes with Rust.\n\nExamples​\nNOTE\n\nThis code has yet to be audited. Please use at your own risk.\n\n// Out: Stylus says: 'hello there!'\nconsole!(\"hello there!\");\n// Out: Stylus says: 'format some arguments'\nconsole!(\"format {} arguments\", \"some\");\n\nlet local_variable = \"Stylus\";\n// Out: Stylus says: 'Stylus is awesome!'\nconsole!(\"{local_variable} is awesome!\");\n// Out: Stylus says: 'When will you try out Stylus?'\nconsole!(\"When will you try out {}?\", local_variable);\n\nsrc/main.rs​\n#![cfg_attr(not(feature = \"export-abi\"), no_main)]\n\nextern crate alloc;\n\n\nuse stylus_sdk::{console, prelude::*, stylus_proc::entrypoint, ArbResult};\n\n#[storage]\n#[entrypoint]\npub struct Hello;\n\n\n#[public]\nimpl Hello {\n    fn user_main(_input: Vec<u8>) -> ArbResult {\n        // Will print 'Stylus says: Hello Stylus!' on your local dev node\n        // Be sure to add \"debug\" feature flag to your Cargo.toml file as\n        // shown below.\n        console!(\"Hello Stylus!\");\n        Ok(Vec::new())\n    }\n}\n\nCargo.toml​\n[package]\nname = \"stylus_hello_world\"\nversion = \"0.1.7\"\nedition = \"2021\"\nlicense = \"MIT OR Apache-2.0\"\nkeywords = [\"arbitrum\", \"ethereum\", \"stylus\", \"alloy\"]\n\n[dependencies]\nalloy-primitives = \"=0.7.6\"\nalloy-sol-types = \"=0.7.6\"\nmini-alloc = \"0.4.2\"\nstylus-sdk = \"0.6.0\"\nhex = \"0.4.3\"\nsha3 = \"0.10\"\n\n[dev-dependencies]\ntokio = { version = \"1.12.0\", features = [\"full\"] }\nethers = \"2.0\"\neyre = \"0.6.8\"\n\n[features]\nexport-abi = [\"stylus-sdk/export-abi\"]\n\n[lib]\ncrate-type = [\"lib\", \"cdylib\"]\n\n[profile.release]\ncodegen-units = 1\nstrip = true\nlto = true\npanic = \"abort\"\nopt-level = \"s\"\n\nEdit this page\nPrevious\nOverview\nNext\nPrimitive Data Types\nExamples\nsrc/main.rs\nCargo.toml\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to configure the Data Availability Committee (DAC) in your chain | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/data-availability-committees/configure-dac",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nGet started\nDeploy a Data Availability Server (DAS)\nDeploy a mirror Data Availability Server\nConfigure a Data Availability Committee (DAC)\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to configure the Data Availability Committee (DAC) in your chain\n\nAnyTrust chains rely on an external Data Availability Committee (DAC) to store data and provide it on-demand instead of using its parent chain as the Data Availability (DA) layer. The members of the DAC run a Data Availability Server (DAS) to handle these operations. Once the DA servers are running, the chain needs to be configured with their information to effectively store and retrieve data from them.\n\nIn this how-to, you'll learn how to configure the DAC in your chain. Refer to the Introduction for the full process of running DA servers and configuring the chain.\n\nThis how-to assumes that you're familiar with:\n\nThe DAC's role in the AnyTrust protocol. Refer to Inside AnyTrust for a refresher.\nKubernetes. The examples in this guide use Kubernetes to containerize your DAS.\nHow to deploy a Data Availability Server (DAS). This is needed to understand where the data we'll be handling in this guide comes from.\nThe Foundry toolkit\nStep 0: Prerequisites​\n\nBefore starting to generate the keyset and configuring the nodes and chain, you'll need to gather the following information from all the DA servers run by the DAC members:\n\nPublic BLS Key\nURL of the RPC endpoint\nURL(s) of the REST endpoint(s)\n\nYou should also make sure that at least one DAS is running as an archive DAS, otherwise the information will not be available after the expiry time.\n\nStep 1: Generate the keyset and keyset hash with all the information from the servers​\nWhat is a keyset?​\n\nThe AnyTrust protocol assumes that for the n members of the DAC, a minimum of h members maintain integrity. So h is then the minimum number of trusted committee members on an AnyTrust chain. In scenarios where k = (n + 1) - h members of the DAC pledge to grant access to a specific piece of information, these k members must sign and attest they have stored the data to be considered successful.\n\nTo perform this signing operation, each DAC member must generate their own set of BLS public and private keys. They should do this independently and ensure these keys are random and only used by them. You can find more information about how to generate a BLS pair of keys in Generating BLS Keys.\n\nAn Anytrust chain needs to know all DAC members' public keys to validate the integrity of the data being batched and posted. A keyset is a list of all DAC members' RPC endpoint and BLS public key. Additionally, it also contains information about how many signatures are needed to approve a Data Availability Certificate (DACert), via a special assumed-honest parameter (i.e., the h parameter we mentioned above). This design lets the chain owner modify the DAC membership over time, and DAC members change their keys if needed. See Inside AnyTrust for more information.\n\nWe use this keyset, and its hash to configure the SequencerInbox contract with the valid keyset, and also the batch poster (to request storing information) and full nodes (to request information already stored).\n\nHow to generate a keyset and a keyset hash​\n\nNitro comes with a special tool to generate both the keyset and the keyset hash. To use it, you need to first structure the keyset information in a JSON object with the following structure:\n\n{\n    \"keyset\": {\n      \"assumed-honest\": h,\n      \"backends\": [\n        {\n          \"url\": \"https://rpc-endpoint-of-member-1/\",\n          \"pubkey\":\"PUBLIC_KEY_OF_MEMBER_1\"\n        },\n        {\n          \"url\": \"https://rpc-endpoint-of-member-2/\",\n          \"pubkey\":\"PUBLIC_KEY_OF_MEMBER_2\"\n        },\n\n        ...\n\n        {\n          \"url\": \"https://rpc-endpoint-of-member-n/\",\n          \"pubkey\":\"PUBLIC_KEY_OF_MEMBER_N\"\n        }\n      ]\n    }\n}\n\n\nThe JSON fields represent the following:\n\nassumed_honest is the amount of members that we assume are honest from the n members of the DAC. This is the h variable we mentioned in the previous section.\nbackends contain information about each member of the DAC:\nurl contains the RPC endpoint of the DAS run by that member\npubkey contains the base64-encoded BLS public key used in the DAS run by that member\n\nOnce you have the JSON structure, save it into a file, for example, keyset-info.json.\n\nFinally, we'll use Nitro's datool dumpkeyset utility inside Docker to generate the keyset and keyset hash.\n\ndocker run -v $(pwd):/data/keyset --entrypoint datool offchainlabs/nitro-node:v3.2.1-d81324d dumpkeyset --conf.file /data/keyset/keyset-info.json\n\n\nThis command will output two results: Keyset and KeysetHash. Save them to use in the next steps.\n\nExample with mocked-up data​\n\nHere's an example that uses mocked-up data:\n\nThe JSON file is:\n\n{\n  \"keyset\": {\n    \"assumed-honest\": 2,\n    \"backends\": [\n      {\n        \"url\": \"http://example\",\n        \"pubkey\": \"YAbcteVnZLty5qRebeswHKhdjEMVwdou+imSfyrI+yVXHOMdLWA3Nf4DGW9tVry/mhmZqJp01TaYIsREXWdsFe1S5QCNqnddyag5yZ/5Y6GZRqx0BXmHTaxPY5kHrhvGnwxmlJVbUk1xjKRFgxxTdTk3c0AfM3JaeWYTed3avV//KGGdwHC+/Z7XPWmeXCNsGhY75YuoEAK2EwcJvAZK9de6lHEwtyBWvxcmOADxo6siacalEO+OdBL9VtHvG5FqEwbjsdnILAmTcb2YYVgqyq2joW6d/uXQ685hCWWYqC8RLQqTXoyrXEjYLjEEsMe6eRV9rRoBmj5/atB3uOYwixFv7A9YI5YiRjw2MfoB4rQnJAkhW4AJQiwWcV2+3lkJBg==\"\n      },\n      {\n        \"url\": \"http://example\",\n        \"pubkey\": \"YAg1+ZXyR48kiS0FDaoon4trnBsYW80oUy+I1hDCZCotxvNQl0AjbTPD4tkTaqsX+BnIxnEpO7ondxd2Lo0cH3usnhfdKNKTmpWbs45QD5wRw4zrvEJuLeqXxAF1plXRdACubHX/SeiEx5RpJJ5wlTJYhUtk+oRFxYWtRdxtxpdVAcavfP9wdCAsaH+Ke/GjrBkmiXVfIyJ1tMhCGxpWaem5BMKaKSzflht4OnwLTOc2kA3k2MY8X4WmXLRK80vvhArO+Eq3X0TEyRN2ELaBB6/zu9zBkRnHqSfBFbe5v7J9hcUA7nfRPsWpejrmv1HTtwpVAuhBbee1646f7uN2QRyjXIp/P1l8dgZXjPlqRxXOWjXPSOOcCh+qLe4i105oGQ==\"\n      }\n    ]\n  }\n}\n\n\nAnd when running the command we obtain:\n\n$ docker run -v $(pwd):/data/keyset --entrypoint datool offchainlabs/nitro-node:v3.2.1-d81324d dumpkeyset --conf.file /data/keyset/keyset-info.json\nKeyset: 0x0000000000000002000000000000000201216006dcb5e56764bb72e6a45e6deb301ca85d8c4315c1da2efa29927f2ac8fb25571ce31d2d603735fe03196f6d56bcbf9a1999a89a74d5369822c4445d676c15ed52e5008daa775dc9a839c99ff963a19946ac740579874dac4f639907ae1bc69f0c6694955b524d718ca445831c5375393773401f33725a79661379dddabd5fff28619dc070befd9ed73d699e5c236c1a163be58ba81002b6130709bc064af5d7ba947130b72056bf17263800f1a3ab2269c6a510ef8e7412fd56d1ef1b916a1306e3b1d9c82c099371bd9861582acaada3a16e9dfee5d0ebce61096598a82f112d0a935e8cab5c48d82e3104b0c7ba79157dad1a019a3e7f6ad077b8e6308b116fec0f58239622463c3631fa01e2b4272409215b8009422c16715dbede5909060121600835f995f2478f24892d050daa289f8b6b9c1b185bcd28532f88d610c2642a2dc6f3509740236d33c3e2d9136aab17f819c8c671293bba277717762e8d1c1f7bac9e17dd28d2939a959bb38e500f9c11c38cebbc426e2dea97c40175a655d17400ae6c75ff49e884c79469249e70953258854b64fa8445c585ad45dc6dc6975501c6af7cff7074202c687f8a7bf1a3ac192689755f232275b4c8421b1a5669e9b904c29a292cdf961b783a7c0b4ce736900de4d8c63c5f85a65cb44af34bef840acef84ab75f44c4c9137610b68107aff3bbdcc19119c7a927c115b7b9bfb27d85c500ee77d13ec5a97a3ae6bf51d3b70a5502e8416de7b5eb8e9feee376411ca35c8a7f3f597c7606578cf96a4715ce5a35cf48e39c0a1faa2dee22d74e6819\nKeysetHash: 0xfdca3e4e2de25f0a56d0ced68fd1cc64f91b20cde67c964c55105477c02f49be\n\nStep 2: Update the SequencerInbox contract​\n\nOnce we have the keyset and its hash, we can configure the SequencerInbox contract so it accepts DACerts signed by the DAC members.\n\nThe SequencerInbox can be configured with the new keyset by invoking the setValidKeyset method. Note that only the chain owner can call this method.\n\nHere's an example of how to use Foundry to configure the SequencerInbox with the keyset generated in the previous step:\n\ncast send --rpc-url $PARENT_CHAIN_RPC --private-key $CHAIN_OWNER_PRIVATE_KEY $SEQUENCERINBOX_ADDRESS \"setValidKeyset(bytes)\" 0x0000000000000002000000000000000201216006dcb5e56764bb72e6a45e6deb301ca85d8c4315c1da2efa29927f2ac8fb25571ce31d2d603735fe03196f6d56bcbf9a1999a89a74d5369822c4445d676c15ed52e5008daa775dc9a839c99ff963a19946ac740579874dac4f639907ae1bc69f0c6694955b524d718ca445831c5375393773401f33725a79661379dddabd5fff28619dc070befd9ed73d699e5c236c1a163be58ba81002b6130709bc064af5d7ba947130b72056bf17263800f1a3ab2269c6a510ef8e7412fd56d1ef1b916a1306e3b1d9c82c099371bd9861582acaada3a16e9dfee5d0ebce61096598a82f112d0a935e8cab5c48d82e3104b0c7ba79157dad1a019a3e7f6ad077b8e6308b116fec0f58239622463c3631fa01e2b4272409215b8009422c16715dbede5909060121600835f995f2478f24892d050daa289f8b6b9c1b185bcd28532f88d610c2642a2dc6f3509740236d33c3e2d9136aab17f819c8c671293bba277717762e8d1c1f7bac9e17dd28d2939a959bb38e500f9c11c38cebbc426e2dea97c40175a655d17400ae6c75ff49e884c79469249e70953258854b64fa8445c585ad45dc6dc6975501c6af7cff7074202c687f8a7bf1a3ac192689755f232275b4c8421b1a5669e9b904c29a292cdf961b783a7c0b4ce736900de4d8c63c5f85a65cb44af34bef840acef84ab75f44c4c9137610b68107aff3bbdcc19119c7a927c115b7b9bfb27d85c500ee77d13ec5a97a3ae6bf51d3b70a5502e8416de7b5eb8e9feee376411ca35c8a7f3f597c7606578cf96a4715ce5a35cf48e39c0a1faa2dee22d74e6819\n\nStep 3: Craft the new configuration for the batch poster​\n\nTo configure the batch poster, we'll use the JSON structure we created in Step 1. This will allow the batch poster to send RPC requests to all the DA servers (to store the information of the transactions being included in the next batch), craft the DACert, and store it in the SequencerInbox.\n\nThe configuration to enable the DAC in the batch poster looks like this:\n\n{\n  ...\n\n  \"data-availability\": {\n    \"enable\": true,\n    \"rpc-aggregator\": {\n      \"enable\": true,\n      \"assumed-honest\": h,\n      \"backends\": [\n        {\n          \"url\": \"https://rpc-endpoint-of-member-1/\",\n          \"pubkey\":\"PUBLIC_KEY_OF_MEMBER_1\"\n        },\n        {\n          \"url\": \"https://rpc-endpoint-of-member-2/\",\n          \"pubkey\":\"PUBLIC_KEY_OF_MEMBER_2\"\n        },\n\n        ...\n\n        {\n          \"url\": \"https://rpc-endpoint-of-member-n/\",\n          \"pubkey\":\"PUBLIC_KEY_OF_MEMBER_N\"\n        }\n      ]\n    }\n  },\n\n  ...\n}\n\n\nThe following parameters are used:\n\ndata-availability.enable: tells the batch poster to handle information stored in a DAC\ndata-availability.rpc-aggregator: includes information of the RPC endpoints of all the DA servers run by DAC members.\nenable: tells the batch poster that the RPC aggregator will be used\nassumed and backends: include information from the DA servers (following the same format as specified in Step 1)\n\nOnce the configuration is in place, you can restart your batch poster so it begins communicating with the DA servers to store transaction data, while storing the DACert in the SequencerInbox.\n\nStep 4: Craft the new configuration for your chain's nodes​\n\nFinally, we also need to configure all other nodes so they can communicate with the DAC. To do that, we'll also use the JSON structure we created in Step 1.\n\nThe configuration to enable the DAC in a full node looks like this:\n\n{\n  ...\n\n  \"data-availability\": {\n    \"enable\": true,\n    \"rest-aggregator\": {\n      \"enable\": true,\n      \"urls\": [\n          \"https://rest-endpoint-of-member-1/\",\n          \"https://rest-endpoint-of-member-2/\",\n          ...\n          \"https://rest-endpoint-of-member-n/\",\n      ],\n      \"online-url-list\": \"https://url-of-list-of-rest-endpoints\"\n    }\n  },\n\n  ...\n}\n\n\nThe following parameters are used:\n\ndata-availability.enable: tells the node to query information from the DAC\ndata-availability.rest-aggregator: includes information on the REST endpoints of all the DA servers run by DAC members.\nenable: tells the node that the REST aggregator will be used\nurls or online-url-list: usually only one of these is used, although both parameters can be used and the information will be aggregated together. urls is a list of all REST endpoints of the DA servers, and online-url-list is a URL to a list of URLs of the REST endpoints of the DA servers.\n\nOnce the configuration is in place, you can restart your node so it begins communicating with the DA servers to retrieve transaction data.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nDeploy a mirror Data Availability Server\nNext\nMonitoring tools and considerations\nStep 0: Prerequisites\nStep 1: Generate the keyset and keyset hash with all the information from the servers\nWhat is a keyset?\nHow to generate a keyset and a keyset hash\nExample with mocked-up data\nStep 2: Update the SequencerInbox contract\nStep 3: Craft the new configuration for the batch poster\nStep 4: Craft the new configuration for your chain's nodes\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/data-availability-committees/deploy-mirror-das",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nGet started\nDeploy a Data Availability Server (DAS)\nDeploy a mirror Data Availability Server\nConfigure a Data Availability Committee (DAC)\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to deploy a mirror Data Availability Server (DAS)\nRUNNING A REGULAR DAS VS RUNNING A MIRROR DAS\n\nThe main use-case for running a mirror DAS is to complement your setup as a Data Availability Committee (DAC) member. That means that you should run your main DAS first, and then configure the mirror DAS. Refer to How to deploy a DAS if needed.\n\nAnyTrust chains rely on an external Data Availability Committee (DAC) to store data and provide it on-demand instead of using its parent chain as the Data Availability (DA) layer. The members of the DAC run a Data Availability Server (DAS) to handle these operations.\n\nIn this how-to, you'll learn how to configure a mirror DAS that serves GET requests for stored batches of information through a REST HTTP interface. For a refresher on DACs, refer to the Introduction.\n\nThis how-to assumes that you're familiar with:\n\nHow a regular DAS works and what configuration options are available. Refer to How to deploy a DAS for a refresher.\nKubernetes. The examples in this guide use Kubernetes to containerize your DAS.\nWhat is a mirror DAS?​\n\nTo avoid exposing the REST interface of your main DAS to the public in order to prevent spamming attacks (as explained in How to deploy a DAS), you can choose to run a mirror DAS to complement your setup. The mirror DAS will handle all public REST requests, while reading information from the main DAS via its (now private) REST interface.\n\nIn general, mirror DA servers serve two main purposes:\n\nPrevent the main DAS from having to serve requests for data, allowing it to focus only on storing the data received.\nProvide resiliency to the network in the case of a DAS going down.\nConfiguration options​\n\nA mirror DAS will use the same tool and, thus, the same configuration options as your main DAS. You can find an explanation of those options in How to deploy a DAS.\n\nHow to deploy a mirror DAS​\nStep 0: Prerequisites​\n\nGather the following information:\n\nThe latest Nitro docker image: offchainlabs/nitro-node:v3.2.1-d81324d\nAn RPC endpoint for the parent chain. It is recommended to use a third-party provider RPC or run your own node to prevent being rate limited.\nThe SequencerInbox contract address in the parent chain.\nURL of the list of REST endpoints of other DA servers to configure the REST aggregator.\nStep 1: Set up a persistent volume​\n\nFirst, we'll set up a volume to store the DAS database. In k8s, we can use a configuration like this:\n\napiVersion: v1\nkind: PersistentVolumeClaim\nmetadata:\n  name: das-mirror\nspec:\n  accessModes:\n    - ReadWriteOnce\n  resources:\n  requests:\n    storage: 200Gi\n  storageClassName: gp2\n\nStep 2: Deploy the mirror DAS​\n\nTo run the mirror DAS, we'll use the daserver tool and we'll configure the following parameters:\n\nParameter\tDescription\n--data-availability.parent-chain-node-url\tRPC endpoint of a parent chain node\n--data-availability.sequencer-inbox-address\tAddress of the SequencerInbox in the parent chain\n--enable-rest\tEnables the REST server listening on --rest-addr and --rest-port\n--rest-addr\tREST server listening interface (default \"localhost\")\n--rest-port\t(Optional) REST server listening port (default 9877)\n--log-level\tLog level: 1 - ERROR, 2 - WARN, 3 - INFO, 4 - DEBUG, 5 - TRACE (default 3)\n--data-availability.rest-aggregator.enable\tEnables retrieval of sequencer batch data from a list of remote REST endpoints\n--data-availability.rest-aggregator.online-url-list\tA URL to a list of URLs of REST DAS endpoints that is checked at startup. This option is additive with the urls option\n--data-availability.rest-aggregator.urls\tList of URLs including 'http://' or 'https://' prefixes and port numbers to REST DAS endpoints. This option is additive with the online-url-list option\n--data-availability.rest-aggregator.sync-to-storage.check-already-exists\tWhen using a REST aggregator, checks if the data already exists in this DAS's storage. Must be disabled for fast sync with an IPFS backend (default true)\n--data-availability.rest-aggregator.sync-to-storage.eager\tWhen using a REST aggregator, eagerly syncs batch data to this DAS's storage from the REST endpoints, using the parent chain as the index of batch data hashes; otherwise only syncs lazily\n--data-availability.rest-aggregator.sync-to-storage.eager-lower-bound-block\tWhen using a REST aggregator that's eagerly syncing, starts indexing forward from this block from the parent chain. Only used if there is no sync state.\n--data-availability.rest-aggregator.sync-to-storage.retention-period\tWhen using a REST aggregator, period to retain the synced data (defaults to forever)\n--data-availability.rest-aggregator.sync-to-storage.state-dir\tWhen using a REST aggregator, directory to store the sync state in, i.e. the block number currently synced up to, so that it doesn't sync from scratch each time\n\nTo enable caching, you can use the following parameters:\n\nParameter\tDescription\n--data-availability.local-cache.enable\tEnables local in-memory caching of sequencer batch data\n--data-availability.local-cache.capacity\tMaximum number of entries (up to 64KB each) to store in the cache. (default 20000)\n\nFinally, for the storage backends you wish to configure, use the following parameters. Toggle between the different options to see all available parameters.\n\nLOCAL BADGER DATABASE DEPRECATED\n\nThe local badger DB storage option (set with local-db-storage) has been deprecated and should be replaced with the local files storage option (set with local-file-storage).\n\nA migration tool has been included in Nitro to migrate all data from the local badger db to local files. You can activate it by using the parameter --data-availability.migrate-local-db-to-file-storage.\n\nAWS S3 bucket\nLocal files\n(Deprecated) Local Badger database\nParameter\tDescription\n--data-availability.s3-storage.enable\tEnables storage/retrieval of sequencer batch data from an AWS S3 bucket\n--data-availability.s3-storage.access-key\tS3 access key\n--data-availability.s3-storage.bucket\tS3 bucket\n--data-availability.s3-storage.region\tS3 region\n--data-availability.s3-storage.secret-key\tS3 secret key\n--data-availability.s3-storage.object-prefix\tPrefix to add to S3 objects\n--data-availability.s3-storage.discard-after-timeout\tWhether to discard data after its expiry timeout (setting it to false, activates the “archive” mode)\n\nHere's an example daserver command for a mirror DAS that:\n\nEnables local cache\nEnables AWS S3 bucket storage that doesn't discard data after expiring (archive)\nEnables local file storage that, by default, doesn't discard data after expiring (archive)\nUses a local main DAS as part of the REST aggregator\ndaserver\n    --data-availability.parent-chain-node-url \"<YOUR PARENT CHAIN RPC ENDPOINT>\"\n    --data-availability.sequencer-inbox-address \"<ADDRESS OF SEQUENCERINBOX ON PARENT CHAIN>\"\n    --enable-rest\n    --rest-addr '0.0.0.0'\n    --log-level 3\n    --data-availability.local-cache.enable\n    --data-availability.rest-aggregator.enable\n    --data-availability.rest-aggregator.urls \"http://your-main-das.svc.cluster.local:9877\"\n    --data-availability.rest-aggregator.online-url-list \"<URL TO LIST OF REST ENDPOINTS>\"\n    --data-availability.rest-aggregator.sync-to-storage.eager\n    --data-availability.rest-aggregator.sync-to-storage.eager-lower-bound-block \"BLOCK NUMBER\"\n    --data-availability.rest-aggregator.sync-to-storage.state-dir /home/user/data/syncState\n    --data-availability.s3-storage.enable\n    --data-availability.s3-storage.access-key \"<YOUR ACCESS KEY>\"\n    --data-availability.s3-storage.bucket \"<YOUR BUCKET>\"\n    --data-availability.s3-storage.region \"<YOUR REGION>\"\n    --data-availability.s3-storage.secret-key \"<YOUR SECRET KEY>\"\n    --data-availability.s3-storage.object-prefix \"<YOUR OBJECT KEY PREFIX>/\"\n    --data-availability.s3-storage.discard-after-timeout false\n    --data-availability.local-file-storage.enable\n    --data-availability.local-file-storage.data-dir /home/user/data/das-data\n\n\nAnd here's an example of how to use a k8s deployment to run that command:\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n    name: das-mirror\nspec:\n    replicas: 1\n    selector:\n    matchLabels:\n        app: das-mirror\n    strategy:\n    rollingUpdate:\n        maxSurge: 0\n        maxUnavailable: 50%\n    type: RollingUpdate\n    template:\n    metadata:\n        labels:\n        app: das-mirror\n    spec:\n        containers:\n        - command:\n        - bash\n        - -c\n        - |\n            mkdir -p /home/user/data/badgerdb\n            mkdir -p /home/user/data/syncState\n            /usr/local/bin/daserver --data-availability.parent-chain-node-url \"<YOUR PARENT CHAIN RPC ENDPOINT>\" --data-availability.sequencer-inbox-address \"<ADDRESS OF SEQUENCERINBOX ON PARENT CHAIN>\" --enable-rest --rest-addr '0.0.0.0' --log-level 3 --data-availability.local-cache.enable --data-availability.rest-aggregator.enable --data-availability.rest-aggregator.urls \"http://your-main-das.svc.cluster.local:9877\" --data-availability.rest-aggregator.online-url-list \"<URL TO LIST OF REST ENDPOINTS>\" --data-availability.rest-aggregator.sync-to-storage.eager  --data-availability.rest-aggregator.sync-to-storage.eager-lower-bound-block \"BLOCK NUMBER\" --data-availability.rest-aggregator.sync-to-storage.state-dir /home/user/data/syncState --data-availability.s3-storage.enable --data-availability.s3-storage.access-key \"<YOUR ACCESS KEY>\" --data-availability.s3-storage.bucket \"<YOUR BUCKET>\" --data-availability.s3-storage.region \"<YOUR REGION>\" --data-availability.s3-storage.secret-key \"<YOUR SECRET KEY>\" --data-availability.s3-storage.object-prefix \"<YOUR OBJECT KEY PREFIX>/\" --data-availability.local-file-storage.enable --data-availability.local-file-storage.data-dir /home/user/data/das-data\n        image: offchainlabs/nitro-node:v3.2.1-d81324d\n        imagePullPolicy: Always\n        resources:\n            limits:\n            cpu: \"4\"\n            memory: 10Gi\n            requests:\n            cpu: \"4\"\n            memory: 10Gi\n        ports:\n        - containerPort: 9877\n            hostPort: 9877\n            protocol: TCP\n        volumeMounts:\n        - mountPath: /home/user/data/\n            name: data\n        readinessProbe:\n            failureThreshold: 3\n            httpGet:\n            path: /health/\n            port: 9877\n            scheme: HTTP\n            initialDelaySeconds: 5\n            periodSeconds: 5\n            successThreshold: 1\n            timeoutSeconds: 1\n        volumes:\n        - name: data\n        persistentVolumeClaim:\n            claimName: das-mirror\n\nArchive DA servers​\n\nArchive DA servers are servers that don't discard any data after expiring. Each DAC should have at the very least one archive DAS to ensure all historical data is available.\n\nTo activate the \"archive mode\" in your DAS, set the parameter discard-after-timeout to false in your storage method. For example:\n\n--data-availability.s3-storage.discard-after-timeout=false\n\n\nNote that local-file-storage doesn't discard data after expiring by default, but expiration can be enabled with enable-expiry.\n\nArchive servers should make use of the --data-availability.rest-aggregator.sync-to-storage options described above to pull in any data that they don't have.\n\nHelm charts​\n\nA helm chart is available at ArtifactHUB. It supports running a mirror DAS by providing the parameters for your server. Find more information in the OCL community Helm charts repository.\n\nTesting the DAS​\n\nOnce the DAS is running, we can test if everything is working correctly using the following methods.\n\nTest 1: REST health check​\n\nThe REST interface enabled in the mirror DAS has a health check on the path /health which will return 200 if the underlying storage is working, otherwise 503.\n\nExample:\n\ncurl -I <YOUR REST ENDPOINT>/health\n\nSecurity considerations​\n\nKeep in mind the following information when running the mirror DAS.\n\nFor a mirror DAS, using a load balancer is recommended to manage incoming traffic effectively. Additionally, as the REST interface is cacheable, consider deploying a Content Delivery Network (CDN) or caching proxy in front of your REST endpoint. The URL for the REST interface will be publicly known; ensure that it is sufficiently distinct from the RPC endpoint to prevent the latter from being easily discovered.\n\nWhat to do next?​\n\nOnce the DAS is deployed and tested, you'll have to communicate the following information to the chain owner, so they can update the chain parameters and configure the sequencer:\n\nThe https URL for the REST endpoint (e.g. das.your-chain.io/rest)\nOptional parameters​\n\nBesides the parameters described in this guide, there are some more options that can be useful when running the DAS. For a comprehensive list of configuration parameters, you can run daserver --help.\n\nParameter\tDescription\n--conf.dump\tPrints out the current configuration\n--conf.file\tAbsolute path to the configuration file inside the volume to use instead of specifying all parameters in the command\nMetrics​\n\nThe DAS comes with the option of producing Prometheus metrics. This option can be activated by using the following parameters:\n\nParameter\tDescription\n--metrics\tEnables the metrics server\n--metrics-server.addr\tMetrics server address (default \"127.0.0.1\")\n--metrics-server.port\tMetrics server port (default 6070)\n--metrics-server.update-interval\tMetrics server update interval (default 3s)\n\nWhen metrics are enabled, several useful metrics are available at the configured port, at path debug/metrics or debug/metrics/prometheus.\n\nRPC metrics​\nMetric\tDescription\narb_das_rpc_store_requests\tCount of RPC Store calls\narb_das_rpc_store_success\tSuccessful RPC Store calls\narb_das_rpc_store_failure\tFailed RPC Store calls\narb_das_rpc_store_bytes\tBytes retrieved with RPC Store calls\narb_das_rpc_store_duration (p50, p75, p95, p99, p999, p9999)\tDuration of RPC Store calls (ns)\nREST metrics​\nMetric\tDescription\narb_das_rest_getbyhash_requests\tCount of REST GetByHash calls\narb_das_rest_getbyhash_success\tSuccessful REST GetByHash calls\narb_das_rest_getbyhash_failure\tFailed REST GetByHash calls\narb_das_rest_getbyhash_bytes\tBytes retrieved with REST GetByHash calls\narb_das_rest_getbyhash_duration (p50, p75, p95, p99, p999, p9999)\tDuration of REST GetByHash calls (ns)\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nDeploy a Data Availability Server (DAS)\nNext\nConfigure a Data Availability Committee (DAC)\nWhat is a mirror DAS?\nConfiguration options\nHow to deploy a mirror DAS\nStep 0: Prerequisites\nStep 1: Set up a persistent volume\nStep 2: Deploy the mirror DAS\nArchive DA servers\nHelm charts\nTesting the DAS\nTest 1: REST health check\nSecurity considerations\nWhat to do next?\nOptional parameters\nMetrics\nRPC metrics\nREST metrics\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/data-availability-committees/deploy-das",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nGet started\nDeploy a Data Availability Server (DAS)\nDeploy a mirror Data Availability Server\nConfigure a Data Availability Committee (DAC)\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to deploy a Data Availability Server (DAS)\n\nAnyTrust chains rely on an external Data Availability Committee (DAC) to store data and provide it on-demand instead of using its parent chain as the Data Availability (DA) layer. The members of the DAC run a Data Availability Server (DAS) to handle these operations.\n\nIn this how-to, you'll learn how to deploy a DAS that exposes:\n\nAn RPC interface that the sequencer uses to store batches of data on the DAS.\nAn HTTP REST interface that lets the DAS respond to requests for those batches of data.\n\nFor more information related to configuring a DAC, refer to the Introduction.\n\nThis how-to assumes that you're familiar with:\n\nThe DAC's role in the AnyTrust protocol. Refer to Inside AnyTrust for a refresher.\nKubernetes. The examples in this guide use Kubernetes to containerize your DAS.\nHow does a DAS work?​\n\nA Data Availability Server (DAS) allows storage and retrieval of transaction data batches for an AnyTrust chain. It's the software that the members of the DAC run in order to provide the Data Availability service.\n\nDA servers accept time-limited requests to store data batches from the sequencer of an AnyTrust chain, and return a signed certificate promising to store that data during the established time. They also respond to requests to retrieve the data batches.\n\nConfiguration options​\n\nWhen setting up a DAS, there are certain options you can configure to suit your infrastructure needs:\n\nInterfaces available in a DAS​\n\nThere are two main interfaces that can be enabled in a DAS: an RPC interface to store data in the DAS, intended to be used only by the AnyTrust sequencer; and a REST interface that supports only GET operations and is intended for public use.\n\nDA servers listen on two primary interfaces:\n\nIts RPC interface listens for das_store RPC messages coming from the sequencer. Messages are signed by the sequencer, and the DAS checks this signature upon receipt.\nIts REST interface respond to HTTP GET requests pointed at /get-by-hash/<hex encoded data hash>. This uses the hash of the data batch as a unique identifier, and will always return the same data for a given hash.\nStorage options​\n\nA DAS can be configured to use one or more of four storage backends:\n\nAWS S3 bucket\nFiles on local disk\n(DEPRECATED) Badger database on local disk\nLOCAL BADGER DATABASE DEPRECATED\n\nThe local Badger DB storage option (set with local-db-storage) has been deprecated and should be replaced with the local files storage option (set with local-file-storage).\n\nA migration tool has been included in Nitro to migrate all data from the local badger db to local files. You can activate it by using the parameter --data-availability.migrate-local-db-to-file-storage.\n\nIf more than one option is selected, store requests must succeed to all of them for it to be considered successful, while retrieve requests only require one of them to succeed.\n\nIf there are other storage backends you'd like us to support, send us a message on Discord, or contribute directly to the Nitro repository.\n\nCaching​\n\nAn in-memory cache can be enabled to avoid needing to access underlying storage for retrieve requests.\n\nRequests sent to the REST interface (to retrieve data from the DAS) always return the same data for a given hash, so the result is cacheable. It also contains a cache-control header specifying that the object is immutable and to cache it for up to 28 days.\n\nState synchronization​\n\nDA servers also have an optional REST aggregator which, when a data batch is not found in cache or storage, requests that batch to other REST servers defined in a list and stores that batch upon receiving it. This is how a DAS that misses storing a batch (the AnyTrust protocol doesn't require all of them to report success in order to post the batch's certificate to the parent chain) can automatically repair gaps in the data it stores, and also how a mirror DAS can sync its data. A public list of REST endpoints is published online, which the DAS can be configured to download and use, and additional endpoints can be specified in the configuration.\n\nHow to deploy the DAS​\nStep 0: Prerequisites​\n\nGather the following information:\n\nThe latest Nitro docker image: offchainlabs/nitro-node:v3.2.1-d81324d\nAn RPC endpoint for the parent chain. It is recommended to use a third-party provider RPC or run your own node to prevent being rate limited.\nThe SequencerInbox contract address in the parent chain.\nIf you wish to configure a REST aggregator for your DAS, you'll need the URL where the list of REST endpoints is kept.\nStep 1: Generate the BLS keypair​\n\nNext, we'll generate a BLS keypair. The private key will be used to sign the Data Availability Certificates (DACert) when receiving requests to store data, and the public key will be used to prove that the DACert was signed by the DAS. The BLS private key is sensitive and care must be taken to ensure it is generated and stored in a safe environment.\n\nThe BLS keypair must be generated using the datool keygen utility. Later, it will be passed to the DAS by file or command line.\n\nWhen running the key generator, we'll specify the --dir parameter with the absolute path to the directory inside the volume to store the keys in.\n\nHere's an example of how to use the datool keygen utility inside Docker and store the key that will be used by the DAS in the next step.\n\ndocker run -v $(pwd)/bls_keys:/data/keys --entrypoint datool \\\noffchainlabs/nitro-node:v3.2.1-d81324d keygen --dir /data/keys\n\nStep 2: Deploy the DAS​\n\nTo run the DAS, we'll use the daserver tool and we'll configure the following parameters:\n\nParameter\tDescription\n--data-availability.parent-chain-node-url\tRPC endpoint of a parent chain node\n--data-availability.sequencer-inbox-address\tAddress of the SequencerInbox in the parent chain\n--data-availability.key.key-dir\tThe absolute path to the directory inside the volume to read the BLS keypair ('das_bls.pub' and 'das_bls') from\n--enable-rpc\tEnables the HTTP-RPC server listening on --rpc-addr and --rpc-port\n--rpc-addr\tHTTP-RPC server listening interface (default \"localhost\")\n--rpc-port\t(Optional) HTTP-RPC server listening port (default 9876)\n--enable-rest\tEnables the REST server listening on --rest-addr and --rest-port\n--rest-addr\tREST server listening interface (default \"localhost\")\n--rest-port\t(Optional) REST server listening port (default 9877)\n--log-level\tLog level: 1 - ERROR, 2 - WARN, 3 - INFO, 4 - DEBUG, 5 - TRACE (default 3)\n\nTo enable caching, you can use the following parameters:\n\nParameter\tDescription\n--data-availability.local-cache.enable\tEnables local in-memory caching of sequencer batch data\n--data-availability.local-cache.capacity\tMaximum number of entries (up to 64KB each) to store in the cache. (default 20000)\n\nTo enable the REST aggregator, use the following parameters:\n\nParameter\tDescription\n--data-availability.rest-aggregator.enable\tEnables retrieval of sequencer batch data from a list of remote REST endpoints\n--data-availability.rest-aggregator.online-url-list\tA URL to a list of URLs of REST DAS endpoints that is checked at startup. This option is additive with the urls option\n--data-availability.rest-aggregator.urls\tList of URLs including 'http://' or 'https://' prefixes and port numbers to REST DAS endpoints. This option is additive with the online-url-list option\n--data-availability.rest-aggregator.sync-to-storage.check-already-exists\tWhen using a REST aggregator, checks if the data already exists in this DAS's storage. Must be disabled for fast sync with an IPFS backend (default true)\n--data-availability.rest-aggregator.sync-to-storage.eager\tWhen using a REST aggregator, eagerly syncs batch data to this DAS's storage from the REST endpoints, using the parent chain as the index of batch data hashes; otherwise only syncs lazily\n--data-availability.rest-aggregator.sync-to-storage.eager-lower-bound-block\tWhen using a REST aggregator that's eagerly syncing, starts indexing forward from this block from the parent chain. Only used if there is no sync state.\n--data-availability.rest-aggregator.sync-to-storage.retention-period\tWhen using a REST aggregator, period to retain the synced data (defaults to forever)\n--data-availability.rest-aggregator.sync-to-storage.state-dir\tWhen using a REST aggregator, directory to store the sync state in, i.e. the block number currently synced up to, so that it doesn't sync from scratch each time\n\nFinally, for the storage backends you wish to configure, use the following parameters. Toggle between the different options to see all available parameters.\n\nAWS S3 bucket\nLocal files\n(Deprecated) Local Badger database\nParameter\tDescription\n--data-availability.s3-storage.enable\tEnables storage/retrieval of sequencer batch data from an AWS S3 bucket\n--data-availability.s3-storage.access-key\tS3 access key\n--data-availability.s3-storage.bucket\tS3 bucket\n--data-availability.s3-storage.region\tS3 region\n--data-availability.s3-storage.secret-key\tS3 secret key\n--data-availability.s3-storage.object-prefix\tPrefix to add to S3 objects\n--data-availability.s3-storage.discard-after-timeout\tWhether to discard data after its expiry timeout (setting it to false, activates the “archive” mode)\n\nHere's an example daserver command for a DAS that:\n\nEnables both interfaces: RPC and REST\nEnables local cache\nEnables a REST aggregator\nEnables AWS S3 bucket storage\nEnables local files storage\ndaserver\n    --data-availability.parent-chain-node-url \"<YOUR PARENT CHAIN RPC ENDPOINT>\"\n    --data-availability.sequencer-inbox-address \"<ADDRESS OF SEQUENCERINBOX ON PARENT CHAIN>\"\n    --data-availability.key.key-dir /home/user/data/keys\n    --enable-rpc\n    --rpc-addr '0.0.0.0'\n    --log-level 3\n    --enable-rest\n    --rest-addr '0.0.0.0'\n    --data-availability.local-cache.enable\n    --data-availability.rest-aggregator.enable\n    --data-availability.rest-aggregator.online-url-list \"<URL TO LIST OF REST ENDPOINTS>\"\n    --data-availability.s3-storage.enable\n    --data-availability.s3-storage.access-key \"<YOUR ACCESS KEY>\"\n    --data-availability.s3-storage.bucket \"<YOUR BUCKET>\"\n    --data-availability.s3-storage.region \"<YOUR REGION>\"\n    --data-availability.s3-storage.secret-key \"<YOUR SECRET KEY>\"\n    --data-availability.s3-storage.object-prefix \"<YOUR OBJECT KEY PREFIX>/\"\n    --data-availability.local-file-storage.enable\n    --data-availability.local-file-storage.data-dir /home/user/data/das-data\n\n\nAnd here's an example of how to use a k8s deployment to run that command:\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: das-server\nspec:\nreplicas: 1\nselector:\n    matchLabels:\n    app: das-server\nstrategy:\n    rollingUpdate:\n    maxSurge: 0\n    maxUnavailable: 50%\n    type: RollingUpdate\ntemplate:\n    metadata:\n    labels:\n        app: das-server\n    spec:\n    containers:\n    - command:\n        - bash\n        - -c\n        - |\n        mkdir -p /home/user/data/badgerdb\n        /usr/local/bin/daserver --data-availability.parent-chain-node-url \"<YOUR PARENT CHAIN RPC ENDPOINT>\" --data-availability.sequencer-inbox-address \"<ADDRESS OF SEQUENCERINBOX ON PARENT CHAIN>\" --data-availability.key.key-dir /home/user/data/keys --enable-rpc --rpc-addr '0.0.0.0' --log-level 3 --enable-rest --rest-addr '0.0.0.0' --data-availability.local-cache.enable --data-availability.rest-aggregator.enable --data-availability.rest-aggregator.online-url-list \"<URL TO LIST OF REST ENDPOINTS>\" --data-availability.s3-storage.enable --data-availability.s3-storage.access-key \"<YOUR ACCESS KEY>\" --data-availability.s3-storage.bucket \"<YOUR BUCKET>\" --data-availability.s3-storage.region \"<YOUR REGION>\" --data-availability.s3-storage.secret-key \"<YOUR SECRET KEY>\" --data-availability.s3-storage.object-prefix \"<YOUR OBJECT KEY PREFIX>/\" --data-availability.s3-storage.discard-after-timeout false --data-availability.local-file-storage.enable --data-availability.local-file-storage.data-dir /home/user/data/das-data\n        image: offchainlabs/nitro-node:v3.2.1-d81324d\n        imagePullPolicy: Always\n        resources:\n        limits:\n            cpu: \"4\"\n            memory: 10Gi\n        requests:\n            cpu: \"4\"\n            memory: 10Gi\n        ports:\n        - containerPort: 9876\n        hostPort: 9876\n        protocol: TCP\n        - containerPort: 9877\n        hostPort: 9877\n        protocol: TCP\n        volumeMounts:\n        - mountPath: /home/user/data/\n        name: data\n        readinessProbe:\n        failureThreshold: 3\n        httpGet:\n            path: /health/\n            port: 9877\n            scheme: HTTP\n        initialDelaySeconds: 5\n        periodSeconds: 5\n        successThreshold: 1\n        timeoutSeconds: 1\n    volumes:\n    - name: data\n        persistentVolumeClaim:\n        claimName: das-server\n\nArchive DA servers​\n\nArchive DA servers are servers that don't discard any data after expiring. Each DAC should have at the very least one archive DAS to ensure all historical data is available.\n\nTo activate the \"archive mode\" in your DAS, set the parameter discard-after-timeout to false in your storage method. For example:\n\n--data-availability.s3-storage.discard-after-timeout=false\n\n\nNote that local-file-storage doesn't discard data after expiring by default, but expiration can be enabled with enable-expiry.\n\nArchive servers should make use of the --data-availability.rest-aggregator.sync-to-storage options described above to pull in any data that they don't have.\n\nHelm charts​\n\nA helm chart is available at ArtifactHUB. It supports running a DAS by providing the BLS key and the parameters for your server. Find more information in the OCL community Helm charts repository.\n\nTesting the DAS​\n\nOnce the DAS is running, we can test if everything is working correctly using the following methods.\n\nTest 1: RPC health check​\n\nThe RPC interface enabled in the DAS has a health check for the underlying storage that can be invoked by using the RPC method  das_healthCheck that returns a status 200 if the DAS is active.\n\nExample:\n\ncurl -X POST \\\n     -H 'Content-Type: application/json' \\\n     -d '{\"jsonrpc\":\"2.0\",\"id\":0,\"method\":\"das_healthCheck\",\"params\":[]}' \\\n     <YOUR RPC ENDPOINT>\n\nTest 2: Store and retrieve data​\n\nThe RPC interface of the DAS validates that requests to store data are signed by the sequencer's ECDSA key, identified via a call to the SequencerInbox contract on the parent chain. It can also be configured to accept store requests signed with another ECDSA key of your choosing. This could be useful for running load tests, canaries, or troubleshooting your own infrastructure.\n\nUsing this facility, a load test could be constructed by writing a script to store arbitrary amounts of data at an arbitrary rate; a canary could be constructed to store and retrieve data on some interval. We show here a short guide on how to do that.\n\nStep 1: Generate an ECDSA keypair​\n\nFirst we'll generate an ECDSA keypair with datool keygen. Create a folder inside /some/local/dir to store the ECDSA keypair, for example /some/local/dir/keys. Then run datool keygen:\n\ndatool keygen --dir /some/local/dir/keys --ecdsa\n\n\nYou can also use the docker run command as follows:\n\ndocker run --rm -it -v /some/local/dir:/home/user/data --entrypoint datool offchainlabs/nitro-node:v3.2.1-d81324d keygen --dir /home/user/data/keys --ecdsa\n\nStep 2: Change the DAS configuration and restart the server​\n\nAdd the following configuration parameter to daserver:\n\n--data-availability.extra-signature-checking-public-key /some/local/dir/keys/ecdsa.pub\n\n\nOR\n\n--data-availability.extra-signature-checking-public-key \"0x<contents of ecdsa.pub>\"\n\n\nAnd then restart it.\n\nStep 3: Store data signed with the ECDSA private key​\n\nNow you can use the datool utility to send store requests signed with the ECDSA private key:\n\ndatool client rpc store  --url http://localhost:9876 --message \"Hello world\" --signing-key /some/local/dir/keys/ecdsa\n\n\nOR\n\ndatool client rpc store  --url http://localhost:9876 --message \"Hello world\" --signing-key \"0x<contents of ecdsa>\"\n\n\nYou can also use the docker run command:\n\ndocker run --rm -it -v /some/local/dir:/home/user/data --network=\"host\" --entrypoint datool offchainlabs/nitro-node:v3.2.1-d81324d client rpc store --url http://localhost:9876 --message \"Hello world\" --signing-key /home/user/data/keys/ecdsa\n\n\nThe above command will output the Hex Encoded Data Hash which can then be used to retrieve the data in the next step.\n\nStep 4: Retrieve the stored data​\n\nUse again the datool to retrieve the stored data. Notice that to perform this step you must have the REST interface enabled in the DAS:\n\ndatool client rest getbyhash --url http://localhost:9877 --data-hash 0xDataHash\n\n\nYou can also use the docker run command:\n\ndocker run --rm -it --network=\"host\" --entrypoint datool offchainlabs/nitro-node:v3.2.1-d81324d client rest getbyhash --url http://localhost:9877 --data-hash 0xDataHash\n\n\nIf we set 0xDataHash to 0x052cca0e379137c975c966bcc69ac8237ac38dc1fcf21ac9a6524c87a2aab423 (from the previous step), then the result should be: Message: Hello world\n\nThe retention period defaults to 24 hours, but can be configured when calling datool client rpc store with the parameter --das-retention-period and the number of milliseconds for the retention period.\n\nTest 3: REST health check​\n\nThe REST interface has a health check on the path /health which will return a status 200 if the underlying storage is working, otherwise 503.\n\nExample:\n\ncurl -I <YOUR REST ENDPOINT>/health\n\nTest 4: Retrieve data from a batch poster transaction​\n\nYou can also do a test to retrieve the transaction data posted by a batch poster transaction. The transaction will contain both keyset and data hash information in its data field in method addSequencerL2BatchFromOrigin(uint256 sequenceNumber, bytes data,uint256 afterDelayedMessagesRead, address gasRefunder,uint256 prevMessageCount,uint256 newMessageCount).\n\nAfter you decode a batch poster transaction and get its data within the function data, you can continue to decode the data as follows:\n\nThe first part (1 byte) is the header flag, which is used to specify which type of batch it is. Here we need to check if it has bit 0x80 (For example, 0x88 and 0x80 are both valid, but 0x55 is wrong).\n\nThe second part (32 bytes) is the keyset hash. You can learn more about what keyset is here.\n\nThe third part (32 bytes) is the data hash, and this is what we need to retrieve data. When you get this hash, you can retrieve data directly by following what we demonstrate in Step 4.\n\nRunning a mirror DAS​\n\nTo avoid exposing the REST interface of your main DAS to the public in order to prevent spamming attacks (as explained in Security considerations), you can choose to run a mirror DAS to complement your setup. The mirror DAS will handle all public REST requests, while reading information from the main DAS via its (now private) REST interface.\n\nIn general, mirror DA servers serve two main purposes:\n\nPrevent the main DAS from having to serve requests for data, allowing it to focus only on storing the data received.\nProvide resiliency to the network in the case of a DAS going down.\n\nFind information about how to setup a mirror DAS in How to deploy a mirror DAS.\n\nSecurity considerations​\n\nKeep in mind the following information when running the DAS.\n\nA DAS should strive not to miss any batch of information sent by the sequencer. Although it can use a REST aggregator to fetch missing information from other DA servers, it should aim to synchronize all received information directly. To facilitate this, avoid placing any load balancing layer before the DAS, enabling it to handle all incoming traffic.\n\nTaking that into account, there's a risk of Denial of Service attacks on those servers if the endpoint for the RPC interface is publicly known. To mitigate this risk, ensure the RPC endpoint's URL is not easily discoverable. It should be known only to the sequencer. Share this information with the chain owner through a private channel to maintain security.\n\nFinally, as explained in the previous section, if you're also running a mirror DAS, there's no need to publicly expose the REST interface of your main DAS. Your mirrors can synchronize over your private network using the REST interface from your main DAS and other public mirrors.\n\nOther considerations​\nWhen using nginx in the networking stack, a DAS might fail receiving batches that are over a certain size. If this happens, the DAS won't be able to sign any more certificates and the batch poster will receive an error 413 Request Entity Too Large. To prevent this behavior, the parameter client_max_body_size from nginx configuration should be configured with a higher value than the default 1M. It's recommended to set it to at least 50M.\nWhat to do next?​\n\nOnce the DAS is deployed and tested, you'll have to communicate the following information to the chain owner, so they can update the chain parameters and configure the sequencer:\n\nPublic key\nThe https URL for the RPC endpoint which includes some random string (e.g. das.your-chain.io/rpc/randomstring123), communicated through a secure channel\nThe https URL for the REST endpoint (e.g. das.your-chain.io/rest)\nOptional parameters​\n\nBesides the parameters described in this guide, there are some more options that can be useful when running the DAS. For a comprehensive list of configuration parameters, you can run daserver --help.\n\nParameter\tDescription\n--conf.dump\tPrints out the current configuration\n--conf.file\tAbsolute path to the configuration file inside the volume to use instead of specifying all parameters in the command\nMetrics​\n\nThe DAS comes with the option of producing Prometheus metrics. This option can be activated by using the following parameters:\n\nParameter\tDescription\n--metrics\tEnables the metrics server\n--metrics-server.addr\tMetrics server address (default \"127.0.0.1\")\n--metrics-server.port\tMetrics server port (default 6070)\n--metrics-server.update-interval\tMetrics server update interval (default 3s)\n\nWhen metrics are enabled, several useful metrics are available at the configured port, at path debug/metrics or debug/metrics/prometheus.\n\nRPC metrics​\nMetric\tDescription\narb_das_rpc_store_requests\tCount of RPC Store calls\narb_das_rpc_store_success\tSuccessful RPC Store calls\narb_das_rpc_store_failure\tFailed RPC Store calls\narb_das_rpc_store_bytes\tBytes retrieved with RPC Store calls\narb_das_rpc_store_duration (p50, p75, p95, p99, p999, p9999)\tDuration of RPC Store calls (ns)\nREST metrics​\nMetric\tDescription\narb_das_rest_getbyhash_requests\tCount of REST GetByHash calls\narb_das_rest_getbyhash_success\tSuccessful REST GetByHash calls\narb_das_rest_getbyhash_failure\tFailed REST GetByHash calls\narb_das_rest_getbyhash_bytes\tBytes retrieved with REST GetByHash calls\narb_das_rest_getbyhash_duration (p50, p75, p95, p99, p999, p9999)\tDuration of REST GetByHash calls (ns)\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nGet started\nNext\nDeploy a mirror Data Availability Server\nHow does a DAS work?\nConfiguration options\nInterfaces available in a DAS\nStorage options\nCaching\nState synchronization\nHow to deploy the DAS\nStep 0: Prerequisites\nStep 1: Generate the BLS keypair\nStep 2: Deploy the DAS\nArchive DA servers\nHelm charts\nTesting the DAS\nTest 1: RPC health check\nTest 2: Store and retrieve data\nTest 3: REST health check\nTest 4: Retrieve data from a batch poster transaction\nRunning a mirror DAS\nSecurity considerations\nOther considerations\nWhat to do next?\nOptional parameters\nMetrics\nRPC metrics\nREST metrics\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "ArbOS 20 Atlas | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/arbos-releases/arbos20",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nOverview\nArbOS 32 Bianca\nArbOS 20 Atlas\nArbOS 11\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nArbOS 20 Atlas\n\nArbOS 20 Atlas is shipped via Nitro v2.3.1, which is available on Docker hub with the image tag: offchainlabs/nitro-node:v2.3.1-26fad6f. This release of Nitro is a mandatory upgrade for Arbitrum One and Nova validators. For Arbitrum One and Nova, the ArbOS 20 upgrade requires a governance vote to activate.\n\nRequirements:​\nNitro v2.3.1 or higher\nnitro-contracts v1.2.1 or higher\nWasm module root: 0x8b104a2e80ac6165dc58b9048de12f301d70b02a0ab51396c22b4b4b802a16a4\nAccess to the Ethereum Beacon Chain APIs, either from your own self-managed L1 Ethereum node or from a 3rd party provider like those on this list.\nHigh-level description of ArbOS 20 changes​\n\nArbOS 20 is an upgrade to enable Arbitrum's support for L1 Ethereum's Dencun upgrade scheduled for March 2024. As a result, all of the ArbOS specific changes revolve around implementing the majority of the Cancun EIPs on Arbitrum:\n\nEnable Arbitrum chains to batch and post transaction data in the form of Blobs to L1 Ethereum, to support EIP-4844. This includes updates to the Sequencer Inbox contract to support posting transactions in the form of blobs, updating Nitro's fraud prover to support proving additional hashes (KZG and SHA256 preimages), and updates to the core Nitro node software to handle parsing data from EIP-4844 blobs.\nAddition of the TSTORE and TLOAD EVM opcodes introduced in EIP-1153 offering a cheaper option than storage for data that’s discarded at the end of a transaction.\nAddition of the MCOPY EVM opcode introduced in EIP-5656 for cheaper memory copying.\nChanges to the SELFDESTRUCT EVM opcode to reflect the behavior on L1 Ethereum, as outlined in EIP-6780.\nAddition of a batch poster manager role that will have the ability to grant and revoke batch-posting affordances. This role is assigned to the operator of the sequencer to allow the batch poster manager perform key rotations for the batch posters. The DAO will continue to have the ability to revoke the seqauencer role, meaning there is no change to the current system's trust model since the DAO ca update the batch poster manager at any time (along with any batch posters).\nIncreasing the max block height that a batch can be posted, relative to the current block, to 64 bringing this in line with Ethereum's finality guarantees. The current value of 12 was set prior to the Ethereum merge and could mean that a small L1 reorg can cause an otherwise valid batch to revert.\nFix Sequencer Inbox bug: when posting a batch, the Sequencer provides the \"newMessageCount” value as a parameter; if the Sequencer is malicious, it can provide the max uint256 value which in turn would make subsequent calls to forceInclusion revert with an overflow error. Atlas’s upgrade to the Sequencer inbox includes a change) in which forceInclusion does not modify the message count, fixing this bug. This bug had been disclosed to Arbitrum RaaS providers and to the Arbitrum DAO Security Council.\nSpecial notes on ArbOS 20: Atlas support for EIP-4844​\nUpgrading to the Atlas ArbOS release will require access to L1 Ethereum beacon chain endpoints to retrieve blob data. For nodes of a chain that come online 18 days after Atlas gets activated on their chain will need access to historical data to sync up to the latest state. If you are not operating your own Ethereum consensus client, please visit this page to view a list of beacon chain RPC providers where you can access blob data.\nApplications on Arbitrum will not have to be modified or take any explicit action to get the benefits of using EIP-4844 (i.e. the whole chain opts-in with ArbOS 20 “Atlas”).\nArbOS 20 “Atlas” adds support for Arbitrum chains to send data in a blob storage format to data availability layers, like L1 Ethereum, that support the blob transaction type. This includes Arbitrum One and Arbitrum Nova. ArbOS 20 “Atlas” does not add support for Arbitrum chains to receive data in a blob storage format. This means that an L3 Orbit chain on top of an Arbitrum L2 will use calldata when posting L3 transaction data to the underlying L2. The L2 Arbitrum chain will then be able to post data to a L1 data availability layer like Ethereum using blobs.\nThere currently aren’t estimates on what the end-user gas savings of using blob data will be. This topic is something being actively worked on and monitored. Without Mainnet data, the estimates for blob gas prices will not be accurate enough to reliably predict the cost reductions that users will experience - and even with Mainnet data, the savings will vary by use case (i.e. no current way to predict the price impacts from all blob gas market participants yet). In general, however, the use of blobs will reduce the cost of using Arbitrum L2s. To learn more about what EIP-4844 will mean for L2 users, please checkout this blog post on Medium by Offchain Lab's Co-foudner and Chief Scientist Ed Felten.\nBlock explorers​\n\nBelow is a non-comprehensive list of explorers that support querying and viewing blob data on Ethereum that get posted by Arbitrum L2 chains.\n\nBlockscout. For self-deployment, blobs are supported as of blockscout v6.2.0 and blockscout-frontend v1.2.6.\nArbiscan\nBlobscan\nBeaconcha.in\nAdditional requirement for Arbitrum Orbit L2 chain operators: enabling blob batch posting​\n\nThis section maps to Step 4 in the guide on How to upgrade ArbOS on your Arbitrum Orbit L2 chain and contains additional instructions for Arbitrum Orbit L2 chain operators for ArbOS 20 Atlas. Specifically, the details below are meant to help Arbitrum Orbit L2 chain operators enable blob batch posting to L1 Ethereum following their successful upgrade to the ArbOS 20 Atlas release.\n\nCAUTION\n\nBefore proceeding, make sure you have successfully completed Steps 1 through 3 of the guide on How to upgrade ArbOS on your Orbit chain.\n\nTo enable the posting of transaction data in Blobs to L1 Ethereum, you must set node.batch-poster.post-4844-blobs=true on the batch poster.\n\nFull list of ArbOS Atlas specific configuration options for Orbit chains​\nFlag\tDescription\n--node.batch-poster.post-4844-blobs\tBoolean. Default: false. Used to enable or disable the posting of transaction data using Blobs to L1 Ethereum. If using calldata is more expensive and if the parent chain supports EIP4844 blobs, the batch poster will use blobs when this flag is set to true. Can be true or false.\n--node.batch-poster.ignore-blob-price\tBoolean. Default: false. If the parent chain supports EIP4844 blobs and ignore-blob-price is set to true, the batch poster will use EIP4844 blobs even if using calldata is cheaper. Can be true or false.\n\nThe above configurations are also available in the Orbit command line options reference section and can be set using the command line or using the JSON node configuration below:\n\n \"node\": {\n    ...\n    \"batch-poster\": {\n    ...\n      \"post-4844-blobs\": true,\n      \"ignore-blob-price\": false,\n    ...\n    },\n  }\n\n\nReference links for ArbOS 20 Atlas​\nNitro v2.3.1 Release details on Github\nOriginal DAO proposal: AIP: ArbOS Version 20 \"Atlas\"\nAIP: ArbOS Version 20 \"Atlas\" Snapshot Vote\nFormal Tally (on-chain) vote for AIP: ArbOS Version 20\nArbOS 20 Atlas Audit Report by Trail of Bits\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nArbOS 32 Bianca\nNext\nArbOS 11\nRequirements:\nHigh-level description of ArbOS 20 changes\nSpecial notes on ArbOS 20: Atlas support for EIP-4844\nBlock explorers\nAdditional requirement for Arbitrum Orbit L2 chain operators: enabling blob batch posting\nReference links for ArbOS 20 Atlas\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/oracles/supra/use-supras-vrf",
    "html": "Skip to main content\nArbitrum Docs\nPage Not Found\n\nWe could not find what you were looking for.\n\nPlease contact the owner of the site that linked you to the original URL and let them know their link is broken.\n\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/oracles/supra/use-supras-price-feed-oracle",
    "html": "Skip to main content\nArbitrum Docs\nPage Not Found\n\nWe could not find what you were looking for.\n\nPlease contact the owner of the site that linked you to the original URL and let them know their link is broken.\n\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/oracles/trellor/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nAPI3\nChainlink\nChronicle\nORA\nHow to use Supra price feed oracle\nHow to use Supra VRF\nTrellor\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nTrellor\n\nTellor is a decentralized oracle network that incentivizes an open, permissionless network of data reporting and validation, ensuring that any verifiable data can be brought on-chain. It supports basic spot prices, sophisticated pricing specs (TWAP/VWAP), Snapshot Vote Results, and custom data needs.\n\nQuerying the price of $ETH through Tellor​\n\nHere’s an example of how to use a Tellor data feed to query the current price of $ETH on-chain. The way it works is that a query is crafted asking for the price of one currency against another and sent to the oracle contract. If the information for that query is available, it will be returned. Oracle contracts can be found on the Contracts Reference page.\n\nTellor provides an npm package with the contracts needed to query the contract. We first install that package in our project:\n\nnpm install usingtellor\n\n\nOur function will just wrap the call to the Oracle contract with the query we are interested in. In this case, we want to obtain the “SpotPrice” of “eth” against “usd”. We will request this information to the Arbitrum oracle contract 0xD9157453E2668B2fc45b7A803D3FEF3642430cC0. We’ll use this example contract:\n\ncontract ARBPriceConsumer is UsingTellor {\n    /**\n     * Network: Arbitrum One\n     * Aggregator: ARB/USD\n     * Address: 0xD9157453E2668B2fc45b7A803D3FEF3642430cC0\n     */\n    constructor(address payable _tellorAddress) UsingTellor(_tellorAddress)\n    {}\n\n    /**\n     * Returns the latest price.\n     */\n    function getLatestPrice() public view returns (uint256) {\n        bytes memory _queryData = abi.encode(\"SpotPrice\", abi.encode(\"eth\", \"usd\"));\n        bytes32 _queryId = keccak256(_queryData);\n\n        (bytes memory _value, uint256 _timestampRetrieved) =\n            getDataBefore(_queryId, block.timestamp - 20 minutes);\n        if (_timestampRetrieved == 0) return 0;\n        require(block.timestamp - _timestampRetrieved < 24 hours);\n        return abi.decode(_value, (uint256));\n    }\n}\n\n\nYou can adapt this contract to your needs. Just remember to use the ticker of the assets you want to request the price for and to deploy your contract to the appropriate network, with the address of the Oracle contract in that network. Remember, we have a Quickstart available that goes through the process of compiling and deploying a contract.\n\nSee also​\nTellor’s documentation demonstrates how to query price feeds and other data feeds.\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nHow to use Supra VRF\nNext\nContribute third-party docs\nQuerying the price of $ETH through Tellor\nSee also\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/oracles/supra/supras-vrf",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nAPI3\nChainlink\nChronicle\nORA\nHow to use Supra price feed oracle\nHow to use Supra VRF\nTrellor\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nSupra, VRF\nCOMMUNITY MEMBER CONTRIBUTION\n\nShoutout to @ksdumont for contributing the following third-party document!\n\nSupra’s VRF can provide the exact properties required for a random number generator (RNG) to be fair with tamper-proof, unbiased, and cryptographically verifiable random numbers to be employed by smart contracts.\n\nIntegrating with Supras' VRF is quick and easy. Supra currently supports several Solidity/EVM-based networks, like Arbitrum, and non-EVM networks like Sui, Aptos.\n\nTo get started, you will want to visit Supras' docs site and review the documentation or continue to follow this guide for a quick start.\n\nLatest version of Supra VRF requires a customer controlled wallet address to act as the main reference for access permissions and call back(response) transaction gas fee payments. Therefore, users planning to consume Supra VRF should get in touch with our team to get your wallet registered with Supra.\n\nOnce your wallet is registered by the Supra team, you could use it to whitelist any number of VRF requester smart contracts and pre-pay/top up the deposit balance maintained with Supra in order to pay for the gas fees of callback(response) transactions.\n\nYou will be interacting with two main contracts:\n\nSupra Deposit Contract: To whitelist smart contracts under the registered wallet address, pre-pay/top up the callback gas fee deposit maintained with Supra.\nSupra Router Contract: To request and receive random numbers.\nStep 1: Create the Supra router contract interface​​\n\nAdd the following code to the requester contract i.e, the contract which uses VRF as a service. You can also add the code in a separate interface and inherit the interface in the requester contract.\n\ninterface ISupraRouterContract {\n\tfunction generateRequest(string memory _functionSig, uint8 _rngCount, uint256 _numConfirmations, uint256 _clientSeed, address _clientWalletAddress) external returns(uint256);\n\tfunction generateRequest(string memory _functionSig, uint8 _rngCount, uint256 _numConfirmations, address _clientWalletAddress) external returns(uint256);\n}\n\n\nThis interface will help the requester contract interact with the Supra router contract and through which the requester contract can use the VRF service.\n\nStep 2: Configure the Supra router contract address​​\n\nContracts that need random numbers should utilize the Supra router contract. In order to do that, they need to create an interface and bind it to the on-chain address of the Supra router contract.\n\ncontract ExampleContract {\n    ISupraRouter internal supraRouter;\n\n    constructor(address routerAddress) {\n        supraRouter = ISupraRouter(0x7d86fbfc0701d0bf273fd550eb65be1002ed304e);\n    }\n}\n\nStep 3: Use the VRF service and request a random number​​\n\nIn this step, we will use the “generateRequest” function of the Supra Router Contract to create a request for random numbers. There are two modes for the \"generateRequest\" function. The only difference between them is that you can optionally provide a client-side input, which will also be part of the payload being threshold signed to provide randomness.\n\n_functionSig- a string parameter, here the requester contract will have to pass the function signature which will receive the callback i.e., a random number from the Supra Router Contract. The function signature should be in the form of the function name following the parameters it accepts. We will see an example later in the document. _rngCount - an integer parameter, it is for the number of random numbers a particular requester wants to generate. Currently, we can generate a maximum of 255 random numbers per request. _numConfirmations - an integer parameter that specifies the number of block confirmations needed before supra VRF can generate the random number. _clientSeed (optional) - an optional integer parameter that could be provided by the client (defaults to 0). This is for additional unpredictability. The source of the seed can be a UUID of 256 bits. This can also be from a centralized source. _clientWalletAddress - an “address” type parameter, which takes the client wallet address which is already registered with the Supra Team, as input. Supra's VRF process requires splitting the contract logic into two functions. The request function - the signature of this function is up to the developer The callback function - the signature must be of the form “uint256 nonce, uint256[] calldata rngList”\n\nfunction exampleRNG() external {\n     //Function validation and logic\n     // requesting 10 random numbers\n     uint8 rngCount = 10;\n\n     // we want to wait for 1 confirmation before the request is considered complete/final\n     uint256 numConfirmations = 1;\n\taddress _clientWalletAddress = //Add the whitelisted wallet address here\n     uint256 generated_nonce = supraRouter.generateRequest(“exampleCallback(uint256,uint256[])”, rngCount, numConfirmations, _clientWalletAddress);\n\n     // store generated_nonce if necessary (eg: in a hashmap)\n     // this can be used to track parameters related to the request, such as user address, nft address etc in a lookup table\n     // these can be accessed inside the callback since the response from supra will include the nonce\n}\n\nStep 4 - Add the validation in the callback function of requester contract​​\n\nInside the callback function where the requester contract wants the random number (in this example the callback function is exampleCallback), the requester contract will have to add the validation such that only the Supra router contract can call the function. The validation is necessary to protect against malicious contracts/users executing the callback with fake data. For example, if the callback function is pickWinner in the requester contract, the snippet can be as follows.\n\nfunction exampleCallback(uint256 _nonce ,uint256[] _rngList) external {\n    require(msg.sender == address(SupraRouter));\n    // Following the required logic of the function\n }\n\nStep 5 : Whitelist your requester contract with Supra deposit contract and deposit funds​​\n\nIt is important to note that your wallet address must be registered with Supra before this step. If that is completed, then you need to whitelist your requester smart contract under your wallet address and deposit funds to be paid for your call back transactions gas fees. The simplest way to interact with the deposit contract will be through Remix IDE. Go to Remix IDE & create a file with name IDepositContract.sol Paste the following code in the file:\n\ninterface IDepositUserContract {\n\tfunction depositFundClient() external payable;\n\tfunction addContractToWhitelist(address _contractAddress) external;\n\tfunction removeContractFromWhitelist(address _contractAddress) external;\n\tfunction setMinBalanceClient(uint256 _limit) external;\n\tfunction withdrawFundClient(uint256 _amount) external;\n\tfunction checkClientFund(address _clientAddress) external view returns (uint256);\n\tfunction checkEffectiveBalance(address _clientAddress) external view returns (uint256);\n\tfunction checkMinBalanceSupra() external view returns (uint256);\n\tfunction checkMinBalance(address _clientAddress) external view returns(uint256);\n\tfunction countTotalWhitelistedContractByClient(address _clientAddress) external view returns (uint256);\n\tfunction getSubscriptionInfoByClient(address _clientAddress) external view returns (uint256, uint256, bool);\n\tfunction isMinimumBalanceReached(address _clientAddress) external view returns (bool);\n\tfunction listAllWhitelistedContractByClient(address _clientAddress) external view returns (address[] memory);\n\n}\n\n\nNavigate to the “Navigate & run Transactions” tab in remix, and paste the deposit contract address into the text box besides the “At Address” button & press the at address button. You will find the instance for the deposit contract created using which a user can interact and use the features provided by the deposit contract. Following functions will facilitate whitelisting your requester smart contracts and fund deposits. “addContracttoWhitelist(address)” - The whitelisted users will have to whitelist their contract which they will be using to request for random numbers. The parameter this function takes is the User’s contract address. This function will be called after the user deploys the requester contract post development and makes it ready for interacting with the Supra Contracts. “depositFundClient()” - is another mandatory function for a user to use once, before the user starts requesting from that contract. This is a function which will deposit funds in the deposit contract from the users for the response/callback transaction. The funds for a specific user should remain higher than the minimum amount set by the Supra( 0.1 Eth for Arbitrum testnet) for the new request transactions to be accepted.\nBasically the gist here is that the user will have to interact with the Deposit contract and add funds for their accounts, which will be utilized for the response transaction gas fee. There will be a script from Supra which will be monitoring the funds and will alert the user if a refill is required.\n\nExample implementation​\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.0;\ninterface ISupraRouter {\n   function generateRequest(string memory _functionSig , uint8 _rngCount, uint256 _numConfirmations, uint256 _clientSeed,address _clientWalletAddress) external returns(uint256);\n   function generateRequest(string memory _functionSig , uint8 _rngCount, uint256 _numConfirmations,address _clientWalletAddress) external returns(uint256);\n}\ncontract Interaction {\n   address supraAddr;\n   constructor(address supraSC) {\n       supraAddr = supraSC;\n   }\n   mapping (uint256 => string ) result;\n   mapping (string => uint256[] ) rngForUser;\n   function getRNGForUser(uint8 rngCount, string memory username) external {\n      uint256 nonce =  ISupraRouter(supraAddr).generateRequest(\"myCallbackUsername(uint256,uint256[])\", rngCount, 1, 123, msg.sender);\n//Can pass \"msg.sender\" when calling from the whitelisted wallet address\n      result[nonce] = username;\n   }\n   function myCallbackUsername(uint256 nonce, uint256[] calldata rngList) external {\n      require(msg.sender == supraAddr, \"only supra router can call this function\");\n      uint8 i = 0;\n      uint256[] memory x = new uint256[](rngList.length);\n      rngForUser[result[nonce]] = x;\n      for(i=0; i<rngList.length;i++){\n         rngForUser[result[nonce]][i] = rngList[i] % 100;\n      }\n   }\n   function viewUserName(string memory username) external view returns (uint256[] memory) {\n      return rngForUser[username];\n   }\n   }\n\nGoing further with Supra​\n\nIf you want to take the next step, consider registering for the Supra Network Activate Program (SNAP).\n\nThe Supra Network Activate Program (SNAP) offers companies discounted oracle credits, technical documentation, and customer support to embed much-needed oracles and VRF/RNG. SNAP supports Web3 scaling and growth to buffer costs which could typically inhibit a company’s success.\n\nThe SNAP program is partnered with some of Web3's most prolific names who are helping with project selection and qualification.\n\nConnect with us!​\n\nStill looking for answers? We got them! Check out all the ways you can reach us:\n\nVisit us at supraoracles.com\nRead our Docs\nChat with us on Telegram\nFollow us on Twitter\nJoin our Discord\nCheck us out on Youtube\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nHow to use Supra price feed oracle\nNext\nTrellor\nStep 1: Create the Supra router contract interface​\nStep 2: Configure the Supra router contract address​\nStep 3: Use the VRF service and request a random number​\nStep 4 - Add the validation in the callback function of requester contract​\nStep 5 : Whitelist your requester contract with Supra deposit contract and deposit funds​\nExample implementation\nGoing further with Supra\nConnect with us!\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/oracles/supra/supras-price-feed",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nAPI3\nChainlink\nChronicle\nORA\nHow to use Supra price feed oracle\nHow to use Supra VRF\nTrellor\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nSupra, price feed oracle\nCOMMUNITY MEMBER CONTRIBUTION\n\nShoutout to @ksdumont for contributing the following third-party document!\n\nSupra is a novel, high-throughput Oracle & IntraLayer: A vertically integrated toolkit of cross-chain solutions (data oracles, asset bridges, automation network, and more) that interlink all blockchains, public (L1s and L2s) or private (enterprises).\n\nIntegrating with Supra's price feeds is quick and easy. Supra currently supports several Solidity/EVM-based networks, like Arbitrum, and non-EVM networks like Sui, Aptos.\n\nTo see all of the networks Supra is on, please visit Supras' Networks!\n\nTo get started, you will want to visit Supras' docs site and review the documentation or continue to follow this guide for a quick start.\n\nStep 1: Create The S-Value interface​\n\nAdd the following code to the solidity smart contract that you wish to retrieve an S-Value.\n\ninterface ISupraSValueFeed {\n\n    function getSvalue(uint64 _pairIndex) external view returns (bytes32, bool);\n\n    function getSvalues(uint64[] memory _pairIndexes) external view returns (bytes32[] memory, bool[] memory);\n\n}\n\n\nThis creates the interface that you will later apply in order to fetch a price from SupraOracles.\n\nStep 2: Configure The S-Value feed address​\n\nTo fetch the S-Value from a SupraOracles smart contract, you must first find the S-Value feed address for the chain of your choice.\n\nFor Arbitrum, the address is 0x8a358F391d93f7558D5F5E61BDf533e2cc3Cf7a3\n\nWhen you have the proper address, create an instance of the S-Value feed using the interface we previously defined for Arbitrum:\n\ncontract ISupraSValueFeedExample {\n    ISupraSValueFeed internal sValueFeed;\n    constructor() {\n        sValueFeed = ISupraSValueFeed(0x8a358F391d93f7558D5F5E61BDf533e2cc3Cf7a3);\n    }\n}\n\nStep 3: Add unpack function to decode response for S-Value feed​\n\nTo decode S-value response from SupraOracles smart contract, you need to add the following code in your contract.\n\n// Some codefunction unpack(bytes32 data) internal pure returns(uint256[4] memory) {\n        uint256[4] memory info;\n\n        info[0] = bytesToUint256(abi.encodePacked(data >> 192));       // round\n        info[1] = bytesToUint256(abi.encodePacked(data << 64 >> 248)); // decimal\n        info[2] = bytesToUint256(abi.encodePacked(data << 72 >> 192)); // timestamp\n        info[3] = bytesToUint256(abi.encodePacked(data << 136 >> 160)); // price\n\n        return info;\n    }\n\n    function bytesToUint256(bytes memory _bs) internal pure returns (uint256 value) {\n        require(_bs.length == 32, \"bytes length is not 32.\");\n        assembly {\n            value := mload(add(_bs, 0x20))\n        }\n    }\n\nStep 4: Get the S-Value crypto price​\n\nNow you can simply access the S-Value crypto price of our supported market pairs. In this step, we'll get the price of single or multiple trading pairs in our smart contract.\n\nfunction getPrice(uint64 _priceIndex) external view returns (uint256[4] memory) {\n\n        (bytes32 val,)= sValueFeed.getSvalue(_priceIndex);\n\n        uint256[4] memory decoded = unpack(val);\n\n        return decoded;\n}\n\nfunction getPriceForMultiplePair(uint64[] memory _pairIndexes) external view returns (uint256[4][] memory) {\n\n        (bytes32[] memory val, ) = sValueFeed.getSvalues(_pairIndexes);\n\n        uint256[4][] memory decodedArray = new uint256[4][](val.length);\n\n        for(uint i=0; i< val.length; i++){\n\n            uint256[4] memory decoded = unpack(val[i]);\n            decodedArray[i] = decoded;\n        }\n\n        return decodedArray;\n}\n\n\nTada! You now have a method in your smart contract that you can call at any time to retrieve the price of any crypto pair!\n\nGoing further with Supra​\n\nIf you want to take the next step, consider registering for the Supra Network Activate Program (SNAP).\n\nThe Supra Network Activate Program (SNAP) offers companies discounted oracle credits, technical documentation, and customer support to embed much-needed oracles and VRF/RNG. SNAP supports Web3 scaling and growth to buffer costs which could typically inhibit a company’s success.\n\nThe SNAP program is partnered with some of Web3's most prolific names who are helping with project selection and qualification.\n\nConnect with us!​\n\nStill looking for answers? We got them! Check out all the ways you can reach us:\n\nVisit us at supraoracles.com\nRead our Docs\nChat with us on Telegram\nFollow us on Twitter\nJoin our Discord\nCheck us out on Youtube\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nORA\nNext\nHow to use Supra VRF\nStep 1: Create The S-Value interface\nStep 2: Configure The S-Value feed address\nStep 3: Add unpack function to decode response for S-Value feed\nStep 4: Get the S-Value crypto price\nGoing further with Supra\nConnect with us!\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/oracles/ora/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nAPI3\nChainlink\nChronicle\nORA\nHow to use Supra price feed oracle\nHow to use Supra VRF\nTrellor\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nORA\n\nORA is Ethereum's Trustless AI. As a verifiable oracle protocol, ORA brings AI and complex compute onchain. Its main product, Onchain AI Oracle (OAO), integrates AI capabilities directly onchain.\n\nORA breaks down the limitations of smart contracts by offering verifiable AI inference so that developers can innovate freely.\n\nOAO quickstart​\n\nThis quickstart is designed to help you build a smart contract on Arbitrum able to interact with OAO. You can find more details in our docs Quickstart.\n\nWorkflow​\nThe user contract sends the AI request to OAO on Arbitrum, by calling requestCallback function on the OAO contract.\nEach AI request will initiate an opML inference.\nOAO will emit a requestCallback event which will be collected by opML node.\nopML node will run the AI inference, and then upload the result on Arbitrum, waiting for the challenge period.\nDuring the challenge period, the opML validators will check the result and challenge it if the submitted result is incorrect.\nIf the submitted result is successfully challenged by one of the validators, the submitted result will be updated on Arbitrum.\nAfter the challenge period, the submitted result onchain is finalized.\nWhen the result is uploaded or updated on Arbitrum, the provided AI inference in opML will be dispatched to the user's smart contract via its specific callback function.\nIntegration​\nOverview​\n\nTo integrate with OAO, you will need to write your own contract.\n\nTo build with AI models of OAO, we provided an example of contract using OAO: Prompt.\n\nSmart contract integration​\nInherit AIOracleCallbackReceiver in your contract and bind with a specific OAO address:\nconstructor(IAIOracle _aiOracle) AIOracleCallbackReceiver(_aiOracle) {}\n\nWrite your callback function to handle the AI result from OAO. Note that only OAO can call this function:\nfunction aiOracleCallback(uint256 requestId, bytes calldata output, bytes calldata callbackData) external override onlyAIOracleCallback()\n\nWhen you want to initiate an AI inference request, call OAO as follows:\naiOracle.requestCallback(modelId, input, address(this), gas_limit, callbackData);\n\nReference​\n\n4 models are available on Arbitrum One: Stable Diffusion (ID: 50), Llama3 8B Instruct (ID: 11), OpenLM Score 7B (ID: 14) and OpenLM Chat 7B (ID: 15).\n\nPrompt and SimplePrompt are both example smart contracts interacted with OAO.\n\nFor simpler application scenarios (eg. Prompt Engineering based AI like GPTs), you can directly use Prompt or SimplePrompt.\n\nSimplePrompt saves gas by only emitting the event without storing historical data.\n\nArbitrum One:\n\nOAO Proxy: 0x0A0f4321214BB6C7811dD8a71cF587bdaF03f0A0\nPrompt: 0xC20DeDbE8642b77EfDb4372915947c87b7a526bD\nSimplePrompt: 0xC3287BDEF03b925A7C7f54791EDADCD88e632CcD\n\nArbitrum Sepolia tesnet:\n\nOAO Proxy: 0x0A0f4321214BB6C7811dD8a71cF587bdaF03f0A0\nPrompt: 0xC3287BDEF03b925A7C7f54791EDADCD88e632CcD\nSimplePrompt: 0xBC24514E541d5CBAAC1DD155187A171a593e5CF6\nUseful links:​\nRead ORA documentation\nJoin our Discord where our team can help you\nFollow us on X\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nChronicle\nNext\nHow to use Supra price feed oracle\nOAO quickstart\nWorkflow\nIntegration\nOverview\nSmart contract integration\nReference\nUseful links:\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/oracles/chronicle/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nAPI3\nChainlink\nChronicle\nORA\nHow to use Supra price feed oracle\nHow to use Supra VRF\nTrellor\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nChronicle\n\nChronicle Protocol is a novel Oracle solution that overcomes the current limitations of transferring data on-chain by developing scalable, cost-efficient, decentralized, and verifiable Oracles, rewriting the rulebook on data transparency and accessibility.\n\nQuerying the price of $ARB using Chronicle​\n\nChronicle contracts are read-protected by a whitelist, meaning you won't be able to read them on-chain without your address being added to the whitelist. On the Testnet, users can add themselves to the whitelist through the SelfKisser contract; a process playfully referred to as \"kissing\" themselves. To access production Oracles on the Mainnet, please open a support ticket in Discord in the 🆘 ｜ support channel.\n\nFor the deployment addresses, please check out the Dashboard.\n\n// SPDX-License-Identifier: MIT\npragma solidity ^0.8.16;\n\n/**\n * @title OracleReader\n * @notice A simple contract to read from Chronicle oracles\n * @dev To see the full repository, visit https://github.com/chronicleprotocol/OracleReader-Example.\n * @dev Addresses in this contract are hardcoded for the Arbitrum Sepolia testnet.\n * For other supported networks, check the https://chroniclelabs.org/dashboard/oracles.\n */\ncontract OracleReader {\n    /**\n    * @notice The Chronicle oracle to read from.\n    * Chronicle_ARB_USD_1 - 0xdD7c06561689c73f0A67F2179e273cCF45EFc964\n    * Network: Arbitrum Sepolia\n    */\n\n    IChronicle public chronicle = IChronicle(address(0xdD7c06561689c73f0A67F2179e273cCF45EFc964));\n\n    /**\n    * @notice The SelfKisser granting access to Chronicle oracles.\n    * SelfKisser_1:0xc0fe3a070Bc98b4a45d735A52a1AFDd134E0283f\n    * Network: Arbitrum Sepolia\n    */\n    ISelfKisser public selfKisser = ISelfKisser(address(0xc0fe3a070Bc98b4a45d735A52a1AFDd134E0283f));\n\n    constructor() {\n        // Note to add address(this) to chronicle oracle's whitelist.\n        // This allows the contract to read from the chronicle oracle.\n        selfKisser.selfKiss(address(chronicle));\n    }\n\n    /**\n    * @notice Function to read the latest data from the Chronicle oracle.\n    * @return val The current value returned by the oracle.\n    * @return age The timestamp of the last update from the oracle.\n    */\n    function read() external view returns (uint256 val, uint256 age) {\n        (val, age) = chronicle.readWithAge();\n    }\n}\n\n// Copied from [chronicle-std](https://github.com/chronicleprotocol/chronicle-std/blob/main/src/IChronicle.sol).\ninterface IChronicle {\n    /**\n    * @notice Returns the oracle's current value.\n    * @dev Reverts if no value set.\n    * @return value The oracle's current value.\n    */\n    function read() external view returns (uint256 value);\n\n    /**\n    * @notice Returns the oracle's current value and its age.\n    * @dev Reverts if no value set.\n    * @return value The oracle's current value using 18 decimals places.\n    * @return age The value's age as a Unix Timestamp .\n    * */\n    function readWithAge() external view returns (uint256 value, uint256 age);\n}\n\n// Copied from [self-kisser](https://github.com/chronicleprotocol/self-kisser/blob/main/src/ISelfKisser.sol).\ninterface ISelfKisser {\n    /// @notice Kisses caller on oracle `oracle`.\n    function selfKiss(address oracle) external;\n}\n\nMore examples​\n\nFor more examples of integrating Chronicle Oracles, please check the documentation portal.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nChainlink\nNext\nORA\nQuerying the price of $ARB using Chronicle\nMore examples\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Chainlink | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/oracles/chainlink/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nAPI3\nChainlink\nChronicle\nORA\nHow to use Supra price feed oracle\nHow to use Supra VRF\nTrellor\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nChainlink\n\nChainlink is a widely-recognized Web3 services platform that specializes in decentralized oracle networks. It lets you build Ethereum and Arbitrum dApps that connect to a variety of off-chain data feeds and APIs, including those that provide asset prices, weather data, random number generation, and more.\n\nQuerying the price of $ARB through Chainlink​\n\nHere’s an example on how to use a price feed from Chainlink to query the current price of $ARB on-chain. We’ll use an interface provided by Chainlink that can be configured with the address of the proxy that holds the information we want to request, and wrap the operation in a contract.\n\nChainlink provides an npm package with the contracts needed to access their feeds. We first install that package in our project:\n\nyarn add @chainlink/contracts\n\n\nTo use a data feed, we retrieve the information through the AggregatorV3Interface and the proxy address of the feed we want to query.\n\nimport \"@chainlink/contracts/src/v0.8/interfaces/AggregatorV3Interface.sol\";\n\n\nIn this case, we want to obtain the current price of $ARB in $USD in Arbitrum One, so we need to know the address of the proxy that will provide that information. Chainlink maintains a list of price feed address here. For $ARB/$USD, we’ll use the address 0xb2A824043730FE05F3DA2efaFa1CBbe83fa548D6.\n\nWe can now build the function to get the latest price of $ARB. We’ll use this example contract:\n\ncontract ARBPriceConsumer {\n    AggregatorV3Interface internal priceFeed;\n\n    /**\n     * Network: Arbitrum One\n     * Aggregator: ARB/USD\n     * Address: 0xb2A824043730FE05F3DA2efaFa1CBbe83fa548D6\n     */\n\t\taddress constant PROXY = 0xb2A824043730FE05F3DA2efaFa1CBbe83fa548D6;\n\n    constructor() {\n        priceFeed = AggregatorV3Interface(PROXY);\n    }\n\n    /**\n     * Returns the latest price.\n     */\n    function getLatestPrice() public view returns (int) {\n        (\n            /* uint80 roundID */,\n            int price,\n            /*uint startedAt*/,\n            /*uint timeStamp*/,\n            /*uint80 answeredInRound*/\n        ) = priceFeed.latestRoundData();\n        return price;\n    }\n}\n\n\nYou can adapt this contract to your needs. Just remember to use the address of the asset you want to request the price for in the appropriate network, and to deploy your contract to the same network. Remember we have a Quickstart available that goes through the process of compiling and deploying a contract.\n\nMore examples​\n\nRefer to Chainlink’s documentation for more examples of querying price feeds plus other data feeds available.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nAPI3\nNext\nChronicle\nQuerying the price of $ARB through Chainlink\nMore examples\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/oracles/api3/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nAPI3\nChainlink\nChronicle\nORA\nHow to use Supra price feed oracle\nHow to use Supra VRF\nTrellor\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nAPI3\n\nAPI3 is a collaborative project to deliver traditional API services to smart contract platforms in a decentralized and trust-minimized way. API3 provides the technology for Airnodes to push off-chain data to on-chain contracts. This data can then be queried directly through the Airnode (initiating a “pull-type” request) or through dAPIs (data-feeds sourced directly from multiple first-party oracles owned and operated by API providers).\n\nQuerying the price of $ARB through API3​\n\nHere’s an example of how to use an API3 data feed to query the current price of $ARB on-chain. The API3 market provides a list of all the dAPIs available across multiple chains including testnets. You can go forward and activate the dAPI you want to use.\n\nAPI3 provides an npm package with the contracts needed to access their feeds. We first install that package in our project:\n\nyarn add @api3/contracts\n\n\nTo use a data feed, we retrieve the information through the specific proxy address for that feed. We’ll use the IProxy interface to do so.\n\nimport \"@api3/contracts/api3-server-v1/proxies/interfaces/IProxy.sol\";\n\n\nIn this case, we want to obtain the current price of $ARB in $USD in Arbitrum One, so we need to know the proxy address that will provide that information. We will search the feed on the API3 Market and connect our wallet. We would then want to see if the feed is active, and if it is, we can check its configuration parameters, deploy the proxy contract and click on Integrate. You can find the proxy address of ARB/USD here.\n\nINFO\n\nIf a dAPI is already active, you can use the proxy address directly. If it is not active, you can activate it by clicking on Activate and following the instructions to deploy a proxy contract.\n\nWe can now build the function to get the latest price of $ARB. We’ll use this example contract:\n\ncontract ARBPriceConsumer {\n    /**\n     * Network: Arbitrum One\n     * Aggregator: ARB/USD\n     * Proxy: 0x0cB281EC7DFB8497d07196Dc0f86D2eFD21066A5\n     */\n    address constant PROXY = 0x0cB281EC7DFB8497d07196Dc0f86D2eFD21066A5;\n\n    /**\n     * Returns the latest price.\n     */\n    function getLatestPrice()\n        external\n        view\n        returns (int224 value, uint256 timestamp)\n    {\n        (value, timestamp) = IProxy(PROXY).read();\n        // If you have any assumptions about `value` and `timestamp`, make sure\n        // to validate them right after reading from the proxy.\n    }\n}\n\n\nYou can adapt this contract to your needs. Just remember to use the address of the asset you want to request the price for in the appropriate network and to deploy your contract to the same network. Remember we have a Quickstart available that goes through the process of compiling and deploying a contract.\n\nQuerying a random number through API3​\n\nAPI3 QRNG is a public utility provided with the courtesy of Australian National University (ANU). It is served as a public good, it is free of charge (apart from the gas costs), and it provides quantum randomness when requiring RNG on-chain.\n\nTo request randomness on-chain, the requester submits a request for a random number to AirnodeRrpV0. The ANU Airnode gathers the request from the AirnodeRrpV0 protocol contract, retrieves the random number off-chain, and sends it back to AirnodeRrpV0. Once received, it performs a callback to the requester with the random number.\n\nHere’s an example of a basic QrngRequester that requests a random number.\n\nAPI3 provides an npm package with the contracts needed to access the ANU QRNG airnode. We first install that package in our project:\n\nyarn add @api3/airnode-protocol\n\n\nWe’ll need several pieces of data to request a random number:\n\naddress airnodeRrp: Address of the protocol contract. See the Chains page for a list of addresses on different chains. For Arbitrum, we’ll use 0xb015ACeEdD478fc497A798Ab45fcED8BdEd08924.\naddress airnode: The address that belongs to the Airnode that will be called to get the QRNG data via its endpoints. See the Providers page for a list of addresses on different chains. For Arbitrum we’ll use 0x9d3C147cA16DB954873A498e0af5852AB39139f2.\nbytes32 endpointId: Endpoint ID known by the Airnode that will map to an API provider call (allowed to be bytes32(0)). You can also find that information in the Providers page. For Arbitrum we’ll use 0xfb6d017bb87991b7495f563db3c8cf59ff87b09781947bb1e417006ad7f55a78.\naddress sponsorWallet: The address of the wallet that will pay for the gas costs for the callback request to get the random number on-chain. You need to fund this wallet with enough ETH to cover the gas costs.\n\nTo derive your sponsorWallet address, you can use the following command:\n\nyarn @api3/airnode-admin derive-sponsor-wallet-address \\\n  --airnode-address 0x9d3C147cA16DB954873A498e0af5852AB39139f2 \\\n  --airnode-xpub xpub6DXSDTZBd4aPVXnv6Q3SmnGUweFv6j24SK77W4qrSFuhGgi666awUiXakjXruUSCDQhhctVG7AQt67gMdaRAsDnDXv23bBRKsMWvRzo6kbf \\\n  --sponsor-address <use-the-address-of-your-requester-contract>\n\n  # The command outputs.\n  Sponsor wallet address: 0x6394...5906757\n  # Use this address as the value for _sponsorWallet.\n\n\nWe can now build the function to get a random number. We’ll use this example contract:\n\nimport \"@api3/airnode-protocol/contracts/rrp/requesters/RrpRequesterV0.sol\";\n\ncontract QrngRequester is RrpRequesterV0 {\n    event RequestedUint256(bytes32 indexed requestId);\n    event ReceivedUint256(bytes32 indexed requestId, uint256 response);\n\n    /**\n     * Network: Arbitrum One\n     * AirnodeRrpV0 Address: 0xb015ACeEdD478fc497A798Ab45fcED8BdEd08924\n     * Airnode: 0x9d3C147cA16DB954873A498e0af5852AB39139f2\n     * Endpoint ID: 0xfb6d017bb87991b7495f563db3c8cf59ff87b09781947bb1e417006ad7f55a78\n     */\n    address constant _airnodeRrp = 0xb015ACeEdD478fc497A798Ab45fcED8BdEd08924;\n    address constant airnode = 0x9d3C147cA16DB954873A498e0af5852AB39139f2;\n    bytes32 constant endpointIdUint256 = 0xfb6d017bb87991b7495f563db3c8cf59ff87b09781947bb1e417006ad7f55a78;\n    mapping(bytes32 => bool) public waitingFulfillment;\n    address sponsorWallet;\n\n    constructor() RrpRequesterV0(_airnodeRrp) {}\n\n    // Set the sponsor wallet address that you just derived.\n    function setSponsorWallet(address _sponsorWallet) external {\n        sponsorWallet = _sponsorWallet;\n    }\n\n    function makeRequestUint256() external {\n        bytes32 requestId = airnodeRrp.makeFullRequest(\n            airnode,\n            endpointIdUint256,\n            address(this),\n            sponsorWallet,\n            address(this),\n            this.fulfillUint256.selector,\n            \"\"\n        );\n        waitingFulfillment[requestId] = true;\n        emit RequestedUint256(requestId);\n    }\n\n    function fulfillUint256(bytes32 requestId, bytes calldata data)\n        external\n        onlyAirnodeRrp\n    {\n        require(\n            waitingFulfillment[requestId],\n            \"Request ID not known\"\n        );\n        waitingFulfillment[requestId] = false;\n        uint256 qrngUint256 = abi.decode(data, (uint256));\n\n        // Use `qrngUint256` here...\n\n        emit ReceivedUint256(requestId, qrngUint256);\n    }\n}\n\n\nYou can adapt this contract to your needs. Just remember to set the sponsorWallet address before making the request to use the appropriate network's addresses, and to deploy your contract to the same network. Remember, we have a Quickstart available that goes through the process of compiling and deploying a contract.\n\nMore examples​\n\nRefer to API3’s documentation for more examples of querying other data feeds and Airnodes.\n\nYou can also check out some other detailed guides:\n\nSubscribing to dAPIs\nReading a dAPI Proxy\nUsing QRNG with Remix\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nOracles overview\nNext\nChainlink\nQuerying the price of $ARB through API3\nQuerying a random number through API3\nMore examples\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/arbos/l2-l1-messaging",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nL1-to-L2 messaging\nL2-to-L1 messaging\nArbOS\nFraud proofs\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nL2 to L1 messaging and the outbox\n\nArbitrum's Outbox system allows for arbitrary L2 to L1 contract calls; i.e., messages initiated from L2 which eventually resolve in execution on L1. L2-to-L1 messages (aka \"outgoing\" messages) bear many things in common with Arbitrum's L1-to-L2 messages (Retryables), \"in reverse\" though with a few differences.\n\nProtocol Flow​\n\nPart of the L2 state of an Arbitrum chain — and consequently, part of what's asserted in every RBlock — is a Merkle root of all L2-to-L1 messages in the chain's history. Upon an asserted RBlock being confirmed (typically ~1 week after its asserted), this Merkle root is posted on L1 in the Outbox contract. The Outbox contract then lets users execute their messages — validating Merkle proofs of inclusion, and tracking which L2 to L1 messages have already been spent.\n\nClient Flow​\n\nFrom a client perspective, an L2 to L1 message begins with a call to the L2 ArbSys precompile contract's sendTxToL1 method. Once the message is included in an assertion (typically within ~1 hour) and the assertion is confirmed (typically about ~ 1 week), any client can execute the message. To do this, the client first retrieves the proof data via a call to the Arbitrum chain's \"virtual\"/precompile-esque** NodeInterface contract's constructOutboxProof method. The data returned can then be used in the Outbox's executeTransaction method to perform the L1 execution.\n\nProtocol Design Details​\n\nAn important feature in the design of the Outbox system is that calls to confirmNode have constant overhead. Requiring that confirmNode only update the constant-sized outgoing message root hash, and that users themselves carry out the final step of execution, achieves this goal; i.e., no matter the number of outgoing messages in the root, or the gas cost of executing them on L1, the cost of confirming nodes remains constant; this ensures that the RBlock confirmation processed can't be griefed.\n\nUnlike Retryables, which have an option to provide Ether for automatic L2 execution, outgoing messages can't provide in-protocol automatic L1 execution, for the simple reason that Ethereum itself doesn't offer scheduled execution affordances. However, application-layer contracts that interact with the Outbox could in principle be built to provide somewhat-analogous \"execution market\" functionality for outsourcing the final L1 execution step.\n\nAnother difference between outgoing messages and Retryables is that Retryables have a limited lifetime before which they must be redeemed (or have their lifetime explicitly extended), whereas L2 to L1 messages are stored in L1 state, and thus persist permanently / have no deadline before which they must be executed.\nThe week long delay period before outgoing messages can be executed is inherent and fundamental to the nature of Arbitrum Rollup, or any Optimistic Rollup style L2; the moment a transaction is published on-chain, any observer can anticipate its result; however, for Ethereum itself to accept its result, the protocol must give time for Arbitrum validators to detect and prove fault if need-be. For a protocol overview, see Inside Arbitrum\n\n** We refer to NodeInterface as a \"virtual\" contract; its methods are accessible via calls 0x00000000000000000000000000000000000000C8, but it doesn't really live on chain. It isn't really a precompile, but behaves a lot like a precompile that can't receive calls from other contracts. This is a cute trick that let's us provide Arbitrum-specific data without having to implement a custom RPC.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nL1-to-L2 messaging\nNext\nArbOS\nProtocol Flow\nClient Flow\nProtocol Design Details\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/l1-gas-pricing",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nTransaction lifecycle\nSequencer\nAnyTrust protocol\nGas / fees\nL2 gas and fees\nL1 pricing\nAdvanced concepts\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nL1 gas pricing\n\nArbOS dynamically prices L1 gas, with the price adjusting to ensure that the amount collected in L1 gas fees is as close as possible to the costs that must be covered, over time.\n\nL1 fee collection​\n\nA transaction is charged for L1 gas if and only if it arrived as part of a sequencer batch. This means that someone would have paid for L1 gas to post the transaction on the L1 chain.\n\nThe estimated cost of posting a transaction on L1 is the product of the transaction's estimated size, and the current L1 Gas Basefee. This estimated cost is divided by the current L2 gas basefee to obtain the amount of L2 gas that corresponds to the L1 operation (more information about this can be found in this article).\n\nThe estimated size is measured in L1 gas and is calculated as follows: first, compress the transaction's data using the brotli-zero algorithm, then multiply the size of the result by 16. (16 is because L1 charges 16 gas per byte. L1 charges less for bytes that are zero, but that doesn't make sense here.) Brotli-zero is used in order to reward users for posting transactions that are compressible. Ideally we would like to reward for posting transactions that contribute to the compressibility (using the brotli compressor) of the entire batch, but that is a difficult notion to define and in any case would be too expensive to compute at L2. Brotli-zero is an approximation that is cheap enough to compute.\n\nL1 gas fee funds that are collected from transactions are transferred to a special L1PricerFundsPool account, so that account's balance represents the amount of funds that have been collected and are available to pay for costs.\n\nThe L1 pricer also records the total number of \"data units\" (the sum of the estimated sizes, after multiplying by 16) that have been received.\n\nL1 costs​\n\nThere are two types of L1 costs: batch posting costs, and rewards.\n\nBatch posting costs reflect the actual cost a batch poster pays to post batch data on L1. Whenever a batch is posted, the L1 contract that records the batch will send a special \"batch posting report\" message to L2 ArbOS, reporting who paid for the batch and what the L1 basefee was at the time. This message is placed in the chain's delayed inbox, so it will be delivered to L2 ArbOS after some delay.\n\nWhen a batch posting report message arrives at L2, ArbOS computes the cost of the referenced batch by multiplying the reported basefee by the batch's data cost. (ArbOS retrieves the batch's data from its inbox state, and computes the L1 gas that the batch would have used by counting the number of zero bytes and non-zero bytes in the batch.) The resulting cost is recorded by the pricer as funds due to the party who is reported to have submitted the batch.\n\nThe second type of L1 cost is an optional (per chain) per-unit reward for handling transaction calldata. In general the reward might be paid to the sequencer, or to members of the Data Availability Committee in an AnyTrust chain, or to anyone else who incurs per-calldata-byte costs on behalf of the chain. The reward is a fixed number of wei per data unit, and is paid to a single address.\n\nThe L1 pricer keeps track of the funds due to the reward address, based on the number of data units handled so far. This amount is updated whenever a batch posting report arrives at L2.\n\nAllocating funds and paying what is owed​\n\nWhen a batch posting report is processed at L2, the pricer allocates some of the collected funds to pay for costs incurred. To allocate funds, the pricer considers three timestamps:\n\ncurrentTime is the current time, when the batch posting report message arrives at L2\nupdateTime is the time at which the reported batch was submitted (which will typically be around 20 minutes before currentTime)\nlastUpdateTime is the time at which the previous reported batch was submitted\n\nThe pricer computes an allocation fraction F = (updateTime-lastUpdateTime) / (currentTime-lastUpdateTime) and allocates a fraction F of funds in the L1PricerFundsPool to the current report. The intuition is that the pricer knows how many funds have been collected between lastUpdateTime and currentTime, and we want to figure out how many of those funds to allocate to the interval between lastUpdateTime and updateTime. The given formula is the correct allocation, if we assume that funds arrived at a uniform rate during the interval between lastUpdateTime and currentTime. The pricer similarly allocates a portion of the total data units to the current report.\n\nNow the pricer pays out the allocated funds to cover the rewards due and the amounts due to batch posters, reducing the balance due to each party as a result. If the allocated funds aren't sufficient to cover everything that is due, some amount due will remain. If all of the amount due can be covered with the allocated funds, any remaining allocated funds are returned to the L1PricerFundsPool.\n\nAdjusting the L1 gas basefee​\n\nAfter allocating funds and paying what is owed, the L1 Pricer adjusts the L1 Gas Basefee. The goal of this process is to find a value that will cause the amount collected to equal the amount owed over time.\n\nThe algorithm first computes the surplus (funds in the L1PricerFundsPool, minus total funds due), which might be negative. If the surplus is positive, the L1 Gas Basefee is reduced, so that the amount collected over a fixed future interval will be reduced by exactly the surplus. If the surplus is negative, the Basefee is increased so that the shortfall will be eliminated over the same fixed future interval.\n\nA second term is added to the L1 Gas Basefee, based on the derivative of the surplus (surplus at present, minus the surplus after the previous batch posting report was processed). This term, which is multiplied by a smoothing factor to reduce fluctuations, will reduce the Basefee if the surplus is increasing, and increase the Basefee if the surplus is shrinking.\n\nGetting L1 fee info​\n\nThe L1 gas basefee can be queried via ArbGasInfo.getL1BaseFeeEstimate. To estimate the L1 fee a transaction will use, the NodeInterface.gasEstimateComponents() or NodeInterface.gasEstimateL1Component() method can be used.\n\nArbitrum transaction receipts include a gasUsedForL1 field, showing the amount of gas used on L1 in units of L2 gas.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nL2 gas and fees\nNext\nDeep dive: Inside Arbitrum\nL1 fee collection\nL1 costs\nAllocating funds and paying what is owed\nAdjusting the L1 gas basefee\nGetting L1 fee info\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Troubleshooting: Arbitrum bridge | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/arbitrum-bridge/troubleshooting",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nQuickstart\nUSDC on Arbitrum One\nTroubleshooting\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nTroubleshooting: Arbitrum bridge\nHow do I move assets between One and Nova?​\n\nBoth Arbitrum One and Arbitrum Nova run as layers on top of Ethereum. Thus, you can always move assets between the two chains in two steps by going \"through\" Ethereum. In other words: withdraw your assets from Arbitrum One to Ethereum and then deposit them onto Nova, or conversely, withdraw your assets from Nova on to Ethereum and then deposit them on to Arbitrum One. These steps can all be done at https://bridge.arbitrum.io/.\n\nWhat fees do I have to pay when bridging funds from L1 to L2?​\n\nWhen bridging over tokens from L1 to L2, you will have to sign one or two transactions with their corresponding fees:\n\nIf you are bridging a token for the first time, you'll sign one approval transaction.\nIn all cases, you'll sign a deposit transaction that will send your tokens to the Bridge.\n\nKeep in mind that the approval transaction needs to be executed at least once per token and wallet. This means that if you bridge the same token from the same wallet again, you probably won't have to pay for that transaction. However, if you bridge the same token from a different wallet, you will have to pay for that transaction again.\n\nIn any case, the bridge and your wallet will guide you through the process, showing the transaction(s) that you need to sign in order to have your tokens bridged to Arbitrum.\n\nHow long does it take before I receive my funds when I initiate a withdrawal from Arbitrum chains (One and Nova)?​\n\nUsing the official Arbitrum Bridge, the process will take roughly one week. However, some users opt to use third-party fast bridges, which often bypass this delay (remember that these bridges are created and maintained by third parties, so please DYOR!).\n\nThere's some variability in the exact wall-clock time of the dispute window, plus there's some expected additional \"padding\" time on both ends (no more than about an hour, typically).\n\nThe variability of the dispute window comes from the slight variance of block times. Arbitrum One's dispute window is 45818 blocks; this converts to about 6.5 days, assuming slightly more than 12 seconds per block, the average block time of Ethereum.\n\nThe \"padding on both ends\" involves three events that have to occur between a client receiving their transaction receipt from the sequencer and their L2-to-L1 message being executable. After getting their receipt,\n\nThe sequencer posts their transaction in a batch (usually within a few minutes, though the sequencer will wait a bit longer if the L1 is congested). Then,\nA validator includes their transaction in an RBlock (usually within the hour). Then, after the ~week long dispute window passes, the RBlock is confirmable, and\nSomebody (anybody) confirms the RBlock on L1 (usually within ~15 minutes).\n\nAdditionally, in the rare and unlikely event of a dispute, this delay period will be extended for the dispute to resolve.\n\nIs there a way to cancel a withdrawal from Arbitrum?​\n\nThere is no way to cancel a withdrawal that has been already initiated. However, you can claim your funds on L1 and deposit them again on L2 once the withdrawal period is past.\n\nCan I use a smart contract wallet in the bridge?​\n\nSupport for Smart Contract Wallets is currently limited to token depositing and withdrawal. Keep in mind that when withdrawing funds, you won't be able to claim them on L1 using the bridge (unless you also control that address on L1). In that case, you can use the cross-chain dashboard to claim your funds on L1.\n\nETH deposits and withdrawals using a Smart Contract Wallet are currently not supported, but will soon be available.\n\nHow can I claim withdrawn funds if I don't control on L1 the address that initiated the transaction on L2?​\n\nOnce the withdrawal period is past, you can use the cross-chain dashboard to execute the message on L1. Paste the transaction hash that initiated the withdrawal on L2, and follow the process described in the dashboard.\n\nLast updated on Nov 18, 2024\nPrevious\nUSDC on Arbitrum One\nNext\nTransaction lifecycle\nHow do I move assets between One and Nova?\nWhat fees do I have to pay when bridging funds from L1 to L2?\nHow long does it take before I receive my funds when I initiate a withdrawal from Arbitrum chains (One and Nova)?\nIs there a way to cancel a withdrawal from Arbitrum?\nCan I use a smart contract wallet in the bridge?\nHow can I claim withdrawn funds if I don't control on L1 the address that initiated the transaction on L2?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/sequencer",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nTransaction lifecycle\nSequencer\nAnyTrust protocol\nGas / fees\nAdvanced concepts\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nThe Sequencer and Censorship Resistance\n\nThe Sequencer is a specially designated Arbitrum full node which, under normal conditions, is responsible for submitting users’ transactions onto L1. In principle, a chain’s Sequencer can take different forms; as Arbitrum One currently stands, the Sequencer is a single, centralized entity; eventually, sequencing affordances could be given to a distributed committee of sequencers which come to consensus on ordering. However, regardless of its form, the Sequencer has a fundamental limitation that doesn’t apply to any other part of the system: it must operate under its own security assumptions; i.e., it can’t, in principle, derive security directly from layer 1. This brings up the question of how Arbitrum Rollup maintains its claim to censorship resistance when-and-if the Sequencer misbehaves.\n\nHere we will describe the mechanics of how the Sequencer typically operates, and how any user can bypass the Sequencer entirely to submit any Arbitrum transaction (including one that, say, initiates an L2 to L1 message to withdraw funds) directly from layer 1. Thus mechanism thereby preserves censorship resistance even if the Sequencer is being completely unresponsive or even malicious.\n\nThe Core Inbox​\n\nWhen we talk about “submitting a transaction into an Arbitrum chain,” we’re talking about getting it included into the chain’s core Inbox, represented by the sequencerInboxAccs byte array in Bridge. Once transactions are included in the core Inbox, their ordering is fixed, execution is fully deterministic, and we can trustlessly treat the resultant state as having L1-level finality (see “Transaction Lifecycle”). The Sequencer’s role (or lack thereof) concerns strictly what happens prior; i.e., how a transaction makes its way into the core Inbox. We’ll break down the possible routes a transaction can take into two scenarios: a well-behaved Sequencer, and a faulty Sequencer.\n\nHappy/Common Case: Sequencer Is Live and Well-behaved​\n\nHere, we start by assuming that the Sequencer is fully operational, and is running with the intent of processing users’ transactions in as safe and timely a manner as possible. The Sequencer can receive a user’s transaction two ways — either directly via an RPC request, or via the underlying L1.\n\nIf a user is posting a “standard” Arbitrum transaction (i.e., interacting with an L2 native dapp), the user will submit the signed transaction directly to the Sequencer, much like how a user submits a transaction to an Ethereum node when interacting with L1. Upon receiving it, the Sequencer will execute it and nearly instantaneously deliver the user a receipt. Some short time later — usually no more than a few minutes — the Sequencer will include the user’s transaction in a batch and post it on L1 by calling one of the SequencerInbox’s addSequencerL2Batch methods. Note that only the Sequencer has the authority to call these methods; this assurance that no other party can include a message directly is, in fact, the very thing that gives the Sequencer the unique ability to provide instant, \"soft-confirmation\" receipts. Once posted in a batch, the transactions have L1-level finality.\n\nAlternatively, a user can submit their L2 message to the Sequencer by posting it on the underlying L1. This path is necessary if the user wishes to perform some L1 operation along with the L2 message and to preserve atomicity between the two — the textbook example here being a token deposit via a bridge (escrow on L1, mint on L2). The user does this by publishing an L1 transaction (i.e., sending a normal transaction to an L1 node) that calls one of the relevant methods on the Inbox contract; i.e., sendUnsignedTransaction. This adds a message onto what we’ll call “the delayed Inbox”, (represented by the delayedInboxAccs in the Bridge contract), which is effectively a queue that messages wait in before being moved over to the core Inbox. The Sequencer will emit an L2 receipt about ~10 minutes after the transaction has been included in the delayed Inbox (the reason for this delay is to minimize the risk of short term L1 reorgs which could in turn cause an L2 reorg and invalidate the Sequencer’s L2 receipts.) Again, the last step is for the Sequencer to include the L2 message in a batch — when calling the batch submission methods, the Sequencer specifies how many messages in the delayed inbox to include — finalizing the transaction.\n\nIn sum — in either happy case, the user first delivers their message to the Sequencer, who in turn ensures that it arrives in the core Inbox.\n\nUnhappy/Uncommon Case: Sequencer Isn’t Doing Its Job​\n\nNow let’s suppose the Sequencer, for whatever reason, is entirely failing to carry out its task of submitting messages. A user can still get their transaction included in two steps:\n\nFirst, they submit their L2 message via L1 into the delayed Inbox as described above: note that although atomic cross-chain messages are the common case for using the delayed Inbox, it can in principle be used to submit any L2 message.\n\nOnce in the delayed Inbox, we obviously can’t rely on the Sequencer to include the transaction in a batch. Instead, we can use SequencerInbox’s forceInclusion method. Once a message has been in the delayed Inbox for a sufficient amount of time, forceInclusion can be called to move it from the delayed Inbox into the core Inbox, at which point it’s finalized. Crucially, any account can call forceInclusion.\n\nCurrently, on Arbitrum One, this delay time between submission and force inclusion is roughly 24 hours, as specified by maxTimeVariation.delayBlocks / maxTimeVariation.delaySeconds. A force inclusion from L1 would directly affect the state for any unconfirmed L2 transactions; keeping conservatively high delay value ensures it should only be used under extraordinary circumstances.\n\nOn top of the delay itself, the forceInclusion path has the downside of uncertainty around transaction ordering; i.e., while waiting for a message's max delay to pass, a malicious Sequencer could, in principle, directly post messages in front of it. However, there’s ultimately nothing the Sequencer can do to stop it from being included in the core Inbox, at which point its ordering is finalized.\n\nWhile the slow, “unhappy” path isn’t optimal, and should rarely, if ever, be necessary, its availability as an option ensures Arbitrum Rollup always preserves its trustless security model, even if the permissioned parts of the system act faulty.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nTransaction lifecycle\nNext\nAnyTrust protocol\nThe Core Inbox\nHappy/Common Case: Sequencer Is Live and Well-behaved\nUnhappy/Uncommon Case: Sequencer Isn’t Doing Its Job\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/arbitrum-bridge/usdc-arbitrum-one",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nQuickstart\nUSDC on Arbitrum One\nTroubleshooting\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nUSDC on Arbitrum One\n\nArbitrum One supports two different types of USDC:\n\nArbitrum-native USDC (USDC): USDC tokens native to the Arbitrum One chain.\nBridged USDC (USDC.e): Ethereum-native USDC tokens that have been bridged to Arbitrum One.\nDifferences between USDC and USDC.e​\n\tArbitrum-native USDC\tBridged USDC\nToken Name\tUSD Coin\tBridged USDC\nToken Symbol\tUSDC\tUSDC.e\nToken Address\t\n\n0xaf88d065e77c8cC2239327C5EDb3A432268e5831\n\n\t\n\n0xff970a61a04b1ca14834a43f5de4533ebddb5cc8\n\n\nBenefits\tCEX Support, directly redeemable 1:1 for U.S dollars\t\n\nThe Arbitrum Bridge will continue to facilitate transfers of all USDC tokens. When depositing Ethereum-native USDC, the option exists to receive Bridged USDC using Arbitrum's bridge or Arbitrum-native USDC using Circle’s Cross-Chain Transfer Protocol.\n\nHistorical context​\n\nArbitrum One has supported Bridged USDC since conception, which previously had over a billion Bridged USDC in circulation. On June 8th 2023, Circle added support for the Cross-Chain Transfer Protocol and launched Arbitrum-native USDC, which enabled direct minting and burning of Arbitrum-Native USDC on Arbitrum One. Due to this, the Bridged USDC token symbol was renamed from USDC to USDC.e to accommodate Arbitrum-native USDC. The expectation is that over time the conversion of Bridged USDC to Arbitrum-native USDC will continue.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nQuickstart\nNext\nTroubleshooting\nDifferences between USDC and USDC.e\nHistorical context\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/sequencer/run-sequencer-coordination-manager",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nRun a feed relay\nRead the sequencer feed\nRun a Sequencer Coordination Manager (SQM)\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to run a Sequencer Coordinator Manager (SQM)\n\nThe Sequencer Coordinator Manager (SQM) is a command-line tool that allows you to manage the priority list of sequencers, update their positions, add new sequencers to the list, and refresh the lists from the Redis server. The tool offers keyboard-only support. Any changes you make are stored locally until you choose to save and push them to the Redis server.\n\nHere is an example of how to start the Sequencer Coordinator Manager and connect to a local Redis server:\ngit clone --branch v3.2.1 https://github.com/OffchainLabs/nitro.git\ncd nitro\nmake target/bin/seq-coordinator-manager\n./target/bin/seq-coordinator-manager redis://127.0.0.1:6379\n\n\nIf mouse support is enabled, you can use your mouse to explore the tool. Otherwise, use your keyboard to explore the UI. The enter key selects options; c switches focus between lists. When you bring up any form, you can navigate within the form's options using the Tab key and use the up/down arrow keys to select options from the dropdown menu.\n\nNOTE\n\nOne of the sequencers is marked with a chosen indicator. This visual cue helps you identify the current chosen sequencer.\n\nYou can click/enter on any sequencer element in the priority list to bring up a form for updating its position. Within this form, you have the options to make changes via a dropdown menu and then either click Update to see the change locally, Cancel to cancel the operation, or Remove to remove the sequencer from the priority list.\n\nWhen a sequencer is removed, it is automatically added to the --Not in priority list but online-- list if it is online. Please remember that all changes made using this method are local and need to be saved to the Redis server by pressing s from the keyboard shortcuts to make them permanent.\n\nAfter selecting a sequencer from the non-priority list, you are given the option to add the selected sequencer to the priority list at any position of your choice. You can specify the position via a dropdown menu that lists all possible positions. Clicking Update will then display the updated priority list with the newly added sequencer in the chosen position.\n\nYou can also add a new sequencer to the priority list by pressing a from the keyboard shortcuts. This action will bring up a form to enter the sequencer details. After adding the sequencer URL, you can click Add to see the changes or Cancel to abort the operation.\n\nTo exit the tool, press q from the keyboard shortcuts.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRead the sequencer feed\nNext\nBuild Nitro locally\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/sequencer/read-sequencer-feed",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nRun a feed relay\nRead the sequencer feed\nRun a Sequencer Coordination Manager (SQM)\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to read the sequencer feed\n\nRunning an Arbitrum relay locally as a feed relay lets you subscribe to an uncompressed sequencer feed for real-time data as the sequencer accepts and orders transactions off-chain.\n\nWhen connected to websocket port 9642 of the local relay, you'll receive a data feed that looks something like this:\n\n{\n  \"version\": 1,\n  \"messages\": [\n    {\n      \"sequenceNumber\": 25757171,\n      \"message\": {\n        \"message\": {\n          \"header\": {\n            \"kind\": 3,\n            \"sender\": \"0xa4b000000000000000000073657175656e636572\",\n            \"blockNumber\": 16238523,\n            \"timestamp\": 1671691403,\n            \"requestId\": null,\n            \"baseFeeL1\": null\n          },\n          \"l2Msg\": \"BAL40oKksUiElQL5AISg7rsAgxb6o5SZbYNoIF2DTixsqDpD2xII9GJLG4C4ZAhh6N0AAAAAAAAAAAAAAAC7EQiq1R1VYgL3/oXgvD921hYRyAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAArAAaAkebuEnSAUvrWVBGTxA7W+ZMNn5uyLlbOH7Nrs0bYOv6AOxQPqAo2UB0Z7vqlugjn+BUl0drDcWejBfDiPEC6jQA==\"\n        },\n        \"delayedMessagesRead\": 354560\n      },\n      \"signature\": null\n    }\n  ]\n}\n\n\nBreaking this feed down a bit: the top-level data structure is defined by the BroadcastMessage struct:\n\ntype BroadcastMessage struct {\n\tVersion int `json:\"version\"`\n\t// Note: the \"Messages\" object naming is slightly ambiguous: since there are different types of messages\n\tMessages                       []*BroadcastFeedMessage         `json:\"messages,omitempty\"`\n\tConfirmedSequenceNumberMessage *ConfirmedSequenceNumberMessage `json:\"confirmedSequenceNumberMessage,omitempty\"`\n}\n\n\nThe messages field is the BroadcastFeedMessage struct:\n\ntype BroadcastFeedMessage struct {\n\tSequenceNumber arbutil.MessageIndex         `json:\"sequenceNumber\"`\n\tMessage        arbstate.MessageWithMetadata `json:\"message\"`\n\tSignature      []byte                       `json:\"signature\"`\n}\n\n\nEach message conforms to arbstate.MessageWithMetadata:\n\ntype MessageWithMetadata struct {\n\tMessage             *arbos.L1IncomingMessage `json:\"message\"`\n\tDelayedMessagesRead uint64                   `json:\"delayedMessagesRead\"`\n}\n\n\nFinally, we get the transaction's information in the message subfield as an L1IncomingMessage:\n\ntype L1IncomingMessage struct {\n\tHeader *L1IncomingMessageHeader `json:\"header\"`\n\tL2msg  []byte                   `json:\"l2Msg\"`\n\t// Only used for `L1MessageType_BatchPostingReport`\n\tBatchGasCost *uint64 `json:\"batchGasCost,omitempty\" rlp:\"optional\"`\n}\n\n\nYou can use the ParseL2Transactions function to decode the message.\n\nUsing the feed relay, you can also retrieve the L2 block number of a message:\n\nOn Arbitrum One, this can be done by adding the Arbitrum One genesis block number (22207817) to the sequence number of the feed message.\nNote that in the case of Arbitrum Nova, the Nitro genesis number is 0, so it doesn't need to be included when adding to the feed message's sequence number.\nINFO\n\nNote that the messagess[0].message.message.header.blockNumber is L1 block number instead of L2 block number\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRun a feed relay\nNext\nRun a Sequencer Coordination Manager (SQM)\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/more-types/run-classic-node",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nRun an archive node\nRun a validator\nRun a Classic node\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to run a Classic node\nDo you need to run a Classic node?​\n\nArbitrum One has been upgraded to Nitro, the latest Arbitrum tech stack. \"Arbitrum Classic\" is our term for the old, pre-Nitro tech stack. The Nitro node databases have the raw data of all blocks, including pre-Nitro blocks. However, Nitro nodes cannot execute anything on pre-Nitro blocks. You need an Arbitrum Classic archive node to execute data on pre-Nitro blocks.\n\nThe following commands are supported when running an Arbitrum Classic archive node:\n\neth_call\neth_estimateGas\neth_getBalance\neth_getCode\neth_getTransactionCount\neth_getStorageAt\n\n🔉 Note that Arbitrum Nova and Arbitrum Sepolia started as a Nitro chain, so they don't have classic blocks.\n\nRequired artifacts​\nLatest Docker Image: offchainlabs/arb-node:v1.4.5-e97c1a4\nLatest classic snapshot for Arbitrum One: https://snapshot.arbitrum.foundation/arb1/classic-archive.tar\nRequired parameters​\n--l1.url=<Layer 1 Ethereum RPC URL>\nMust provide standard Ethereum node RPC endpoint.\n--node.chain-id=<L2 Chain ID>\nMust use 42161 for Arbitrum One\nImportant ports​\nRPC: 8547\nWebSocket: 8548\nPutting it all together​\nWhen running docker image, an external volume should be mounted to persist the database across restarts. The mount point should be /home/user/.arbitrum/mainnet.\nHere is an example of how to run a classic archive node for Arbitrum One (only needed for archive requests on pre-Nitro blocks, so you'll probably want to enable the archive mode in your nitro node as well):\ndocker run --rm -it  -v /some/local/dir/arbitrum-mainnet/:/home/user/.arbitrum/mainnet -p 0.0.0.0:8547:8547 -p 0.0.0.0:8548:8548 offchainlabs/arb-node:v1.4.5-e97c1a4 --l1.url=https://l1-node:8545 --node.chain-id=42161 --l2.disable-upstream\n\nNote on permissions​\nThe Docker image is configured to run as non-root UID 1000. This means if you are running in Linux and you are getting permission errors when trying to run the docker image, run this command to allow all users to update the persistent folders.\nmkdir /some/local/dir/arbitrum-mainnet\nchmod -fR 777 /some/local/dir/arbitrum-mainnet\n\nOptional parameters​\n\nWe show here a list of the parameters that are most commonly used when running a Classic node. You can also use the flag --help for a full comprehensive list of the available parameters.\n\n--core.cache.timed-expire\nDefaults to 20m, or 20 minutes. Age of oldest blocks to hold in cache so that disk lookups are not required\n--node.rpc.max-call-gas\nMaximum amount of gas that a node will use in call, default is 5000000\n--core.checkpoint-gas-frequency\nDefaults to 1000000000. Amount of gas between saving checkpoints to disk. When making archive queries node has to load closest previous checkpoint and then execute up to the requested block. The farther apart the checkpoints, the longer potential execution required. However, saving checkpoints more often slows down the node in general.\n--node.cache.allow-slow-lookup\nWhen this option is present, will load old blocks from disk if not in memory cache\nIf archive support is desired, recommend using --node.cache.allow-slow-lookup --core.checkpoint-gas-frequency=156250000\n--node.rpc.tracing.enable\nNote that you also need to have a database populated with an archive node if you want to trace previous transactions\nThis option enables the ability to call a tracing api which is inspired by the parity tracing API with some differences\nExample: curl http://arbnode -X POST -H \"Content-Type: application/json\" -d '{\"jsonrpc\":\"2.0\",\"method\":\"arbtrace_call\",\"params\":[{\"to\": \"0x6b175474e89094c44da98b954eedeac495271d0f\",\"data\": \"0x70a082310000000000000000000000006E0d01A76C3Cf4288372a29124A26D4353EE51BE\"},[\"trace\"], \"latest\"],\"id\":67}'\nThe trace_* methods are renamed to arbtrace_*, except trace_rawTransaction is not supported\nOnly trace type is supported. vmTrace and stateDiff types are not supported\nThe self-destruct opcode is not included in the trace. To get the list of self-destructed contracts, you can provide the deletedContracts parameter to the method\nFeed relay​\nArbitrum classic does not communicate with Nitro sequencer, so the classic relay is no longer used.\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRun a validator\nNext\nRun a feed relay\nDo you need to run a Classic node?\nRequired artifacts\nRequired parameters\nImportant ports\nPutting it all together\nNote on permissions\nOptional parameters\nFeed relay\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Nitro database snapshots | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/nitro/nitro-database-snapshots",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nNitro database snapshots\n\nNitro stores the chain state and data in a database in the local filesystem. When starting Nitro for the first time, it will initialize an empty database by default and start processing transactions from Genesis. It takes a long time for the node to sync from Genesis, so starting from a database snapshot is advisable instead. Moreover, for the Arb1 chain, you must start from a snapshot because Nitro cannot process transactions from the Classic Arbitrum node.\n\nSupply the snapshot URL to Nitro​\n\nThere are multiple ways to supply Nitro with the database snapshot. The most straightforward way is to provide the configuration, so Nitro downloads the snapshot by itself. It is also possible to download the database manually and supply it to Nitro.\n\nDownloading the latest snapshot​\n\nNitro has a CLI configuration for downloading the latest snapshot from a remote server. Set the flag --init.latest to either archive, pruned, or genesis, and Nitro will download the preferred snapshot. You may also change the --init.latest-base flag to set the base URL when searching for the latest snapshot.\n\nHow it works​\n\nWhen searching for the latest snapshot, Nitro uses the chain name provided in --chain.name. Make sure to set it correctly; otherwise, Nitro might be unable to find the snapshot. Nitro will look for a remote file in <latest-base>/<chain-name>/latest-<kind>.txt, where <kind> is the option supplied to --init.latest. This file should contain either the path or the full URL to the snapshot; if it only contains the path, Nitro will use the <latest-base> as the base URL.\n\nAfter finding the latest snapshot URL, Nitro will download the archive and temporarily store it in the directory specified in --init.download-path. Nitro looks for a SHA256 checksum on the remote server and verifies the checksum of the snapshot after finishing the download. (It is possible to disable this feature by setting --init.validate-checksum to false.)\n\nThe snapshot can be a single archive file or a series of parts. Nitro first tries to download the snapshot as a single archive. In this case, Nitro will look for a checksum file in <archive-url>.sha256. If the remote server returns not found (404 status code), Nitro will proceed to download the snapshot in parts. When downloading in parts, Nitro will look for a manifest file in <archive-url>.manifest.txt containing each part's name and checksum. In this case, Nitro will download each part in the manifest file and concatenate them into a single archive.\n\nFinally, Nitro decompresses and extracts the snapshot archive, placing it in the database directory. Nitro will delete the archive after extracting it, so if you need to set up multiple nodes with the same snapshot, consider downloading it manually, as explained below.\n\nDownloading the snapshot from a URL​\n\nInstead of letting Nitro search for the latest snapshot, you can provide a specific URL to download by setting the flag --init.url with the snapshot URL. If the URL points to a remote server, it should start with the https:// protocol definition. Given the URL, Nitro will download the snapshot as described in the \"Downloading the Latest Snapshot\" section.\n\nNitro also supports importing files from the local file system. In this case, you should provide the file path to --init.url starting with the prefix file:// followed by the file path. Beware that when running Nitro inside a Docker container, you must mount a volume containing the provided snapshot using the docker flag -v (see Docker documentation). Otherwise, the Nitro container running inside Docker won’t be able to find the snapshot in your local filesystem.\n\nDownloading the snapshot manually​\n\nIt is possible to download the snapshot manually and supply the archive instead of having Nitro download it.\n\nThe first step is downloading the snapshot. The command below illustrates how to do that on the command line using wget. The -c flag tells the wget to continue the download from where it left off, which is helpful because snapshots can be huge files, and the download can fail mid-way. The -P flag tells wget to place the snapshot on the temporary dir.\n\nwget -c -P /tmp \"$SNAPSHOT_URL\"\n\n\nAfter downloading the snapshot, make sure to verify whether the checksum matches the one provided by the remote server. To fetch the checksum, you may run the command below.\n\nwget -q -O - \"$SNAPSHOT_URL\".sha256\n\n\nOnce you know the expected snapshot checksum, run the command below to compute the checksum of the downloaded snapshot. Then, compare both and see if they are the same. If they are not the same, consider redownloading the snapshot. You must provide a valid snapshot to Nitro; otherwise, it won’t work properly.\n\nsha256sum $PATH_TO_SNAPSHOT\n\n\nFinally, you can provide a path to the downloaded snapshot archive to Nitro using the --init.url flag, as described in the \"Download the Snapshot from a URL\" section.\n\nDownloading snapshot parts​\n\nIf the snapshot is divided into parts, you should first download the manifest file in <snapshot-url>.manifest.txt. This manifest contains the names and checksums of each part. For instance, the snippet below shows how the manifest file should look. You may use the commands described previously to download each part of the snapshot and verify their checksums.\n\na938e029605b81e03cd4b9a916c52d96d74c985ac264e2f298b90495c619af74  archive.tar.part0\n9e095ce82e70fa62bb6e7b4421e7f2c04b2cd9e21d2bc62cbbaaeb877408357b  archive.tar.part1\ne92172d6eaf770a76c7477e6768f742fc51555a5050de606bd0f837e59c7a61d  archive.tar.part2\nd1b6fb9aeeb23903cdbb2a7cca8e6909bff4ee8e51c8a5acac2a142b3e3a5437  archive.tar.part3\nf37e4552453202f2044e58b307bab7e466205bd280426abbc84f8646c6430cfa  archive.tar.part4\n972c5f513faca6ac4fadd22c70bea97707c6d38e9a646432bc311f0ca10497ed  archive.tar.part5\n\n\nAfter downloading all the parts and verifying their checksums, you may use the command below to join them into a single archive.\n\ncat archive.tar.part* > archive.tar\n\nExtracting the snapshot manually​\n\nIt is also possible to extract the snapshot archive and place the files manually. First, you need to download the snapshot archive as described in \"Manually Downloading the Snapshot\". Then, create the directory where Nitro will look for its database. By default, Nitro stores the database on $HOME/.arbitrum/$CHAIN/nitro. Move the archive to this directory and extract it. The commands below exemplify this process for the Arbitrum Sepolia chain.\n\nexport CHAIN=sepolia-rollup\nexport ARCHIVE_PATH=/tmp/archive.tar.gz\nmkdir -p $HOME/.arbitrum/$CHAIN/nitro\ncd $HOME/.arbitrum/$CHAIN/nitro\ntar zxfv $ARCHIVE_PATH\n\n\nYou should see the following subdirectories in this directory after extracting the archive.\n\narbitrumdata\nl2chaindata\nnodes\n\nCreating a snapshot​\n\nTo generate a snapshot for the Nitro database, you first need to stop the process gracefully. You must not generate the snapshot while Nitro runs because the database might be in an intermediary state. Nitro should print logs like the ones described below when stopping.\n\n^CINFO [08-22|18:10:55.015] shutting down because of sigint\nINFO [08-22|18:10:55.016] delayed sequencer: context done          err=\"context canceled\"\nINFO [08-22|18:10:55.016] rpc response                             method=eth_getBlockByNumber logId=123 err=\"context canceled\" result=null attempt=0 args=\"[\\\"0x405661\\\", false]\"\nINFO [08-22|18:10:55.293] Writing cached state to disk             block=39988 hash=8bebf3..939ab2 root=4f7a22..00c334\nINFO [08-22|18:10:55.297] Persisted trie from memory database      nodes=643 size=156.31KiB time=3.673459ms gcnodes=329 gcsize=102.61KiB gctime=\"248.708µs\" livenodes=2448 livesize=806.00KiB\nINFO [08-22|18:10:55.297] Writing cached state to disk             block=39987 hash=ddcd60..fe0fc3 root=d6973e..7b9265\nINFO [08-22|18:10:55.298] Persisted trie from memory database      nodes=34  size=11.19KiB  time=\"283.875µs\" gcnodes=0   gcsize=0.00B     gctime=0s          livenodes=2414 livesize=794.81KiB\nINFO [08-22|18:10:55.298] Writing cached state to disk             block=39861 hash=2a9dd3..f00ff0 root=139d5a..d6bf21\nINFO [08-22|18:10:55.298] Persisted trie from memory database      nodes=73  size=24.88KiB  time=\"502.916µs\" gcnodes=0   gcsize=0.00B     gctime=0s          livenodes=2341 livesize=769.93KiB\nINFO [08-22|18:10:55.299] Writing cached state to disk             block=39861 hash=2a9dd3..f00ff0 root=139d5a..d6bf21\nINFO [08-22|18:10:55.299] Persisted trie from memory database      nodes=0   size=0.00B     time=\"1.417µs\"   gcnodes=0   gcsize=0.00B     gctime=0s          livenodes=2341 livesize=769.93KiB\nINFO [08-22|18:10:55.299] Writing snapshot state to disk           root=bd18ce..3b0763\nINFO [08-22|18:10:55.299] Persisted trie from memory database      nodes=0   size=0.00B     time=\"1.125µs\"   gcnodes=0   gcsize=0.00B     gctime=0s          livenodes=2341 livesize=769.93KiB\nINFO [08-22|18:10:55.304] Blockchain stopped\n\n\nAfter nitro stops, go to the database directory and generate an archive file for the directories arbitrumdata, l2chaindata, and nodes. By default, the database directory for nitro is $HOME/.arbitrum/$CHAIN/nitro. The commands below exemplify how to generate the snapshot for Nitro.\n\nexport CHAIN=sepolia-rollup\nexport ARCHIVE_PATH=/tmp/archive.tar.gz\ncd $HOME/.arbitrum/$CHAIN/nitro\ntar zcfv $ARCHIVE_PATH arbitrumdata l2chaindata nodes\n\n\nThis command purposely omits the wasm directory from the snapshot archive. The wasm contains native-code executables, so it might be a security concern for users downloading the snapshot. If the user downloading the snapshot trusts you, or if you are storing it for your own use, you may include the wasm directory in it.\n\nOptional: divide it into parts​\n\nIt is possible to divide the snapshot into smaller parts to facilitate its download. This is particularly useful for archive snapshots of heavily used chains, such as arb1. These kinds of snapshots can reach terabytes, so dividing them into smaller parts is helpful. The snippet below illustrates how to divide the snapshot into parts using the split command. The -b argument tells the split to divide the snapshot into 100 GB parts. The -d argument tells split to enumerate the parts using a numeric suffix instead of an alphabetic one.\n\nsplit -b 100g -d archive.tar.gz archive.tar.gz.part\n\n\nAfter dividing it into parts, you should generate the manifest file containing the parts' names and checksums. Nitro will use these files to know how many parts there are and to validate their checksum. The command below exemplifies how to do that.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nMigrate to Nitro from Classic\nNext\nTroubleshooting\nSupply the snapshot URL to Nitro\nDownloading the latest snapshot\nHow it works\nDownloading the snapshot from a URL\nDownloading the snapshot manually\nDownloading snapshot parts\nExtracting the snapshot manually\nCreating a snapshot\nOptional: divide it into parts\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/nitro/migrate-state-and-history-from-classic",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to migrate state and history from a classic (pre-Nitro) node to a Nitro node\n\nWhen running a Nitro node for the first time on a chain that produced classic blocks in the past (like Arbitrum One), you need to initialize its database to, at least, the state of the chain after executing the last classic block. The common, and recommended, way of doing that is to provide a database snapshot using the --init.url option (as mentioned in How to run a full node (Nitro)). In this how-to we show you an alternative way for doing that, migrating the state and history of the chain from a fully synced classic node.\n\nIS THIS HOW-TO FOR YOU?\n\nAs mentioned, the recommended way of initializing a Nitro node is by using a pre-initialized database snapshot with the --init.url option. This guide is for those that are interested in re-creating the full state of the chain from the genesis block using their own classic node.\n\nKeep in mind that this process only applies to Arbitrum One. Other Arbitrum chains didn't produce classic blocks in the past, they started as Nitro chains.\n\nPrerequisites​\n\nTo successfully migrate the state and history of the chain from a classic (pre-Nitro) node to a Nitro node, you'll need:\n\nA fully synced classic node: you can find instructions on how to run a classic node in this page.\nA clean, uninitialized Nitro node: you can find instructions on how to set up a Nitro node in this page.\nStep 1: Enable export options in your classic node​\n\nLaunch your classic node with the option --node.rpc.nitroexport.enable=true. All exported data will be written to directory \"nitroexport\" under the classic instance directory (e.g. ${HOME}/.arbitrum/mainnet/nitroexport). Make sure the classic node has read the entire rollup state.\n\nCAUTION\n\nEnabling the export options is only recommended for nodes with no public/external interfaces.\n\nEXPORTED FILE CONTENTS ARE NOT DETERMINISTIC\n\nExporting the state of your own classic node should produce the same state as using files supplied by the Arbitrum Foundation (i.e. the same genesis blockhash). However, multiple exports of the same state will not necessarily create identical intermediate files. For example, state export is done in parallel, so the order of entries in the file is not deterministic.\n\nStep 2: Export information from your classic node​\nBlock & transaction history​\n\nThese are block headers, transactions and receipts executed in the classic node. Nitro node uses the history to be able to answer simple requests, like eth_getTransactionReceipt, from the classic history. The last block in the chain is the only one that affects the genesis block: timestamp is copied from the last block, and parentHash is taken from the last block's blockHash.\n\nCall the RPC method arb_exportHistory with parameter \"latest\" to initiate history export. It will return immediately.\nCalling arb_exportHistoryStatus will return the latest block exported, or an error if the export failed.\nData will be stored in the directory nitroexport/nitro/l2chaindata/ancient.\nRollup state​\n\nThe rollup state is exported as a series of JSON files. State read from these JSON files will be added to Nitro's genesis block.\n\nCall the RPC method arb_exportState with parameter \"latest\" to initiate state export. Unless disconnected, this will only return after the state export is done.\nData will be stored in the directory nitroexport/state/<block_number>/.\nOutbox messages (optional)​\n\nThis data does not impact consensus and is optional. It allows a Nitro node to provide the information required when executing a withdrawal made on the classic rollup.\n\nCall the RPC method arb_exportOutbox with parameter \"0xffffffffffffffff\" to initiate outbox export. It will return immediately.\nCalling arb_exportOutboxStatus will return the latest outbox batch exported, or an error if the export failed.\nData will be stored in the directory nitroexport/nitro/classic-msg.\nStep 3: Initialize your Nitro node importing the exported data​\nPlace the l2chaindata and classic-msg (if exported) directories in Nitro's instance directory (e.g. ${HOME}/.arbitrum/arb1-nitro/).\nLaunch the Nitro node with the argument --init.import-file=/path/to/state/index.json\nCAUTION\n\nThis state import operation requires more resources than a regular run of a Nitro node.\n\nOther useful Nitro options​\nFlag\tDescription\n--init.accounts-per-sync\tAllows the node to make partial database writes to hard-disk during initialization, allowing memory to be freed. This should be used if memory load is very high. A reasonable initial value to try would be 100000. Systems with constrained memory might require a lower value.\n--init.then-quit\tCauses the node to quit after initialization is done.\n--init.force\tFor an already-initialized node, forces the node to recalculate Nitro's genesis block. If the genesis blockhash doesn't match what's in the database, the node will panic.\nSee also​\nHow to run a full node (Nitro)\nHow to run a full node (Classic, pre-Nitro)\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nBuild Nitro locally\nNext\nDatabase snapshots\nPrerequisites\nStep 1: Enable export options in your classic node\nStep 2: Export information from your classic node\nBlock & transaction history\nRollup state\nOutbox messages (optional)\nStep 3: Initialize your Nitro node importing the exported data\nOther useful Nitro options\nSee also\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to build Nitro locally (Debian, Ubuntu, MacOS) | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/nitro/build-nitro-locally",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nHow to build Nitro locally (Debian, Ubuntu, MacOS)\n\nArbitrum Nitro is the software that powers all Arbitrum chains. This how-to shows how you can build a Docker image, or binaries, directly from Nitro's source code. If you want to run a node for one of the Arbitrum chains, however, it is recommended that you use the docker image available on DockerHub, as explained in How to run a full node.\n\nThis how-to assumes that you're running one of the following operating systems:\n\nDebian 11.7 (arm64)\nUbuntu 22.04 (amd64)\nMacOS Sonoma 14.3.\nBuild a Docker image​\nStep 1. Configure Docker​\nFor Debian/Ubuntu​\nfor pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done\n# Add Docker's official GPG key:\nsudo apt-get update\nsudo apt-get install ca-certificates curl gnupg\nsudo install -m 0755 -d /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/debian/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\nsudo chmod a+r /etc/apt/keyrings/docker.gpg\n\n# Add the repository to Apt sources:\necho \\\n  \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/debian \\\n  \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\nsudo service docker start\n\n\n(Note that if you are running Ubuntu 22.04, you might get an Unable to locate package docker-buildx-plugin error. Try sudo apt install docker-buildx instead.)\n\nFor MacOS​\n\nDepending on whether your Mac has an Intel processor or Apple silicon, download the corresponding disk image from Docker, and move it into your Applications folder.\n\n[Optional] Run docker from a different user​\n\nAfter installing docker, you might want to be able to run it with your current user instead of root. You can run the following commands to do so.\n\nsudo groupadd docker\nsudo usermod -aG docker $USER\nnewgrp docker\n\n\nFor troubleshooting, check Docker's section in their documentation\n\nStep 2. Download the Nitro source code​\ngit clone --branch v3.2.1 https://github.com/OffchainLabs/nitro.git\ncd nitro\ngit submodule update --init --recursive --force\n\nStep 3. Build the Nitro node Docker image​\ndocker build . --tag nitro-node\n\n\nThat command will build a Docker image called nitro-node from the local source.\n\nBuild Nitro's binaries natively​\n\nIf you want to build the node binaries natively, execute steps 1-3 of the Build a Docker image section and continue with the steps described here. Notice that even though we are building the binaries outside of Docker, it is still used to help build some WebAssembly components.\n\nStep 4. Configure prerequisites​\nFor Debian/Ubuntu​\napt install git curl build-essential cmake npm golang clang make gotestsum wabt lld-13 python3\nnpm install --global yarn\nln -s /usr/bin/wasm-ld-13 /usr/local/bin/wasm-ld\n\nFor MacOS​\n\nInstall Homebrew package manager and add it to your PATH environment variable:\n\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\necho \"export PATH=/opt/homebrew/bin:$PATH\" >> ~/.zprofile && source ~/.zprofile\n\n\n(replace ~/.zprofile with ~/.bash_profile if you use bash instead of zsh).\n\nInstall essentials:\n\nbrew install git curl make cmake npm go golangci-lint wabt llvm lld libusb gotestsum\nnpm install --global yarn\nsudo mkdir -p /usr/local/bin\necho \"export PATH=/opt/homebrew/opt/llvm/bin:$PATH\" >> ~/.zprofile && source ~/.zprofile\n\nStep 5. Configure node 18​\nFor Debian/Ubuntu​\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | bash\nsource \"$HOME/.bashrc\"\nnvm install 18\nnvm use 18\n\nFor MacOS​\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | bash\nexport NVM_DIR=\"$HOME/.nvm\"\n[ -s \"$NVM_DIR/nvm.sh\" ] && \\. \"$NVM_DIR/nvm.sh\"\nnvm install 18\nnvm use 18\n\nStep 6. Configure Rust 1.80.1​\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsource \"$HOME/.cargo/env\"\nrustup install 1.80.1\nrustup default 1.80.1\nrustup install nightly\nrustup target add wasm32-unknown-unknown --toolchain 1.80.1\nrustup target add wasm32-wasi --toolchain 1.80.1\nrustup target add wasm32-unknown-unknown --toolchain nightly\nrustup target add wasm32-wasi --toolchain nightly\nrustup component add rust-src --toolchain nightly\ncargo install cbindgen\n\nStep 7. Configure Go 1.23​\nInstall Bison​\nFor Debian/Ubuntu​\nsudo apt-get install bison\n\nFor MacOS​\nbrew install bison\n\nInstall and configure Go​\nbash < <(curl -s -S -L https://raw.githubusercontent.com/moovweb/gvm/master/binscripts/gvm-installer)\nsource \"$HOME/.gvm/scripts/gvm\"\ngvm install go1.23\ngvm use go1.23 --default\ncurl -sSfL https://raw.githubusercontent.com/golangci/golangci-lint/master/install.sh | sh -s -- -b $(go env GOPATH)/bin v1.54.2\n\n\nIf you use zsh, replace bash with zsh.\n\nInstall foundry​\ncurl -L https://foundry.paradigm.xyz | bash\nfoundryup\n\nStep 8. Start build​\nmake\n\nStep 9. Produce binaries​\nmake build\n\nWarnings on MacOS​\n\nIn MacOS with Apple Silicon, warnings like the following might appear but they will not hinder the compilation process.\n\nld: warning: object file was built for newer 'macOS' version (14.4) than being linked (14.0)\n\n\nTo solve these warnings, export the following environment variables before building Nitro.\n\nexport MACOSX_DEPLOYMENT_TARGET=$(sw_vers -productVersion)\nexport CGO_LDFLAGS=-Wl,-no_warn_duplicate_libraries\n\nStep 10. Run your node​\n\nTo run your node using the generated binaries, use the following command from the nitro folder, with your desired parameters\n\n./target/bin/nitro <node parameters>\n\nWASM module root error (v2.3.4 or later)​\n\nSince v2.3.4, the State Transition Function (STF) contains code that is not yet activated on the current mainnet and testnet chains. Because of that, you might receive the following error when connecting your built node to those chains:\n\nERROR[05-21|21:59:17.415] unable to find validator machine directory for the on-chain WASM module root err=\"stat {WASM_MODULE_ROOT}: no such file or directory\"\n\n\nTry add flag:\n\n--validation.wasm.allowed-wasm-module-roots={WASM_MODULE_ROOT}\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRun a Sequencer Coordination Manager (SQM)\nNext\nMigrate to Nitro from Classic\nBuild a Docker image\nStep 1. Configure Docker\nStep 2. Download the Nitro source code\nStep 3. Build the Nitro node Docker image\nBuild Nitro's binaries natively\nStep 4. Configure prerequisites\nStep 5. Configure node 18\nStep 6. Configure Rust 1.80.1\nStep 7. Configure Go 1.23\nStep 8. Start build\nStep 9. Produce binaries\nStep 10. Run your node\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/sequencer/run-feed-relay",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nRun a feed relay\nRead the sequencer feed\nRun a Sequencer Coordination Manager (SQM)\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to run a feed relay\nCAUTION\n\nIf running a single node, there is no need to run a feed relay. When running more that one node, it is strongly suggested to run a single feed relay per datacenter, which will reduce ingress fees and improve stability.\n\nCAUTION\n\nFeed endpoints will soon require compression with a custom dictionary, so if connecting to feed with anything other than a standard node, it is strongly suggested to run a local feed relay which will provide an uncompressed feed by default.\n\nThe feed relay is in the same docker image as the Nitro node.\n\nHere is an example of how to run the feed relay for Arbitrum One:\ndocker run --rm -it  -p 0.0.0.0:9642:9642 --entrypoint relay offchainlabs/nitro-node:v3.2.1-d81324d --node.feed.output.addr=0.0.0.0 --node.feed.input.url=wss://arb1.arbitrum.io/feed --chain.id=42161\n\nHere is an example of how to run nitro-node for Arbitrum One with custom relay:\ndocker run --rm -it  -v /some/local/dir/arbitrum:/home/user/.arbitrum -p 0.0.0.0:8547:8547 -p 0.0.0.0:8548:8548 offchainlabs/nitro-node:v3.2.1-d81324d --parent-chain.connection.url=https://l1-mainnet-node:8545 --chain.id=42161 --http.api=net,web3,eth --http.corsdomain=* --http.addr=0.0.0.0 --http.vhosts=* --node.feed.input.url=ws://local-relay-address:9642\n\n\nNote that Arbitrum classic does not communicate with Nitro sequencer, so classic relay is no longer used.\n\nHelm charts (Kubernetes)​\n\nIf you are using Kubernetes to run your feed relay, a helm chart is available at ArtifactHUB. It supports running a Nitro relay by providing the feed input URL. Find more information in the OCL community Helm charts repository.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRun a Classic node\nNext\nRead the sequencer feed\nHelm charts (Kubernetes)\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/more-types/run-archive-node",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nRun an archive node\nRun a validator\nRun a Classic node\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to run an archive node\n\nAn Arbitrum archive node is a full node that maintains an archive of historical chain states. This how-to walks you through the process of configuring an archive node on your local machine so that you can query both pre-Nitro and post-Nitro state data.\n\nCAUTION\n\nMost users won't need to configure an archive node. This node type is great for a small number of use cases - for example if you need to process historical data.\n\nBefore we begin​\n\nBefore the Nitro upgrade, Arbitrum One ran on the Classic stack for about one year (before block height 22207817). Although the Nitro chain uses the latest snapshot of the Classic chain's state as its genesis state, the Nitro stack can't serve archive requests for pre-Nitro blocks.\n\nRunning an Arbitrum One full node in archive mode lets you access both pre-Nitro and post-Nitro blocks, but it requires you to run both Classic and Nitro nodes together. You may not need to do this, depending on your use case:\n\nUse case\tRequired node type(s)\tDocs\nAccess the Arbitrum network without running your own node\tFully managed by third-parties, exposed via RPC endpoints\tRPC endpoints and providers\nRun an archive node for Arbitrum Sepolia (testnet) or Arbitrum Nova\tFull node (Nitro)\tHow to run a full node (Nitro)\nSend post-Nitro archive requests\tFull node (Nitro)\tHow to run a full node (Nitro)\nSend pre-Nitro archive requests\tFull node (Classic)\tHow to run a full node (Classic, pre-Nitro)\nSend post-Nitro and pre-Nitro archive requests\tFull node (Nitro) and full node (Classic)\tThat's what this how-to is for; you're in the right place.\nSystem requirements​\nCAUTION\n\nAs of May 2024, archive node snapshots for Arbitrum One, Arbitrum Nova, and Arbitrum Sepolia are no longer being updated on https://snapshot-explorer.arbitrum.io/ due to accelerated database and state growth. Teams who use these publicly available archive snapshots will need to wait longer than usual for their nodes to sync up.\n\nThe Offchain Labs team is actively exploring and working on solutions to address this and will provide an update as soon as possible. In the meantime, the Offchain Labs team continues to recommend that teams periodically create their own snapshots by stopping one of their archive nodes and backing up their database.\n\nCAUTION\n\nThe minimum storage requirements will change as the Nitro chains grow (growing rates are specified below). We recommend exceeding the minimum requirements as much as you can to minimize risk and maintenance overhead.\n\nRAM: 16GB+ for Nitro and 32GB+ for Classic\nCPU: 4+ core CPU\nStorage (last updated on April 2024):\nArbitrum One: 9.7TB SSD, currently growing at a rate of about 850GB per month\nArbitrum Nova: 4.3TB SSD, currently growing at a rate of about 1.8TB GB per month\nDocker images: We'll specify these in the below commands; you don't need to download them manually.\nLatest Docker image for Arbitrum One Nitro: offchainlabs/nitro-node:v3.2.1-d81324d\nLatest Docker image for Arbitrum One Classic: offchainlabs/arb-node:v1.4.5-e97c1a4\nDatabase snapshots:\nNitro database snapshot\nUse the parameter --init.url= on the first startup to initialize the Nitro database (you can find a list of snapshots here). Example: --init.url=\"https://snapshot.arbitrum.foundation/arb1/nitro-archive.tar\"\nArbitrum One Classic database snapshot\nDownload the latest Arbitrum One Classic database snapshot at https://snapshot.arbitrum.foundation/arb1/classic-archive.tar and place it in the mounted point directory\nNote that other chains don't have Classic blocks and thus don't require an initial genesis database.\nSnapshot Explorer\nYou can find more snapshots on our snapshot explorer\nReview and configure ports​\nRPC: 8547\nSequencer Feed: 9642\nWebSocket: 8548\nReview and configure parameters​\nArbitrum Nitro\tArbitrum Classic\tDescription\n--parent-chain.connection.url=<Layer 1 Ethereum RPC URL>\t--l1.url=<Layer 1 Ethereum RPC URL>\tProvide an standard L1 node RPC endpoint that you run yourself or from a third-party node provider (see RPC endpoints and providers)\n--chain.id=<L2 chain ID>\t--l2.chain-id=<L2 Chain ID>\tSee RPC endpoints and providers for a list of Arbitrum chains and the respective L2 chain IDs\n--execution.caching.archive\t--node.caching.archive\tRequired for running an Arbitrum One Nitro archival node and retains past block state\n-\t--node.cache.allow-slow-lookup\tRequired for running an Arbitrum One Classic archival node. When this option is present, it will load old blocks from disk if not in memory cache.\n-\t--core.checkpoint-gas-frequency=156250000\tRequired for running an Arbitrum One Classic archival node.\nArbitrum Nitro\tArbitrum Classic\tDescription\n--parent-chain.connection.url=<Layer 1 Ethereum RPC URL>\t--l1.url=<Layer 1 Ethereum RPC URL>\tProvide an standard L1 node RPC endpoint that you run yourself or from a third-party node provider (see RPC endpoints and providers)\n--chain.id=<L2 chain ID>\t--l2.chain-id=<L2 Chain ID>\tSee RPC endpoints and providers for a list of Arbitrum chains and the respective L2 chain IDs\n--execution.caching.archive\t--node.caching.archive\tRequired for running an Arbitrum One Nitro archival node and retains past block state\n-\t--node.cache.allow-slow-lookup\tRequired for running an Arbitrum One Classic archival node. When this option is present, it will load old blocks from disk if not in memory cache.\n-\t--core.checkpoint-gas-frequency=156250000\tRequired for running an Arbitrum One Classic archival node.\nRun the Docker image(s)​\n\nWhen running a Docker image, an external volume should be mounted to persist the database across restarts. The mount point should be /home/user/.arbitrum/mainnet.\n\nTo run both Arbitrum Nitro and/or Arbitrum Classic in archive mode, follow one or more of the below examples:\n\nArbitrum One Nitro archive node:\ndocker run --rm -it -v /some/local/dir/arbitrum:/home/user/.arbitrum -p 0.0.0.0:8547:8547 -p 0.0.0.0:8548:8548 offchainlabs/nitro-node:v3.2.1-d81324d --parent-chain.connection.url https://l1-node:8545 --chain.id=42161 --http.api=net,web3,eth --http.corsdomain=* --http.addr=0.0.0.0 --http.vhosts=* --execution.caching.archive\n\nArbitrum One Classic archive node:\ndocker run --rm -it -v /some/local/dir/arbitrum-mainnet/:/home/user/.arbitrum/mainnet -p 0.0.0.0:8547:8547 -p 0.0.0.0:8548:8548 offchainlabs/arb-node:v1.4.5-e97c1a4 --l1.url=https://l1-node:8545/ --node.chain-id=42161 --l2.disable-upstream --node.cache.allow-slow-lookup --core.checkpoint-gas-frequency=156250000 --core.lazy-load-core-machine\n\nArbitrum One Nitro archive node with forwarding classic execution support:\ndocker run --rm -it -v /some/local/dir/arbitrum:/home/user/.arbitrum -p 0.0.0.0:8547:8547 -p 0.0.0.0:8548:8548 offchainlabs/nitro-node:v3.2.1-d81324d --parent-chain.connection.url https://l1-node:8545 --chain.id=42161 --execution.rpc.classic-redirect=<classic node RPC> --http.api=net,web3,eth --http.corsdomain=* --http.addr=0.0.0.0 --http.vhosts=* --execution.caching.archive\n\n\nNote that the above commands both map to port 8547 on their hosts. To run both on the same host, you should edit those mapping to different ports and specify your Classic node RPC URL as <classic node RPC> in your Nitro start command. To verify the connection health of your node(s), see Docker network between containers - Docker Networking Example.\n\nA note on permissions​\n\nThe Docker image is configured to run as non-root UID 1000. If you're running in Linux and you're getting permission errors when trying to run the Docker image, run this command to allow all users to update the persistent folders, replacing arbitrum-mainnet as needed:\n\nmkdir /some/local/dir/arbitrum-mainnet\nchmod -fR 777 /some/local/dir/arbitrum-mainnet\n\nOptional parameters​\n\nBoth Nitro and Classic have multiple other parameters that can be used to configure your node. For a full comprehensive list of the available parameters, use the flag --help.\n\nTroubleshooting​\n\nIf you run into any issues, visit the node-running troubleshooting guide.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nArbOS 11\nNext\nRun a validator\nBefore we begin\nSystem requirements\nReview and configure ports\nReview and configure parameters\nRun the Docker image(s)\nOptional parameters\nTroubleshooting\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/arbos-releases/overview",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nOverview\nArbOS 32 Bianca\nArbOS 20 Atlas\nArbOS 11\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nArbOS software releases: Overview\nINFO\n\nThis document provides an overview of Nitro node software releases that upgrade ArbOS. Visit the Nitro Github repository for a detailed index of Nitro releases.\n\nArbitrum chains are powered by Arbitrum nodes running the Nitro software stack. The Nitro software stack includes ArbOS, the Layer 2 EVM hypervisor that facilitates the execution environment of an Arbitrum chain.\n\nAlthough new Nitro releases are shipped regularly, only a subset of Nitro releases carry ArbOS upgrades. These special Nitro releases are significant because ArbOS upgrades are Arbitrum's equivalent to a \"hard fork\" - an upgrade that alters a node's ability to produce valid Arbitrum blocks. This is why validator nodes supporting a public Arbitrum chain (One, Nova) must update Nitro whenever a new ArbOS version is released and voted for adoption by the ArbitrumDAO.\n\nNote that every Nitro release is backwards compatible. In other words, the latest version of Nitro will support all previous ArbOS releases. This means that your validator's Nitro version must be greater than or equal to the version that includes the latest ArbOS upgrade.\n\nHOW OFTEN SHOULD I BE UPGRADING MY ARBOS VERSION?\n\nIt is strongly recommended to keep your Nitro's node software up-to-date as best you can to ensure you are benefting from the latest improvements to the Arbitrum technology stack. ArbOS version bumps are especially important because these upgrades change how Arbitrum nodes produce and validate assertions on a rollup's state.\n\nArbOS upgrades are carried out by the chain's owner; in the case of Arbitrum One and Nova, the owner is the Arbitrum DAO and so an upgrade will require a governance proposal and vote to pass to complete the upgrade. This is an example of a Nitro release that contains an ArbOS version bump, specifically to ArbOS 11.\n\nVisit Inside Arbitrum Nitro to learn more about Nitro's architecture; more information about ArbOS software releases is available on the Arbitrum DAO forum.\n\nList of available ArbOS releases​\nArbOS 32 \"Bianca\"\nArbOS 20 \"Atlas\"\nArbOS 11\nNaming and numbering scheme​\n\nBeginning with ArbOS 20, ArbOS releases use the name of planetary moons in our solar system, ascending in alphabetical order (i.e. the next ArbOS upgrade after ArbOS 20 \"Atlas\" will be a planetary moon that begins with the letter \"B\").\n\nThe number used to denote each upgrade will increment by 10, starting from ArbOS 20 (i.e., the next ArbOS upgrade after ArbOS 20 will be ArbOS 31). This was done because there are teams who have customized their Orbit chain's behavior or precompiles and who may wish to use ArbOS's naming schema between official ArbOS version bumps (e.g. ArbOS 12 could be the name of a customized version of ArbOS for a project's L3 Orbit chain).\n\nNote that there may be cases where special optimizations or critical fixes are needed for a specific family of ArbOS releases that will diverge from the standard numbering scheme described above. For example, ArbOS 32 will be the canonical ArbOS version for the “Bianca” family of releases. Node operators and chain owners are expected to upgrade from ArbOS 20 directly to ArbOS 32 (instead of ArbOS 30 or ArbOS 31).\n\nNetwork status​\n\nTo view the status and timeline of network upgrades on Arbitrum One and Nova, please visit this page.\n\nExpectations for Orbit chain owners​\n\nFor Orbit chain owners or maintainers: it is important to note that before upgrading your Orbit chain(s) to the newest ArbOS release, we strongly encourage waiting at least 2 weeks after the new ArbOS release has been activated on Arbitrum One and Nova before attempting the upgrade yourself. The rationale behind this short time buffer is to allow the Offchain Labs team to address any upgrade issues or stability concerns that may arise with the initial rollout so that we can minimize the chances of your chain(s) hitting the same or similar issues and to maximize the likelihood of an eventual smooth, seamless upgrade. Arbitrum Orbit chains, as always, can pick up new features & enable new customizations as they see fit. ArbOs 31 \"Bianca\" which unlocks Stylus for use, is no exception to this rule. However, we believe this delay ensures consistent UX across all Orbit chain owners and managers for these critical upgrades.\n\nNote that enabling an ArbOS upgrade is not as simple as bumping your chain’s Nitro node version. Instead, there are other steps required that are outlined in our docs on How to upgrade ArbOS on your Orbit chain. Please be sure to follow them and let us know if you encounter any issues.\n\nStay up to date​\n\nTo stay up to date with proposals, timelines, and statuses of network upgrades to Arbitrum One and Nova:\n\nSubscribe to the Arbitrum Node Upgrade Announcement channel on Telegram\nJoin both the #dev-announcements and #node-runners Discord channels in the Arbitrum Discord server\nFollow the official Arbitrum (@Arbitrum) and Arbitrum Developers (@ArbitrumDevs) X accounts, formerly Twitter.\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nL1 Ethereum RPC providers\nNext\nArbOS 32 Bianca\nList of available ArbOS releases\nNaming and numbering scheme\nNetwork status\nExpectations for Orbit chain owners\nStay up to date\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/l1-ethereum-beacon-chain-rpc-providers",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nL1 Ethereum beacon chain RPC providers\nNOTE\n\nThis reference document provides an overview of Ethereum beacon chain RPC providers for Arbitrum validators to use for accessing blob data following Ethereum's Dencun upgrade in March 2024. The list curated here is not comprehensive and in no way does Offchain Labs endorse or benefit from your use of any of these providers.\n\nFollowing Ethereum's Dencun upgrade in March 2024, Layer 2 blockchains like Arbitrum will be able to roll up and post batches of transaction data on Ethereum in the form of a new transaction format called a Blob. This Blob data will be part of the beacon chain and is fully downloadable by all consensus nodes. This means that data stored in blobs are inaccessible by the EVM, unlike Calldata.\n\nWhat does this mean for node operators?​\n\nTo run a node for an L2 Arbitrum chain (i.e. Arbitrum One, Arbitrum Nova, and L2 Orbit chains), your node will need access to blob data to sync up to the latest state of your Arbitrum L2 chain. Blob data on Ethereum is stored on the beacon chain and is inaccessible to the EVM, hence why dedicated RPC endpoints for the beacon chain will be required after the Dencun upgrade. You can find more details on node requirements in the Run a full node guide.\n\nFurthermore, new node operators joining a network or node operators who come online following an extended period of offline time will require access to historical blob data to sync up to the latest state of their Arbitrum chain.\n\nOffchain Labs has plans to reduce a Nitro validator's reliance on historical blob data and will share updates on this effort in the future.\n\nList of Ethereum beacon chain RPC providers​\nProvider\tMainnet Beacon chain APIs?\tMainnet Historical blob data?\tHolesky Beacon chain APIs?\tSepolia Beacon chain APIs?\nAnkr\t✅\t✅\t\t\nChainbase\t✅\t\t\t\nChainstack\t✅\t✅\t\t✅\nConduit*\t✅\t✅\t\t\nBlastAPI\t\t\t✅\t\nNirvana Labs\t✅\t✅\t\t\nNodeReal\t✅\t\t\t\nQuickNode\t✅\t✅\t✅\t✅\ndRPC\t✅\t✅\t✅\t✅\n\nPlease reach out to these teams individually if you need assistance with setting up your validator with any of the above providers.\n\n*Case-by-case basis, please contact them directly for help\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRun a local dev node\nNext\nOverview\nWhat does this mean for node operators?\nList of Ethereum beacon chain RPC providers\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/quickstart",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nQuickstart: Run a node\nINFO\n\nThere is no protocol level incentive to run an Arbitum full node. If you’re interested in accessing an Arbitrum chain, but you don’t want to set up your own node, see our RPC endpoints and providers to get RPC access to fully-managed nodes hosted by a third party provider.\n\nAPI SECURITY DISCLAIMER\n\nWhen exposing API endpoints to the Internet or any untrusted/hostile network, the following risks may arise:\n\nIncreased risk of crashes due to OOM: Exposing endpoints raises the risk of Out-of-Memory (OOM) crashes.\nIncreased risk of not keeping up with chain progression: Resource starvation (IO or CPU) may occur, leading to an inability to keep up with chain progression.\n\nWe strongly advise against exposing API endpoints publicly. Users considering such exposure should exercise caution and implement the right measures to enhance resilience.\n\nWhen it comes to interacting with the Arbitrum network, users have the option to run either a full node or an archive node. There are distinct advantages to running an Arbitrum full node. In this quickstart, we will explore the reasons why a user may prefer to run a full node instead of an archive node. By understanding the benefits and trade-offs of each type of node, users can make an informed decision based on their specific requirements and objectives.\n\nConsiderations for running an Arbitrum full node​\nTransaction validation and security: Running a full node allows users to independently validate transactions and verify the state of the Arbitrum blockchain. Users can have full confidence in the authenticity and integrity of the transactions they interact with.\nReduced trust requirements: By running a full node, users can interact with the Arbitrum network without relying on third-party services or infrastructure. This reduces the need to trust external entities and mitigates the risk of potential centralized failures or vulnerabilities.\nLower resource requirements: Compared to archive nodes, full nodes generally require fewer resources such as storage and computational power. This makes them more accessible to users with limited hardware capabilities or those operating on resource-constrained environments.\n\nFor detailed instructions on how to run an Arbitrum full node, see here.\n\nConsiderations for running an Arbitrum archive node​\n\nWhile full nodes offer numerous advantages, there are situations where running an archive node may be more appropriate. Archive nodes store the complete history of the Arbitrum network, making them suitable for users who require extensive historical data access or advanced analytical purposes. However, it's important to note that archive nodes are more resource-intensive, requiring significant storage capacity and computational power.\n\nFor detailed instructions on how to run an Arbitrum archive node, see here.\n\nConsiderations for running an Arbitrum classic node​\n\nThe significance of running an Arbitrum classic node is mainly applicable to individuals with specific needs for an archive node and access to classic-related commands. More details can be found here.\n\nFor detailed instructions on how to run an Arbitrum classic node, see here.\n\nConsiderations for running a feed relay​\n\nIf you are running a single node, there is no requirement to set up a feed relay. However, if you have multiple nodes, it is highly recommended to have a single feed relay per datacenter. This setup offers several advantages such as reducing ingress fees and enhancing stability within the network.\n\nIn the near future, feed endpoints will mandate compression using a custom dictionary. Therefore, if you plan to connect to a feed using anything other than a standard node, it is strongly advised to run a local feed relay. This will ensure that you have access to an uncompressed feed by default, maintaining optimal performance and compatibility.\n\nFor detailed instructions on how to run a feed relay, see here.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nOverview\nNext\nRun a full node\nConsiderations for running an Arbitrum full node\nConsiderations for running an Arbitrum archive node\nConsiderations for running an Arbitrum classic node\nConsiderations for running a feed relay\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "A gentle introduction to Arbitrum | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/welcome/arbitrum-gentle-introduction",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nA gentle introduction to Arbitrum\nQ: Hello! What’s Arbitrum?​\n\nHi! Arbitrum is a technology suite designed to scale Ethereum. You can use Arbitrum chains to do all things you do on Ethereum — use Web3 apps, deploy smart contracts, etc., but your transactions will be cheaper and faster. Our flagship product — Arbitrum Rollup — is an Optimistic rollup protocol that inherits Ethereum-level security.\n\nQ: What, what’s “Ethereum”? What's a “smart contract”? Where am I?​\n\nIf you aren’t yet familiar with the Ethereum ecosystem, you can check out ethereum.org for an intro. Come back whenever you're ready, no rush.\n\nQ: You said Arbitrum exists to “scale” Ethereum; why does Ethereum need this help? Is there something wrong with Ethereum?​\n\nEthereum is awesome; on its own, however, it’s also very limited. The Ethereum blockchain only allows about 20-40 transactions per second (TPS) (that’s in total, for all Ethereum users); when the limit is reached, users are forced to compete against each other for their transactions to be included, which causes fees to go up.\n\nQ: Why does Ethereum have such low TPS?​\n\nThis was a deliberate decision in Ethereum’s design. Ethereum requires that its nodes (computers running the Ethereum software) have a way of coming to consensus on the current state of things; the way they do this is by processing every transaction in Ethereum’s history; i.e., if you’ve ever used Ethereum, every Ethereum full node has a copy of your transactions in its blockchain ledger.\n\nOne of the Ethereum community’s precepts, being an open, decentralized, peer to peer system, is that it should be reasonably accessible for anyone to run an Ethereum node and validate the chain for themselves; i.e., if it gets too expensive (in terms of hardware requirements / computational resources), this undercuts the fundamental goal of decentralization. The combination of these two factors — every node has to process every transaction, and we want it to be relatively feasible to run a node — means Ethereum transaction throughput has to be capped fairly low.\n\nQ: And Arbitrum Rollup fixes this?​\n\nArbitrum rollup fixes this! The basic idea is this: an Arbitrum Rollup chain runs as a sort of sub-module within Ethereum. Unlike regular, layer 1 ( “L1”) Ethereum transactions, we don’t require Ethereum nodes to process every Arbitrum transaction; rather, Ethereum adopts an “innocent until proven guilty\" attitude to Arbitrum. Layer 1 initially “optimistically assumes” activity on Arbitrum is following the proper rules. If a violation occurs (i.e., somebody claims “now I have all of your money”), this claim can be disputed back on L1; fraud will be proven, the invalid claim disregarded, and the malicious party will be financially penalized.\n\nThis ability to adjudicate and prove fraud on L1 is Arbitrum’s key, fundamental feature, and is how and why the system inherits Ethereum’s security.\n\nQ: So we can use Ethereum to prove fraud on Arbitrum; cool! But if fraud is committed, can we be absolutely sure that we'll be able to prove it?​\n\nYes, indeed we can be. This is where the “rollup” part comes in. The data that gets fed into an Arbitrum Rollup chain (i.e., user’s transaction data) is posted directly on Ethereum. Thus, as long as Ethereum itself is running securely, anybody who’s interested has visibility into what’s going on in Arbitrum, and has the ability to detect and prove fraud.\n\nQ: Who actually does this work (of checking for fraud, proving it, etc?)​\n\nThe parties who move the Arbitrum chain state forward on L1 — i.e., making claims about the chain’s state, disputing other’s claims, etc. — are called validators. In practice, we don’t expect the average Arbitrum user to be interested in running a validator, just like the average Ethereum user typically doesn’t run their own layer 1 staking node. The crucial property, however, is that anybody can; becoming an Arbitrum validator requires no special permission (once the allowlist is lifted), only that a user runs the open source validator software (and stakes Ether when/if they need to take action).\n\nAdditionally, as long as there’s even just one honest validator, the chain will remain secure; i.e., it only takes one non-malicious fraud-prover to catch any number of malicious trouble-makers. These properties together make the system “trustless”; users are not relying on any special designated party for their funds to be secure.\n\nQ: And how exactly is “fraud” “proven”? Sounds complicated.​\n\nOh, it’s not so bad. In essence: if two validators disagree, only one of them (at most) can be telling the truth. In a dispute, the two validators play an interactive, call-and-response game, in which they narrow down their dispute to a single computational step (think of something small and simple, like multiplying two numbers). This one step gets executed on L1, and will, by necessity, prove that the honest party was telling the truth. For a more detailed rundown, see here.\n\nQ: This dispute game obviously takes some time; does this impose any sort of delay on Arbitrum users' transactions?​\n\nThe only delay that's felt by a user is in \"withdrawing\" — moving their funds from Arbitrum back to Ethereum; if users are withdrawing directly from Arbitrum to Ethereum, they must typically wait 1 week before receiving their funds on L1. If users use a fast-bridge application, however, they can bypass this delay period entirely (likely for a small fee). Anything else a user does — i.e., depositing funds from Ethereum onto Arbitrum, or using a dapp deployed on an Arbitrum chain — doesn't incur this delay period.\n\nQ: Okay, so backing up: the “optimistic execution” part is how and why Arbitrum is able to offer low fees, yes?​\n\nPrimarily, yes, this is the heart of where the savings come from. However, there are a number of other means by which Arbitrum alleviates the burden on L1, all of which translate to lower transaction costs for end users. For one, Arbitrum transactions are submitted on the L1 in batches; typically, a single batch (submitted in a single L1 transaction) will contain several hundred L2 transactions. Batching amortizes the overhead cost of interacting with the L1, and thus offers significant savings over posting individual transactions at a time. Furthermore, the transaction data is posted on L1 in compressed form (and only decompressed within the L2 environment), further minimizing the transaction’s L1 footprint.\n\nQ: As far as the experience of using Arbitrum: when you said that it’s very similar to using Ethereum…​\n\nWe really meant it, yes. Different layer 2 protocols emphasize and optimize for different things; Arbitrum was created with Ethereum compatibility as a top priority. This means users can use Arbitrum with all their favorite Ethereum wallets; developers can build and deploy contracts with all their favorite Ethereum libraries and tooling; in fact, most of the time, the experience of using Arbitrum will feel identical to that of using Ethereum (with the important exception of it being much cheaper and faster).\n\nMuch development went into achieving this level of Ethereum compatibility. But at its core: the Arbitrum itself uses a fork of Geth — the most widely used Ethereum implementation — with modifications to transform it into a trustless layer 2. This means most of the code running in Arbitrum is identical to the code running in Ethereum. We call this cutting-edge approach Nitro (developers can see the codebase here).\n\nQ: So builders can do all the stuff they do on Ethereum on Arbitrum, nice! But can they do more?​\n\nThey can; the latest version of the Arbitrum tech stack, called Stylus, keeps Nitro's Ethereum compatibility, while adding on powerful new features, namely the ability to write highly performant smart contracts in programming languages like Rust, C++, and more. Stylus is currently on public testnet; you can read more about it here.\n\nQ: So it sounds like Arbitrum Rollup is an ideal solution that solves any and all scaling problems…?​\n\nArbitrum Rollup is very awesome and cool; its design is geared heavily toward avoidance of introducing any centralization or trust assumptions, and it is thus a clear, strict net-win for the Ethereum ecosystem. Decentralization, however, comes at a (literal) price, and not all applications and users necessarily want or need to pay that price. For dapp use-cases with different security considerations, different tools in the Arbitrum suite are appropriate; i.e., Arbitrum AnyTrust chains!\n\nQ: What’s an AnyTrust chain?​\n\nAn Arbitrum AnyTrust chain doesn’t have the same decentralization / trustlessness / permissionless security guarantees of a Rollup chain, and thus can offer lower fees. Rollup and AnyTrust are similar in many ways, though have one key difference: whereas in Rollup, all data is posted on L1 (which allows anyone to permissionless join as a validator), in AnyTrust, data is managed off-chain. In the case of a challenge, an AnyTrust chain reverts back to “rollup mode”; the security assumption here is that at least 2 of the committee members are honest (i.e., they will provide the data when it’s necessary). Keeping the data off-chain in the happy/common case means the system can charge the user significantly lower fees. For applications that require high transaction throughput and don’t require the full decentralization that rollups provide, AnyTrust could be a sensible tradeoff.\n\nQ: So there's more than one Arbitrum chain out there?​\n\nYep! The fact that multiple chains can run in parallel is a crucial perk to off-chain scaling technology. Currently, on Ethereum mainnet, there are 2 Arbitrum chains: one Arbitrum Rollup chain, called \"Arbitrum One,\" and one AnyTrust chain, called \"Nova\"; users and developers can pick whatever suits their security / transaction cost needs.\n\nDevelopers also have the option of launching their own Arbitrum chains that run top an Arbitrum layer 2. These are called Orbit chains and you can read more about them here.\n\nQ: Who makes decisions about the future of Arbitrum One and Arbitrum Nova?​\n\nThe Arbitrum One and Nova chains are owned by the Governance system; to learn more, see the Arbitrum Governance docs.\n\nEdit this page\nLast updated on Nov 18, 2024\nNext\nGet started\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Gas and Fees | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/gas-fees",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nTransaction lifecycle\nSequencer\nAnyTrust protocol\nGas / fees\nL2 gas and fees\nL1 pricing\nAdvanced concepts\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nGas and Fees\n\nThere are two parties a user pays when submitting a tx:\n\nthe poster, if reimbursable, for L1 resources such as the L1 calldata needed to post the tx\nthe network fee account for L2 resources, which include the computation, storage, and other burdens L2 nodes must bear to service the tx\n\nThe L1 component is the product of the transaction's estimated contribution to its batch's size — computed using Brotli on the transaction by itself — and the L2's view of the L1 data price, a value which dynamically adjusts over time to ensure the batch-poster is ultimately fairly compensated. For details, see L1 Pricing.\n\nThe L2 component consists of the traditional fees Geth would pay to stakers in a vanilla L1 chain, such as the computation and storage charges applying the state transition function entails. ArbOS charges additional fees for executing its L2-specific precompiles, whose fees are dynamically priced according to the specific resources used while executing the call.\n\nGas Price Floor​\n\nThe L2 gas price on a given Arbitrum chain has a set floor, which can be queried via ArbGasInfo's getMinimumGasPrice method (currently 0.01 gwei on Arbitrum One and 0.01 gwei on Nova).\n\nEstimating Gas​\n\nCalling an Arbitrum Node's eth_estimateGas RPC gives a value sufficient to cover the full transaction fee at the given L2 gas price; i.e., the value returned from eth_estimateGas multiplied by the L2 gas price tells you how much total Ether is required for the transaction to succeed. Note that this means that for a given operation, the value returned by eth_estimateGas will change over time (as the L1 calldata price fluctuates.) (See 2-D fees and How to estimate gas in Arbitrum for more.)\n\nTips in L2​\n\nThe sequencer prioritizes transactions on a first-come first-served basis. Because tips do not make sense in this model, they are ignored. Arbitrum users always just pay the basefee regardless of the tip they choose.\n\nGas Estimating Retryables​\n\nWhen a transaction schedules another, the subsequent transaction's execution will be included when estimating gas via the node's RPC. A transaction's gas estimate, then, can only be found if all the transactions succeed at a given gas limit. This is especially important when working with retryables and scheduling redeem attempts.\n\nBecause a call to redeem donates all of the call's gas, doing multiple requires limiting the amount of gas provided to each subcall. Otherwise the first will take all of the gas and force the second to necessarily fail irrespective of the estimation's gas limit.\n\nGas estimation for Retryable submissions is possible via the NodeInterface and similarly requires the auto-redeem attempt to succeed.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nAnyTrust protocol\nNext\nL1 pricing\nGas Price Floor\nEstimating Gas\nTips in L2\nGas Estimating Retryables\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/introduction",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nIntroduction\n\nThe Arbitrum SDK is a powerful TypeScript library that streamlines interactions with Arbitrum networks. It offers robust tools for bridging tokens and passing messages between networks through an intuitive interface to the underlying smart contracts.\n\nKey Features\n\nToken Bridging: Effortlessly bridge tokens between Ethereum and Arbitrum.\nMessage Passing: Seamlessly pass messages across networks.\nContracts Interface: Leverage a strongly-typed interface for interacting with smart contracts.\n\nBelow is an overview of the Arbitrum SDK functionality. See the tutorials for more examples.\n\nGetting Started​\n\nInstall dependencies\n\nnpm\nyarn\npnpm\nnpm install @arbitrum/sdk\n\nUsing the Arbitrum SDK​\nBridging assets​\n\nArbitrum SDK can be used to bridge assets to or from an Arbitrum Network. The following asset bridgers are currently available:\n\nEthBridger\nErc20Bridger\n\nAll asset bridgers have the following methods which accept different parameters depending on the asset bridger type:\n\ndeposit - moves assets from the Parent to the Child chain\nwithdraw - moves assets from the Child to the Parent chain\nExample ETH Deposit to Arbitrum One​\nimport { getArbitrumNetwork, EthBridger } from '@arbitrum/sdk'\n\n// get the `@arbitrum/sdk` ArbitrumNetwork object using the chain id of the Arbitrum One chain\nconst childNetwork = await getArbitrumNetwork(42161)\nconst ethBridger = new EthBridger(childNetwork)\n\nconst ethDepositTxResponse = await ethBridger.deposit({\n  amount: utils.parseEther('23'),\n  parentSigner, // an ethers v5 signer connected to mainnet ethereum\n  childProvider, // an ethers v5 provider connected to Arbitrum One\n})\n\nconst ethDepositTxReceipt = await ethDepositTxResponse.wait()\n\n\nLearn more in the Eth Deposit tutorial\n\nExample ETH Withdrawal from Arbitrum One​\nimport { getArbitrumNetwork, EthBridger } from '@arbitrum/sdk'\n\n// get the `@arbitrum/sdk` ArbitrumNetwork object using the chain id of the Arbitrum One chain\nconst childNetwork = await getArbitrumNetwork(42161)\nconst ethBridger = new EthBridger(childNetwork)\n\nconst withdrawTx = await ethBridger.withdraw({\n  amount: utils.parseEther('23'),\n  childSigner, // an ethers v5 signer connected to Arbitrum One\n  destinationAddress: childWallet.address,\n})\nconst withdrawRec = await withdrawTx.wait()\n\n\nLearn more in the Eth Withdraw tutorial\n\nNetworks​\n\nArbitrum SDK comes pre-configured for Mainnet and Sepolia, and their Arbitrum counterparts. Any other networks that are not pre-configured must be registered before being used.\n\nConfiguring Network​\n\nTo interact with a custom ArbitrumNetwork, you can register it using the registerCustomArbitrumNetwork function.\n\nimport { registerCustomArbitrumNetwork } from '@arbitrum/sdk'\n\nregisterCustomArbitrumNetwork({\n  chainID: 123456,\n  name: 'Custom Arbitrum Network',\n})\n\nCross chain messages​\n\nWhen assets are moved by the Parent and Child cross chain messages are sent. The lifecycles of these messages are encapsulated in the classes ParentToChildMessage and ChildToParentMessage. These objects are commonly created from the receipts of transactions that send cross chain messages. A cross chain message will eventually result in a transaction being executed on the destination chain, and these message classes provide the ability to wait for that finalizing transaction to occur.\n\nRedeem a Parent-to-Child Message​\nimport {\n  ParentTransactionReceipt,\n  ParentToChildMessageStatus,\n} from '@arbitrum/sdk'\n\nconst parentTxnReceipt = new ParentTransactionReceipt(\n  txnReceipt // ethers-js TransactionReceipt of an ethereum tx that triggered a Parent-to-Child message (say depositing a token via a bridge)\n)\n\nconst parentToChildMessage = (\n  await parentTxnReceipt.getParentToChildMessages(\n    childSigner // connected ethers-js Wallet\n  )\n)[0]\n\nconst res = await parentToChildMessage.waitForStatus()\n\nif (res.status === ParentToChildMessageStatus.Child) {\n  // Message wasn't auto-redeemed; redeem it now:\n  const response = await parentToChildMessage.redeem()\n  const receipt = await response.wait()\n} else if (res.status === ParentToChildMessageStatus.REDEEMED) {\n  // Message successfully redeemed\n}\n\n\nLearn more in the Redeem Failed Retryable Tickets tutorial\n\nInbox Tools​\n\nAs part of normal operation, the Arbitrum sequencer will send messages into the rollup chain. However, if the sequencer is unavailable and not posting batches, the inbox tools can be used to force the inclusion of transactions into the Arbitrum network.\n\nHere's how you can use the inbox tools to withdraw ether from Arbitrum One without waiting for the sequencer:\n\nconst childNetwork = await getArbitrumNetwork(await childWallet.getChainId())\n\nconst inboxSdk = new InboxTools(parentWallet, childNetwork)\nconst arbSys = ArbSys__factory.connect(ARB_SYS_ADDRESS, childProvider)\nconst arbSysIface = arbSys.interface\nconst childCalldata = arbSysIface.encodeFunctionData('withdrawEth', [\n  parentWallet.address,\n])\n\nconst txChildRequest = {\n  data: childCalldata,\n  to: ARB_SYS_ADDRESS,\n  value: 1,\n}\n\nconst childSignedTx = await inboxSdk.signChildTx(txChildRequest, childWallet)\nconst childTxhash = ethers.utils.parseTransaction(childSignedTx).hash\nconst resultsParent = await inboxSdk.sendChildSignedTx(childSignedTx)\n\nconst inboxRec = await resultsParent.wait()\n\n\nLearn more in the Delayed Inbox tutorial.\n\nUtils​\nEventFetcher - A utility to provide typing for the fetching of events\nMultiCaller - A utility for executing multiple calls as part of a single RPC request. This can be useful for reducing round trips.\nconstants - A list of useful Arbitrum related constants\nDevelopment​\nRun Integration tests​\nCopy the .env-sample file to .env and update the values with your own.\nFirst, make sure you have a Nitro test node running. Follow the instructions here.\nAfter the node has started up (that could take up to 20-30 mins), run yarn gen:network.\nOnce done, finally run yarn test:integration to run the integration tests.\n\nDefaults to Arbitrum Sepolia, for custom network use --network flag.\n\nArbitrum Sepolia expects env var ARB_KEY to be prefunded with at least 0.02 ETH, and env var INFURA_KEY to be set. (see integration_test/config.ts)\n\nEdit this page\nPrevious\nTroubleshooting\nNext\nMigrating from v3 to v4\nGetting Started\nUsing the Arbitrum SDK\nBridging assets\nNetworks\nCross chain messages\nInbox Tools\nUtils\nDevelopment\nRun Integration tests\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Troubleshooting: Building Arbitrum dApps | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/troubleshooting-building",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nTroubleshooting: Building Arbitrum dApps\nHow does gas work on Arbitrum?​\n\nFees on Arbitrum chains are collected on L2 in the chains' native currency (ETH on both Arbitrum One and Nova).\n\nA transaction fee is comprised of both an L1 and an L2 component:\n\nThe L1 component is meant to compensate the Sequencer for the cost of posting transactions on L1 (but no more). (See L1 Pricing.)\n\nThe L2 component covers the cost of operating the L2 chain; it uses Geth for gas calculation and thus behaves nearly identically to L1 Ethereum. One difference is that unlike on Ethereum, Arbitrum chains enforce a gas price floor; currently 0.1 gwei on Arbitrum One and 0.01 gwei on Nova (See Gas).\n\nL2 Gas price adjusts responsively to chain congestion, ala EIP 1559.\n\nI tried to create a retryable ticket but the transaction reverted on L1. How can I debug the issue?​\n\nCreation of retryable tickets can revert with one of these custom errors:\n\nInsufficientValue: not enough gas included in your L1 transaction's callvalue to cover the total cost of your retryable ticket; i.e., msg.value < (maxSubmissionCost + l2CallValue + gasLimit * maxFeePerGas). Note that your L1 transaction's callvalue must cover this full cost. See Retryable Tickets Lifecycle for more information.\nInsufficientSubmissionCost: provided submission cost isn't high enough to create your retryable ticket.\nGasLimitTooLarge: provided gas limit is greater than 2^64\nDataTooLarge: provided data is greater than 117.964 KB (90% of Geth's 128 KB transaction size limit).\n\nTo figure out which error caused your transaction to revert, we recommend using etherscan's Parity VM trace support (Tenderly is generally a very useful debugging tool; however, it can be buggy when it comes to custom Geth errors).\n\nUse the following link to view the Parity VM trace of your failed transaction (replacing the tx-hash with your own, and using the appropriate etherscan root url):\n\nhttps://etherscan.io/vmtrace?txhash=0x51a8088c9b319bbad649c36d9cf2b4e9b61a6099a158181676c8e79dbce2df58&type=parity#raw\n\nTo find out the reversion error signature, go to the \"Raw Traces\" tab, and scroll down to find the last \"subtrace\" in which your transaction is reverted. Then find \"output\" field of that subtrace.\n\n(In the above example the desirable \"output\" is:\n\n\n\n\n0xfadf238a0000000000000000000000000000000000000000000000000000c4df7e2903b00000000000000000000000000000000000000000000000000000a39a1d002808)\n\nThe first four bytes of the output is the custom error signature; in our example it's 0xfadf238a .\n\n\n\n\nTo let's find out which is custom error this signature represents, we can use this handy tool by Samzcsun: https://sig.eth.samczsun.com/\n\nChecking 0xfadf238a gives us InsufficientSubmissionCost(uint256,uint256).\n\n\n\n\nHow is the L1 portion of an Arbitrum transaction's gas fee computed?​\n\nThe L1 fee that a transaction is required to pay is determined by compressing its data with brotli and multiplying the size of the result (in bytes) by ArbOS's current calldata price; the latter value can be queried via the getPricesInWeimethod of the ArbGasInfoprecompile. You can find more information about gas calculations in Understanding Arbitrum: 2-Dimensional Fees and How to estimate gas in Arbitrum.\n\nWhat is a retryable ticket's \"submission fee\"? How can I calculate it? What happens if I the fee I provide is insufficient?​\n\nA retryable's submission fee is a special fee a user must pay to create a retryable ticket. The fee is directly proportional to the size of the L1 calldata the retryable ticket uses. The fee can be queried using the Inbox.calculateRetryableSubmissionFeemethod. If insufficient fee is provided, the transaction will revert on L1, and the ticket won't get created.\n\nWhich method in the Inbox contract should I use to submit a retryable ticket (aka L1 to L2 message)?​\n\nThe method you should (almost certainly) use is Inbox.createRetryableTicket. There is an alternative method, Inbox.unsafeCreateRetryableTicket, which, as the name suggests, should only be used by those who fully understand its implications.\n\nThere are two differences between createRetryableTicket and unsafeCreateRetryableTicket:\n\nMethod createRetryableTicket will check that provided L1 callvalue is sufficient to cover the costs of creating and executing the retryable ticket (at the specified parameters) and otherwise revert directly at L1. unsafeCreateRetryableTicket, in contrast, will allow a retryable ticket to be created that is guaranteed to revert on L2.\nMethod createRetryableTicket will check if either the provided excessFeeRefundAddress or the callValueRefundAddress are contracts on L1; if they are, to prevent the situation where refunds are guaranteed to be irrecoverable on L2, it will convert them to their address alias, providing a potential path for fund recovery. unsafeCreateRetryableTicket will allow the creation of a retryable ticket with refund addresses that are L1 contracts; since no L1 contract can alias to an address that is also itself an L1 contract, refunds to these addresses on L2 will be irrecoverable.\n\n(Astute observers may note a third ticket creation method, createRetryableTicketNoRefundAliasRewrite; this is included only for backwards compatibility, but should be considered deprecated in favor of unsafeCreateRetryableTicket)\n\nWhy do I get \"custom tx type\" errors when I use hardhat?​\n\nIn Arbitrum, we use a number of non-standard EIP-2718 typed transactions. See here for the full list and the rationale.\n\nNote that if you're using Hardhat, v2.12.2 added support for forking networks like Arbitrum with custom transaction types (find more information here).\n\nWhy does it look like two identical transactions consume a different amount of gas?​\n\nCalling an Arbitrum node's eth_estimateGas RPC returns a value sufficient to cover both the L1 and L2 components of the fee for the current gas price; this is the value that, e.g., will appear in users' wallets in the \"gas limit\" field.\n\nThus, if the L1 calldata price changes over time, it will appear (in e.g., a wallet) that a transaction's gas limit is changing. In fact, the L2 gas limit isn't changing, merely the total gas required to cover the transaction's L1 + L2 fees.\n\nSee 2-D fees and How to estimate gas in Arbitrum for more.\n\nWhy am I getting error \"429 Too Many Requests\" when using one of Offchain Labs' Public RPCs?​\n\nOffchain Labs offers public RPCs for free, but limits requests to prevent DOSing. Hitting the rate limit could come from your request frequency and/or the resources required to process the requests. If you are hitting our rate limit, we recommend running your own node or using a third party node provider.\n\nHow do block.number and block.timestamp work on Arbitrum?​\n\nSolidity calls to block.number on Arbitrum will return the block number/ timestamp of the underlying L1 on a slight delay; i.e., updated every few minutes. Note that L2 block numbers (i.e., as seen in block explorers / returned by RPCs) are different, and are typically updated roughly every second.\n\nSolidity calls to block.timestamp on Arbitrum are not linked to the timestamp of the L1 block. It is updated every L2 block based on the sequencer's clock. Furthermore, for transactions that are force-included from L1 (bypassing the Sequencer) block.timestamp will be equal to the L1 timestamp when the transaction was put in the delayed inbox on L1 (not force-included), or the L2 timestamp of the previous L2 block (whichever is greater of the two timestamps).\n\nFor more info, see block numbers and time.\n\nDo I need to download any special npm libraries in order to use web3.js, ethers.js or viem on Arbitrum?​\n\nNope, web3.js, ethers.js and viem will work out of the box just like they do on L1 Ethereum.\n\nOnce upon a time, Arbitrum developers were required to download supplemental packages with names like \"arb-provider-ethers\" and \"arb-ethers-web3-bridge\", but these packages are deprecated and no longer required! Any guide that directs devs to use them should be considered outdated.\n\nHow many block numbers must we wait for in Arbitrum before we can confidently state that the transaction has reached finality?​\n\nArbitrum's block intervals fluctuate with throughput, so relying on block numbers for finality isn't recommended. However, Arbitrum nodes support Ethereum's JSON RPC, enabling the use of eth_getBlockByNumber() to determine block finality. Here, we provide additional details on how to achieve this.\n\nYou can use eth_getBlockByNumber() with the string \"latest\", \"safe\", or \"finalized\", each offering varying degrees of finality:\n\nlatest: Provides you with the most recent Arbitrum block number, also known as the tip of the chain. This block is typically the last sequenced block and may not yet be posted on L1. As long as you trust the Sequencer to eventually post this information on L1, relying on the latest block should be fine.\nsafe: Provides you with the most recent Arbitrum block number that has achieved attestations from a two-thirds majority of Ethereum's validator set. This occurs when the Sequencer's batch is posted as an L1 block on Ethereum and then the batch transactions achieve safe finality there. While safe blocks are typically resistant to re-orgs, they can still be re-orged in the event of a significant L1 re-org.\nfinalized: Provides you with the most recent Arbitrum block number that is finalized on Ethereum. This means that the Sequencer's batch has been published as an L1 block on the Ethereum network and has reached a substantial depth, making it eligible for hard finality. Unlike safe blocks, finalized blocks are highly improbable to undergo re-orgs.\n\nTo learn more about the different phases of an Arbitrum transaction, from client initiation to Layer 1 confirmation, check out The Lifecycle of an Arbitrum Transaction.\n\nHow can I list my token on the Arbitrum Bridge?​\n\nThe L2 token list used in the Arbitrum bridge is generated from the L1 tokens that are part of the token list of Uniswap, Gemini , Coinmarketcap or Coingecko. This is valid for L1-native tokens that have been bridged over to L2, and for L2-native tokens that have been bridged over to L1 as long as they are part of any of those lists.\n\nCurrently, there isn't any L2-only token list.\n\nWhat is a testnet or a devnet?​\n\nTestnets (or devnets) primarily serve developers who want to test out the applications they're building without having to use any real mainnet funds.\n\nArbitrum Sepolia is a testnet that has the same full feature-set as the mainnet network. It is also a \"true\" L2 that runs on top of the Sepolia testnet (L1), using it for security and settlement.\n\nUsers can bridge any asset from the Sepolia testnet (L1) into the Arbitrum Sepolia testnet (and back!), using the official bridge.\n\nIs there any testnet available on Arbitrum?​\n\nYes, there's an Arbitrum Sepolia testnet (421614) that uses the Nitro tech stack and runs on top of Ethereum Sepolia. You can find more information here.\n\nWhen was Arbitrum One upgraded from Classic to Nitro?​\n\nArbitrum One was upgraded on August 31st, 2022 (block 22207818), from the Classic stack to the improved Nitro tech stack, maintaining the same state.\n\nDo Arbitrum chains support precompiles that are present on Ethereum?​\n\nYes, all Arbitrum chains support all precompiles that Ethereum supports, as well as others that are not present on Ethereum. Check the precompiles reference page for more information about Arbitrum specific precompiles.\n\nWhat's the contract code size limit in Arbitrum chains?​\n\nAs specified in EIP-170, contracts of up to 24KB are deployable on Arbitrum chains.\n\nHow can I find the L2 block(s) that corresponds to a given L1 block?​\n\nFirst of all, you should be familiar with how block numbers behave on Arbitrum. You can find information about it in Block numbers and time.\n\nWhen you query an RPC node for a transaction receipt or a block information, you obtain as part of the result the property l1BlockNumber, which is the L1 block number that the sequencer viewed when it processed the transaction.\n\nWith that, although it might be computationally complex, you can binary search the L1 block number you are looking for, and get all L2 blocks that have that l1BlockNumber.\n\nIf you want a more specific result, you can perform the same operation with the timestamp from the L1 block, instead of the actual block number.\n\nWhy do some old transactions have extremely high gas prices when querying them?​\n\nWhen Arbitrum One was running under the Arbitrum Classic stack (before Nitro), the gas price was an unbounded bid, so when requesting those transactions via RPC, you may obtain a very high amount in the gasPrice property.\n\nInstead of that, it is recommended to look at the effectiveGasPrice property from the transaction receipt.\n\nWhat is the WASM module root?​\n\nThe WASM module root is a 32 byte hash, which is a merkelization of the Go replay binary and its dependencies.\n\nThe replay binary is much too large to post on-chain, so this hash is set in the L1 rollup contract to determine the correct replay binary during fraud proofs.\n\nYou can find more information in How to customize your Orbit chain's behavior.\n\nWhy do I get a \"gas required exceeds allowance\" when trying to estimate the gas costs of a request?​\n\nDuring an eth_estimateGas call the actual request will be simulated on the node, so if the transaction reverts or if there aren't enough funds in the wallet that's making the call (usually the from parameter), the eth_estimateGas request will return the error gas required exceeds allowance.\n\nMake sure you have enough funds in your wallet, and the gas fields of the request (if you're using them) are correctly set.\n\nHow can I verify that an L2 block has been processed as part of a specific RBlock?​\n\nIf you want to verify that the latest confirmed (or created) assertion has processed a specific L2 block, you can follow these steps:\n\nFrom the rollup contract, obtain the latest confirmed (or created) Rblock through the function latestConfirmed (or latestNodeCreated). In this context, we refer to RBlocks as \"nodes\".\nObtain the node information through getNode\nFind the NodeCreated event that was emitted when that node was created.\nIn that NodeCreated event, there's an assertion property that contains the state of the chain before processing the specified blocks, and after processing them. Get the afterState.globalState property\nThat value contains a bytes32Vals array with the latest L2 block hash processed in the first element.\n\nYou can find an example script in our arbitrum-tutorials repository.\n\nWhy is the fee of some Classic transactions slightly different than the multiplication of gasLimit and effectiveGasPrice?​\n\nGas prices in Classic transactions worked a bit differently than in Nitro transactions. Classic transactions handled four different prices: L1 fixed, L1 calldata, L2 computation and L2 storage. You can see all those prices in the Advanced TxInfo of Arbiscan (here's an example).\n\nWhen querying the receipt of a Classic transaction on a Nitro node, there's some calculation done to get an effectiveGasPrice that is close to (but not exactly) what those four prices represent. That's why if you multiply the gasLimit by the effectiveGasPrice you might end up with a transaction fee that is slightly different than the actual fee paid.\n\nTo get the exact fees paid, you can query a Classic node, which will return all the accurate information in an object called feeStats. That object will contain all the information split into the four different gas fields: prices, unitsUsed and paid (which is price * unitsUsed).\n\nHow can I update the information of my bridged token on Arbiscan?​\n\nIf you have a native-L1 token that was bridged to L2 via the standard gateway, you might find that you can't claim ownership of the L2 contract of your token as it was generated by another contract.\n\nTo update its information on Arbiscan (logo, socials, etc.), you can open a ticket through Arbiscan support system and request them to replicate the information of your token on L1 to L2.\n\nWhy does my transaction revert with InvalidFEOpcode when using Foundry?​\n\nFoundry and other similar development tools that enable chain forking, do not support Arbitrum precompiles. If your transaction is calling a precompile, it is likely that it will revert with InvalidFEOpcode.\n\nTo rule out that possibility, it is recommended to send the transaction with a different tool.\n\nWhy do I receive an \"intrinsic gas too low\" error when sending a transaction even with a high gas price?​\n\nThe error intrinsic gas too low usually refers to not providing enough gas to pay for the L1 component of the transaction fees. This is usually a problem related to not setting a high enough gas limit (instead of gas price), due to how Arbitrum handles gas. You can find more information in the article Understanding Arbitrum: 2-dimensional fees and the page How to estimate gas.\n\nHow can I interpret Arbitrum transaction traces?​\n\nIn Arbitrum, every block contains a system transaction of type ArbitrumInternalTxType, which is created by the ArbOS itself for specific state updates, such as the L1 base fee and the block number. These transactions are distinct from typical Ethereum transactions and are exclusively generated by the ArbOS state transition function, not by external entities like externally owned accounts (EOAs) or smart contracts. Despite having an INVALID opcode, these transactions are represented in the trace API to signify their presence in the block, even though they're not triggered by an opcode within EVM execution.\n\nOne of the key functionalities of ArbitrumInternalTxType involves managing value transfers related to acknowledging batch postings. When batches of transactions are submitted to Layer 1, a special cross-chain message is produced as a receipt, confirming the successful posting of the batch. The function ApplyInternalTxUpdate is responsible for processing and updating the system's state based on these cross-chain messages, ensuring consistency and integrity across the Arbitrum network.\n\nAnother functionality of ArbitrumInternalTxType transactions is handling the value held in retryables when they are discarded. Retryable transactions are essentially transactions that can be retried if they fail to execute on the destination chain. However, in certain scenarios, these retryable transactions might get discarded, for instance, due to expiration or other conditions.\n\nIn such cases, the escrowed call value, which is the value associated with the retryable transaction, will be paid out to a specified callValueRefundAddress account. This address is designated during the initial submission of the transaction on the parent chain. The purpose of this mechanism is to ensure that funds associated with retryable transactions are not lost in case they cannot be successfully executed, thereby maintaining the integrity and reliability of the Arbitrum network.\n\nTo accurately reflect value transfers associated with these transactions, we employ a unique callType parameter: invalid. Unlike conventional EVM calls (such as delegatecall, call, etc.), this designation signifies a different system transaction. Essentially, it denotes a straightforward value transfer from one account to another, with no inherent invocation of smart contract logic. While technically feasible to conduct this transfer within a conventional call type, our deliberate choice of invalid aims to enhance the clarity and distinctiveness of this transaction type within the EVM ecosystem.\n\nNotably, the sender account remains consistent across all instances of this transaction type for the batch posting receipt version. However, it's important to note that for retryable transactions, the sender account differs as each retryable transaction escrows its value in a unique vault specific to that transaction. This ensures that funds associated with each retryable transaction are securely held until either successful execution or eventual refund.\n\n\nNote that:\n\nAll pre-Nitro transactions are labeled as ArbitrumLegacyTxType by Nitro.\nTraces are not available for pre-Nitro (Classic) transactions.\n\nWhy do some blocks have a total gas limit that's over the standard block gas limit?​\n\nThe execution gas block limit of Arbitrum chains is 32 million. However, when querying a block, we might find a gasLimit value that exceeds that number.\n\nThis happens because this gasLimit field accounts for both execution gas and the correspondent gas limit of the L1 costs (you can find more information about the role of the L1 costs in a transaction's gas limit on this article). The gas limit corresponding to L1 costs is practically unlimited, so we might find very high values on the gasLimit field of a block.\n\nThe effective block gas limit (32 million) only accounts for execution gas limit. We can check the actual gas used for execution on a specific block, by checking the gasUsed field.\n\nLast updated on Nov 18, 2024\nPrevious\nMainnet risks\nNext\nIntroduction\nHow does gas work on Arbitrum?\nI tried to create a retryable ticket but the transaction reverted on L1. How can I debug the issue?\nHow is the L1 portion of an Arbitrum transaction's gas fee computed?\nWhat is a retryable ticket's \"submission fee\"? How can I calculate it? What happens if I the fee I provide is insufficient?\nWhich method in the Inbox contract should I use to submit a retryable ticket (aka L1 to L2 message)?\nWhy do I get \"custom tx type\" errors when I use hardhat?\nWhy does it look like two identical transactions consume a different amount of gas?\nWhy am I getting error \"429 Too Many Requests\" when using one of Offchain Labs' Public RPCs?\nHow do block.number and block.timestamp work on Arbitrum?\nDo I need to download any special npm libraries in order to use web3.js, ethers.js or viem on Arbitrum?\nHow many block numbers must we wait for in Arbitrum before we can confidently state that the transaction has reached finality?\nHow can I list my token on the Arbitrum Bridge?\nWhat is a testnet or a devnet?\nIs there any testnet available on Arbitrum?\nWhen was Arbitrum One upgraded from Classic to Nitro?\nDo Arbitrum chains support precompiles that are present on Ethereum?\nWhat's the contract code size limit in Arbitrum chains?\nHow can I find the L2 block(s) that corresponds to a given L1 block?\nWhy do some old transactions have extremely high gas prices when querying them?\nWhat is the WASM module root?\nWhy do I get a \"gas required exceeds allowance\" when trying to estimate the gas costs of a request?\nHow can I verify that an L2 block has been processed as part of a specific RBlock?\nWhy is the fee of some Classic transactions slightly different than the multiplication of gasLimit and effectiveGasPrice?\nHow can I update the information of my bridged token on Arbiscan?\nWhy does my transaction revert with InvalidFEOpcode when using Foundry?\nWhy do I receive an \"intrinsic gas too low\" error when sending a transaction even with a high gas price?\nHow can I interpret Arbitrum transaction traces?\nWhy do some blocks have a total gas limit that's over the standard block gas limit?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Token bridging overview | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/token-bridging/overview",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nOverview\nETH bridging\nERC-20 token bridging\nBridge tokens programmatically\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nToken bridging overview\n\nToken bridging is a fundamental aspect of any Layer 2 (L2) protocol. Arbitrum uses its ability to pass messages between L1 and L2 (see Cross-chain messaging) to allow projects to trustlessly move assets from Ethereum to an Arbitrum chain and back. Any asset and asset type can in principle be bridged, including Ether, ERC-20 tokens and ERC-721 tokens among others.\n\nThis section offers a series of conceptual documents explaining how asset bridging works and what options exist to bridge ether (ETH) and other types of asset between layers, as well as a series of how-tos showcasing the different methods available for making your token bridgeable.\n\nThis section is divided in 3 parts:\n\nETH bridging: explains how Arbitrum handles bridging ETH, the native token of Ethereum and the Arbitrum chains, between L1 and L2.\nERC-20 token bridging: explains the architecture of the token bridge for this type of asset, describing the different options available to make a token bridgeable.\nBridge tokens programmatically: goes over the process of making an ERC-20 token bridgeable using the different types of gateway available in the token bridge.\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nReference\nNext\nETH bridging\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/nodeinterface/overview",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nOverview\nReference\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nNodeInterface overview\n\nThe Arbitrum Nitro software includes a special NodeInterface contract available at address 0xc8 that is only accessible via RPCs (it's not actually deployed on-chain, and thus can't be called by smart contracts). The way it works is that the node uses Geth's InterceptRPCMessage hook to detect messages sent to the address 0xc8, and swaps out the message it's handling before deriving a transaction from it.\n\nThe reference page contains information about all methods available in the NodeInterface.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nReference\nNext\nReference\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/arbitrum-vs-ethereum/comparison-overview",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nComparison overview\nBlock gas limit, numbers and time\nRPC methods\nSolidity support\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nDifferences between Arbitrum and Ethereum: Overview\n\nArbitrum is designed to be as compatible and consistent with Ethereum as possible, from its high-level RPCs to its low-level bytecode and everything in between. Decentralized app (dApp) developers with experience building on Ethereum will likely find that little-to-no new specific knowledge is required to build on Arbitrum.\n\nThis section describes the differences, perks, and gotchas that devs are advised to be aware of when working with Arbitrum. This first page serves as an overview of where you might find these differences, with links to the relevant pages when needed.\n\nBlock numbers and time​\n\nTime in L2s is tricky. The timing assumptions one is used to making about Ethereum blocks don't exactly carry over into the timing of Arbitrum blocks. See Block numbers and time for details about how block numbers and time are handled in Arbitrum.\n\nRPC methods​\n\nAlthough the majority of RPC methods follow the same behavior than in Ethereum, some methods might produce a different result, or add more information, when used on an Arbitrum chain. You can find more information about these differences in RPC methods.\n\nSolidity support​\n\nYou can deploy Solidity contracts onto Arbitrum just like you do Ethereum. There are only a few minor differences in behavior. Find more information about it in Solidity support.\n\nFees​\n\nThe fees an Arbitrum transaction pays for execution essentially work identically to gas fees on Ethereum. Arbitrum transactions must also, however, pay a fee component to cover the cost of posting their calldata to the parent chain (for example, calldata on Arbitrum One, an L2, is posted to Ethereum, an L1). Find more information about the two components of gas fees in Gas and fees and L1 pricing.\n\nCross-chain messaging​\n\nArbitrum chains support arbitrary message passing from a parent chain (for example, a Layer 1 (L1) like Ethereum) to a child chain (for example, a Layer 2 (L2) like Arbitrum One or Arbitrum Nova). These are commonly known as \"L1 to L2 messages\". Developers using this functionality should familiarize themselves with how they work. Find more information about it in L1 to L2 messaging.\n\nSimilarly, Arbitrum chains can also send messages to the parent chain. Find more information about them in L2 to L1 messaging and the outbox.\n\nPrecompiles​\n\nBesides supporting all precompiles available in Ethereum, Arbitrum provides L2-specific precompiles with methods smart contracts can call the same way they can solidity functions. You can find a full reference of them in Precompiles.\n\nNodeInterface​\n\nThe Arbitrum Nitro software includes a special NodeInterface contract available at address 0xc8 that is only accessible via RPCs (it's not actually deployed on-chain, and thus can't be called by smart contracts). Find more information about this interface in NodeInterface.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nCross-chain messaging\nNext\nBlock gas limit, numbers and time\nBlock numbers and time\nRPC methods\nSolidity support\nFees\nCross-chain messaging\nPrecompiles\nNodeInterface\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/oracles/overview-oracles",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nOracles\nNOTE\n\nThis is a conceptual overview of oracles. For more detailed information on how to use oracles in your applications, check out our third-party oracles documentation.\n\nIn this conceptual overview, we'll explore oracles, how they work, and some general applications. This overview will provide a foundational understanding and set expectations for developers who want to integrate oracles into their applications.\n\nWhat are oracles?​\n\nOracles are third-party services that provide smart contracts with external information. They act as a bridge between blockchains and the outside world, which expands their functionality by enabling smart contracts to access data beyond their native networks.\n\nTypes of oracles​\n\nOracles can be classified based on their source, direction of information, trust, and how they provide information to smart contracts. Some common types of oracles include:\n\nInbound and Outbound oracles: Inbound oracles share information from external sources to smart contracts, while outbound oracles send information from smart contracts to the external world.\nCentralized and Decentralized oracles: A centralized oracle is a single entity and sole data provider for a smart contract. Decentralized oracles increase reliability by relying on multiple sources of truth and distributing trust among participants.\nPush and Pull oracles: Push oracles proactively provide data to smart contracts without being explicitly requested. They push data to the smart contract when a specified event or condition occurs. On the other hand, pull oracles require smart contracts to request data explicitly. They pull data from external sources in response to a query from the smart contract.\nSoftware oracles: These oracles interact with online sources of information, such as databases, servers, or websites, and transmit the data to the blockchain. They often provide real-time information like exchange rates or digital asset prices.\nHardware oracles: These oracles obtain information from the physical world using electronic sensors, barcode scanners, or other reading devices. They \"translate\" real-world events into digital values that smart contracts can understand.\nHow do push oracles work?​\n\nPush oracles proactively provide data to smart contracts without being explicitly requested. When a specified event or condition occurs, the push oracle triggers the smart contract with the relevant data. For example, a push oracle might send weather data to a smart contract once the temperature reaches a certain threshold.\n\nHow do pull oracles work?​\n\nPull oracles require smart contracts to request data explicitly. A smart contract sends a query to the oracle, retrieving and relaying the requested information to the contract. For example, a smart contract might request the current price of a specific digital asset from a pull oracle.\n\nUse cases for oracles​\n\nOracles serve a purpose in various applications across industries. Some general use cases include:\n\nPrediction markets: Oracles provide real-world data to prediction market platforms, allowing users to bet on future events or outcomes.\nSupply chain management: Hardware oracles can track the location and status of goods throughout the supply chain, enabling smart contracts to automate various processes and improve efficiency.\nInsurance: Oracles can supply data about events such as natural disasters, accidents, or price fluctuations, allowing smart contracts to automate claims processing and payouts.\nDecentralized finance (DeFi): Oracles provide critical price and market data to DeFi applications, enabling them to operate efficiently and securely.\n\nIn summary, oracles are a crucial component of the blockchain ecosystem, bridging the gap between on-chain and off-chain data sources. They enhance the functionality of smart contracts and enable a wide range of applications across various industries. As blockchain technology continues to evolve, developing secure and reliable oracles will remain essential in unlocking the full potential of smart contracts and decentralized applications.\n\nResources​\n\nYou can learn more about oracles in our third-party oracles documentation.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nSolidity support\nNext\nOverview\nWhat are oracles?\nTypes of oracles\nHow do push oracles work?\nHow do pull oracles work?\nUse cases for oracles\nResources\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Cross-chain messaging overview | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/cross-chain-messaging",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nCross-chain messaging overview\n\nThe Arbitrum protocol and related tooling makes it easy for developers to build cross-chain applications; i.e., applications that involve sending messages from Ethereum to an Arbitrum chain, and/or from an Arbitrum chain to Ethereum.\n\nEthereum-to-Arbitrum messaging​\n\nArbitrary L1 to L2 contract calls can be created via the Inbox's createRetryableTicket method; upon publishing the L1 transaction, the L2 side will typically get included within minutes. Happily / commonly, the L2 execution will automatically succeed, but if reverts, and it can be rexecuted via a call to the redeem method of the ArbRetryableTx precompile.\n\nFor details and protocol specification, see L1 to L2 Messages.\n\nFor an example of retryable tickets in action, see the Greeter tutorial, which uses the Arbitrum SDK.\n\nArbitrum-to-Ethereum messaging​\n\nSimilarly, L2 contracts can send Arbitrary messages for execution on L1. These are initiated via calls to the ArbSys precompile contract's sendTxToL1 method. Upon confirmation (about 1 week later), they can executed by retrieving the relevant data via a call to NodeInterface contract's constructOutboxProof method, and then executing them via the Outbox's executeTransaction method.\n\nFor details and protocol specification, see L2 to L1 Messages.\n\nFor a demo, see the Outbox Tutorial.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nChains and testnets\nNext\nComparison overview\nEthereum-to-Arbitrum messaging\nArbitrum-to-Ethereum messaging\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Third-party Orbit infrastructure providers | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/infra-options-orbit-chains",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nThird-party Orbit infrastructure providers\n\nThis document provides an overview of third-party Orbit chain infrastructure providers that support production-grade Orbit chain deployments. Note that this list is not exhaustive, and will be continuously updated as the Orbit ecosystem evolves.\n\nRollup-as-a-Service (RaaS) providers​\n\nFor most production use-cases, we encourage Orbit chain operators to work with one of the following RaaS (Rollup as a Service) providers. These providers manage the infrastructure required to maintain high-performance, secure Orbit chain deployments:\n\nQuickNode\nCaldera\nConduit\nAltLayer\nGelato\nAsphere\nAlchemy\nZeeve\nChain explorers​\n\nChain explorers let you view transactions, blocks, addresses, and network activity associated with your Orbit chain. The following explorers support Orbit chains, and can be used to monitor and analyze your chain's activity:\n\nBlockscout\nSocialscan\nLore\nRoutescan\n\nAdditionally, Orbit chains leveraging blobs for data availability may use tools like Blobscan to see which blob/block includes a given transaction.\n\nBridges​\n\nYou can easily launch an Orbit chain with a canonical token bridge, which allows transfers to and from the chain via Arbitrum One, Nova, or the parent chain to which your Orbit chain settles transactions.\n\nFor applications that require the ability to transfer assets to chains outside of the Orbit ecosystem or in an expedited manner (without waiting for complete finality), the following third-party bridging providers can be used:\n\nLayerZero\nConnext\nHyperlane\nAxelar\nAcross\nDecent\nData availability​\n\nOne way to reduce transaction fees for Orbit chains is to configure a Data Availability (DA) solution that stores chain data off-chain. Although the AnyTrust protocol offers native support for this functionality (and is configurable by default on Orbit AnyTrust chains), the following third-party providers give you another way to store data off-chain. Note that using these services will limit your chain's ability to leverage AnyTrust protocol improvements as they relate to transaction fee and DA configurability:\n\nCelestia\nEigenDA\nAvailDA\nNear (coming soon)\nIndexers​\n\nIndexers provide a convenient way to retrieve historic or application-specific data without having to interface with your chain through an RPC endpoint. The following third-party providers offer indexing services that can be used with Orbit chains:\n\nQuickNode\nAlchemy\nThe Graph\nGoldsky\nOrmi\nTraceye\nOracles​\n\nThe following Oracle providers can be used to integrate off-chain data with your Orbit chain's smart contracts:\n\nChainlink\nChronicle\nPyth\nRedstone\nRandomizer (VRF only)\nSupra\nRedStone\nRPC endpoints​\n\nRPC endpoints are the primary interface through which users and developers interact with any chain, whether it be for transaction submission, reading state, or indexing historical data. The following third-party providers offer RPC endpoint services compatible with Orbit chains:\n\nAlchemy\nAnkr\nChainstack\nQuickNode\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nPublic preview\nNext\nFAQ\nRollup-as-a-Service (RaaS) providers\nChain explorers\nBridges\nData availability\nIndexers\nOracles\nRPC endpoints\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum chains overview | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/public-chains",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nArbitrum chains overview\n\nArbitrum chains are Layer 2 solutions built on top of the Ethereum blockchain, designed to increase scalability and reduce transaction costs. In this conceptual overview, we’ll learn about the different Arbitrum chains and how they relate to each other. We’ll describe the available Arbitrum production and testnet chains, their differences, and the technology stacks that these chains use.\n\nWhat Arbitrum production chains are available?​\nArbitrum One​\n\nArbitrum One is a Layer 2 (L2) optimistic rollup chain that implements the Arbitrum Rollup protocol and settles to Ethereum's Layer 1 (L1) chain. It lets you build high-performance Ethereum dApps with low transaction costs and Ethereum-grade security guarantees, introducing no additional trust assumptions. This is made possible by the Nitro technology stack, a \"Geth-at-the-core\" architecture that gives Arbitrum One (and Nova) advanced calldata compression, separate contexts for common execution and fault proving, Ethereum L1 gas compatibility, and more.\n\nArbitrum Nova​\n\nArbitrum Nova is a high-performance alternative to Arbitrum One's chain. While Arbitrum One implements the purely trustless Rollup protocol, Arbitrum Nova implements the mostly trustless AnyTrust protocol. They key difference between Rollup and AnyTrust is that the AnyTrust protocol introduces an additional trust assumption in the form of a data availability committee (DAC). This committee (detailed below) is responsible for expediting the process of storing, batching, and posting L2 transaction data to Ethereum's L1. This lets you use Arbitrum in scenarios that demand performance and affordability, while Arbitrum One is optimal for scenarios that demand Ethereum's pure trustlessness.\n\nWhat Arbitrum testnet chains are available?​\nArbitrum Sepolia​\n\nArbitrum Sepolia serves as a testnet chain replicating the capabilities of Arbitrum One's main network. Linked to the Sepolia testnet, it offers developers a secure platform to experiment with and evaluate their smart contracts prior to actual deployment on the mainnet.\n\nArbitrum Goerli​\n\nArbitrum Goerli was a testnet chain that mirrored the functionality of the Arbitrum One mainnet and was connected to the Ethereum Goerli testnet. It was deprecated on November 18th 2023, and deactivated on March 18th, 2024.\n\nCAUTION\n\nThe old testnet RinkArby was deprecated on December 20th, 2022.\n\nStylus testnet​\n\nStylus uses the Nitro technology and allows for efficient smart contract creation using languages like Rust, C, and C++. Leveraging Arbitrum's EVM equivalence, Stylus contracts achieve remarkable speed and low gas fees. With full interoperability between Solidity and Stylus contracts, new horizons emerge, while significantly cheaper memory costs unlock novel blockchain use cases.\n\nCAUTION\n\nStylus testnet will be deprecated once Stylus comes out of beta and is enabled on the Sepolia testnet.\n\nWhat differences there are between the available Arbitrum chains?​\n\nThe main differences between the Arbitrum chains lie in their purpose and the environment they operate in.\n\nArbitrum One and Arbitrum Nova are production chains designed for real-world use. They're connected to the Ethereum mainnet and handle real, valuable transactions. They both use Arbitrum's Nitro technology stack under the hood, but Arbitrum One implements the Rollup protocol, while Nova implements the AnyTrust protocol. Arbitrum One is designed for general use, providing a scalable and cost-effective solution for running Ethereum-compatible smart contracts. On the other hand, Arbitrum Nova is designed for applications that require a higher transaction throughput and don’t require the full decentralization that rollups provide.\n\nFinally, Arbitrum Sepolia is a testnet chain. It's designed for testing purposes and is connected to the Sepolia testnet, which uses test Ether with no real-world value.\n\nWhat technology stacks use the Arbitrum chains?​\nNitro​\n\nNitro is the technology that powers Arbitrum One, Arbitrum Nova (with AnyTrust configuration),and Arbitrum Sepolia. It's designed to offer high throughput and low cost, making it ideal for scaling Ethereum applications. Nitro is a major upgrade to the “Classic” stack, offering several improvements including advanced calldata compression, separate contexts for common execution and fault proving, Ethereum L1 gas compatibility, and more. You can find more information about Nitro in Inside Arbitrum Nitro.\n\nAnyTrust (variant of Nitro)​\n\nAnyTrust is a variant of the Nitro technology stack that lowers costs by accepting a mild trust assumption. The AnyTrust protocol relies on an external Data Availability Committee (DAC) to store data and provide it on demand. The DAC has N members, of which AnyTrust assumes at least two are honest. Keeping the data off-chain in the happy/common case means the system can charge the user significantly lower fees. You can find more information about AnyTrust in Inside AnyTrust.\n\nClassic (deprecated)​\n\nThe Classic technology stack is the original version of Arbitrum. It has been deprecated and replaced by the Nitro technology stack.\n\nConclusion​\n\nUnderstanding the different Arbitrum chains and their technology stacks is crucial for developers working on blockchain and web3 applications. Each chain offers a unique set of features and benefits, making them suitable for different use cases. By choosing the right chain and technology stack, developers can ensure their applications are secure, scalable, and cost-effective.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nEstimate gas\nNext\nCross-chain messaging\nWhat Arbitrum production chains are available?\nArbitrum One\nArbitrum Nova\nWhat Arbitrum testnet chains are available?\nArbitrum Sepolia\nArbitrum Goerli\nStylus testnet\nWhat differences there are between the available Arbitrum chains?\nWhat technology stacks use the Arbitrum chains?\nNitro\nAnyTrust (variant of Nitro)\nClassic (deprecated)\nConclusion\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/how-to-estimate-gas",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to estimate gas in Arbitrum\nLOOKING FOR STYLUS GUIDANCE?\n\nHead over to the Stylus gas docs for Stylus-specific guidance.\n\nThis how-to is intended for users and developers interested in understanding how gas operates in Arbitrum, how it's calculated, and how to estimate it before submitting transactions. More detailed information about these calculations can be found in this Medium article and the Gas and Fees page.\n\nSkip the formula, focus on practical know-how​\n\nBefore diving into the specifics and the formula, if you're looking for a practical way to estimate gas for your transaction, you can rely on the standard gas estimation process. This can be achieved by calling an Arbitrum node's eth_estimateGas, which provides a value (gas limit) that should sufficiently cover the entire transaction fee at the specified L2 gas price.\n\nMultiplying the value obtained from eth_estimateGas by the L2 gas price will give you the total amount of Ether required for the transaction to be successful. It's important to note that, for a specific operation, the result of eth_estimateGas value may vary over time due to fluctuations in the L1 calldata price, see below to learn why!\n\nAlternatively, to obtain the gas limit for your transaction, you can call NodeInterface.gasEstimateComponents() and then use the first result, which is gasEstimate. Next, to find the total cost, you need to multiply this amount by the L2 gas price, which is available in the third result, baseFee.\n\nNote that when working with L1 to L2 messages (also known as retryable tickets), you can use the function L1ToL2MessageGasEstimator.estimateAll() of the Arbitrum SDK or NodeInterface.estimateRetryableTicket() to get all the gas information needed to send a successful transaction.\n\nBreaking down the formula​\n\nWe'll now break down the formula mentioned in the Medium article, moving then to where to get the information of each variable, and finally seeing an example of how to apply the formula in your code as well as other practical ways of estimating gas costs.\n\nHowever, if you want to jump straight to the code, we have created this script in our tutorials repository that goes through all the calculations explained in this how-to.\n\nAs explained in the Medium article, the transaction fees to pay at any given moment are the result of the following product:\n\nTransaction fees (TXFEES) = L2 Gas Price (P) * Gas Limit (G)\n\n\nThis Gas Limit includes the gas of the L2 computation and an additional buffer to cover the L1 gas to be paid by the Sequencer when posting the batch including this transaction on L1.\n\nGas Limit (G) = Gas used on L2 (L2G) + Extra Buffer for L1 cost (B)\n\n\nThis buffer takes into account the cost of posting the transaction, batched and compressed, on L1. The L1 estimated posting cost is calculated by multiplying these two values:\n\nL1S, which estimates the amount of data the transaction will take up in the batch by compressing the transaction with Brotli.\nL1P, which is the L2's estimated view of the current L1's price of data (per byte), which the L2 dynamically adjusts over time.\n\nMore information is available in this page.\n\nL1 Estimated Cost (L1C) = L1 price per byte of data (L1P) * Size of data to be posted in bytes (L1S)\n\n\nTo calculate the buffer, that estimated cost is divided by the L2 Gas Price.\n\nExtra Buffer (B) = L1 Estimated Cost (L1C) / L2 Gas Price (P)\n\n\nFinally, using all of the above elements, the formula can be written as follows:\n\nTXFEES = P * (L2G + ((L1P * L1S) / P))\n\nWhere do we get all this information from?​\n\nWe'll use one resource available in Arbitrum: the NodeInterface.\n\nP (L2 Gas Price) ⇒ Price to pay for each gas unit. It starts at 0.01 gwei on Arbitrum One (0.01 gwei on Arbitrum Nova) and can increase depending on the demand for network resources.\nCall NodeInterface.GasEstimateComponents() and get the third element, baseFee.\nL2G (Gas used on L2) ⇒ Gas used to compute the transaction on L2. This does not include the “posting on L1” part of the calculations. The value of L2G will depend on the transaction itself, but having the data of the transaction, we can calculate it as follows:\nCall NodeInterface.GasEstimateComponents() with the transaction data and subtract the second element (gasEstimateForL1, which estimates the L1 part of the fees) from the first (gasEstimate, which includes both the L1 and the L2 parts).\nL1P (L1 estimated price per byte of data) ⇒ Estimated cost of posting 1 byte of data on L1:\nCall NodeInterface.GasEstimateComponents(), get the fourth element l1BaseFeeEstimate and multiply it by 16.\nL1S (Size of data to be posted on L1, in bytes) ⇒ This will depend on the data of the transaction. Keep in mind that Arbitrum adds a fixed amount to this number to make up for the static part of the transaction, which is also posted on L1 (140 bytes). We can do a small calculation to obtain this value: call NodeInterface.GasEstimateComponents() take the second element, gasEstimateForL1 (this is equivalent to B in our formula), multiply it by P and divide it by L1P.\nFor Arbitrum Nova (AnyTrust), the size of the data is also a fixed value, as only the Data Availability Certificate is posted on L1, as explained here.\n\n(Note: for L1P and L1S, you can also call NodeInterface.gasEstimateL1Component() to get l1BaseFeeEstimate and gasEstimateForL1)\n\nAn example of how to apply this formula in your code​\n\nFinally, we show an example of how to get the values we just described and how to estimate the gas usage of a transaction in Javascript. We'll use our SDK to connect to the NodeInterface.\n\nWe first instantiate a factory object for the NodeInterface, using two methods from the SDK. l2Provider is a regular JSON RPC provider for the L2 network we are using, and NODE_INTERFACE_ADDRESS is the addresses that we need to call to access NodeInterface methods in said network.\n\nconst { NodeInterface__factory } = require(\"@arbitrum/sdk/dist/lib/abi/factories/NodeInterface__factory\");\nconst { NODE_INTERFACE_ADDRESS } = require(\"@arbitrum/sdk/dist/lib/dataEntities/constants\");\n\n...\n\n// Instantiation of the NodeInterface object\nconst nodeInterface = NodeInterface__factory.connect(\n    NODE_INTERFACE_ADDRESS,\n    baseL2Provider\n);\n\n\nFor this example, we'll use the method NodeInterface.gasEstimateComponents() to get the information we need. For the gasEstimateComponents() call, we'll pass a destinationAddress (this should be the address that you intend to call in your transaction) and the data we want to send, to get results as accurate as possible. You can also specify a different block number (in hex) in the object passed as the last parameter.\n\n// Getting the gas prices from ArbGasInfo.getPricesInWei()\nconst gasComponents = await arbGasInfo.callStatic.getPricesInWei();\n\n// And the estimations from NodeInterface.GasEstimateComponents()\nconst gasEstimateComponents = await nodeInterface.callStatic.gasEstimateComponents(\n  destinationAddress,\n  false,\n  txData,\n  {\n    blockTag: 'latest',\n  },\n);\n\n\nWith this, we can now get the values of the 4 variables we'll use in our formula:\n\n// Getting useful values for calculating the formula\nconst l1GasEstimated = gasEstimateComponents.gasEstimateForL1;\nconst l2GasUsed = gasEstimateComponents.gasEstimate.sub(gasEstimateComponents.gasEstimateForL1);\nconst l2EstimatedPrice = gasEstimateComponents.baseFee;\nconst l1EstimatedPrice = gasEstimateComponents.l1BaseFeeEstimate.mul(16);\n\n// Calculating some extra values to be able to apply all variables of the formula\n// -------------------------------------------------------------------------------\n// NOTE: This one might be a bit confusing, but l1GasEstimated (B in the formula) is calculated based on l2 gas fees\nconst l1Cost = l1GasEstimated.mul(l2EstimatedPrice);\n// NOTE: This is similar to 140 + utils.hexDataLength(txData);\nconst l1Size = l1Cost.div(l1EstimatedPrice);\n\n// Setting the basic variables of the formula\nconst P = l2EstimatedPrice;\nconst L2G = l2GasUsed;\nconst L1P = l1EstimatedPrice;\nconst L1S = l1Size;\n\n\nAnd finally, we estimate the transaction fees applying the formula described in the beginning.\n\n// L1C (L1 Cost) = L1P * L1S\nconst L1C = L1P.mul(L1S);\n\n// B (Extra Buffer) = L1C / P\nconst B = L1C.div(P);\n\n// G (Gas Limit) = L2G + B\nconst G = L2G.add(B);\n\n// TXFEES (Transaction fees) = P * G\nconst TXFEES = P.mul(G);\n\n\nRefer to our tutorials repository for a working example of this code.\n\nFinal note​\n\nNote that gas estimations from the above techniques are approximate and the actual gas fees may differ. We encourage developers to set this expectation explicitly wherever this information is shared with end-users.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nQuickstart (Solidity)\nNext\nChains and testnets\nSkip the formula, focus on practical know-how\nBreaking down the formula\nWhere do we get all this information from?\nAn example of how to apply this formula in your code\nFinal note\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "types | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sdk/reference/utils/types",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nIntroduction\nMigrating from v3 to v4\nReference\nIndex\nAssetBridger\nDataEntities\nInbox\nMessage\nUtils\nArbProvider\nByte_serialize_params\nEventFetcher\nLib\nMulticall\nTypes\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\ntypes\nType Aliases​\nOmitTyped<T, K>​\ntype OmitTyped<T, K>: Omit<T, K>;\n\n\nOmit doesnt enforce that the seconds generic is a keyof the first OmitTyped guards against the underlying type prop names being refactored, and not being updated in the usage of OmitTyped\n\nType parameters​\nType parameter\nT\nK extends keyof T\nSource​\n\nutils/types.ts:6\n\nPartialPick<T, K>​\ntype PartialPick<T, K>: OmitTyped<T, K> & Partial<T>;\n\n\nMake the specified properties optional\n\nType parameters​\nType parameter\nT\nK extends keyof T\nSource​\n\nutils/types.ts:11\n\nRequiredPick<T, K>​\ntype RequiredPick<T, K>: Required<Pick<T, K>> & T;\n\n\nMake the specified properties required\n\nType parameters​\nType parameter\nT\nK extends keyof T\nSource​\n\nutils/types.ts:16\n\nEdit this page\nPrevious\nMulticall\nNext\nA gentle introduction\nType Aliases\nOmitTyped<T, K>\nType parameters\nSource\nPartialPick<T, K>\nType parameters\nSource\nRequiredPick<T, K>\nType parameters\nSource\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/bold-adoption-for-orbit-chains",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nBoLD for Orbit chains\nPUBLIC PREVIEW DOCUMENT\n\nThis document is currently in public preview and may change significantly as feedback is captured from readers like you. Click the Request an update button at the top of this document or join the Arbitrum Discord to share your feedback.\n\nLaunch details and key dates​\nStatus: Alpha - continued testing and evaluation of performance of BoLD with Stylus\nArbitrum Sepolia Q4 2024\nArbitrum One Q1 2025\nArbitrum Nova Q1 2025\ntldr;​\n\nArbitrum BoLD is an upgrade to the dispute protocol on Arbitrum chains that delivers both permissionless validation and core security benefits. As with all features on the Arbitrum stack, Orbit chains can adopt BoLD at their own discretion and on their own timeline. To upgrade to BoLD, it is required to upgrade both the Nitro node software and the rollup's smart contracts on its parent chain.\n\nRecommended Adoption Path​\n\nBoLD brings new security benefits to Orbit chains, regardless of whether their validators are permissioned or permissionless. These new security benefits include improved resistance to delay attacks and increased censorship resistance for L3s. We strongly recommend Orbit chains adopt Arbitrum BoLD to register these security benefits while keeping validation permissioned.\n\nWARNING\n\nIt is strongly recommended that existing and prospective Orbit chains upgrade to use Arbitrum BoLD but keep validation permissioned because of the increased risks associated with allowing any entity to advance and challenge the state of your chain. The risks are summarized below. Rigorous testing and research has been poured into the parameters chosen for Arbitrum One and so we cannot formally support or endorse use of permissionless Arbitrum BoLD in other configurations.\n\nBelow is a quick breakdown of the benefits of permissioned BoLD vs. permissionless BoLD for your Orbit chain:\n\nBenefits of adopting Arbitrum BoLD​\n\nArbitrum BoLD enables an Arbitrum chain to be permissionlessly validated thanks to several key improvements to the existing dispute protocol. These key improvements benefit an Arbitrum Orbit chain even if validation is kept permissioned on a BoLD-enabled Orbit chain.\n\nBelow are some benefits for an Orbit chain that come with adopting Arbitrum BoLD - regardless of whether validation is kept permissioned or not:\n\nImproved resistance to delay attacks​\n\nDisputes on a BoLD-enabled chain are resolved in a round-robin style format where disputes can be concurrently resolved. This is an evolution from the current dispute protocol, where challenges are resolved one-by-one. This evolution means that an upper time bound can be placed on all disputes such that a malicious actor cannot delay the chain indefinitely like they can today. Even when validation is kept permissioned, this upper time bound is critical to mitigating the risk of delay attacks by parties on the validator allowlist for an Orbit chain.\n\nBeing on the latest version of Arbitrum technology​\n\nAdopting Arbitrum BoLD for your Orbit chain will require upgrading the Nitro node software and deploying a new set of contracts on your parent chain. While not specifically related to Arbitrum BoLD, it is always strongly recommended that Orbit chain owners upgrade and keep their chain on the latest stable releases of both Nitro node software and the relevant on-chain contracts. This is critical to ensure your Orbit chain benefits from the latest security improvements and features that the Offchain Labs team is constantly churning out.\n\nSecured by interactive fraud-proofs​\n\nArbitrum chains will continue to be secured with an interactive proving game between validators using fraud proofs. The same single-honest party assumption applies but now with strict improvements to security to the point where chains like Arbitrum One can be permissionlessly validated and have their state assertions be permissionlesly challenged.\n\nUse of your project's native token as the bonding asset to secure the chain​\n\nArbitrum BoLD enables the chain owner to use any ERC-20 token on the parent chain as the bond for validators to participate in securing the network. By default, this token will be WETH for Arbitrum One and we recommend teams consult our documentation to understand why WETH was selected for Arbitrum One (and not ARB).\n\nIncreased censorship resistance for L3 Orbit chains​\n\nToday, the force inclusion window is a fixed 24 hours. This force inclusion window exists to enable both users and validators to force-include their transactions and assertions on the parent chain, with a 24-hour delay, if the sequencer is offline or censoring transactions. Arbitrum BoLD's release will come with the Censorship Timeout feature that will automatically reduce the force inclusion time window if the parent chain or sequencer is maliciously censoring user transactions/assertions or the sequencer goes offline. This massively benefits Orbit L3 chains (that settle to a BoLD-enabled parent chain) as it ensures the chain can advance with minimal UX degradation during periods of censorship. You can read more about how this feature works in the gentle introduction to BoLD.\n\nCaveats that come with adopting Arbitrum BoLD for permissionless validation​\n\nArbitrum BoLD's implementation and specification have been thoroughly tested and audited. The upgrade to Arbitrum BoLD is not the subject of this section, but rather the caveats and nuances that come with whether to enable permissionless validation.\n\nWARNING\n\nIt is strongly recommended that existing and prospective Orbit chains upgrade to use Arbitrum BoLD but keep validation permissioned because of the increased risks associated with allowing any entity to advance and challenge the state of your chain. The risks are summarized below. Rigorous testing and research has been poured into the parameters chosen for Arbitrum One and so we cannot formally support or endorse use of permissionless Arbitrum BoLD in other configurations.\n\nEnabling permissionless validation means that any entity can spin up a validator and open challenges to dispute invalid claims made by other validators on the network. This opens up an Orbit chain to the risk of spam and attacks by unknown and malicious entities. To mitigate this risk for Arbitrum One, a considerable amount of research and testing has been done to optimize the trade-offs between deterring attacks and managing the costs of defending Arbitrum for honest parties. This research includes carefully calculating all relevant bond sizes, challenge period durations, and relevant plans for operating the infrastructure. More information on this research can be found in the BoLD whitepaper. Below are a few examples of various risks that an Orbit chain will hold should they pursue permissionless BoLD:\n\nRisk of resource exhaustion attacks​\n\nWhere malicious entities can acquire and utilize more resources than honest parties can put together during a challenge. Such an attack can take many forms and includes both on-chain and off-chain computational/infra costs. For example, a well-coordinated attack on an Orbit chain could overwhelm honest parties if the malicious actors can spend more gas and computational power and acquire more of the bonding asset than the defenders can. This risk can be mitigated by a combination of high bond sizes, use of a price-independent bonding asset, use of a bonding asset with high liquidity, strong economic guarantees that attackers will lose most of their resources, sufficiently long challenge periods, and robust infrastructure operations and resources that can respond and scale up when necessary. More information on resource exhaustion attacks and how Arbitrum BoLD's design accounts for this risk can be found in Section 6.1.4 of the BoLD whitepaper. We recommend teams consider a resource exhaustion ratio greater than 5 assuming very high L1 gas costs (like 100gwei/gas).\n\nIncreased infrastructure costs and overhead​\n\nRelated to, and expanding on, the above point about resource exhaustion attacks, the honest parties operating active validators and proposers for a BoLD-enabled chain will need to be ready to vertically scale their infrastructure, and cover the off-chain costs of doing so, in the event of an attack. This is because a malicious actor may choose to spam and overwhelm the honest defenders with multiple challenges. Making moves, honest or malicious, costs resources to perform bisections on history committments down to a single step of execution. If this happens, each malicious challenge must be met with an honest counter-challenge during the interactive fraud proof game. Orbit chains who decide to adopt Arbitrum BoLD in permissionless mode are strongly encouraged to work with their Rollup-as-a-Service (RaaS) team to: deploy robust monitoring for challenges, set aside a budget to vertically scale up infrastructure and fund counter-challenges, and have an incident response plan drafted and rehearsed to ensure prompt and decisive reactionary steps in the event of an attack.\n\nRisks to liveness or delays of the chain​\n\nIf the bond sizes are set too low, an adversary can cheaply create a challenge and delay confirmation of an assertion for up to an entire extra challenge period if they can censor honest BoLD moves. Remember that challenges, while time-bound, still take time to complete. Delaying the confirmation of assertions for a chain could negatively impact the chain in many ways that an attacker could benefit from (e.g., profiting from price volatility and price impacts on the Orbit chain's token may make delaying the chain worthwhile for an attacker). We recommend teams set bond sizes to be much greater than the opportunity cost of a week of delay, based on your chain's TVL (e.g. if your chain's TVL is $1B, then the opportunity cost of $1B should be used as a floor for the block level bond amount size). We further recommend that the bonding token used is highly liquid on the parent chain and relatively non-volatile.\n\nConclusion for Orbit chains considering BoLD Permissionless Validation​\n\nDue to the uniquely different tokenomics, sizes, and varying types of Arbitrum Orbit chains deployed (or in active development) today, Offchain Labs does not provide a \"one-size-fits-all\" recommendation for how best to safely set up and enable permissionless validation for Orbit chains. Instead, we recommend teams adopt Arbitrum BoLD but keep validation permissioned.\n\nIf your team would like to have permissionless validation for your Orbit chain, please reach out to us via this form so that we can schedule some time to understand your needs better.\n\nHow to adopt Arbitrum BoLD​\n\nAs mentioned earlier, the upgrade to the dispute protocol involves both a Nitro node software upgrade and the deployment/upgrade of new smart contracts on your Orbit's parent chain.\n\nMore details on deploying Arbitrum BoLD for your Orbit chain will be added here when they are available.\n\nEdit this page\nLast updated on Nov 20, 2024\nPrevious\nCustom gas token SDK\nNext\nPublic preview\nLaunch details and key dates\ntldr;\nRecommended Adoption Path\nBenefits of adopting Arbitrum BoLD\nCaveats that come with adopting Arbitrum BoLD for permissionless validation\nConclusion for Orbit chains considering BoLD Permissionless Validation\nHow to adopt Arbitrum BoLD\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Public preview: What to expect | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/concepts/public-preview-expectations",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nPublic preview: What to expect\n\nOrbit chains are currently a public preview offering. This concept document explains what \"public preview\" means, what to expect from Orbit's public preview capabilities, and how to engage with our team as you tinker.\n\nArbitrum Orbit is Mainnet ready, but deploy to Testnet first​\n\nArbitrum Orbit's core technology has undergone a comprehensive audit and is now able to support deployments to Mainnet.\n\nIt's important to note that Orbit is a new technology and as such, there are risks involved.\n\nTo mitigate these risks, you're strongly encouraged to deploy your Orbit chain on Testnet first. If you don't launch on Testnet first, you significantly increase risk.\n\nRefer to the Orbit quickstart for instructions that walk you through the process of deploying your Orbit chain to Testnet.\n\nHow products like Orbit are developed at Offchain Labs​\n\nOffchain Labs builds products in a way that aligns loosely with the spirit of \"building in public\". We like to release things early and often so that we can capture feedback and iterate in service of your needs, as empirically as possible.\n\nTo do this, some of our product offerings are documented with public preview disclaimers that look like this:\n\nThis banner's purpose is to set expectations while inviting readers like you to express your needs so that we can incorporate them into the way that we iterate on product.\n\nWhat to expect when using public preview offerings​\n\nAs you tinker and provide feedback, we'll be listening. Sometimes, we'll learn something non-obvious that will result in a significant change. More commonly, you'll experience incremental improvements to the developer experience as the offering grows out of its public preview status, towards stable status.\n\nPublic preview offerings are evolving rapidly, so don't expect the degree of release notes discipline that you'd expect from a stable offering. Keep your eyes open for notifications regarding patch, minor, and major changes, along with corresponding relnotes that highlight breaking changes and new capabilities.\n\nHow to provide feedback​\n\nOur product team primarily uses three feedback channels while iterating on public preview capabilities:\n\nDocs: Click on the Request an update button located in the top-right corner of any document to provide feedback on the docs and/or developer experience. This will lead you to a prefilled Github issue that members of our product team periodically review.\nDiscord: Join the Arbitrum Discord to engage with members of the Arbitrum community and product team.\nGoogle form: Complete this form to ask for support.\nWhat to expect when providing feedback​\n\nOur ability to respond to feedback is determined by our ever-evolving capacity and priorities. We can't guarantee responses to all feedback submissions, but our small-but-mighty team is listening, and we'll try our best to acknowledge and respond to your feedback. No guarantees though!\n\nPS, our small-but-mighty team is hiring.\n\nThank you!​\n\nThanks for helping us build things that meet your needs! We're excited to engage with OGs and newcomers alike; please don't hesitate to reach out.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nBoLD for Orbit chains\nNext\nThird-party infrastructure providers\nArbitrum Orbit is Mainnet ready, but deploy to Testnet first\nHow products like Orbit are developed at Offchain Labs\nWhat to expect when using public preview offerings\nHow to provide feedback\nWhat to expect when providing feedback\nThank you!\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/concepts/custom-gas-token-sdk",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nSDK support for custom gas token Orbit chains\n\nArbitrum SDK is a TypeScript library for client-side interactions with Arbitrum. It provides common helper functionality as well as access to the underlying smart contract interfaces.\n\nCustom gas token APIs​\n\nCustom gas token support in the Arbitrum SDK introduces a suite of APIs designed for the specific purpose of facilitating bridging operations. These APIs are tailored for use cases where there is a need to transfer a native token or an ERC-20 token from the parent chain to an orbit chain utilizing a custom gas token. The process involves an initial step of authorizing the native token on the parent chain. To streamline this, our APIs provide functionalities for token approval and offer a mechanism to verify the current status of this approval. Detailed below is a guide to how each of these APIs can be effectively utilized for distinct purposes:\n\nEthBridger Context:\n\nAPIs: getApproveGasTokenRequest and approveGasToken.\nPurpose: These APIs are essential for the bridging of native tokens to the Orbit chain. They facilitate the necessary approval for native tokens, allowing contracts to manage fund movements. This process includes escrowing a specified amount of the native token on the parent chain and subsequently bridging it to the Orbit chain.\nNote that you should use EthBridger when bridging the native token between the parent chain and the orbit chain.\n\nErc20Bridger Context:\n\nAPIs: getApproveGasTokenRequest and approveGasToken.\nPurpose: In the scenario of bridging ERC20 assets to an Orbit chain, these APIs play a crucial role. Token Bridging on Arbitrum Nitro stack uses Retryable tickets and needs specific amount of fees to be paid for creation and redemption of the ticket. For more information about retryable tickets please take a look at this part of our docs. The Orbit chain operates as a custom gas token network, necessitating the payment of fees in native tokens for the creation of retryable tickets and their redemption on the Orbit chain. To cover the submission and execution fees associated with retryable tickets on the Orbit chain, an adequate amount of native tokens must be approved and allocated on the parent chain to cover the fees.\nNote that you should use Erc20Bridger when bridging an ERC-20 token between the parent chain and the orbit chain.\n\nNote that these APIs are just needed for custom gas token orbit chains and for ETH-powered rollup and anytrust orbit chains, you don't need to use them.\n\nNote that when native tokens are transferred to the custom gas token orbit chain, they function equivalently to ETH on EVM chains. This means these tokens will exhibit behavior identical to that of ETH, the native currency on EVM chains. This similarity in functionality is a key feature to consider in transactions and operations within the orbit chain.\n\nNote that everything else is under the hood, and the custom gas token code paths will be executed just if the L2Network object config has a nativeToken field.\n\nRegistering a custom token in the Token Bridge​\n\nWhen registering a custom token in the Token Bridge of a custom-gas-token Orbit chain, there's an additional step to perform before calling registerTokenToL2.\n\nSince the Token Bridge router and the generic-custom gateway expect to have allowance to transfer the native token from the msg.sender() to the inbox contract, it's usually the token in the parent chain who handles those approvals. In the TestCustomTokenL1, we offer as an example of implementation. We see that the contract transfers the native tokens to itself and then approves the router and gateway contracts. If we follow that implementation, we only need to send an approval transaction to the native token to allow the TestCustomTokenL1 to transfer the native token from the caller of the registerTokenToL2 function to itself.\n\nYou can find a tutorial that deploys two tokens and registers them in the Token Bridge of a custom-gas-token-based chain.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nOrbit chain ownership\nNext\nBoLD for Orbit chains\nCustom gas token APIs\nRegistering a custom token in the Token Bridge\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/concepts/chain-ownership",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nOrbit chain ownership\n\nA chain owner of an Orbit chain is an entity that can carry out critical upgrades to the chain's core protocol; this includes upgrading protocol contracts, setting core system parameters, and adding & removing other chain owners.\n\nAn Orbit chain's initial chain owner is set by the chain's creator when the chain is deployed.\n\nThe chain-ownership architecture is designed to give Orbit chain creators flexibility in deciding how upgrades to their chain occur.\n\nArchitecture​\n\nChain ownership affordance is handled via Upgrade Executor contracts.\n\nEach Orbit chain is deployed with two Upgrade Executors — one on the Orbit chain itself, and one on its parent chain. At deployment, the chain's critical affordances are given to the Upgrade Executor contracts.\n\nSome examples:\n\nThe parent chain's core protocol contracts are upgradeable proxies that are controlled by a proxy admin; the proxy admin is owned by the Upgrade Executor on the parent chain.\nThe core Rollup contract's admin role is given to the Upgrade Executor on the parent chain.\nThe affordance to call setters on the ArbOwner procompile — which allows for setting system gas parameters and scheduling ArbOS upgrades (among other things) — is given to the Upgrade Executor on the Orbit chain.\n\nCalls to an Upgrade Executor can only be made by chain owners; e.g., entities granted the EXECUTOR_ROLE affordance on the Upgrade Executor. Upgrade executors also have the ADMIN_ROLE affordance granted to themselves, which lets chain owners add or remove chain owners.\n\nWith this architecture, the Upgrade Executor represents a single source of truth for affordances over critical upgradability of the chain.\n\nUpgrades​\n\nUpgrades occur via a chain owner initiating a call to an Upgrade Executor, which in turns calls some chain-owned contract.\n\nChain owners can either call UpgradeExecutor.executeCall, which will in turn call the target contract directly, or UpgradeExecutor.execute, which will delegate-call to an \"action contract\" and use its code to call the target contract.\n\nOwnership flexibility​\n\nA chain owner is simply an address; it is set by the Orbit chain's deployer and can represent any sort of governance scheme. I.e., it could be an EOA (as is set via the Orbit Quickstart), a Multisig, a governance token system, etc.\n\nThe Arbitrum DAO governed chains, while not Orbit chains themselves, use a similar architecture and upgrade pattern as Orbit chains, with both a governance token and a Multisig (aka, the \"Security Council\") as chain owners. For more info and best practices on action contracts, see \"DAO Governance Action Contracts\".\n\n(NOTE: The DAO Governed chains' Upgrade Executor contracts don't have the .executeCall method; only the .execute method)\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nAdd your chain to the bridge\nNext\nCustom gas token SDK\nArchitecture\nUpgrades\nOwnership flexibility\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to run a full node for an Orbit chain | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/node-running/how-tos/running-an-orbit-node",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to run a full node for an Orbit chain\n\nThis how-to provides step-by-step instructions for running an Orbit node on your local machine.\n\nPrerequisites​\n\nLatest Docker Image: offchainlabs/nitro-node:v3.2.1-d81324d\n\nMinimum Hardware Configuration\nRAM: 8-16 GB\nCPU: 2-4 core CPU (For AWS: t3 xLarge\nStorage: Depends on the Orbit chain and its traffic overtime\nRequired parameters​\n1. Parent chain parameters​\n\nThe parent-chain argument needs to provide a standard RPC endpoint for an EVM node, whether self-hosted or obtained from a node service provider:\n\n--parent-chain.connection.url=<Parent chain RPC URL>\n\nNOTE\n\nPublic Arbitrum RPC endpoints rate-limit connections. To avoid hitting a bottleneck, you can run a local node for the parent chain or rely on third-party RPC providers.\n\n2. Child chain parameters​\n\nIn the Arbitrum Orbit context, the child chain is an L2 or an L3 Orbit chain, and the required parameters are chain.info-json and chain.name\n\n1. chain.info-json​\n\n--chain.info-json is a JSON string that contains required information about the Orbit chain.\n\n--chain.info-json=<Orbit Chain's chain info>\n\n\nAn example of chain.info-json is available in the next section.\n\n2. chain.name​\n\n--chain.name is a mandatory flag that needs to match the chain name used in --chain.info-json:\n\n--chain.name=<My Arbitrum L3 Chain>\n\n3. execution.forwarding-target​\n\nYou need to set the --execution.forwarding-target flag if you are running a regular full node (Not sequencer).\n\n--execution.forwarding-target=<Your Sequencer node endpoint url>\n\n4. AnyTrust chains​\n\nFor Anytrust chains, you need to to add the following flags to the command or configuration:\n\n--node.data-availability.enable\n\n\nAnd:\n\n--node.data-availability.rest-aggregator.urls=<A list of DAS REST endpoints>\n\n\nOr:\n\n--node.data-availability.rest-aggregator.online-url-list=<A url that returns a list of the DAS REST endpoints>\n\n3.Important ports​\nProtocol\tPort\nRPC/http\t8547\nRPC/websocket\t8548\nSequencer Feed\t9642\nPlease note: the RPC/websocket protocol requires some ports to be enabled, you can use the following flags:\n--ws.port=8548\n--ws.addr=0.0.0.0\n--ws.origins=\\*\n4. Putting it all together​\n\nWhen running a Docker image, an external volume should be mounted to persist the database across restarts. The mount point inside the Docker image should be /home/user/.arbitrum\n\nExample:\n\ndocker run --rm -it  -v /some/local/dir/arbitrum:/home/user/.arbitrum -p 0.0.0.0:8547:8547 -p 0.0.0.0:8548:8548 offchainlabs/nitro-node:v3.2.1-d81324d --parent-chain.connection.url=<Parent chain RPC URL> --chain.id=<OrbitChainId> --chain.name=<My Arbitrum Orbit Chain> --http.api=net,web3,eth --http.corsdomain=* --http.addr=0.0.0.0 --http.vhosts=* --chain.info-json=<Orbit Chain's chain info> --execution.forwarding-targe=<Your Sequencer node endpoint url>\n\n\nEnsure that /some/local/dir/arbitrum already exists otherwise the directory might be created with root as owner, and the Docker container won't be able to write to it\n\nWhen using the flag --chain.info-json=<Orbit Chain's chain info>, replace <Orbit Chain's chain info> with the specific chain info JSON string of the Orbit chain for which you wish to run the node:\n\nExample:\n\n--chain.info-json=\"[{\\\"chain-id\\\":94692861356,\\\"parent-chain-id\\\":421614,\\\"chain-name\\\":\\\"My Arbitrum L3 Chain\\\",\\\"chain-config\\\":{\\\"chainId\\\":94692861356,\\\"homesteadBlock\\\":0,\\\"daoForkBlock\\\":null,\\\"daoForkSupport\\\":true,\\\"eip150Block\\\":0,\\\"eip150Hash\\\":\\\"0x0000000000000000000000000000000000000000000000000000000000000000\\\",\\\"eip155Block\\\":0,\\\"eip158Block\\\":0,\\\"byzantiumBlock\\\":0,\\\"constantinopleBlock\\\":0,\\\"petersburgBlock\\\":0,\\\"istanbulBlock\\\":0,\\\"muirGlacierBlock\\\":0,\\\"berlinBlock\\\":0,\\\"londonBlock\\\":0,\\\"clique\\\":{\\\"period\\\":0,\\\"epoch\\\":0},\\\"arbitrum\\\":{\\\"EnableArbOS\\\":true,\\\"AllowDebugPrecompiles\\\":false,\\\"DataAvailabilityCommittee\\\":false,\\\"InitialArbOSVersion\\\":10,\\\"InitialChainOwner\\\":\\\"0xAde4000C87923244f0e95b41f0e45aa3C02f1Bb2\\\",\\\"GenesisBlockNum\\\":0}},\\\"rollup\\\":{\\\"bridge\\\":\\\"0xde835286442c6446E36992c036EFe261AcD87F6d\\\",\\\"inbox\\\":\\\"0x0592d3861Ea929B5d108d915c36f64EE69418049\\\",\\\"sequencer-inbox\\\":\\\"0xf9d77199288f00440Ed0f494Adc0005f362c17b1\\\",\\\"rollup\\\":\\\"0xF5A42aDA664E7c2dFE9DDa4459B927261BF90E09\\\",\\\"validator-utils\\\":\\\"0xB11EB62DD2B352886A4530A9106fE427844D515f\\\",\\\"validator-wallet-creator\\\":\\\"0xEb9885B6c0e117D339F47585cC06a2765AaE2E0b\\\",\\\"deployed-at\\\":1764099}}]\"\n\n\nWhen shutting down the Docker image, it is important to allow a graceful shutdown so that the current state can be saved to disk. Here is an example of how to do a graceful shutdown of all Docker images currently running\n\ndocker stop --time=300 $(docker ps -aq)\n\nNote on permissions​\n\nThe Docker image is configured to run as non-root UID 1000. If you are running Linux or macOS and you are getting permission errors when trying to run the Docker image, run this command to allow all users to update the persistent folders:\n\nmkdir /data/arbitrum\nchmod -fR 777 /data/arbitrum\n\nNote on Sequencer feed​\n\nNitro nodes can be configured to receive real time ordered transactions from the sequencer feed. If you don't set the feed input url, your node will listen to the parent chain's inbox contract to get the ordered transactions, which will cause your node to be unable to synchronize the latest state.\n\nSet the following configurations to your fullnode to make it can receive the sequencer feed:\n\n--node.feed.input.url=<Sequencer feed url>\n\n\nAfter that, your node can synchronize the latest state from the sequencer feed.\n\n(Chain owners only) In order for a node to read the sequencer feed, the chain's sequencer needs to be configured with the following parameters:\n\n--node.feed.output.enable=true --node.feed.output.addr=<Sequencer feed url> --node.feed.output.port=<Sequencer feed port>\n\nOptional parameters​\n\nWe show here a list of the parameters that are most commonly used when running your Orbit node. You can also use the flag --help for a full comprehensive list of the available parameters.\n\nFlag\tDescription\n--execution.rpc.classic-redirect=<RPC>\tRedirects archive requests for pre-nitro blocks to this RPC of an Arbitrum Classic node with archive database. Only for Arbitrum One.\n--http.api\tOffered APIs over the HTTP-RPC interface. Default: net,web3,eth,arb. Add debug for tracing.\n--http.corsdomain\tAccepts cross origin requests from these comma-separated domains (browser enforced).\n--http.vhosts\tAccepts requests from these comma-separated virtual hostnames (server enforced). Default: localhost. Accepts *.\n--http.addr\tAddress to bind RPC to. May require 0.0.0.0 for Docker networking.\n--execution.caching.archive\tRetains past block state. For archive nodes.\n--node.feed.input.url=<feed address>\tDefault: wss://<chainName>.arbitrum.io/feed. ⚠️ One feed relay per datacenter is advised. See feed relay guide.\n--execution.forwarding-target=<RPC>\tDefaults to the L2 Sequencer RPC based on provided L1 and L2 chain IDs.\n--execution.rpc.evm-timeout\tDefault: 5s. Timeout for eth_call. (0 == no timeout).\n--execution.rpc.gas-cap\tDefault: 50000000. Gas cap for eth_call/estimateGas. (0 = no cap).\n--execution.rpc.tx-fee-cap\tDefault: 1. Transaction fee cap (in ether) for RPC APIs. (0 = no cap).\n--ipc.path\tFilename for IPC socket/pipe within datadir. 🔉 Not supported on macOS. Note the path is within the Docker container.\n--init.prune\tPrunes database before starting the node. Can be \"full\" or \"validator\".\n--init.url=\"<snapshot file>\"\t(Non-Orbit Nitro nodes only) URL to download the genesis database from. Required only for the first startup of an Arbitrum One node. Reference to snapshots and archive node guide.\n--init.download-path=\"/path/to/dir\"\t(Non-Orbit Nitro nodes only) Temporarily saves the downloaded database snapshot. Defaults to /tmp/. Used with --init.url.\n--node.batch-poster.post-4844-blobs\tBoolean. Default: false. Used to enable or disable the posting of transaction data using Blobs to L1 Ethereum. If using calldata is more expensive and if the parent chain supports EIP4844 blobs, the batch poster will use blobs when this flag is set to true. Can be true or false.\n--node.batch-poster.ignore-blob-price\tBoolean. Default: false. If the parent chain supports EIP4844 blobs and ignore-blob-price is set to true, the batch poster will use EIP4844 blobs even if using calldata is cheaper. Can be true or false.\n--init.latest\tstring. if set, searches for the latest snapshot of the given kind (accepted values: \"archive\" , \"pruned\" , \"genesis\")\n--init.latest-base\tstring. Default: \"https://snapshot.arbitrum.foundation/\". Base url used when searching for the latest. (If you are running orbit chains you might need to check with orbit chain team to get the url)\n--init.then-quit\tAllows any --init.* parameters to complete, and then the node will automatically quit. It doesn't initiate pruning by itself but works in conjunction with other --init.* parameters, making it easier to script tasks like database backups after initialization processes finish.\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nMonitoring tools and considerations\nNext\nAdd your chain to the bridge\nPrerequisites\nRequired parameters\n1. Parent chain parameters\n2. Child chain parameters\n3.Important ports\n4. Putting it all together\nNote on permissions\nNote on Sequencer feed\nOptional parameters\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/add-orbit-chain-to-bridge-ui",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to add your Orbit chain to Arbitrum's bridge\n\nThis how-to will walk you through the process of adding your Orbit chain to the Arbitrum bridge. There's one section for mainnet Orbit chains, and another for local testnet Orbit chains. You can access either section using the links on the right column.\n\nRequest adding a mainnet Orbit chain to the Arbitrum bridge​\n\nMainnet Orbit chains can be added to the Arbitrum Bridge by filling out this form.\n\nOnce receiving your request, our team will review and apply internal criteria to include your chain in the bridge. Here are some of the criteria that a chain must follow to be added to the bridge:\n\nThe use case must fall within existing legal and marketing guidelines\nThe core rollup / token bridge contracts must not have been modified, except the cases where modifications have been done with a certified partnership and communicated to Offchain Labs\nThe infrastructure and core contracts are hosted by one of our partnered RaaS teams\nAdd a local testnet Orbit chain to the Arbitrum bridge​\n\nCurrently, adding a testnet Orbit chain to the Arbitrum bridge must be done locally. This means that you will configure the UI to display the desired chain, but this change will only apply to you.\n\nPrerequisites​\nA local testnet Orbit chain's configuration. See the Orbit quickstart to deploy a local Orbit chain, or use an existing JSON configuration.\nA browser-based Ethereum wallet (like MetaMask)\nProcedure​\nNavigate to https://bridge.arbitrum.io/.\nConnect to the bridge UI using your wallet. The bridge UI will automatically switch to the correct testnet view.\nActivate \"Testnet mode\", by clicking on your address in the top right corner -> Settings -> Turn on testnet mode.\nIn the same screen, scroll down to \"Add Testnet Orbit Chain\": \nCopy and paste the JSON configuration (for Orbit chains deployed locally, use the configuration in your generated outputInfo.json file).\nClick \"Add Chain\".\n\nCongratulations! Your chain should now appear in both the network dropdown in the top navigation pane, and as an option in the bridging UI directly.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRun a full Orbit node\nNext\nOrbit chain ownership\nRequest adding a mainnet Orbit chain to the Arbitrum bridge\nAdd a local testnet Orbit chain to the Arbitrum bridge\nPrerequisites\nProcedure\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/reference/monitoring-tools-and-considerations",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nMonitoring tools and considerations\n\nWhen deploying and maintaining an Orbit chain, there are several key elements that need to be monitored. This page lists tools that are available for chain maintainers, as well as other considerations to keep in mind when monitoring an Orbit chain.\n\nOrbit verification script​\n\nThe Orbit verification script retrieves information from an Orbit chain and its parent chain to verify that all parameters are configured correctly. After gathering the data, it generates a comprehensive report and issues warnings for any discrepancies detected. This tool is particularly useful after deploying and configuring an Orbit chain, to make sure that the on-chain information has been correctly set.\n\nTHE ORBIT VERIFICATION SCRIPT IS A WORK-IN-PROGRESS (WIP)\n\nThe Orbit Verification Script is currently under active development and is considered a work-in-progress (WIP). Consequently, its findings should be approached with caution, as there is a potential for false positives.\n\nOrbit retryables tracker​\n\nRetryable tickets are messages sent from a parent chain and executed on the Orbit chain. Due to their asynchronous nature (they are executed several minutes after being created), if insufficient funds are provided at the time of creation, they might not automatically redeem (execute) upon arrival at the Orbit chain. When this occurs, a manual redemption of the ticket is required. The Orbit retryables tracker is designed to assist in identifying and displaying the status of retryable tickets sent from a parent chain to the Orbit chain, and it reports any tickets that have not been automatically redeemed.\n\nData Availability Server (DAS) health checks​\n\nIf you've deployed an AnyTrust chain with a Data Availability Committee, it is recommended to actively monitor the endpoints of the different configured DA servers. The How to deploy a DAS guide contains a section for testing both the RPC and REST endpoints of any given DAS, by using the datool available in Nitro.\n\nFurther monitoring considerations​\n\nFollowing is a non-comprehensive list of other elements of the network that should be monitored.\n\nSequencer's transaction backlog size: This can be considered as a sign of the network health. In some edge cases, a large and growing backlog might cause the sequencer to experience issues when posting batches on the parent chain.\n\nBatches posted in the SequencerInbox contract on the parent chain: The sequencer regularly posts batches on the parent chain, as long as it receives transactions on the Orbit chain. If batches are not being posted in the SequencerInbox for any reason, further analysis should be conducted to understand why.\n\nRBlocks (nodes) created in the Rollup contract on the parent chain: RBlocks are created by validators and contain assertions of the current state of the chain (viewed by the validators). If RBlocks are not being created or confirmed on the parent chain, further analysis should be conducted to understand why.\n\nHigh periods of inactivity: As an extension of the previous point, if no RBlocks (nodes) are created for a certain period of time (due to having no activity in the chain, or any other reason), the validator whitelist mechanism of the Rollup contract can be permissionlessly disabled. That period of time is determined by confirmPeriodBlocks + the constant 45818 since the last RBlock (node) created. In this case, time is measured in L1 blocks (around 7 days + the confirmPeriodBlocks period) for Orbit chains settling to Ethereum or an Arbitrum chain, or measured in the parent chain's block time when settling to other chains.\n\nBatch poster balance: The batch poster account needs to be well funded to be able to post batches. There's no automatic mechanism to keep it funded, so its balance should be monitored and actions should be taken whenever it passes a certain threshold. The recommendation is to keep the account overfunded.\n\nValidators' balance: Validators are in charge of posting and confirming assertions of the state of the Orbit chain on the parent chain. Their balance should be monitored to make sure they are able to perform those actions.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nConfigure a Data Availability Committee (DAC)\nNext\nRun a full Orbit node\nOrbit verification script\nOrbit retryables tracker\nData Availability Server (DAS) health checks\nFurther monitoring considerations\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to upgrade ArbOS on your Orbit chain | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/arbos-upgrade",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nArbOS software releases\nUpgrade ArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to upgrade ArbOS on your Orbit chain\n\nThis how-to provides step-by-step instructions for Orbit chain operators who want to upgrade ArbOS on their Orbit chain(s). Familiarity with ArbOS, Orbit, and chain ownership is expected. Note that Orbit chain owners have full discretion over when and whether to upgrade their ArbOS version.\n\nThe specific upgrade requirements for each ArbOS release are located under each reference page for that specific ArbOS release.\n\nStep 1: Update Nitro on nodes and validators​\n\nRefer to the requirements for the targeted ArbOS release to identify the specific Nitro release that supports the ArbOS version that you're upgrading to. For example, if your upgrade targets ArbOS 20, you'd use Nitro v2.3.1 (Docker image: offchainlabs/nitro-node:v2.3.1-26fad6f) or higher. This is the version of the Nitro stack that needs to be running on each of your Orbit chain's nodes. A list of all Nitro releases can be found on Github.\n\nBegin by upgrading your validator node(s) to the specified Nitro version, then update each remaining Orbit node to match this version.\n\nNote that upgrading your node version must occur before the deadline established for the target ArbOS upgrade. Refer to the timestamp in the ArbOS upgrade schedule for a precise deadline.\n\nStep 2: Upgrade the Wasm module root & your chain's Nitro contracts​\n\nWhile every ArbOS upgrade will require an update to the Wasm module root, not every ArbOS upgrade will require an upgrade to the chain's nitro-contracts version.\n\nIf necessary, as defined in the release notes for each ArbOS release (example of ArbOS 20), you may need to deploy new versions of some (or all) of the Nitro contracts to the parent chain of your Orbit chain. These contracts include the rollup logic, bridging logic, fraud-proof contracts, and interfaces for interacting with Nitro precompiles. To verify the current version of your Nitro contracts, follow these instructions while replacing the inbox contract address and network name with that of your Orbit chain. This information will allow you to find the correct upgrade path for your Nitro contracts.\n\nTo update the Wasm module root and deploy your chain's Nitro contracts to the parent chain for the most recent ArbOS release, you will need the following inputs (obtained from the requirements for the targeted ArbOS release):\n\nThe WASM module root, and if necessary,\nThe required nitro-contracts version\n\nOnce you have the WASM module root and have identified the required nitro-contracts version for the target ArbOS release, if any, please follow the instructions in this guide for specific actions based on the nitro-contracts version you are deploying. Note that each ArbOS release will require performing this step with a different Wasm module root and may require a different version of nitro-contracts. The guide linked above will be kept updated with the instructions for each specific ArbOS release.\n\nThe WASM module root is a 32-byte hash created from the Merkelized Go replay binary and its dependencies. When ArbOS is upgraded, a new Wasm module root is generated due to modifications in the State Transition Function. This new Wasm module root must be set in the rollup contract on the parent chain. You can get the For example, the Wasm module root for ArbOS 20 Atlas is 0x8b104a2e80ac6165dc58b9048de12f301d70b02a0ab51396c22b4b4b802a16a4.\n\nTo set the Wasm module root manually (i.e. not using the above guide), use the Rollup proxy contract's setWasmModuleRoot method. Note that the upgrade executor contract on the parent chain is the designated owner of the rollup contract, so the chain owner account needs to initiate a call to the upgrade executor contract in order to perform the upgrade. This call should include the correct calldata for setting the new Wasm module root.\n\nBACKWARD COMPATIBILITY\n\nWasm module roots are backward compatible, so upgrading them before an ArbOS version upgrade will not disrupt your chain's functionality.\n\nStep 3: Schedule the ArbOS version upgrade​\n\nTo schedule an ArbOS version upgrade for your Orbit chain, follow this guide. In addition to the upgrade action contract address and the account address for the chain owner account, you will need the following inputs:\n\nnewVersion: Specify the ArbOS version you wish to upgrade to (e.g. 20).\ntimestamp: Set the exact Unix timestamp at which you want your Orbit chain to transition to the new ArbOS version.\n\nIf you would prefer to do this manually, simply call the scheduleArbOSUpgrade function on the ArbOwner precompile of the Orbit chain(s) you're upgrading. Because this is an administrative action (similar to upgrading your Wasm module root), the chain owner account must call the target chain's upgrade executor contract with the appropriate calldata in order to invoke the scheduleArbOSUpgrade function of the ArbOwner precompile. This will schedule the ArbOS upgrade using the specified version and timestamp.\n\nIMMEDIATE UPGRADES\n\nTo upgrade immediately (without scheduling), set the timestamp to 0.\n\nOBTAINING THE CURRENT ARBOS VERSION\n\nYou can obtain the current ArbOS version of your chain by calling ArbSys.ArbOSVersion(). Keep in mind that this function adds 55 to the current ArbOS version. For example, if your chain is running on ArbOS 10, calling this function will return 65.\n\nWhen scheduling the ArbOS upgrade through ArbOwner.scheduleArbOSUpgrade you must use the actual ArbOS version you're upgrading to. For example, if you're upgrading to ArbOS 11, you will pass 11 when calling this function.\n\nStep 4: Enable ArbOS specific configurations or feature flags (not always required)​\n\nFor some ArbOS upgrades, such as ArbOS 20 Atlas, there may be additional requirements or steps that need to be satisfied to ensure your Orbit chain can use all of the new features and improvements made available in that particular ArbOS release.\n\nIf there are additional requirements for the targeted ArbOS release you're attempting to upgrade to; the additional requirements will be listed on the reference pages for the targeted ArbOS release. For example, the additional requirements for Orbit chains upgrading to ArbOS 20 can be found here on the ArbOS 20 docs.\n\nCongratulations! You've upgraded your Orbit chain(s) to the specified ArbOS version.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nCalculating AEP license fees\nNext\nGet started\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/more-types/run-validator-node",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nRun an archive node\nRun a validator\nRun a Classic node\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to run a validator\n\nSome Arbitrum nodes will choose to act as validators. This means that they watch the progress of the rollup protocol and perhaps also participate in that protocol to advance the state of the chain securely. Not all nodes will choose to do this. Because the rollup protocol doesn’t decide what the chain will do but merely confirms the correct behavior that is fully determined by the inbox messages, a node can ignore the rollup protocol and simply compute for itself the correct behavior. Here we describe different strategies that validators follow and provide instructions on how to run them.\n\nValidation strategies​\nCurrently, the ability to post assertions on-chain for mainnet Arbitrum chains is allowlisted.\nHere's a full list of validation strategies:\nDefensive (allowlist required)\nPost stake and create challenge if local state disagrees with on-chain assertion (wallet required, will only post stake on-chain if bad assertion found)\nStakeLatest (allowlist required)\nStay staked on latest assertion and challenge any bad assertions found (wallet required, always staked, uses some gas every time new assertion created)\nResolveNodes (allowlist required)\nStay staked on latest assertion, resolve any unconfirmed assertions and challenge any bad assertions found (wallet required, always staked, uses some gas every time unconfirmed assertion resolved or new assertion created)\nMakeNodes (allowlist required)\nContinuously create new assertions, challenging any bad assertions found (wallet required, always staked, most expensive node to run)\nNote that if there is more than one MakeNodes validator running, they might all try to create a new assertion at same time. In that case, only one will be successful, and the others will have still spent gas on reverted calls that didn't do anything.\nThere's one more validation strategy that is not allowlisted and is available for all types of node: Watchtower. A node in Watchtower mode will immediately log an error if an on-chain assertion deviates from the locally computed chain state. It doesn't require a wallet, as it never takes any action on-chain. This strategy is enabled by default in all nodes (full and archive).\nRunning a Watchtower validator​\nBy default, all nodes (full and archive) will run in Watchtower mode.\nIf a deviation is detected, a node running in Watchtower mode will log an error containing the string found incorrect assertion in watchtower mode\nTo verify that the Watchtower mode is enabled, this line should appear in the logs:\nINFO [09-28|18:43:49.367] running as validator                     txSender=nil actingAsWallet=nil whitelisted=false strategy=Watchtower\n\nstrategy should be Watchtower\nThe log line validation succeeded shows that the L2 block validator is working\nThe log line found correct assertion shows that the L1 validator is working\nWatchtower mode adds a small amount of execution and memory overhead. You can deactivate this mode by using the parameter --node.staker.enable=false.\nCreating a wallet for an allowlisted validator​\nWatchtower validators never need a wallet, because they never post on-chain\nDefensive validators need a wallet configured, but the wallet does not need to be funded until it logs that an assertion has been found\nAll other validators require a funded wallet to immediately post stake, as well as additional funds that will be spent at regular intervals\nHere is an example of how to tell Nitro to create validator wallet for Arbitrum One and exit:\ndocker run --rm -it  -v /some/local/dir/arbitrum:/home/user/.arbitrum offchainlabs/nitro-node:v3.2.1-d81324d --parent-chain.connection.url=https://l1-mainnet-node:8545 --chain.id=42161 --node.staker.enable --node.staker.parent-chain-wallet.only-create-key --node.staker.parent-chain-wallet.password=\"SOME SECURE PASSWORD\"\n\nWallet file will be created under the mounted directory inside the arb1/wallet/ directory for Arb1, or nova/wallet/ directory for Nova. Be sure to backup the wallet, it will be the only way to withdraw stake when desired\nRunning an allowlisted defensive validator​\nA defensive validator requires that a wallet has already been created using the above steps\nDefensive validator wallets do not need to be funded initially\nIf a defensive validator detects a deviation, it will log bringing defensive validator online because of incorrect assertion, and wait for funds to be added to wallet so stake can be posted and a dispute created\nHere is an example of how to run an allowlisted defensive validator for Arbitrum One:\ndocker run --rm -it  -v /some/local/dir/arbitrum:/home/user/.arbitrum offchainlabs/nitro-node:v3.2.1-d81324d --parent-chain.connection.url=https://l1-mainnet-node:8545 --chain.id=42161 --node.staker.enable --node.staker.strategy=Defensive --node.staker.parent-chain-wallet.password=\"SOME SECURE PASSWORD\"\n\nFor Orbit chains, you need to set the --chain.info-json=<Orbit Chain's chain info> flag instead of --chain.id=<chain id>\nTo verify validator is working, this log line shows the wallet is setup correctly:\nINFO [09-28|18:43:49.367] running as validator                     txSender=0x... actingAsWallet=0x... whitelisted=true strategy=Defensive\n\nwhitelisted should be true after your wallet has been added to the allowlist\nstrategy should be Defensive\ntxSender and actingAsWallet should both be present and not nil\nThe log line validation succeeded shows that the L2 block validator is working\nThe log line found correct assertion shows that the L1 validator is working\nOrbit chains: grant whitlelist​\nYou need to be the chain owner to include a new validator address in the allowlist:\nFind your upgradeExecutor contract address.\nSend transactions to the executeCall method of theupgradeExecutor contract and set the target address to your Rollup contract's address, set the targetCalldata to 0xa3ffb772{Your new allowlist validator address}. (0xa3ffb772 is the signature of setValidator(address[],bool[]))\nCall your Rollup contract's isValidator(address) and check the result.\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRun an archive node\nNext\nRun a Classic node\nValidation strategies\nRunning a Watchtower validator\nCreating a wallet for an allowlisted validator\nRunning an allowlisted defensive validator\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/customize-deployment-configuration",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nCustomize your chain's deployment\nAdditional configuration parameters\nUse a custom gas token\nCustomize your chain's precompiles\nCustomize your chain's behavior\nConfigure delayed inbox finality\nManage the fee collectors\nCustomize ArbOS version\nImplement Circle bridged USDC\nEnable fast withdrawals\nAEP fee router\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to customize your Orbit chain's deployment configuration\n\nWhen you visit the Orbit chain deployment portal to launch your Orbit chain, you'll be prompted to complete a form that looks like this:\n\nChain ID\nChain name\nChallenge period (blocks)\nStake token\nBase stake\nOwner\n\nThis form will be prefilled with default values that usually don't need to be changed. However, there are some cases where you may want to customize the configuration values. This how-to explains how and when to modify these default values.\n\nLet's briefly review each of the deployment configuration parameters, the rationale underlying the default values, and the tradeoffs that you should consider when modifying them.\n\nChain ID​\n\nDon't worry about this; it's inconsequential for devnets. In production scenarios (which aren't yet supported), you'll want to use a unique integer identifier that represents your chain's network on chain indexes like Chainlist.org.\n\nChain name​\n\nThis name provides a way for people to distinguish your Orbit chain from other Orbit chains. You’ll want to make this a name that you can easily remember, and that your users and developers will recognize.\n\nChallenge period (blocks)​\n\nThe Challenge period (blocks) parameter determines the amount of time your chain's validators have to dispute - or \"challenge\" - the current state of the chain posted to your Orbit chain's base chain on L2.\n\nA longer challenge period means that your chain's nodes will have more time to dispute fraudulent states, but it also means that your chain's users will have to wait longer to withdraw their assets from your chain. This is one of the many tradeoffs that Orbit allows you to make when configuring your chain.\n\nNote that the challenge period is measured in blocks on the underlying L1 chain, not the base (L2) chain. For example, if your Orbit chain settles to Arbitrum Sepolia, the challenge period window would be the number of Challenge period (blocks) multiplied by the L1 Sepolia block time (~12 seconds).\n\nGas token​\n\nThe Gas Token parameter specifies the token (ETH or an ERC-20 token) that is natively used for gas payments on the network. On Ethereum, Arbitrum One, and Arbitrum Nova the gas token is ETH. Orbit chains that are configured as AnyTrust chains can specify a different gas token as long as it falls within certain requirements.\n\nThe main requirement for custom gas tokens is that they are natively deployed on the parent chain. For example, if a team deploying an Orbit chain wants to use a specific ERC-20 as the gas token, that token must be deployed on the parent chain first (i.e. Arbitrum One or Nova). During chain deployment, that token is \"natively bridged\" and then properly configured as the native gas token on the new network.\n\nThere are other important considerations to keep in mind when deciding to use a custom gas token. Restrictions on the ERC-20 token include:\n\nIn this version, only tokens with 18 decimals are permitted to be the native token.\nThe token can't be rebasing or have a transfer fee.\nThe token must only be transferrable via a call to the token address itself.\nThe token must only be able to set allowance via a call to the token address itself.\nThe token must not have a callback on transfer, and more generally a user must not be able to make a transfer to themselves revert.\n\nIt is worth reiterating that currently this feature is only supported on Orbit AnyTrust chains. Additionally, using a gas token other than ETH adds additional overhead when it comes to ensuring chains are funded properly when posting data to their parent chain.\n\nStake token​\n\nYour Orbit chain will be supported by at least one validator node. In order for your chain's validators to post assertions of the state of the chain on the base chain (L2), they're required to stake some value as a way to incentivize honest participation.\n\nThis Stake token parameter specifies the token that your chain's validators must deposit into this contract when they stake. This is specified using the token's contract address on the L2 chain that your chain is settling to, or 0x0000000000000000000000000000000000000000 if you want to use ETH as the stake token.\n\nBase stake​\n\nThe Base stake parameter specifies the amount of the stake token (ETH or an ERC-20 token) that your chain's validators must deposit in order to post assertions of the state of your Orbit chain on the base chain's rollup contracts. This is specified using a float value.\n\nIf your Base stake is low, the barrier to participation will be low, but your chain will be more vulnerable to certain types of attacks.\n\nFor example, an Orbit chain with a base stake of 0.01 ETH could be halted by an adversary who can afford to deploy sacrificial validators that maliciously challenge every RBlock submitted to your Orbit chain's base chain.\n\nThe malicious challenges would result in slashed Orbit chain validators (one slashed validator per malicious challenge), but from the adversary's perspective, periodic slashing is just the price they have to pay to keep your chain offline.\n\nA higher base stake incentivize honest participation by making it more expensive to launch these types of attacks. However, a higher base stake also translates to a higher barrier to entry for your chain's validators. This is another tradeoff to consider.\n\nOwner​\n\nThis account address is responsible for deploying, owning, and updating your Orbit chain's base contracts on its base chain.\n\nIn production scenarios, this is a high-stakes address that's often controlled by a DAO's governance protocol or multisig. For your Orbit devnet chain, think of this as a low-stakes administrative service account.\n\nNote that you'll have to fund this address with enough ETH to cover the gas costs of deploying your core contracts to L2.\n\nWhen deploying your Orbit chain, this address must be a standard Ethereum wallet address (precisely speaking, an EOA); it can't be a smart contract/wallet contract.\n\nAdditional configuration parameters​\n\nThere are a number of additional parameters that are not presented in the deployment UI, but are still configurable for more advanced chain deployers.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nConfigure your chain\nNext\nAdditional configuration parameters\nChain ID\nChain name\nChallenge period (blocks)\nGas token\nStake token\nBase stake\nOwner\nAdditional configuration parameters\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Get started with the Arbitrum Orbit SDK | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/orbit-sdk-introduction",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nGet started\nDeploy a Rollup chain\nDeploy an AnyTrust chain\nDeploy a custom gas token chain\nConfigure your chain's node\nDeploy a token bridge\nConfigure your chain\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nGet started with the Arbitrum Orbit SDK\n\nThe Arbitrum Orbit SDK lets you programmatically create and manage your own Orbit chain(s). Its capabilities include:\n\nConfiguration and deployment of your Orbit chain's core contracts\nInitialization of your chain and management of its configuration post-deployment\n1. Select a chain type​\n\nThere are three types of Orbit chains. Review the following table to determine which type best fits your needs:\n\nChain Type\tDescription\tUse Case\nRollup\tOffers Ethereum-grade security by batching, compressing, and posting data to the parent chain, similarly to Arbitrum One.\tIdeal for applications that require high security guarantees.\nAnyTrust\tImplements the AnyTrust protocol, relying on an external Data Availability Committee (DAC) to store data and provide it on-demand instead of using their parent chain as the Data Availability (DA) layer.\tSuitable for applications that require lower transaction fees.\nCustom gas token\tAn AnyTrust Orbit chain with the ability to specify a custom ERC-20 gas token.\tIdeal for applications that require custom gas fee tokens and lower transaction fees.\n2. Deploy your chain​\n\nAfter selecting a chain type, you need to deploy your Orbit chain. Visit the deployment guide for your selected chain type:\n\nDeploy a Rollup Orbit chain\nDeploy an AnyTrust Orbit chain\nDeploy a Custom Gas Token Orbit chain\n3. Configure your Orbit chain's node​\n\nAfter selecting a chain type, you need to specify your Orbit chain's node configuration by creating a JSON file. Visit Configure your Orbit chain's node, then proceed to the next step.\n\n4. Deploy your Orbit chain's token bridge​\n\nYour Orbit chain's token bridge contracts allow ERC-20 tokens to move between your Orbit chain and its underlying parent chain. See Deploy your Orbit chain's token bridge, then proceed to the next step.\n\n5. Configure your Orbit chain​\n\nWith your node configuration specified and token bridge deployed, you'll be ready to configure your Orbit chain. Visit Configure your Orbit chain to complete this final step.\n\nSee also​\nLearn more about the AnyTrust consensus mechanism\nLearn more about the ERC-20 token bridge architecture\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nManage gas speed limit\nNext\nDeploy a Rollup chain\n1. Select a chain type\n2. Deploy your chain\n3. Configure your Orbit chain's node\n4. Deploy your Orbit chain's token bridge\n5. Configure your Orbit chain\nSee also\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Managing state growth & corresponding issues | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/how-tos/orbit-managing-state-growth",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nManage state growth\nManage gas speed limit\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nManaging state growth & corresponding issues\n\nAs the Orbit ecosystem grows, more and more teams are choosing to build on the Arbitrum tech stack. Orbit offers a feature-rich and scalable rollup stack that allows teams to focus on their ecosystem growth and build great products. As a result, many Orbit chains are seeing usage and throughput increase rapidly, often with sustained transaction load at the chain’s throughput limit for months on end.\n\nThis page aims to educate Orbit chain operators and owners on safely operating a high throughput chain. Amongst all the factors, the primary consideration is state growth rate and state size. We’ll discuss how increased state size affects the performance of different components in the Orbit stack and how certain metrics can be used to indicate a need to upgrade various infrastructure components.\n\nUnderstanding state size and state growth rate​\n\nWhen we say ‘state size’, we mean the total amount of data recorded on the blockchain; state size is a critical metric for node performance as a larger state creates higher infrastructure requirements on nodes for storage and searching through existing states.\n\nThe state growth rate is simply the rate at which state size increases. A high state growth rate creates higher requirements for nodes to process state transitions and perform operations needed to keep up with the tip of the chain.\n\nThe critical Nitro stack parameter affecting state growth and state growth rate is the gas speed limit. Offchain Labs has set the gas speed limit to a default (7,000,000 gas/s), ensuring a safe, sustained operating limit for Orbit chains. You can read more about the nuances of the gas speed limit here.\n\nThe default gas speed limit is designed to ensure Orbit chains operate performantly and sustainably.\n\nBehaviour at ultra-high throughput​\n\nAt high state growth rates, especially in cases where a chain is pushing past prescribed limits, an Orbit chain may display certain behaviors that either indicate or result from the chain load being higher than its infrastructure can support. The following is a list of such behaviors.\n\n1. Read Operation Bottleneck at High Disk Latency​\n\nAs the number of read requests on a chain grows, the impact of disk latency on performance becomes more pronounced. The performance impact can be considered the total amount of read requests made as a multiple of the disk latency. High read request volumes may necessitate switching to using low-latency local NVMe drives.\n\n2. Increased single-core CPU and RAM Utilization​\n\nObserving high utilization on single-core CPU and RAM indicates that you may require more performant hardware. As this trend continues, hardware investments become prohibitively expensive for the ecosystem or require increasingly custom solutions, which decreases accessibility for node runners.\n\n3. Increased Total State Database Size​\n\nThe accelerated state database growth rate, on the order of multiple terabytes of data per month, indicates that your chain may require increasing drive sizes. Played out over time, this may force node runners on the chain to adopt prohibitively expensive or hard-to-procure drives (e.g., those notes available on major cloud providers).\n\n4. Increased Disk Write Operations per Second​\n\nThe number of write operations per second directly correlates to state size growth. As the state growth rate increases, ecosystem nodes that aren’t properly resourced may fall out of sync with the chain.\n\n5. Sync from Genesis Time​\n\nAs state size increases, the time a new node needs to catch up to the chain also increases. A large state size and state growth rate can result in new nodes catching up to the chain in the worst case.\n\nSummary of symptoms, mitigations, risks​\n\nThe general trend with any issue in the table below is as follows:\n\nThe simple resolutions involve moving to more expensive infrastructure.\nWhen simple resolutions are exhausted, infrastructure becomes both expensive and bespoke (options that available cloud providers do not support)\nThe long-term risk (and point of no return) is when infrastructure requirements are too expensive or too inaccessible for node runners.\nBehaviour\tRisk\tMitigations & Considerations\nPerformance degradation due to storage reads at high disk latency\tAn increase in read operations causes nodes to spend more accessing disk state. As the number of read operations increases, these delays can degrade chain performance.\tUpgrade drives to local NVMe (PCIe Gen4/Gen5, not configured with RAID) with higher speeds. In the short term, NVMe usage will greatly increase the cost of node runners. In the extreme, you may run out of usable drive specifications on available infrastructure vendors.\nGrowing or constant sequencer backlog (using arb_sequencer_backlog) over a sustained period.\tSeeing a growing or persistent backlog implies that nodes cannot keep up with the transaction load accepted by the sequencer.\t\nLarge state database size and high growth rate of the state database\tA large state database size will require that nodes run more expensive disks. This reduces the economic feasibility for node runners. In extreme cases, the required disk size may be unsupported by accessible cloud service providers.\tThe primary resolution is to upgrade the disk size requirement for nodes on your chain.\nHigh utilization of single-core CPU and RAM\tAs with the cases above, this symptom implies a need to upgrade hardware. The main risk is the economic feasibility and long-term accessibility of new hardware options.\tThe only resolution is to upgrade your node’s CPU and RAM.\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nOrbit Licensing\nNext\nManage gas speed limit\nUnderstanding state size and state growth rate\nBehaviour at ultra-high throughput\nSummary of symptoms, mitigations, risks\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Stylus Rust SDK advanced features | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/reference/rust-sdk-guide",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nStylus Rust SDK advanced features\n\nThis document provides information about advanced features included in the Stylus Rust SDK, that are not described in the previous pages. For information about deploying Rust smart contracts, see the cargo stylus CLI Tool. For a conceptual introduction to Stylus, see Stylus: A Gentle Introduction. To deploy your first Stylus smart contract using Rust, refer to the Quickstart.\n\nINFO\n\nMany of the affordances use macros. Though this section details what each does, it may be helpful to use cargo expand to see what they expand into if you’re doing advanced work in Rust.\n\nStorage​\n\nThis section provides extra information about how the Stylus Rust SDK handles storage. You can find more information and basic examples in Variables.\n\nRust smart contracts may use state that persists across transactions. There’s two primary ways to define storage, depending on if you want to use Rust or Solidity definitions. Both are equivalent, and are up to the developer depending on their needs.\n\n#[storage]​\n\nThe #[storage] macro allows a Rust struct to be used in persistent storage.\n\n#[storage]\npub struct Contract {\n    owner: StorageAddress,\n    active: StorageBool,\n    sub_struct: SubStruct,\n}\n\n#[storage]\npub struct SubStruct {\n    // types implementing the `StorageType` trait.\n}\n\n\nAny type implementing the StorageType trait may be used as a field, including other structs, which will implement the trait automatically when #[storage] is applied. You can even implement StorageType yourself to define custom storage types. However, we’ve gone ahead and implemented the common ones.\n\nType\tInfo\nStorageBool\tStores a bool\nStorageAddress\tStores an Alloy Address\nStorageUint\tStores an Alloy Uint\nStorageSigned\tStores an Alloy Signed\nStorageFixedBytes\tStores an Alloy FixedBytes\nStorageBytes\tStores a Solidity bytes\nStorageString\tStores a Solidity string\nStorageVec\tStores a vector of StorageType\nStorageMap\tStores a mapping of StorageKey to StorageType\nStorageArray\tStores a fixed-sized array of StorageType\n\nEvery Alloy primitive has a corresponding StorageType implementation with the word Storage before it. This includes aliases, like StorageU256 and StorageB64.\n\nsol_storage!​\n\nThe types in #[storage] are laid out in the EVM state trie exactly as they are in Solidity. This means that the fields of a struct definition will map to the same storage slots as they would in EVM programming languages.\n\nBecause of this, it is often nice to define your types using Solidity syntax, which makes that guarantee easier to see. For example, the earlier Rust struct can re-written to:\n\nsol_storage! {\n    pub struct Contract {\n        address owner;                      // becomes a StorageAddress\n        bool active;                        // becomes a StorageBool\n        SubStruct sub_struct,\n    }\n\n    pub struct SubStruct {\n        // other solidity fields, such as\n        mapping(address => uint) balances;  // becomes a StorageMap\n        Delegate delegates[];               // becomes a StorageVec\n    }\n}\n\n\nThe above will expand to the equivalent definitions in Rust, each structure implementing the StorageType trait. Many contracts, like our example ERC 20, do exactly this.\n\nBecause the layout is identical to Solidity’s, existing Solidity smart contracts can upgrade to Rust without fear of storage slots not lining up. You simply copy-paste your type definitions.\n\nSTORAGE LAYOUT IN CONTRACTS USING INHERITANCE\n\nNote that one exception to this storage layout guarantee is contracts which utilize inheritance. The current solution in Stylus using #[borrow] and #[inherits(...)] packs nested (inherited) structs into their own slots. This is consistent with regular struct nesting in solidity, but not inherited structs. We plan to revisit this behavior in an upcoming release.\n\nTIP\n\nExisting Solidity smart contracts can upgrade to Rust if they use proxy patterns.\n\nConsequently, the order of fields will affect the JSON ABIs produced that explorers and tooling might use. Most developers won’t need to worry about this though and can freely order their types when working on a Rust contract from scratch.\n\nReading and writing storage​\n\nYou can access storage types via getters and setters. For example, the Contract struct from earlier might access its owner address as follows.\n\nimpl Contract {\n    /// Gets the owner from storage.\n    pub fn owner(&self) -> Address {\n        self.owner.get()\n    }\n\n    /// Updates the owner in storage\n    pub fn set_owner(&mut self, new_owner: Address) {\n        if msg::sender() == self.owner.get() { // we'll discuss msg::sender later\n            self.owner.set(new_owner);\n        }\n    }\n}\n\n\nIn Solidity, one has to be very careful about storage access patterns. Getting or setting the same value twice doubles costs, leading developers to avoid storage access at all costs. By contrast, the Stylus SDK employs an optimal storage-caching policy that avoids the underlying SLOAD or SSTORE operations.\n\nTIP\n\nStylus uses storage caching, so multiple accesses of the same variable is virtually free.\n\nHowever it must be said that storage is ultimately more expensive than memory. So if a value doesn’t need to be stored in state, you probably shouldn’t do it.\n\nCollections​\n\nCollections like StorageVec and StorageMap are dynamic and have methods like push, insert, replace, and similar.\n\nimpl SubStruct {\n   pub fn add_delegate(&mut self, delegate: Address) {\n        self.delegates.push(delegate);\n    }\n\n    pub fn track_balance(&mut self, address: Address) {\n        self.balances.insert(address, address.balance());\n    }\n}\n\n\nYou may notice that some methods return types like StorageGuard and StorageGuardMut. This allows us to leverage the Rust borrow checker for storage mistakes, just like it does for memory. Here’s an example that will fail to compile.\n\nfn mistake(vec: &mut StorageVec<StorageU64>) -> U64 {\n    let value = vec.setter(0);\n    let alias = vec.setter(0);\n    value.set(32.into());\n    alias.set(48.into());\n    value.get() // uh, oh. what value should be returned?\n}\n\n\nUnder the hood, vec.setter() returns a StorageGuardMut instead of a &mut StorageU64. Because the guard is bound to a &mut StorageVec lifetime, value and alias cannot be alive simultaneously. This causes the Rust compiler to reject the above code, saving you from entire classes of storage aliasing errors.\n\nIn this way the Stylus SDK safeguards storage access the same way Rust ensures memory safety. It should never be possible to alias Storage without unsafe Rust.\n\nSimpleStorageType​\n\nYou may run into scenarios where a collection’s methods like push and insert aren’t available. This is because only primitives, which implement a special trait called SimpleStorageType, can be added to a collection by value. For nested collections, one instead uses the equivalent grow and setter.\n\nfn nested_vec(vec: &mut StorageVec<StorageVec<StorageU8>>) {\n    let mut inner = vec.grow();  // adds a new element accessible via `inner`\n    inner.push(0.into());        // inner is a guard to a StorageVec<StorageU8>\n}\n\nfn nested_map(map: &mut StorageMap<u32, StorageVec<U8>>) {\n    let mut slot = map.setter(0);\n    slot.push(0);\n}\n\nErase and #[derive(Erase)]​\n\nSome StorageType values implement Erase, which provides an erase() method for clearing state. We’ve implemented Erase for all primitives, and for vectors of primitives, but not maps. This is because a solidity mapping does not provide iteration, and so it’s generally impossible to know which slots to set to zero.\n\nStructs may also be Erase if all of the fields are. #[derive(Erase)] lets you do this automatically.\n\nsol_storage! {\n    #[derive(Erase)]\n    pub struct Contract {\n        address owner;              // can erase primitive\n        uint256[] hashes;           // can erase vector of primitive\n    }\n\n    pub struct NotErase {\n        mapping(address => uint) balances; // can't erase a map\n        mapping(uint => uint)[] roots;     // can't erase vector of maps\n    }\n}\n\n\nYou can also implement Erase manually if desired. Note that the reason we care about Erase at all is that you get storage refunds when clearing state, lowering fees. There’s also minor implications for patterns using unsafe Rust.\n\nThe storage cache​\n\nThe Stylus SDK employs an optimal storage-caching policy that avoids the underlying SLOAD or SSTORE operations needed to get and set state. For the vast majority of use cases, this happens in the background and requires no input from the user.\n\nHowever, developers working with unsafe Rust implementing their own custom StorageType collections, the StorageCache type enables direct control over this data structure. Included are unsafe methods for manipulating the cache directly, as well as for bypassing it altogether.\n\nImmutables and PhantomData​\n\nSo that generics are possible in sol_interface!, core::marker::PhantomData implements StorageType and takes up zero space, ensuring that it won’t cause storage slots to change. This can be useful when writing libraries.\n\npub trait Erc20Params {\n    const NAME: &'static str;\n    const SYMBOL: &'static str;\n    const DECIMALS: u8;\n}\n\nsol_storage! {\n    pub struct Erc20<T> {\n        mapping(address => uint256) balances;\n        PhantomData<T> phantom;\n    }\n}\n\n\nThe above allows consumers of Erc20 to choose immutable constants via specialization. See our WETH sample contract for a full example of this feature.\n\nFunctions​\n\nThis section provides extra information about how the Stylus Rust SDK handles functions. You can find more information and basic examples in Functions, Bytes in, bytes out programming, Inheritance and Sending ether.\n\nPure, View, and Write functions​\n\nFor non-payable methods the #[public] macro can figure state mutability out for you based on the types of the arguments. Functions with &self will be considered view, those with &mut self will be considered write, and those with neither will be considered pure. Please note that pure and view functions may change the state of other contracts by calling into them, or even this one if the reentrant feature is enabled.\n\n#[entrypoint]​\n\nThis macro allows you to define the entrypoint, which is where Stylus execution begins. Without it, the contract will fail to pass cargo stylus check. Most commonly, the macro is used to annotate the top level storage struct.\n\nsol_storage! {\n    #[entrypoint]\n    pub struct Contract {\n        ...\n    }\n\n    // only one entrypoint is allowed\n    pub struct SubStruct {\n        ...\n    }\n}\n\n\nThe above will make the public methods of Contract the first to consider during invocation.\n\nReentrancy​\n\nIf a contract calls another that then calls the first, it is said to be reentrant. By default, all Stylus contracts revert when this happens. However, you can opt out of this behavior by enabling the reentrant feature flag.\n\nstylus-sdk = { version = \"0.6.0\", features = [\"reentrant\"] }\n\n\nThis is dangerous, and should be done only after careful review — ideally by 3rd party auditors. Numerous exploits and hacks have in Web3 are attributable to developers misusing or not fully understanding reentrant patterns.\n\nIf enabled, the Stylus SDK will flush the storage cache in between reentrant calls, persisting values to state that might be used by inner calls. Note that preventing storage invalidation is only part of the battle in the fight against exploits. You can tell if a call is reentrant via msg::reentrant, and condition your business logic accordingly.\n\nTopLevelStorage​\n\nThe #[entrypoint] macro will automatically implement the TopLevelStorage trait for the annotated struct. The single type implementing TopLevelStorage is special in that mutable access to it represents mutable access to the entire program’s state. This idea will become important when discussing calls to other programs in later sections.\n\nInheritance, #[inherit], and #[borrow].​\nINFO\n\nStylus doesn't support contract multi-inheritance yet.\n\nComposition in Rust follows that of Solidity. Types that implement Router, the trait that #[public] provides, can be connected via inheritance.\n\n#[public]\n#[inherit(Erc20)]\nimpl Token {\n    pub fn mint(&mut self, amount: U256) -> Result<(), Vec<u8>> {\n        ...\n    }\n}\n\n#[public]\nimpl Erc20 {\n    pub fn balance_of() -> Result<U256> {\n        ...\n    }\n}\n\n\nBecause Token inherits Erc20 in the above, if Token has the #[entrypoint], calls to the contract will first check if the requested method exists within Token. If a matching function is not found, it will then try the Erc20. Only after trying everything Token inherits will the call revert.\n\nNote that because methods are checked in that order, if both implement the same method, the one in Token will override the one in Erc20, which won’t be callable. This allows for patterns where the developer imports a crate implementing a standard, like the ERC 20, and then adds or overrides just the methods they want to without modifying the imported Erc20 type.\n\nWARNING\n\nStylus does not currently contain explicit override or virtual keywords for explicitly marking override functions. It is important, therefore, to carefully ensure that contracts are only overriding the functions.\n\nInheritance can also be chained. #[inherit(Erc20, Erc721)] will inherit both Erc20 and Erc721, checking for methods in that order. Erc20 and Erc721 may also inherit other types themselves. Method resolution finds the first matching method by Depth First Search.\n\nNote that for the above to work, Token must implement Borrow<Erc20>. You can implement this yourself, but for simplicity, #[storage] and sol_storage! provide a #[borrow] annotation.\n\nsol_storage! {\n    #[entrypoint]\n    pub struct Token {\n        #[borrow]\n        Erc20 erc20;\n        ...\n    }\n\n    pub struct Erc20 {\n        ...\n    }\n}\n\nCalls​\n\nJust as with storage and functions, Stylus SDK calls are Solidity ABI equivalent. This means you never have to know the implementation details of other contracts to invoke them. You simply import the Solidity interface of the target contract, which can be auto-generated via the cargo stylus CLI tool.\n\nTIP\n\nYou can call contracts in any programming language with the Stylus SDK.\n\nsol_interface!​\n\nThis macro defines a struct for each of the Solidity interfaces provided.\n\nsol_interface! {\n    interface IService {\n        function makePayment(address user) payable returns (string);\n        function getConstant() pure returns (bytes32)\n    }\n\n    interface ITree {\n        // other interface methods\n    }\n}\n\n\nThe above will define IService and ITree for calling the methods of the two contracts.\n\nINFO\n\nCurrently only functions are supported, and any other items in the interface will cause an error.\n\nFor example, IService will have a make_payment method that accepts an Address and returns a B256.\n\npub fn do_call(&mut self, account: IService, user: Address) -> Result<String, Error> {\n    account.make_payment(self, user)  // note the snake case\n}\n\n\nObserve the casing change. sol_interface! computes the selector based on the exact name passed in, which should almost always be CamelCase. For aesthetics, the rust functions will instead use snake_case.\n\nConfiguring gas and value with Call​\n\nCall lets you configure a call via optional configuration methods. This is similar to how one would configure opening a File in Rust.\n\npub fn do_call(account: IService, user: Address) -> Result<String, Error> {\n    let config = Call::new_in()\n        .gas(evm::gas_left() / 2)       // limit to half the gas left\n        .value(msg::value());           // set the callvalue\n\n    account.make_payment(config, user)\n}\n\n\nBy default Call supplies all gas remaining and zero value, which often means Call::new_in() may be passed to the method directly. Additional configuration options are available in cases of reentrancy.\n\nReentrant calls​\n\nContracts that opt into reentrancy via the reentrant feature flag require extra care. When the storage-cache feature is enabled, cross-contract calls must flush or clear the StorageCache to safeguard state. This happens automatically via the type system.\n\nsol_interface! {\n    interface IMethods {\n        function pureFoo() external pure;\n        function viewFoo() external view;\n        function writeFoo() external;\n        function payableFoo() external payable;\n    }\n}\n\n#[public]\nimpl Contract {\n    pub fn call_pure(&self, methods: IMethods) -> Result<(), Vec<u8>> {\n        Ok(methods.pure_foo(self)?)    // `pure` methods might lie about not being `view`\n    }\n\n    pub fn call_view(&self, methods: IMethods) -> Result<(), Vec<u8>> {\n        Ok(methods.view_foo(self)?)\n    }\n\n    pub fn call_write(&mut self, methods: IMethods) -> Result<(), Vec<u8>> {\n        methods.view_foo(self)?;       // allows `pure` and `view` methods too\n        Ok(methods.write_foo(self)?)\n    }\n\n    #[payable]\n    pub fn call_payable(&mut self, methods: IMethods) -> Result<(), Vec<u8>> {\n        methods.write_foo(Call::new_in(self))?;   // these are the same\n        Ok(methods.payable_foo(self)?)            // ------------------\n    }\n}\n\n\nIn the above, we’re able to pass &self and &mut self because Contract implements TopLevelStorage, which means that a reference to it entails access to the entirety of the contract’s state. This is the reason it is sound to make a call, since it ensures all cached values are invalidated and/or persisted to state at the right time.\n\nWhen writing Stylus libraries, a type might not be TopLevelStorage and therefore &self or &mut self won’t work. Building a Call from a generic parameter via new_in is the usual solution.\n\npub fn do_call(\n    storage: &mut impl TopLevelStorage,  // can be generic, but often just &mut self\n    account: IService,                   // serializes as an Address\n    user: Address,\n) -> Result<String, Error> {\n\n    let config = Call::new_in(storage)   // take exclusive access to all contract storage\n        .gas(evm::gas_left() / 2)        // limit to half the gas left\n        .value(msg::value());            // set the callvalue\n\n    account.make_payment(config, user)   // note the snake case\n}\n\n\nNote that in the context of a #[public] call, the &mut impl argument will correctly distinguish the method as being write or payable. This means you can write library code that will work regardless of whether the reentrant feature flag is enabled.\n\nNote too that code that previously compiled with reentrancy disabled may require modification in order to type-check. This is done to ensure storage changes are persisted and that the storage cache is properly managed before calls.\n\ncall, static_call, and delegate_call​\n\nThough sol_interface! and Call form the most common idiom to invoke other contracts, their underlying call and static_call are exposed for direct access.\n\nlet return_data = call(Call::new_in(self), contract, call_data)?;\n\n\nIn each case the calldata is supplied as a Vec<u8>. The return result is either the raw return data on success, or a call Error on failure.\n\ndelegate_call is also available, though it's unsafe and doesn't have a richly-typed equivalent. This is because a delegate call must trust the other contract to uphold safety requirements. Though this function clears any cached values, the other contract may arbitrarily change storage, spend ether, and do other things one should never blindly allow other contracts to do.\n\ntransfer_eth​\n\nThis method provides a convenient shorthand for transferring ether.\n\nNote that this method invokes the other contract, which may in turn call others. All gas is supplied, which the recipient may burn. If this is not desired, the call function may be used instead.\n\ntransfer_eth(recipient, value)?;                 // these two are equivalent\n\ncall(Call::new_in().value(value), recipient, &[])?; // these two are equivalent\n\nRawCall and unsafe calls​\n\nOccasionally, an untyped call to another contract is necessary. RawCall lets you configure an unsafe call by calling optional configuration methods. This is similar to how one would configure opening a File in Rust.\n\nlet data = RawCall::new_delegate()   // configure a delegate call\n    .gas(2100)                       // supply 2100 gas\n    .limit_return_data(0, 32)        // only read the first 32 bytes back\n    .flush_storage_cache()           // flush the storage cache before the call\n    .call(contract, calldata)?;      // do the call\n\n\nNote that the call method is unsafe when reentrancy is enabled. See flush_storage_cache and clear_storage_cache for more information.\n\nRawDeploy and unsafe deployments​\n\nRight now the only way to deploy a contract from inside Rust is to use RawDeploy, similar to RawCall. As with RawCall, this mechanism is inherently unsafe due to reentrancy concerns, and requires manual management of the StorageCache.\n\nNote that the EVM allows init code to make calls to other contracts, which provides a vector for reentrancy. This means that this technique may enable storage aliasing if used in the middle of a storage reference's lifetime and if reentrancy is allowed.\n\nWhen configured with a salt, RawDeploy will use CREATE2 instead of the default CREATE, facilitating address determinism.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nRecommended libraries\nNext\nOverview\nStorage\n#[storage]\nsol_storage!\nReading and writing storage\nCollections\nSimpleStorageType\nErase and #[derive(Erase)]\nThe storage cache\nImmutables and PhantomData\nFunctions\nPure, View, and Write functions\n#[entrypoint]\nReentrancy\nTopLevelStorage\nInheritance, #[inherit], and #[borrow].\nCalls\nsol_interface!\nConfiguring gas and value with Call\nReentrant calls\ncall, static_call, and delegate_call\ntransfer_eth\nRawCall and unsafe calls\nRawDeploy and unsafe deployments\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "The AEP License | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/AEPLicense",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nThe AEP License\nWhat do I need to know about the Orbit license?​\n\nNitro is currently licensed under a Business Source License, similar to DeFi protocols like Uniswap and Aave, among others, with an “Additional Use Grant” to ensure that everyone can have full comfort using and running nodes on all public Arbitrum chains.\n\nThe Additional Use Grant also permits deployment of the Nitro software in a permissionless, zero-cost fashion, as a new blockchain provided that the chain settles to either Arbitrum One or Arbitrum Nova. L3s that settle to Arbitrum One or Nova have no obligation to share revenue with the Arbitrum DAO and remain first class members of the Arbitrum ecosystem. As an expansion of this license, the Arbitrum Expansion Program (AEP) is a self-service licensing model that makes it easy for developers to build and customize L2s/L3s using Arbitrum’s technology alongside different parent chains.\n\nBenefits:\n\nLeverage battle-tested technology to permissionlessly deploy L2s/L3s that settle to any supported parent chain.\nGovernance freedom - Orbit chains are not required to be governed by the Arbitrum DAO.\nFlexible licensing allows developers to modify chain configurations. Orbit chains are free to modify any part of the stack, including implementation of custom gas tokens, alternative DA integrations, novel sequencing mechanisms, account abstraction, altVMs, etc.\nL3s that settle to parent chains other than Arb1 and Nova must contribute net chain revenue, where 8% flows to the DAO and 2% to the developer guild.\nEdit this page\nLast updated on Nov 21, 2024\nPrevious\nQuickstart\nNext\nManage state growth\nWhat do I need to know about the Orbit license?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/precompiles/overview",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nOverview\nReference\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nPrecompiles overview\n\nPrecompiles are predefined smart contracts that have special addresses and provide specific functionality which is executed not at the EVM bytecode level, but natively by the Arbitrum client itself. Precompiles are primarily used to introduce specific functions that would be computationally expensive if executed in EVM bytecode, and functions that facilitate the interaction between the Layer 1 (L1) and the Layer 2 (L2). By having them natively in the Arbitrum client, they can be optimized for performance.\n\nBesides supporting all precompiles available in Ethereum, Arbitrum provides L2-specific precompiles with methods smart contracts can call the same way they can solidity functions. For more details on the addresses these precompiles live, and the specific methods available, please refer to the methods documentation.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nOracles\nNext\nReference\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/nodeinterface/reference",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nOverview\nReference\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nNodeInterface reference\n\nThe Arbitrum Nitro software includes a special NodeInterface contract available at address 0xc8 that is only accessible via RPCs (it's not actually deployed on-chain, and thus can't be called by smart contracts). This reference page documents the specific calls available in the NodeInterface. For a more conceptual description of what it is and how it works, please refer to the NodeInterface conceptual page.\n\nNodeInterface methods​\nMethod\tSolidity interface\tGo implementation\tDescription\n\n\nestimateRetryableTicket(address sender, uint256 deposit, address to, uint256 l2CallValue, address excessFeeRefundAddress, address callValueRefundAddress, bytes calldata data)\n\n\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEstimates the gas needed for a retryable submission\nconstructOutboxProof(uint64 size, uint64 leaf)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tConstructs an outbox proof of an l2->l1 send's existence in the outbox accumulator\nfindBatchContainingBlock(uint64 blockNum)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tFinds the L1 batch containing a requested L2 block, reverting if none does\ngetL1Confirmations(bytes32 blockHash)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nGets the number of L1 confirmations of the sequencer batch producing the requested L2 block\n\n\ngasEstimateComponents(address to, bool contractCreation, bytes calldata data)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSame as native gas estimation, but with additional info on the l1 costs\ngasEstimateL1Component(address to, bool contractCreation, bytes calldata data)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEstimates a transaction's l1 costs\nlegacyLookupMessageBatchProof(uint256 batchNum, uint64 index)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns the proof necessary to redeem a message\nnitroGenesisBlock()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns the first block produced using the Nitro codebase\nblockL1Num(uint64 l2BlockNum)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns the L1 block number of the L2 block\nl2BlockRangeForL1(uint64 blockNum)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tFinds the L2 block number range that has the given L1 block number\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nOverview\nNext\nOverview\nNodeInterface methods\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/precompiles/reference#arbsys",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nOverview\nReference\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nPrecompiles reference\n\nArbOS provides L2-specific precompiles with methods smart contracts can call the same way they can solidity functions. This reference page exhaustively documents the specific calls ArbOS makes available through precompiles. For a more conceptual description of what precompiles are and how they work, please refer to the precompiles conceptual page.\n\nThis reference page is divided into two sections. The first one lists all precompiles in a summary table with links to the reference of the specific precompile, along with the address where they live, their purpose and links to the go implementation and solidity interface. The second one details the methods available in each precompile with links to the specific implementation.\n\nGeneral information of precompiles​\n\nThis section is divided into two tables. We first list precompiles we expect users to most often use, and then the rest of precompiles. However, both tables display the same information: name and purpose of the precompile, address, and links to the solidity interface and the go implementation.\n\nCommon precompiles​\nPrecompile\tAddress\tSolidity interface\tGo implementation\tPurpose\nArbAggregator\t0x6d\tInterface\tImplementation\tConfiguring transaction aggregation\nArbGasInfo\t0x6c\tInterface\tImplementation\tInfo about gas pricing\nArbRetryableTx\t0x6e\tInterface\tImplementation\tManaging retryables\nArbSys\t0x64\tInterface\tImplementation\tSystem-level functionality\nArbWasm\t0x71\tInterface\tImplementation\tManages Stylus contracts\nArbWasmCache\t0x72\tInterface\tImplementation\tManages Stylus cache\nOther precompiles​\nPrecompile\tAddress\tSolidity interface\tGo implementation\tPurpose\nArbAddressTable\t0x66\tInterface\tImplementation\tSupporting compression of addresses\nArbBLS\t-\t-\t-\tDisabled (Former registry of BLS public keys)\nArbDebug\t0xff\tInterface\tImplementation\tTesting tools\nArbFunctionTable\t0x68\tInterface\tImplementation\tNo longer used\nArbInfo\t0x65\tInterface\tImplementation\tInfo about accounts\nArbOwner\t0x70\tInterface\tImplementation\tChain administration, callable only by chain owner\nArbOwnerPublic\t0x6b\tInterface\tImplementation\tInfo about chain owners\nArbosTest\t0x69\tInterface\tImplementation\tNo longer used\nArbStatistics\t0x6f\tInterface\tImplementation\tInfo about the pre-Nitro state\nPrecompiles reference​\nArbAddressTable​\n\nArbAddressTable (Interface | Implementation) provides the ability to create short-hands for commonly used accounts.\n\nPrecompile address: 0x0000000000000000000000000000000000000066\n\nMethod\tSolidity interface\tGo implementation\tDescription\naddressExists(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tAddressExists checks if an address exists in the table\ncompress(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tCompress and returns the bytes that represent the address\ndecompress(bytes calldata buf, uint256 offset)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nDecompress the compressed bytes at the given offset with those of the corresponding account\n\n\nlookup(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tLookup the index of an address in the table\nlookupIndex(uint256 index)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tLookupIndex for an address in the table by index\nregister(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tRegister adds an account to the table, shrinking its compressed representation\nsize()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSize gets the number of addresses in the table\nArbAggregator​\n\nArbAggregator (Interface | Implementation) provides aggregators and their users methods for configuring how they participate in L1 aggregation. Arbitrum One's default aggregator is the Sequencer, which a user will prefer unless SetPreferredAggregator is invoked to change it.\n\nCompression ratios are measured in basis points. Methods that are checkmarked are access-controlled and will revert if not called by the aggregator, its fee collector, or a chain owner.\n\nPrecompile address: 0x000000000000000000000000000000000000006D\n\nMethod\tSolidity interface\tGo implementation\tDescription\n\n\n⚠️getPreferredAggregator(address addr)\n\n\t\n\nInterface\n\n\t\n\nImplementation\n\n\tDeprecated: Do not use this method.\n\n\n⚠️getDefaultAggregator()\n\n\t\n\nInterface\n\n\t\n\nImplementation\n\n\tDeprecated: Do not use this method.\ngetBatchPosters()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetBatchPosters gets the addresses of all current batch posters\naddBatchPoster(address newBatchPoster)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tAdds newBatchPoster as a batch poster\ngetFeeCollector(address batchPoster)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetFeeCollector gets a batch poster's fee collector\nsetFeeCollector(address batchPoster, address newFeeCollector)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nSetFeeCollector sets a batch poster's fee collector (caller must be the batch poster, its fee collector, or an owner)\n\n\n\n\n⚠️getTxBaseFee(address aggregator)\n\n\t\n\nInterface\n\n\t\n\nImplementation\n\n\tDeprecated: returns 0\n\n\n⚠️setTxBaseFee(address aggregator, uint256 feeInL1Gas)\n\n\t\n\nInterface\n\n\t\n\nImplementation\n\n\tDeprecated: does nothing\n\nNote: methods marked with ⚠️ are deprecated and their use is not supported.\n\nArbBLS​\nDISABLED\n\nThis precompile has been disabled. It previously provided a registry of BLS public keys for accounts.\n\nArbDebug​\n\nArbDebug (Interface | Implementation) provides mechanisms useful for testing. The methods of ArbDebug are only available for chains with the AllowDebugPrecompiles chain parameter set. Otherwise, calls to this precompile will revert.\n\nPrecompile address: 0x00000000000000000000000000000000000000ff\n\nMethod\tSolidity interface\tGo implementation\tDescription\nbecomeChainOwner()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tCaller becomes a chain owner\nevents(bool flag, bytes32 value)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmit events with values based on the args provided\neventsView()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tTries (and fails) to emit logs in a view context\ncustomRevert(uint64 number)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tThrows a custom error\npanic()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tHalts the chain by panicking in the STF\nlegacyError()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tThrows a hardcoded error\nEvent\tSolidity interface\tGo implementation\tDescription\nBasic\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nEmitted in Events for testing\n\n\nMixed\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nEmitted in Events for testing\n\n\nStore\t\n\nInterface\n\n\t\n\nImplementation\n\n\tNever emitted (used for testing log sizes)\nArbFunctionTable​\n\nArbFunctionTable (Interface | Implementation) provides aggregators the ability to manage function tables, to enable one form of transaction compression. The Nitro aggregator implementation does not use these, so these methods have been stubbed and their effects disabled. They are kept for backwards compatibility.\n\nPrecompile address: 0x0000000000000000000000000000000000000068\n\nMethod\tSolidity interface\tGo implementation\tDescription\nupload(bytes calldata buf)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tUpload does nothing\nsize(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSize returns the empty table's size, which is 0\nget(address addr, uint256 index)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGet reverts since the table is empty\nArbGasInfo​\n\nArbGasInfo (Interface | Implementation) provides insight into the cost of using the chain. These methods have been adjusted to account for Nitro's heavy use of calldata compression. Of note to end-users, we no longer make a distinction between non-zero and zero-valued calldata bytes.\n\nPrecompile address: 0x000000000000000000000000000000000000006C\n\nMethod\tSolidity interface\tGo implementation\tDescription\ngetPricesInWeiWithAggregator(address aggregator)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetPricesInWeiWithAggregator gets prices in wei when using the provided aggregator\ngetPricesInWei()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetPricesInWei gets prices in wei when using the caller's preferred aggregator\ngetPricesInArbGasWithAggregator(address aggregator)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nGetPricesInArbGasWithAggregator gets prices in ArbGas when using the provided aggregator\n\n\ngetPricesInArbGas()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetPricesInArbGas gets prices in ArbGas when using the caller's preferred aggregator\ngetGasAccountingParams()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetGasAccountingParams gets the rollup's speed limit, pool size, and tx gas limit\ngetMinimumGasPrice()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetMinimumGasPrice gets the minimum gas price needed for a transaction to succeed\ngetL1BaseFeeEstimate()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetL1BaseFeeEstimate gets the current estimate of the L1 basefee\ngetL1BaseFeeEstimateInertia()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nGetL1BaseFeeEstimateInertia gets how slowly ArbOS updates its estimate of the L1 basefee\n\n\ngetL1RewardRate()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetL1RewardRate gets the L1 pricer reward rate\ngetL1RewardRecipient()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetL1RewardRecipient gets the L1 pricer reward recipient\ngetL1GasPriceEstimate()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetL1GasPriceEstimate gets the current estimate of the L1 basefee\ngetCurrentTxL1GasFees()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetCurrentTxL1GasFees gets the fee paid to the aggregator for posting this tx\ngetGasBacklog()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetGasBacklog gets the backlogged amount of gas burnt in excess of the speed limit\ngetPricingInertia()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns how slowly ArbOS updates the L2 basefee in response to backlogged gas\ngetGasBacklogTolerance()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nGetGasBacklogTolerance gets the forgivable amount of backlogged gas ArbOS will ignore when raising the basefee\n\n\ngetL1PricingSurplus()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns the surplus of funds for L1 batch posting payments (may be negative)\ngetPerBatchGasCharge()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nReturns the base charge (in L1 gas) attributed to each data batch in the calldata pricer\n\n\ngetAmortizedCostCapBips()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns the cost amortization cap in basis points\ngetL1FeesAvailable()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns the available funds from L1 fees\ngetL1PricingEquilibrationUnits()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nReturns the equilibration units parameter for L1 price adjustment algorithm (Available since ArbOS 20)\n\n\ngetLastL1PricingUpdateTime()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns the last time the L1 calldata pricer was updated (Available since ArbOS 20)\ngetL1PricingFundsDueForRewards()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nReturns the amount of L1 calldata payments due for rewards (per the L1 reward rate) (Available since ArbOS 20)\n\n\ngetL1PricingUnitsSinceUpdate()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nReturns the amount of L1 calldata posted since the last update (Available since ArbOS 20)\n\n\ngetLastL1PricingSurplus()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nReturns the L1 pricing surplus as of the last update (may be negative) (Available since ArbOS 20)\n\nArbInfo​\n\nArbInfo (Interface | Implementation) provides the ability to lookup basic info about accounts and contracts.\n\nPrecompile address: 0x0000000000000000000000000000000000000065\n\nMethod\tSolidity interface\tGo implementation\tDescription\ngetBalance(address account)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetBalance retrieves an account's balance\ngetCode(address account)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetCode retrieves a contract's deployed code\nArbosTest​\n\nArbosTest (Interface | Implementation) provides a method of burning arbitrary amounts of gas, which exists for historical reasons. In Classic, ArbosTest had additional methods only the zero address could call. These have been removed since users don't use them and calls to missing methods revert.\n\nPrecompile address: 0x0000000000000000000000000000000000000069\n\nMethod\tSolidity interface\tGo implementation\tDescription\nburnArbGas(uint256 gasAmount)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tBurnArbGas unproductively burns the amount of L2 ArbGas\nArbOwner​\n\nArbOwner (Interface | Implementation) provides owners with tools for managing the rollup. Calls by non-owners will always revert.\n\nMost of Arbitrum Classic's owner methods have been removed since they no longer make sense in Nitro:\n\nWhat were once chain parameters are now parts of ArbOS's state, and those that remain are set at genesis.\nArbOS upgrades happen with the rest of the system rather than being independent\nExemptions to address aliasing are no longer offered. Exemptions were intended to support backward compatibility for contracts deployed before aliasing was introduced, but no exemptions were ever requested.\n\nPrecompile address: 0x0000000000000000000000000000000000000070\n\nMethod\tSolidity interface\tGo implementation\tDescription\naddChainOwner(address newOwner)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tAddChainOwner adds account as a chain owner\nremoveChainOwner(address ownerToRemove)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tRemoveChainOwner removes account from the list of chain owners\nisChainOwner(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tIsChainOwner checks if the account is a chain owner\ngetAllChainOwners()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetAllChainOwners retrieves the list of chain owners\nsetL1BaseFeeEstimateInertia(uint64 inertia)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nSetL1BaseFeeEstimateInertia sets how slowly ArbOS updates its estimate of the L1 basefee\n\n\nsetL2BaseFee(uint256 priceInWei)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetL2BaseFee sets the L2 gas price directly, bypassing the pool calculus\nsetMinimumL2BaseFee(uint256 priceInWei)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetMinimumL2BaseFee sets the minimum base fee needed for a transaction to succeed\nsetSpeedLimit(uint64 limit)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetSpeedLimit sets the computational speed limit for the chain\nsetMaxTxGasLimit(uint64 limit)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetMaxTxGasLimit sets the maximum size a tx (and block) can be\nsetL2GasPricingInertia(uint64 sec)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetL2GasPricingInertia sets the L2 gas pricing inertia\nsetL2GasBacklogTolerance(uint64 sec)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetL2GasBacklogTolerance sets the L2 gas backlog tolerance\ngetNetworkFeeAccount()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetNetworkFeeAccount gets the network fee collector\ngetInfraFeeAccount()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetInfraFeeAccount gets the infrastructure fee collector\nsetNetworkFeeAccount(address newNetworkFeeAccount)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetNetworkFeeAccount sets the network fee collector to the new network fee account\nsetInfraFeeAccount(address newInfraFeeAccount)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSetInfraFeeAccount sets the infra fee collector to the new network fee account\nscheduleArbOSUpgrade(uint64 newVersion, uint64 timestamp)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tScheduleArbOSUpgrade to the requested version at the requested timestamp\nsetL1PricingEquilibrationUnits(uint256 equilibrationUnits)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets equilibration units parameter for L1 price adjustment algorithm\nsetL1PricingInertia(uint64 inertia)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets inertia parameter for L1 price adjustment algorithm\nsetL1PricingRewardRecipient(address recipient)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets reward recipient address for L1 price adjustment algorithm\nsetL1PricingRewardRate(uint64 weiPerUnit)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets reward amount for L1 price adjustment algorithm, in wei per unit\nsetL1PricePerUnit(uint256 pricePerUnit)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSet how much ArbOS charges per L1 gas spent on transaction data.\nsetPerBatchGasCharge(int64 cost)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the base charge (in L1 gas) attributed to each data batch in the calldata pricer\nsetBrotliCompressionLevel(uint64 level)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nSets the Brotli compression level used for fast compression (Available in ArbOS version 12 with default level as 1)\n\n\nsetAmortizedCostCapBips(uint64 cap)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the cost amortization cap in basis points\nreleaseL1PricerSurplusFunds(uint256 maxWeiToRelease)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReleases surplus funds from L1PricerFundsPoolAddress for use\nsetInkPrice(uint32 price)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the amount of ink 1 gas buys\nsetWasmMaxStackDepth(uint32 depth)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the maximum depth (in wasm words) a wasm stack may grow\nsetWasmFreePages(uint16 pages)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the number of free wasm pages a tx gets\nsetWasmPageGas(uint16 gas)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the base cost of each additional wasm page\nsetWasmPageLimit(uint16 limit)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the initial number of pages a wasm may allocate\nsetWasmMinInitGas(uint8 gas, uint16 cached)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the minimum costs to invoke a program\nsetWasmInitCostScalar(uint64 percent)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the linear adjustment made to program init costs\nsetWasmExpiryDays(uint16 _days)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the number of days after which programs deactivate\nsetWasmKeepaliveDays(uint16 _days)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the age a program must be to perform a keepalive\nsetWasmBlockCacheSize(uint16 count)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets the number of extra programs ArbOS caches during a given block\naddWasmCacheManager(address manager)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tAdds account as a wasm cache manager\nremoveWasmCacheManager(address manager)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tRemoves account from the list of wasm cache managers\nsetChainConfig(string calldata chainConfig)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSets serialized chain config in ArbOS state\nEvent\tSolidity interface\tGo implementation\tDescription\nOwnerActs\t\n\nInterface\n\n\t\n\nImplementation\n\n\t/ Emitted when a successful call is made to this precompile\nArbOwnerPublic​\n\nArbOwnerPublic (Interface | Implementation) provides non-owners with info about the current chain owners.\n\nPrecompile address: 0x000000000000000000000000000000000000006b\n\nMethod\tSolidity interface\tGo implementation\tDescription\nisChainOwner(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tIsChainOwner checks if the user is a chain owner\nrectifyChainOwner(address ownerToRectify)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nRectifyChainOwner checks if the account is a chain owner (Available in ArbOS version 11)\n\n\ngetAllChainOwners()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetAllChainOwners retrieves the list of chain owners\ngetNetworkFeeAccount()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetNetworkFeeAccount gets the network fee collector\ngetInfraFeeAccount()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetInfraFeeAccount gets the infrastructure fee collector\ngetBrotliCompressionLevel()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nGetBrotliCompressionLevel gets the current brotli compression level used for fast compression\n\n\ngetScheduledUpgrade()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tReturns (0, 0, nil) if no ArbOS upgrade is scheduled.\nEvent\tSolidity interface\tGo implementation\tDescription\nChainOwnerRectified\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when verifying a chain owner\nArbRetryableTx​\n\nArbRetryableTx (Interface | Implementation) provides methods for managing retryables. The model has been adjusted for Nitro, most notably in terms of how retry transactions are scheduled. For more information on retryables, please see the retryable documentation.\n\nPrecompile address: 0x000000000000000000000000000000000000006E\n\nMethod\tSolidity interface\tGo implementation\tDescription\nredeem(bytes32 ticketId)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nRedeem schedules an attempt to redeem the retryable, donating all of the call's gas to the redeem attempt\n\n\ngetLifetime()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetLifetime gets the default lifetime period a retryable has at creation\ngetTimeout(bytes32 ticketId)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetTimeout gets the timestamp for when ticket will expire\nkeepalive(bytes32 ticketId)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tKeepalive adds one lifetime period to the ticket's expiry\ngetBeneficiary(bytes32 ticketId)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetBeneficiary gets the beneficiary of the ticket\ncancel(bytes32 ticketId)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tCancel the ticket and refund its callvalue to its beneficiary\ngetCurrentRedeemer()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the redeemer of the current retryable redeem attempt\nsubmitRetryable()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nDo not call. This method represents a retryable submission to aid explorers. Calling it will always revert.\n\nEvent\tSolidity interface\tGo implementation\tDescription\nTicketCreated\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when creating a retryable\nLifetimeExtended\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when extending a retryable's expiry date\nRedeemScheduled\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when scheduling a retryable\nCanceled\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when cancelling a retryable\nRedeemed\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nDEPRECATED in favour of new RedeemScheduled event after the nitro upgrade.\n\nArbStatistics​\n\nArbStatistics (Interface | Implementation) provides statistics about the chain as of just before the Nitro upgrade. In Arbitrum Classic, this was how a user would get info such as the total number of accounts, but there are better ways to get that info in Nitro.\n\nPrecompile address: 0x000000000000000000000000000000000000006F\n\nMethod\tSolidity interface\tGo implementation\tDescription\ngetStats()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nGetStats returns the current block number and some statistics about the rollup's pre-Nitro state\n\nArbSys​\n\nArbSys (Interface | Implementation) provides system-level functionality for interacting with L1 and understanding the call stack.\n\nPrecompile address: 0x0000000000000000000000000000000000000064\n\nMethod\tSolidity interface\tGo implementation\tDescription\narbBlockNumber()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tArbBlockNumber gets the current L2 block number\narbBlockHash(uint256 arbBlockNum)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tArbBlockHash gets the L2 block hash, if sufficiently recent\narbChainID()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tArbChainID gets the rollup's unique chain identifier\narbOSVersion()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tArbOSVersion gets the current ArbOS version\ngetStorageGasAvailable()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGetStorageGasAvailable returns 0 since Nitro has no concept of storage gas\nisTopLevelCall()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tIsTopLevelCall checks if the call is top-level (deprecated)\nmapL1SenderContractAddressToL2Alias(address sender, address unused)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tMapL1SenderContractAddressToL2Alias gets the contract's L2 alias\nwasMyCallersAddressAliased()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tWasMyCallersAddressAliased checks if the caller's caller was aliased\nmyCallersAddressWithoutAliasing()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nMyCallersAddressWithoutAliasing gets the caller's caller without any potential aliasing\n\n\nwithdrawEth(address destination)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tWithdrawEth send paid eth to the destination on L1\nsendTxToL1(address destination, bytes calldata data)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSendTxToL1 sends a transaction to L1, adding it to the outbox\nsendMerkleTreeState()\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nSendMerkleTreeState gets the root, size, and partials of the outbox Merkle tree state (caller must be the 0 address)\n\nEvent\tSolidity interface\tGo implementation\tDescription\nL2ToL1Tx\t\n\nInterface\n\n\t\n\nImplementation\n\n\tLogs a send transaction from L2 to L1, including data for outbox proving\nL2ToL1Transaction\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nDEPRECATED in favour of the new L2ToL1Tx event above after the nitro upgrade\n\n\nSendMerkleUpdate\t\n\nInterface\n\n\t\n\nImplementation\n\n\tLogs a new merkle branch needed for constructing outbox proofs\nArbWasm​\n\nArbWasm (Interface | Implementation) provides helper methods for managing Stylus contracts\n\nPrecompile address: 0x0000000000000000000000000000000000000071\n\nMethod\tSolidity interface\tGo implementation\tDescription\nactivateProgram(address program)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tCompile a wasm program with the latest instrumentation\nstylusVersion()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the latest stylus version\ncodehashVersion(bytes32 codehash)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the stylus version that program with codehash was most recently compiled with\ncodehashKeepalive(bytes32 codehash)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tExtends a program's expiration date (reverts if too soon)\ncodehashAsmSize(bytes32 codehash)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets a program's asm size in bytes\nprogramVersion(address program)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the stylus version that program at addr was most recently compiled with\nprogramInitGas(address program)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the cost to invoke the program\nprogramMemoryFootprint(address program)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the footprint of program at addr\nprogramTimeLeft(address program)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets returns the amount of time remaining until the program expires\ninkPrice()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the amount of ink 1 gas buys\nmaxStackDepth()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the wasm stack size limit\nfreePages()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the number of free wasm pages a tx gets\npageGas()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the base cost of each additional wasm page\npageRamp()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the ramp that drives exponential memory costs\npageLimit()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the maximum initial number of pages a wasm may allocate\nminInitGas()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the minimum costs to invoke a program\ninitCostScalar()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the linear adjustment made to program init costs\nexpiryDays()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the number of days after which programs deactivate\nkeepaliveDays()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the age a program must be to perform a keepalive\nblockCacheSize()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets the number of extra programs ArbOS caches during a given block.\nEvent\tSolidity interface\tGo implementation\tDescription\nProgramActivated\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when activating a WASM program\nProgramLifetimeExtended\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when extending the expiration date of a WASM program\nArbWasmCache​\n\nArbWasmCache (Interface | Implementation) provides helper methods for managing Stylus cache\n\nPrecompile address: 0x0000000000000000000000000000000000000072\n\nMethod\tSolidity interface\tGo implementation\tDescription\nisCacheManager(address manager)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tSee if the user is a cache manager owner.\nallCacheManagers()\t\n\nInterface\n\n\t\n\nImplementation\n\n\tRetrieve all authorized address managers.\ncacheCodehash(bytes32 codehash)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tDeprecated: replaced with CacheProgram.\ncacheProgram(address addr)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nCaches all programs with a codehash equal to the given address. Caller must be a cache manager or chain owner.\n\n\nevictCodehash(bytes32 codehash)\t\n\nInterface\n\n\t\n\nImplementation\n\n\t\n\nEvicts all programs with the given codehash. Caller must be a cache manager or chain owner.\n\n\ncodehashIsCached(bytes32 codehash)\t\n\nInterface\n\n\t\n\nImplementation\n\n\tGets whether a program is cached. Note that the program may be expired.\nEvent\tSolidity interface\tGo implementation\tDescription\nUpdateProgramCache\t\n\nInterface\n\n\t\n\nImplementation\n\n\tEmitted when caching a WASM program\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nOverview\nNext\nOverview\nGeneral information of precompiles\nCommon precompiles\nOther precompiles\nPrecompiles reference\nArbAddressTable\nArbAggregator\nArbBLS\nArbDebug\nArbFunctionTable\nArbGasInfo\nArbInfo\nArbosTest\nArbOwner\nArbOwnerPublic\nArbRetryableTx\nArbStatistics\nArbSys\nArbWasm\nArbWasmCache\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/bold/gentle-introduction",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nThe BoLD dispute protocol\nA gentle introduction\nDeploy a validator on testnet\nBoLD Whitepaper\nTechnical deep dive\nEconomics of Disputes\nSpecification on Github\nAudit Report by Trail of Bits\nAudit Report by Code4rena\nPublic preview\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nA gentle introduction: BoLD\n\nThis introduction is for those who want to learn about BoLD: a new dispute protocol for Optimistic Rollups that can enable permissionless validation for Arbitrum chains. BoLD stands for Bounded Liquidity Delay and is currently deployed on a public testnet for anyone to join and test how challenges will work.\n\nThis next-generation dispute protocol technology will soon be available for any Arbitrum chain, and pending a governance vote, will eventually be made available on Arbitrum Sepolia, Arbitrum One, and Arbitrum Nova.\n\nBoLD will eventually replace the current, permissioned fraud proof mechanism that powers Arbitrum chains today.\n\nIn a nutshell:​\nValidation for Arbitrum One and Arbitrum Nova is a privileged action currently limited to an allow-listed set of parties, maintained by the Arbitrum DAO to reduce the risks of delay attacks. Delay attacks are a class of attacks where malicious entities can open as many disputes as they are willing to forfeit bonds during the challenge period to delay confirmations of assertions (equal to the time needed to resolve those disputes one by one).\nBoLD, an acronym for Bounded Liquidity Delay, is a new challenge resolution protocol for Arbitrum chains that enables permissionless validation by mitigating the risks of delay attacks against optimistic rollups like Arbitrum. This is possible because BoLD's design ensures disputes will be resolved within a fixed time window, currently set to equal 1 challenge period (~6.4 days) for Arbitrum One and Arbitrum Nova. If there is a dispute, BoLD guarantees the maximum total time to be equal to 2 challenge periods (1 for raising disputes, 1 for resolving disputes), a 2 day grace period for the Security Council to intervene if necessary, and a small delta for computing challenges.\nEnabling permissionless validation is key milestone on Arbitrum’s journey to becoming a Stage 2 Rollup - the most advanced and mature rollup technology categorization, according to L2Beat. With BoLD, any honest party can validate and bond their funds to post a correct L2 state assertions to win disputes against malicious entities.\nBoLD is currently considered to be in alpha release and is deployed on a public testnet. Follow this guide to deploy a BoLD validator to test and explore, first hand, how BoLD works to secure Arbitrum chains. To learn more about BoLD, please check out the BoLD whitepaper and BoLD's code and specifications on Github.\nWhat exactly is BoLD?​\n\nBoLD, an acronym for Bounded Liquidity Delay Protocol, is an upgrade to Arbitrum's existing dispute protocol. Specifically, BoLD changes some of the rules used by validators to open and resolve disputes about Arbitrum’s state to ensure only valid states get confirmed on an Arbitrum chain’s parent chain, such as Ethereum.\n\nThe current dispute protocol has working fraud proofs and is used in production today by Arbitrum chains. The changes BoLD brings enable anyone to participate in the validation of the state of the chain and enhance security around withdrawals to L1.\n\nA bonded validator’s responsibilities are to:\n\nPost claims about an Arbitrum chain’s state to its parent chain (for Arbitrum One, the parent chain is L1 Ethereum),\nOpen challenges to dispute invalid claims made by other validators, and\nConfirm valid claims by participating in and winning challenges.\n\nThe goal of BoLD is to unlock permissionless validation by ensuring that disputes are resolved within a fixed period (currently equivalent to 2 challenge periods, plus a two-day grace period for the Security Council to intervene if necessary and a small delta for computation), effectively removing the risk of delay attacks and making withdrawals to a parent chain more secure. BoLD accomplishes this by introducing a new dispute system that lets any single entity defend Arbitrum against malicious parties - effectively allowing anyone to validate, propose, and defend an Arbitrum chain’s state without needing permission to do so.\n\nWhy does Arbitrum need a new dispute protocol?​\n\nWhile Arbitrum chains today benefit from working fraud proofs, BoLD introduces a few subtle but innovative changes that let anyone challenge and win disputes - all within a fixed time period. In other words, Arbitrum chains will continue to be secured with an interactive proving game between validators using fraud proofs, but with the added benefit of this game being completely permissionless and time-bounded to the same length as 1 challenge period (or 6.4 days, by default).\n\nUnder the hood, the reason why BoLD can offer time-bound, permissionless validation is because a correct Arbitrum state assertion is not tied to the entity that bonds their capital to a claim. This property, coupled with the fact that L2 states are completely deterministic and can be proven on Ethereum, means that any number of honest parties can rely on BoLD to prove that their claim is correct. Lastly, a property that will not change with BoLD is the fact that there needs to only be 1 honest party defending Arbitrum.\n\nBoLD brings Arbitrum closer to being recognized as a Stage 2 rollup​\n\nInspired by Vitalik’s proposed milestones, the team over at L2Beat has assembled a widely recognized framework for evaluating the development Ethereum Rollups. Both Vitalik and the L2Beat framework refer to the final stage of rollup development as “Stage 2 - No Training Wheels”. A critical criterion for being considered a Stage 2 rollup is to allow anyone to validate the L2 state and post fraud proofs to Ethereum without restraints. This is considered a key requirement for Stage 2 because it ensures “that the system is not controlled by a limited set of entities and instead is subject to the collective scrutiny of the entire community”.\n\nBoLD enables permissionless validation by allowing anyone to challenge incorrect Arbitrum state assertions and therefore unlocks new avenues for participation in securing the network, fostering greater inclusivity and resilience. This is made possible because BoLD guarantees that a single, honest entity who has their capital bonded to the correct Arbitrum state assertion will always win against malicious adversaries. The research and work to bring BoLD to life underscores Arbitrum's commitment to scaling Ethereum without compromising on security.\n\nWith BoLD at its core, Arbitrum charts a course towards being recognized as a Stage 2 rollup by addressing the currently yellow (above) State Validation wedge in L2Beat's risk analysis pie chart. BoLD contributes to a more permissionless, efficient, and robust rollup ecosystem. Additionally, BoLD will be available as an upgrade for all Orbit chains who wish to adopt it to reap the aforementioned benefits.\n\nBoLD makes withdrawals to L1 Ethereum safer​\n\nToday, there is a period of time, following a state assertion, called the “challenge period,” where any validator can open a dispute over the validity of a given L2 state root. If there are no disputes during the challenge period, the protocol confirms the state root and considers it to be valid - this property is what makes Arbitrum an optimistic rollup. This challenge period is why you must wait ~1 week (6.4 days to be exact) to withdraw assets from Arbitrum One, for example. While this design is secured with working fraud proofs, it is susceptible to delay attacks, where malicious actors continuously open disputes to extend that challenge period for as long as they’re willing to sacrifice bonds - effectively extending the challenge period indefinitely by an amount equal to the time it takes to resolve each dispute, one by one. This risk is not ideal nor safe, and is why validation for Arbitrum One and Nova is confined to a permissioned set of entities overseen by the Arbitrum DAO.\n\nBoLD addresses these challenges head-on by introducing a time limit on the existing rollup protocol for resolving disputes, effectively ensuring that challenges conclude within a 6.4-day window (this window can changed by the DAO for Arbitrum One and Nova). This is possible due to two reasons: (1) BoLD’s design allows for challenges between the honest party and any number of malicious adversaries to happen in parallel, and (2) the use of a time limit that will automatically confirm the honest party’s claims if the challenger fails to respond.\n\nTo summarize with an analogy and the diagram below: Arbitrum’s current dispute protocol assumes that any assertion that gets challenged must be defended against each unique challenger sequentially, like in a “1v1 tournament”. BoLD, on the other hand, enables any single honest party to defend the correct state and be guaranteed to win, similar to an “all-vs-all battle royale” where there must and will always be a single winner in the end.\n\n Note that the timer/clocks above are arbitrary and instead represent the duration of challenges and how challenges are sequential today but can take place in parallel with BoLD. The duration of challenges are independent from one another.\n\nHow is this possible?​\n\nThe BoLD protocol provides the guardrails and rules for how validators challenge claims about the state of an Arbitrum chain. Since Arbitrum’s state is deterministic, there will always be only 1 correct state for a given input of on-chain operations and transactions. The beauty of BoLD’s design guarantees that disputes will be resolved within a fixed time window, removing the risk of delay attacks and ultimately enabling anyone to bond their funds to and successfully defend that singular correct state of Arbitrum.\n\nLet’s dive in to an overview of how BoLD actually works.\n\nAn assertion is made: Validators begin by taking the most recent confirmed RBlock, called Block A, and assert that some number of transactions afterwards, using Nitro’s deterministic State Transition Function (STF), will result in an end state, Block Z. If a validator claims that the end state represented by Block Z is correct, they will bond their funds to Block Z and propose that state to be posted to Ethereum. If nobody disagrees after a certain amount of time, known as the challenge period, then the state represented by the RBlock Block Z is confirmed as the correct state of an Arbitrum chain. However, if someone disagrees with the end state Block Z, they can submit a challenge. This is where BoLD comes into play.\nA challenge is opened: When another validator observes and disagrees with the end state represented by Block Z, they can permissionlessly open a challenge by asserting and bonding capital to a claim on a different end state, represented by an RBlock Block Y. At this point in time, there are now 2 asserted states: Block A → Block Z and Block A → Block Y. Each of these asserted states, at this point in time now that there's a challenge, are referred to edges while a Merkle tree of asserted states from some start to end point (e.g. Block A → Block Z) is more formally known as a history commitment. It is important to note that Ethereum at this point in time has no notion of which edge(s) is correct or incorrect - edges are simply a portion of a claim made by a validator about the history of the chain from some end state all the way back to some initial state. Also note that because a bond put up by a validator is tied to an assertion rather than the party who put up that bond, there can be any number of honest, anonymous parties that can open challenges against incorrect claims. It is important to note that the bonds put up to open challenges are held in a Gnosis Safe multi-sig wallet controlled by the Arbitrum Foundation.\nMulti-level, interactive dissection begins: To resolve the dispute, the disagreeing entities will need to come to an agreement on what the actual, correct asserted state should be. It would be tremendously expensive to re-execute and compare everything from Block A → Block Z and Block A → Block Y, especially since there could be potentially millions of transactions in between A, Z, and Y. Instead, entities take turns bisecting their respective history commitments until they arrive at a single step of instruction where an arbiter, like Ethereum, can declare a winner. Note that this system is very similar to how challenges are resolved on Arbitrum chains today - BoLD only changes some minor, but important, details in the resolution process. Let’s dive into what happens next:\nBlock challenges: when a challenge is opened, the edges are called level-zero edges since they are at the granularity of Arbitrum blocks. The disputing parties take turns bisecting their history commitments until they identify the specific block that they disagree on.\nBig-step challenge: now that the parties have narrowed down their dispute to a single block, that we call Block B, the back-and-forth bisection exercise continues within that block. Note that Block B is claimed by all parties to be some state after the initial state Block A but before the final states Block Z and Block Y. This time, however, the parties will narrow down on a specific range of instructions for the state transition function within the block - essentially working towards identifying a set of instructions within which their disagreement lies. This range is currently defined as 2^20 steps of WASM instructions, which is the assembly of choice for validating Arbitrum chains.\nOne-step challenge: within that range of 2^20 instructions, the back and forth bisecting continues until all parties arrive at a single step of instruction that they disagree on. At this point in time, parties agree on the initial state of Arbitrum before the step but disagree on the end state 1 step immediately after. Remember that since Arbitrum’s state is entirely deterministic, there is only 1 correct end state.\nOne-step proof: Once a challenge is isolated down to a dispute about a single step, both parties run that step to produce, and then submit, a one-step proof to the OneStepProof smart contract on the parent chain (e.g. Ethereum). A one-step proof is a proof that a single step of computation results in a particular state. The smart contract on the parent chain will execute the disputed step to validate the correctness of a submitted proof from the two parties. It is at this point that the honest party's proof will be deemed valid and its tree of edges will be confirmable by time, while the dishonest party has their edges rejected.\nConfirmation: Once the honest one-step edge is confirmed, the protocol will work on confirming or rejecting the parent edges until it reaches the level-zero edge of the honest party. With the honest party’s level-zero edge now confirmed, the honest party’s assertion bond can be withdrawn. Meanwhile, the dishonest party has their bonds taken away to ensure the dishonest party is always punished. Reimbursements for the honest party's L1 gas costs and mini-bonds made at the other challenge levels are handled by the Arbitrum Foundation.\nThere is another way that a level-zero edge can get confirmed: time. At each of the mini-stages of challenge (block challenge, big-step challenge, one-step challenge), there is a timer that increments upwards towards some challenge period, T defined by BoLD. This timer begins ticking for a party when they submit their bisected history commitment until their challenger submits their bisected history commitment in response. An edge is automatically confirmed if the timer reaches T.\n\nThat’s it! We’ve now walked through each of the steps that validators will take to dispute challenges with the BoLD protocol. One final note here is that each of the steps explained above can take place concurrently and this is one of the reasons why BoLD can guarantee that disputes are resolved within a fixed time frame.\n\nWhat can I do with BoLD today?​\n\nToday, BoLD is deployed on a public testnet using Ethereum Sepolia as a base layer for anyone to experiment with and test on. The intent behind this testnet is purely to demonstrate, first-hand, how disputes can effectively resolved by a single party in a fixed challenge period on Arbitrum chains. Feedback gained from developers, users, and researchers will help improve and strengthen BoLD’s design.\n\nIf you’re intrigued by what BoLD can unlock for Arbitrum chains, we encourage you to interact with BoLD by:\n\nFollowing this guide to deploy a BoLD validator to test and explore, first hand, how BoLD works to secure Arbitrum chains. A BoLD testnet block explorer is also available for you to peruse!\nListen to the two governance calls on this proposal! Meeting recordings are here for BoLD governance call #1 and BoLD governance call #2, in addition to a AMA recording on X.com here.\nChecking out this BoLD Technical Deep Dive to learn about BoLD's implementation, alongside the BoLD source code on Github to understand how BoLD works under the hood.\nReviewing the Economics of Disputes in Arbitrum BoLD to learn about rationale behind the design and recommended bonding values.\nReading the formal specification and mathematical proofs behind BoLD in the BoLD whitepaper.\nWen mainnet?​\nWITHDRAWALS LEADING UP TO A BOLD UPGRADE\n\nThe confirmation timing on any withdrawal that is in-flight when the BoLD upgrade is activated will be delayed until the first BoLD assertion is confirmed. This means that for any Arbitrum chain that upgrades to use BoLD, including Arbitrum One and Arbitrum Nova, all pending withdrawals to L1 Ethereum that were initiated before the upgrade will be delayed by 1 challenge period, plus the time between the withdrawal was initiated and the time that the BoLD upgrade takes place. This is because the upgrade effectively \"resets\" the challenge period for that are not yet finalized.\n\nFor example, if the upgrade happened at time t, then a withdrawal initiated at a time t-2 days will need to wait an additional 6.4 days for their withdrawal to be finalized, totaling 8.4 days of maximum delay. Withdrawals that finalize before the upgrade takes place at time t will be unaffected. In other words, the maximum delay a withdrawal will experience leading up to the upgrade is 12.8 days (two challenge periods).\n\nBoLD is in alpha, which means there are a lot of planned improvements on the roadmap. A few high-level next steps for BoLD's journey to being deployed to Arbitrum chains include:\n\nA comprehensive, third-party audit of the BoLD source code to ensure the effectiveness and safety of the design.\nTools and frameworks for the smooth migration of existing validators and a seamless onboarding for new validators to use BoLD for their respective Arbitrum chains.\nMonitoring stack for people to use to see ongoing challenges on the testnet\nA mechanism for the community to pool funds together to bond capital to an assertion made by validators\nThe launch of a public bounty program for white hat security auditors and security professionals to help test and secure the BOLD protocol design.\nProposing, to the Arbitrum DAO, that the BOLD protocol be adopted - first for Arbitrum Sepolia and then eventually for Arbitrum One and Arbitrum Nova.\nCutting a GA release of Nitro that enables BOLD validation.\nFrequently asked questions about BoLD (FAQ):​\nQ: How does bonding work?​\n\nThe entities responsible for posting assertions about Arbitrum state to Ethereum are called validators. If posting assertions were free, anyone could create conflicting assertions to always delay withdrawals by 14 days instead of 7. As such, Arbitrum requires validators to put in a “security deposit”, known as a bond, to be allowed to post assertions. Validators can withdraw their bond as soon as their latest posted assertion has been confirmed, and end their responsibilities. These bonds can be any ERC20 token and should be set to a large enough value (e.g. 200 WETH) to make it economically infeasible for an adversary to attack an Arbitrum chain and to mitigate against spam (that would otherwise delay confirmations). Requiring a high bond to post assertions about Arbitrum seems centralizing, as we are replacing a whitelist of validators with instead a system that requires a lot of money to participate in. To address this, there is a contract that anyone can use to deploy a bonding pool as a way of crowdsourcing funds from others who wish to help defend Arbitrum but who may not individually be able to put up the large upfront bond itself. The use of bonding pools, coupled with the fact that there can be any number of honest anonymous parties ready to defend Arbitrum, means that these high bond values do not harm decentralization.\n\nQ: Why are the bond sizes so high for Arbitrum One?​\n\nThere are two types of “bonds” in BoLD: assertion and challenge. The below sizes are carefully calculated and set for Arbitrum One using a variety of factors, including TVL and optimizing for a balance between cost for honest parties and security of the protocol. As always, the exact bond sizes for an Orbit chain using BoLD is entirely up to the chain owner to decide, if they choose to adopt BoLD at all.\n\nAssertion bond sizes\n\nAssertion bond sizes can be thought of as a “security deposit” that an entity puts down to fulfill the role of a proposer (i.e. a validator who proposes state assertions to L1). The bond sizes are high because the role of a proposer is to ensure that the chain progresses and so whoever fulfills this role assumes a big responsibility. Accordingly, the bond is needed to deter delay attacks, where the attacker would sacrifice the bond in order to cause a week of delay in a group of withdrawals. If the bond is too small or free, there isn’t enough deterrence against this type of attack. Validators who choose to be proposers can withdraw their bond as soon as their most recent posted assertion has been confirmed by the protocol. We expect there to be very few proposers on Arbitrum One, and even one is sufficient for safety.\n\nChallenge bond sizes\n\nIf someone disagrees with a posted assertion from a proposer, they can pool funds together to propose their own assertion that represents the correct history of the chain. Upon doing so, a challenge between the two claims will begin. Anyone can participate in the challenge, as it is not tied up to specific addresses. To resolve a challenge, participants will incur compute and gas costs due to the interactive fraud proof game, and certain moves within a challenge have an additional bond required to prevent resource exhaustion and spam from adversaries. These moves within a challenge require smaller, challenge bonds. The proposed challenge bonds for Arbitrum One are 1110 ETH to fully resolve a dispute, which will also get reimbursed upon the confirmation of assertions by the protocol.\n\nThe rationale behind the specific challenge bond size was made using something called a “resource ratio” - defined as the cost ratio between an adversary and an honest party when participating in the interactive fraud proof game. The value was chosen to ensure that the malicious party will pay 10x the marginal costs of the honest party. This resource ratio, coupled with the fact that an honest party will always get their bonds refunded while a malicious party loses everything, helps prevent and deter attacks to begin with.\n\nTo summarize with a scenario, this effectively means that defending against a $1B dollar attack would require ~$100M of bonds. The ~$100M would be reimbursed upon winning a challenge, where the $1B put up by an adversary would be lost. The proposal aims to send the confiscated funds to the treasury by setting the “excess state receiver” address to the DAO’s treasury address. The tradeoff here is that the higher the resource ratio we want, the more expensive it is for both honest and evil parties to make claims in disputes.\n\nBonding pools as a way to allow people to participate in assertion posting\n\nBoLD ships with trust-less bonding pools that allow any group of participants to pool their funds together to challenge a dishonest proposer, and win. That is, any group of entities can pool funds into a simple contract that will post an assertion to Ethereum without needing to trust each other. Upon observation of an invalid assertion, validators have 1 challenge period (~6.4 days) to pool funds in the contract and respond with a counter assertion. We believe that making it easy to pool the funds to participate in the defense of Arbitrum trustlessly and improves decentralization and the safety of BoLD.\n\nQ: Does the bond requirement only mean that whales can validate Arbitrum One?​\n\nValidating Arbitrum One is *free and accessible. All Arbitrum One nodes, by default, are watchtower validators meaning they can detect and report invalid assertions posted to Ethereum.\n\nHowever, becoming an assertion proposer requires a bond, as without it, anyone could delay all Arbitrum bridged assets by one week. However, BoLD allows for anyone to propose assertions and also challenge invalid assertions via pool contracts, helping keep proposers accountable for their actions.\n\nQ: How does BoLD disincentivize malicious actors from attacking an Arbitrum chain?​\n\nBonds put up by honest parties will always be refunded while malicious actors always stand to lose 100% of their bond. Malicious actors stand to lose everything at each challenge. BoLD delay is bounded and additional challenges would not increase the delay of a particular assertion.\n\nQ: In the event of a challenge, what happens to the confiscated funds from malicious actors for Arbitrum One?​\n\nRecall that BoLD enables any validator to put up a bond to propose assertions about the L2 state. These assertions about the L2 state are deterministic and so an honest party who puts up a bond on the correct assertion will always win in disputes. In these scenarios, the honest party will eventually have their bonds reimbursed while the malicious actor will lose all of their funds.\n\nIn BoLD, all costs spent by malicious actors are confiscated and sent to the Arbitrum DAO treasury. A small reward, called the Defender's Bounty, of 1% will be awarded to entities who put down challenge bonds in defense of Arbitrum One. For the remainder of the funds, the Arbitrum DAO will have full discretion over what to do with the funds confiscated from a malicious actor. This includes, but is not limited to:\n\nUsing the confiscated funds to refund L1 gas costs to honest parties,\nRewarding or reimbursing the honest parties with some, or all, of the confiscated funds in excess of the 1% Defender's Bounty,\nBurning some, or all, of the confiscated funds, or\nKeep some, or all, of the confiscated funds within the Arbitrum DAO Treasury.\n\nAs always, an Orbit chain can choose how they wish to structure and manage confiscated funds from dishonest parties.\n\nQ: Why are honest parties not automatically rewarded with confiscated funds from a malicious actor?​\n\nIt’s tempting to think that rewarding the honest proposer in a dispute can only make the protocol stronger, but this turns out not to be true, because an adversary can sometimes profit by placing the honest stakes themselves.\n\nThis creates perverse incentives that threaten the security of BoLD. Here’s an example, from Ed Felten:\n\n💡 Suppose the top-level assertion bond is $5M. A delay attack, where the attacker wants to cause one week of delay at minimum cost, costs the attacker $5M. If we change the protocol to give the honest proposer 20% of the confiscated bond, then the attack only costs $4M, because the attacker can post both bonds ($10M total) and get back the honest $5M bond, plus a $1M reward. So the protocol is weaker against delay grieving. We can compensate by increasing the top-level assertion bond to $6.25M, so delay griefing still costs $5M, but that increases the cost, to an honest party, required to defend against other attacks. The intuition that giving bigger rewards for honest actions can only make the protocol stronger, though natural, turns out not to be correct. The reason for this is that large rewards create new strategic options for the attacker which might enable them to reduce their cost.\n\nThat said, there’s no harm in paying the honest proposer a fair interest rate on their bond, so they don’t suffer for having helped the protocol by locking up their capital in a bond.\n\nTherefore, the BoLD AIP proposes that the honest parties be rewarded 1% of confiscated bonds from a dishonest party, in the event of a challenge. This reward applies only to entities who deposit challenge bonds and participate in defending Arbitrum against a challenge. The exact amount rewarded to honest parties will be proportional to the amount defender’s deposited into the protocol during a challenge, making bonding pool participants eligible. The process by which this reward is calculated will be done off-chain and payouts will require a DAO vote because the confiscated funds are always sent to a DAO-controlled address.\n\nQ: Why is $ARB not the bonding token used in BoLD? on Arbitrum One?​\n\nAlthough BoLD supports using an ERC20 token, Ethereum, specifically WETH, was chosen over $ARB for a few reasons:\n\nArbitrum One & Arbitrum Nova both inherit their security from Ethereum already, Arbitrum One and Nova rely on Ethereum for both data availability and as the referee for determining winners during fraud proof disputes. It follows then that Ethereum continues to be used in BoLD, which is meant to permissionlessly secure Arbitrum even further. Ethereum’s value is also relatively independent of Arbitrum, especially when compared to the $ARB.\nAccess to liquidity: Ethereum has greater liquidity than $ARB. In the event of an attack on Arbitrum, access and ease of pooling funds may become crucial.\nFraud proofs are submitted to, and arbitrated on, L1 Ethereum. The bonding of capital to make assertions is done so on L1 Ethereum, since Ethereum is the arbitrator of disputes. If BoLD were to use $ARB instead of Ethereum, a large amount of $ARB must be pre-positioned on L1 which is more difficult to do when compared to pre-positioning Ethereum on L1 Ethereum.\n\nAn Orbit chain owner may choose to use any token they wish for bonding, if they adopt and use BoLD permissionless validation.\n\nQ: Can the required token for the validator be set to $ARB and can network $ETH revenues be distribute for validator incentive for Arbitrum One?​\n\nYes. The asset that a validator uses to become a proposer in BoLD can be set to any ERC20 token, including $ARB. For Arbitrum One, $ETH is used for bonds due to a variety of reasons mentioned above. The Arbitrum DAO can change this asset type at any time via a governance proposal. The source and denomination of funds used to incentive validators, should such an economic incentive model exist, will be at the discretion of the Arbitrum DAO.\n\nQ: How are honest parties reimbursed for bonding their capital to help secure Arbitrum One?​\n\nThe Arbitrum DAO reimburses “active” proposers with a fair interest rate, as a way of removing the disincentive to participate, by reimbursing honest parties who bond their own capital and propose assertions for Arbitrum One. The interest rate should be denominated in ETH and should be equal to the annualized yield that Ethereum mainnet validators receive, which at the time of writing, is an APR between 3% to 4% (based on CoinDesk Indices Composite Ether Staking Rate (CESR) benchmark and Rated.Network). This interest is considered a reimbursement because this payment reimburses the honest party for the opportunity cost of locking up their capital and should not be perceived as a “reward” - for the same reasons why the protocol does not reward honest parties with the funds confiscated from a malicious actor. These reimbursement payments can be paid out upon an active proposer’s honest assertion being confirmed on Ethereum and will be calculated and handled off-chain by the Arbitrum Foundation.\n\nBoLD makes it permissionless for any validator to become a proposer and also introduces a way to pay a service fee to honest parties for locking up capital to do so. Validators are not considered active proposers until they successfully propose an assertion with a bond. In order to become an active **proposer for Arbitrum One, post-BoLD, a validator has to propose an L2 state assertion to Ethereum. If they do not have an active bond on L1, they then need to attach a bond to their assertion in order to successfully post the assertion. Subsequent assertions posted by the same address will simply move the already-supplied bond to their latest proposed assertion. Meanwhile, if an entity, say Bob, has posted a successor assertion to one previously made by another entity, Alice, then Bob would be considered by the protocol to be the current active proposer. Alice would no longer be considered by the protocol as the active proposer and once Alice’s assertion is confirmed, then Alice gets her assertion bond refunded. There can only be 1 “active” proposer at any point in time.\n\nThe topic of economic and incentive models for BoLD on Arbitrum One are valuable and we believe it deserves the full focus and attention of the community via a separate proposal/discussion - decoupled from this proposal to bring BoLD to mainnet. Details around proposed economic or incentive models for BoLD will need continued research and development work, but the deployment of BoLD as-is represents a substantial improvement to the security of Arbitrum even without economic-related concerns resolved. The DAO may choose, via governance, to fund other parties or change this reimbursement model at any time.\n\nFor Orbit chains, any economic model can be implemented alongside BoLD, if chain owners decide to adopt BoLD.\n\nQ: For Arbitrum One proposers, is the service fee applied to the amount bonded? If that’s the case, the $ETH would be locked and thus unable to be used to generate yield elsewhere. So, which assets are used to generate this yield for the service fee? Would it involve some $ETH from the Arbitrum bridge?​\n\nThe proposed service fee should correlate to the annualized income that Ethereum mainnet validators receive, over the same time period. At the time of writing, the estimated annual income for Ethereum mainnet validators is approximately 3% to 4% of their stake (based on CoinDesk Indices Composite Ether Staking Rate (CESR) benchmark and Rated.Network).\n\nThe fee is applied to the total amount bonded over the duration of time that a proposer is active. A validator will need to deposit $ETH into the contracts on L1 to become a proposer and so those deposited funds will indeed be unable to be used for yield in other scenarios. The decision on the source of funds for the yield is entirely up to the ArbitrumDAO to decide.\n\nQ: For Arbitrum One, will the off-chain compute costs be reimbursed? (i.e. the costs for a validator computing the hashes for a challenge)​\n\nReimbursement will not be made for off-chain compute costs as we view these to be costs borne by all honest operators, alongside the maintenance and infra costs that regularly arise from running a node.\n\nOur testing has demonstrated that the cost of running a sub-challenge in BoLD, the most computationally-heavy step, on an AWS r5.4xlarge EC2 instance, costs around $2.50 USD (~$1/hour for 1 challenge with 2.5hour duration) using on-demand prices for US East (N. Virginia). Therefore, the additional costs from off-chain compute is assumed to be negligible relative to the regular infra costs of operating a node.\n\nQ: How will BoLD impact Arbitrum Nova?​\n\nAlthough this AIP proposes that both Arbitrum One and Nova upgrade to use BoLD, we recommend for the removal of the allowlist of validators for Arbitrum One while keeping Nova permissioned with a DAO-controlled allowlist of entities - unchanged from today.\n\nThis decision was made for two reasons. First, Arbitrum Nova’s TVL is much lower than Arbitrum One’s TVL, (~$17B vs. ~$46M at the time of writing, from L2Beat). This means that the high bond sizes necessary for preventing spam and delay attacks would make up a significant proportion of Nova’s TVL - which we believe introduces a centralization risk as very few parties would be incentivized to secure Nova. A solution here would be to lower the bond sizes, which brings us to the second reason: lower bond sizes reduce the costs of delay grieving attacks (where malicious actors delay the chain’s progress) and therefore hurt the security of the chain. We believe enabling permissionless validation for Nova is not worth the capital requirement tradeoffs, given the unique security model of AnyTrust chains.\n\nNotably, since Arbitrum Nova's security already depends on at least one DAC member providing honest data availability, trusting the same committee to have at least one member provide honest validation does not add a major trust assumption. This requires all DAC members also to run validators. If the DAC is also validating the chain, a feature the Offchain Labs team has been working on, Fast Withdrawals, would allow users to withdraw assets from Nova in ~15 minutes, or the time it takes to reach L1 finality. This is made possible by the DAC attesting to and instantly confirming an assertion. Fast Withdrawals will be the subject of future forum post and snapshot vote.\n\nQ: When it comes to viewing the upfront assertion bond (to be a proposer) as the security budget for Arbitrum One, is it possible for an attacker to go above the security budget and, if yes, what happens then?​\n\nThe upfront capital to post assertions is 3600 ETH, with subsequent sub challenge assertions requiring 555/79 ETH (per level) - this applies to honest proposers as well as malicious entities. A malicious entity can post multiple invalid top level assertions and/or open multiple challenges and the honest entity can\n\nIt is critical to note that Arbitrum state transitions are entirely deterministic. An honest party bonded to the correct state assertion, the honest party will get all their costs refunded while a malicious entity stands to lose everything. Additionally, BoLD’s design ensures that any party bonded to the correct\n\nIf a malicious entity wanted to attack Arbitrum, they would need to deposit 3600 ETH to propose an invalid state assertion.\n\nQ: How do BoLD-based L3s challenge periods operate, considering the worst-case scenario?​\n\nTo recap, both Arbitrum’s current dispute protocol and BoLD require assertions to be posted to the parent chain and employ interactive proving, which involves a back-and-forth between two entities until a single step of disagreement is reached. That single step (of disagreement) is then submitted to contracts on the parent chain. Those contracts are used to declare a winner. For L2s, like Arbitrum One, BoLD must be deployed on a credibly-neutral, censorship-resistant backend to ensure disputes are fairly resolved. Ethereum, therefore, is the perfect candidate for deployment of the BoLD protocol for L2s.\n\nBut you might now be wondering: what about L3 Orbit chains that don’t settle to Ethereum? Unlike L2s that settle to Ethereum, assertions on an L3’s state need to be posted to an L2 either via (A) the L3 sequencer or (B) the delayed inbox queue managed by the L2 sequencer on L2. In the event that the parent chain (in this case, L2) is being repeatedly censored or if the L2 sequencer is offline, every block level assertion and/or sub-challenge assertion would need to wait 24 hours before they can bypass the sequencer (using the theSequencerInbox’s forceInclusion method described here). If this were to happen, challenge resolution would be delayed by a time t where t = (24 hours) * number of moves for a challenge. To illustrate with sample numbers, if a challenge takes 50 sequential moves to resolve, then the delay would be 50 days!\n\nTo mitigate the risk of this issue manifesting for Arbitrum chains, Offchain Labs has included a feature called Delay Buffer as part of BoLD’s 1.0.0 release. The Delay Buffer feature aims to limit the negative effects of: prolonged parent chain censorship, prolonged sequencer censorship, and/or unexpected sequencer outages. This is accomplished by implementing some time threshold that is decremented when unexpected delays occur. Once that time threshold is met, the force inclusion window is lowered - effectively enabling entities to make moves without the 24 hour delay-per-move.\n\nUnder reasonable parameterization, the sequencer could be offline / censoring for 24 hours twice, before the force inclusion window is effectively dropped from 24 hours to a minimum inclusion time. The force inclusion window gradually (over weeks) replenishes to it's original value over time as long as the sequencer is on \"good behavior\" - regularly sequencing messages without unexpected delays. We believe that the Delay Buffer feature provides stronger guarantees of censorship resistance for Arbitrum chains.\n\nThe methodology for calculating the parameters, specifically for L3 Orbit chains, will be made available at a later date for teams who wish to use BoLD.\n\nQ: What is the user flow for using the assertion bonding pool contract?​\n\nAnyone can deploy an assertion bonding pool using AssertionStakingPoolCreator.sol as a means to crowdsource funds to put up a bond for an assertion. To defend Arbitrum using a bonding pool, an entity would first deploy this pool with the assertion they believe is correct and wish to put up a bond to challenge an adversary's assertion. Then, anyone can verify that the claimed assertion is correct by running the inputs through their node's State Transition Function (STF). If other parties agree that the assertion is correct, then they can deposit their funds into the contract. When enough funds have been deposited, anyone can permissionlessly trigger the creation of the assertion on-chain to start the challenge. Finally, once the honest parties' assertion is confirmed by the dispute protocol, all involved entities can get their funds reimbursed and can withdraw. The Arbitrum Nitro node validation software also comes with an optional feature called \"auto pooling,\" where the entire workflow of assertion bonding pool deployment and depositing funds into the said pool are automated. If \"auto pooling\" is activated & the private key controlling the validator has funds, a pool will be trustlessly deployed alongside an assertion with the available funds. If a validator with the \"auto pooling\" feature enabled sees an assertion on-chain that it agrees with and a bonding pool already exists for that assertion, then the validator will automatically deposit funds into the bonding pool to \"join\" the others who are backing that on-chain assertion in a trustless manner.\n\nQ: What type of hardware will be necessary to run a BoLD validator?​\n\nThe minimum hardware requirements for running a BoLD validator is still being researched and finalized. The goal, however, is that regular consumer hardware (i.e. laptop) can effectively be used by an honest party to secure an Arbitrum chain using BoLD in the average case.\n\nQ: How do BoLD validators communicate with one another? Is it over a P2P network?​\n\nBoLD validators for Arbitrum chains communicate directly with smart contracts on L1 Ethereum. This means that opening challenges, submitting bisected history commitments, one-step proofs, and confirmations are all refereed on Ethereum. There is no p2p between validators.\n\nQ: For an L3 Orbit chain, secured using BoLD, that settles to Arbitrum One, does the one-step proof happen on the parent chain?​\n\nYes\n\nQ: For Arbitrum One, does implementing BoLD reduce the scope or remove the need for the Arbitrum Security Council?​\n\nBoLD can limit the scope of Arbitrum One and Nova’s reliance on the Security Council as it takes Arbitrum chains one-step closer to full decentralization.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nWAVM modules\nNext\nTechnical deep dive\nIn a nutshell:\nWhat exactly is BoLD?\nWhy does Arbitrum need a new dispute protocol?\nBoLD brings Arbitrum closer to being recognized as a Stage 2 rollup\nBoLD makes withdrawals to L1 Ethereum safer\nHow is this possible?\nWhat can I do with BoLD today?\nWen mainnet?\nFrequently asked questions about BoLD (FAQ):\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "WAVM Modules | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/fraud-proofs/wavm-modules",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nInteractive challenges\nOne step proof assumptions\nWasm To WAVM\nCustom WAVM opcodes\nWAVM floats\nWAVM modules\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nWAVM Modules\n\nWASM natively has a notion of modules. Normally, in WASM, a module is the entire program. A .wasm file represents one module, and generally they aren't combined. An exception to this is C compiled via Clang, where wasm files are also used as object files, but its linking scheme is not supported in other languages.\n\nIn WAVM this is extended to make the executing program composed of multiple modules. These may call each other, and library modules may write to their caller's memory to return results.\n\nThe entrypoint module​\n\nThe entrypoint module is where execution begins. It calls modules' start functions if specified, and then calls the main module's main function, which is language specific. For Go it sets argv to [\"js\"] to match the JS environment, and calls run. For Rust it calls main with no arguments.\n\nLibrary exports​\n\nLibraries may export functions with the name pattern module__name, which future libraries or the main module can import as \"module\" \"name\".\n\nFor instance, this is used for wasi-stub to provide functions rust imports according to the WebAssembly System Interface.\n\nFloating point operations​\n\nTo provide floating point operations for future libraries, the soft float library exports functions which perform floating point ops. These have the same name as the WASM instruction names, except . is replaced with _. Their type signature is also the same, except all f32s and f64s are bitcasted to i32s and i64s.\n\nFuture modules can implicitly use these by using WASM floating point operations, which are replaced at the WASM->WAVM level with bitcasts and cross module calls to these functions.\n\nWAVM guest calls​\n\nLibraries may call the main module's exports via \"env\" \"wavm_guest_call__*\".\n\nFor instance, go-stub calls Go's resume function when queueing async events via wavm_guest_call_resume(), and then retrieves the new stack pointer with wavm_guest_call_getsp().\n\nCaller module internals call​\n\nEvery stack frame retains its caller module and its caller module's \"internals offset\", which is the first internal function index. WAVM appends 4 \"internal\" functions to each module, which perform a memory load or store of 1 or 4 bytes.\n\nVia wavm_caller_{load,store}{8,32}, a library may access its caller's memory, which is implemented by calling these internal functions of the caller's module. Only libraries can access their caller's memory; the main module cannot.\n\nFor instance, this is used to read arguments from and write return values to the Go stack, when Go calls into go-stub.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nWAVM floats\nNext\nA gentle introduction\nThe entrypoint module\nLibrary exports\nFloating point operations\nWAVM guest calls\nCaller module internals call\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "WAVM Floating point implementation | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/fraud-proofs/wavm-floats",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nInteractive challenges\nOne step proof assumptions\nWasm To WAVM\nCustom WAVM opcodes\nWAVM floats\nWAVM modules\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nWAVM Floating point implementation\n\nImplementing correct, consistent, and deterministic floating point operations directly in WAVM (meaning both a Rust Arbitrator implementation and Solidity OSP implementation) would be an extremely tricky endeavor. WASM specifies floating point operations as being compliant to IEEE 754-2019, which is not deterministic, and full of edge cases.\n\nInstead, floating point operations (apart from trivial bit-casts like i32 <-> f32) are implemented using the C Berkeley SoftFloat-3e library running inside WAVM. Arbitrator links other WAVM guests against this, by replacing float point operations with cross module calls to the library.\n\nBerkeley SoftFloat does not implement all necessary floating point operations, however. Most importantly, it does not provide a min function, despite IEEE 754-2019 specifying one. The implementation of these operations, along with the export of convenient APIs for WASM opcode implementations, are contained in bindings32.c for 32 bit integers and bindings64.c for 64 bit integers.\n\nThis ensures that floating point operations are deterministic and consistent between Arbitrator and the OSP, as they are implemented exclusively using operations already known to be deterministic and consistent. However, it does not ensure that the floating point operations are perfectly compliant to the WASM specification. Go uses floating points in its JS<->Go WASM interface, and floating points may be used outside core state transition code for imprecise computations, but the former is well exercised as used in Nitro, and the latter generally doesn't rely on details like the minimum of NaN and infinity.\n\nKnown divergences from the WASM specification​\n\nFloating point to integer truncation will saturate on overflow, instead of erroring. This is generally safer, because on x86, overflowing simply produces an undefined result. A WASM proposal exists to add new opcodes which are defined to saturate, but it's not widely adopted.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nCustom WAVM opcodes\nNext\nWAVM modules\nKnown divergences from the WASM specification\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/fraud-proofs/wavm-custom-opcodes",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nInteractive challenges\nOne step proof assumptions\nWasm To WAVM\nCustom WAVM opcodes\nWAVM floats\nWAVM modules\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nWAVM Custom opcodes not in WASM\n\nIn addition to the MVP WASM specification, WAVM implements the multi value and sign extension ops WASM proposals.\n\nWAVM also implements the following unique opcodes, which are not part of WASM nor any WASM proposal.\n\nInvariants​\n\nMany of these opcodes have implicit invariants about what's on the stack, e.g. \"Pops an i32 from the stack\" assumes that the top of the stack has an i32. If these conditions are not satisfied, execution is generally not possible. These invariants are maintained by WASM validation and Arbitrator codegen. (See One Step Proof Assumptions.)\n\nCodegen internal​\n\nThese are generated when breaking down a WASM instruction that does many things into many WAVM instructions which each do one thing. For instance, a WASM local.tee is implemented in WAVM with dup and then local.set, the former of which doesn't exist in WASM.\n\nOther times, these opcodes help out an existing WASM opcode by splitting out functionality. For instance, the WAVM return opcode by itself does not clean up the stack, but its WASM->WAVM codegen includes a loop that utilizes IsStackBoundary to perform the stack cleanup specified for WASM's return.\n\nOpcode\tName\tDescription\n0x8000\tEndBlock\tPops an item from the block stack.\n0x8001\tEndBlockIf\tPeeks the top value on the stack, assumed an i32. If non-zero, pops an item from the block stack.\n0x8002\tInitFrame\tPops a caller module index i32, then a caller module internals offset i32, and finally a return InternalRef from the stack. Creates a stack frame with the popped info and the locals merkle root in proving argument data.\n0x8003\tArbitraryJumpIf\tPops an i32 from the stack. If non-zero, jumps to the program counter in the argument data.\n0x8004\tPushStackBoundary\tPushes a stack boundary to the stack.\n0x8005\tMoveFromStackToInternal\tPops an item from the stack and pushes it to the internal stack.\n0x8006\tMoveFromInternalToStack\tPops an item from the internal stack and pushes it to the stack.\n0x8007\tIsStackBoundary\tPops an item from the stack. If a stack boundary, pushes an i32 with value 1. Otherwise, pushes an i32 with value 0.\n0x8008\tDup\tPeeks an item from the stack and pushes another copy of that item to the stack.\n\nThe above opcodes eliminate the need for the following WASM opcodes (which are transpiled into other WAVM opcodes):\n\nloop\nif/else\nbr_table\nlocal.tee\nLinking​\n\nThis is only generated to link modules together. Each import is replaced with a local function consisting primarily of this opcode, which handles the actual work needed to change modules.\n\nOpcode\tName\tDescription\n0x8009\tCrossModuleCall\tPushes the current program counter, module number, and module's internals offset to the stack. Then splits its argument data into the lower 32 bits being a function index, and the upper 32 bits being a module index, and jumps to the beginning of that function.\nHost calls​\n\nThese are only used in the implementation of \"host calls\". Each of these has an equivalent host call method, which can be invoked from libraries. The exception is CallerModuleInternalCall, which is used for the implementation of all of the wavm_caller_* host calls. Those calls are documented in wavm-modules.mdx.\n\nFor these instruction descriptions, all pointers and offsets are represented as WASM i32s.\n\nOpcode\tName\tDescription\n0x800A\tCallerModuleInternalCall\tPushes the current program counter, module number, and module's internals offset (all i32s) to the stack. Then, it retrieves the caller module internals offset from the current stack frame. If 0, errors, otherwise, jumps to the caller module at function (internals offset + opcode argument data) and instruction 0.\n0x8010\tGetGlobalStateBytes32\tPops a pointer and then an index from the stack. If the index is greater than or equal to the number of global state bytes32s, errors. If the pointer mod 32 is not zero, errors. If the pointer + 32 is outside the programs memory, errors. Otherwise, writes the global state bytes32 value of the specified index to the specified pointer in memory.\n0x8011\tSetGlobalStateBytes32\tPops a pointer and then an index from the stack. If the index is greater than or equal to the number of global state bytes32s, errors. If the pointer mod 32 is not zero, errors. If the pointer + 32 is outside the programs memory, errors. Otherwise, reads a bytes32 from the specified pointer in memory and sets the global state bytes32 value of the specified index to it.\n0x8012\tGetGlobalStateU64\tPops a pointer and then an index from the stack. If the index is greater than or equal to the number of global state u64s, errors. If the pointer mod 32 is not zero, errors. If the pointer + 8 is outside the programs memory, errors. Otherwise, writes the global state u32 value of the specified index to the specified pointer in memory.\n0x8013\tSetGlobalStateU64\tPops a pointer and then an index from the stack. If the index is greater than or equal to the number of global state u64s, errors. If the pointer mod 32 is not zero, errors. If the pointer + 8 is outside the programs memory, errors. Otherwise, reads a u64 from the specified pointer in memory and sets the global state u64 value of the specified index to it.\n0x8020\tReadPreImage\tPops an offset and then a pointer from the stack. If the pointer mod 32 is not zero, errors. If the pointer + 32 is outside the programs memory, errors. Reads a 32 byte Keccak-256 hash from the specified pointer in memory. Writes up to 32 bytes of the preimage to that hash, beginning with the offset byte of the preimage. If offset is greater than or equal to the number of bytes in the preimage, writes nothing. Pushes the number of bytes written to the stack as an i32.\n0x8021\tReadInboxMessage\tPops an offset, then a pointer, and then an i64 message number from the stack. If the pointer mod 32 is not zero, errors. If the pointer + 32 is outside the programs memory, errors. Attempts to read an inbox message from the inbox identifier contained in the argument data (0 for the sequencer inbox, 1 for the delayed inbox) at the specified message number. If this exceeds the machine's inbox limit, enters the \"too far\" state. Otherwise, writes up to 32 bytes of the specified inbox message, beginning with the offset byte of the message. If offset is greater than or equal to the number of bytes in the preimage, writes nothing. Pushes the number of bytes written to the stack as an i32.\n0x8022\tHaltAndSetFinished\tSets the machine status to finished, halting execution and marking it as a success.\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nWasm To WAVM\nNext\nWAVM floats\nInvariants\nCodegen internal\nLinking\nHost calls\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/arbos/l1-l2-messaging",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nL1-to-L2 messaging\nL2-to-L1 messaging\nArbOS\nFraud proofs\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nL1 to L2 messaging\nRetryable Tickets​\n\nRetryable tickets are Arbitrum's canonical method for creating L1 to L2 messages, i.e., L1 transactions that initiate a message to be executed on L2. A retryable can be submitted for a fixed cost (dependent only on its calldata size) paid at L1; its submission on L1 is separable / asynchronous with its execution on L2. Retryables provide atomicity between the cross chain operations; if the L1 transaction to request submission succeeds (i.e. does not revert) then the execution of the Retryable on L2 has a strong guarantee to ultimately succeed as well.\n\nRetryable Tickets Lifecycle​\n\nHere we walk through the different stages of the lifecycle of a retryable ticket; (1) submission, (2) auto-redemption, and (3) manual redemption.\n\nSubmission​\nCreating a retryable ticket is initiated with a call (direct or internal) to the createRetryableTicket function of the inbox contract. A ticket is guaranteed to be created if this call succeeds. Here, we describe parameters that need to be carefully set. Note that, this function forces the sender to provide a reasonable amount of funds (at least enough to submitting, and attempting to executing the ticket), but that doesn't guarantee a successful auto-redemption.\nParameter\tDescription\nl1CallValue (also referred to as deposit)\tNot a real function parameter, it is rather the callValue that is sent along with the transaction\naddress to\tThe destination L2 address\nuint256 l2CallValue\tThe callvalue for retryable L2 message that is supplied within the deposit (l1CallValue)\nuint256 maxSubmissionCost\tThe maximum amount of ETH to be paid for submitting the ticket. This amount is (1) supplied within the deposit (l1CallValue) to be later deducted from sender's L2 balance and is (2) directly proportional to the size of the retryable’s data and L1 basefee\naddress excessFeeRefundAddress\tThe unused gas cost and submssion cost will deposit to this address, formula is: (gasLimit x maxFeePerGas - execution cost) + (maxSubmission - (autoredeem ? 0 : submission cost)). (Note: excess deposit will transfer to the alias address of the parent chain tx's msg.sender rather than this address)\naddress callValueRefundAddress\tThe L2 address to which the l2CallValue is credited if the ticket times out or gets cancelled (this is also called the beneficiary, who's got a critical permission to cancel the ticket)\nuint256 gasLimit\tMaximum amount of gas used to cover L2 execution of the ticket\nuint256 maxFeePerGas\tThe gas price bid for L2 execution of the ticket that is supplied within the deposit (l1CallValue)\nbytes calldata data\tThe calldata to the destination L2 address\n\nSender's deposit must be enough to make the L1 submission succeed and for the L2 execution to be attempted. If provided correctly, a new ticket with a unique TicketID is created and added to retryable buffer. Also, funds (submissionCost + l2CallValue) are deducted from the sender and placed into the escrow for later use in redeeming the ticket.\n\nTicket creation causes the ArbRetryableTx precompile to emit a TicketCreated event containing the TicketID on L2.\n\nno\nyes\n🧍\nInitiating an L1-L2 message\nEnough deposit?\nTicket creation fails\nTicket is created\nTicket Submission\n\n🧍 The user who initiates an L1-L2 message\n\nInitiating an L1-L2 message A call to inbox.createRetryableTicket function that puts the message in the L2 inbox that can be re-executed for some fixed amount of time if it reverts\n\nCheck user's deposit Logic that checks if the user have enough funds to create a ticket. This is done by checking if the msg.value provided by the user is greater than or equal to maxSubmissionCost + l2CallValue + gasLimit * maxFeePerGas\n\nTicket creation fails Ticket creation fails and no funds are deducted from the user\n\nTicket is created A ticket is created and added to the retryable buffer on L2 Funds (l2CallValue + submissionCost) are deducted to cover the callvalue from the user and placed into escrow (on L2) for later use in redeeming the ticket\n\nAutomatic Redemption​\nIt is very important to note that the submission of a ticket on L1 is separable / asynchronous from its execution on L2, i.e., a successful L1 ticket creation does not guarantee a successful redemption. Once the ticket is successfully created, the two following conditions are checked: (1) if the user's L2 balance is greater than (or equal to) maxFeePerGas * gasLimit and (2) if the maxFeePerGas (provided by the user in the ticket submission process) is greater than (or equal to) the l2Basefee. If these conditions are both met, ticket's submission is followed by an attempt to execute it on L2 (i.e., an auto-redeem using the supplied gas, as if the redeem method of the ArbRetryableTx precompile had been called). Depending on how much gas the sender has provided in step 1, ticket's redemption can either (1) immediately succeed or (2) fail. We explain both situations here:\n\nIf the ticket is successfully auto-redeemed, it will execute with the sender, destination, callvalue, and calldata of the original submission. The submission fee is refunded to the user on L2 (excessFeeRefundAddress). Note that to ensure successful auto-redeem of the ticket, one could use the Arbitrum SDK which provides a convenience function that returns the desired gas parameters when sending L1-L2 messages.\n\nIf a redeem is not done at submission or the submission's initial redeem fails (for example, because the L2 gas price has increased unexpectedly), the submission fee is collected on L2 to cover the resources required to temporarily keep the ticket in memory for a fixed period (one week), and only in this case, a manual redemption of the ticket is required (see next section).\n\nyes\nno\nAuto-redeem succeeds?\nTicket is executed\nTicket is deleted\ncallValueRefundAddress gets refunded\nAutomatic Redemption of the Ticket\n\nDoes the auto-redeem succeed? Logic that determines if the user's L2 Balance is greater than (or equal to) maxFeePerGas * gasLimit && maxFeePerGas is greater than (or equal to) the l2Basefee\n\nTicket is executed Ticket is executed, the actual submissionFee is refunded to the excessFeeRefundAddress since the ticket was not kept in the buffer on L2\n\nTicket is deleted Ticket gets deleted from the L2 retryable buffer\n\ncallValueRefundAddress gets refunded callValueRefundAddress gets refunded with (maxGas - gasUsed) * gasPrice. Note that this amount is capped by l1CallValue in the auto-redeem\n\nManual Redemption​\n\nAt this point, anyone can attempt to manually redeem the ticket again by calling ArbRetryableTx's redeem precompile method, which donates the call's gas to the next attempt. Note that the amount of gas is NOT limited by the original gasLimit set during the ticket creation. ArbOS will enqueue the redeem, which is its own special ArbitrumRetryTx type, to its list of redeems that ArbOS guarantees to exhaust before moving on to the next non-redeem transaction in the block its forming. In this manner redeems are scheduled to happen as soon as possible, and will always be in the same block as the tx that scheduled it. Note that the redeem attempt's gas comes from the call to redeem, so there's no chance the block's gas limit is reached before execution.\n\nIf the fixed period (one week) elapses without a successful redeem, the ticket expires and will be automatically discarded, unless some party has paid a fee to keep the ticket alive for another full period. A ticket can live indefinitely as long as it is renewed each time before it expires.\n\nyes\nno\nyes\nno\nTicket manually cancelled or not redeemed in 7 days?\ncallValueRefundAddress gets refunded\nTicket is deleted\nTicket manually redeemed?\nManual Redemption of the Ticket\n\nIs the ticket manually cancelled or not redeemed within 7 days? Logic that determines if the ticket is manually cancelled or not redeemed within 7 days (i.e., is expired)\n\ncallValueRefundAddress gets refunded callValueRefundAddress is refunded with the l2CallValue\n\nTicket is deleted Ticket gets deleted from the L2 retryable buffer\n\nIs the ticket manually redeemed Logic that determines if the ticket is manually redeemed\n\nAVOID LOSING FUNDS!\n\nIf a ticket expires after 7 days without being redeemed or re-scheduled to a future date, any message and value (other than the escrowed callvalue) it carries could be lost without possibility of being recovered.\n\nOn success, the To address receives the escrowed callvalue, and any unused gas is returned to ArbOS's gas pools. On failure, the callvalue is returned to the escrow for the future redeem attempt. In either case, the network fee was paid during the scheduling tx, so no fees are charged and no refunds are made.\n\nNote that during redemption of a ticket, attempts to cancel the same ticket, or to schedule another redeem of the same ticket, will revert. In this manner retryable tickets are not self-modifying.\n\nIf a ticket with a callvalue is eventually discarded (cancelled or expired), having never successfully run, the escrowed callvalue will be paid out to a callValueRefundAddress account that was specified in the initial submission (step 1).\n\nIMPORTANT NOTES:\n\nIf a redeem is not done at submission or the submission's initial redeem fails, anyone can attempt to redeem the retryable again by calling ArbRetryableTx's redeem precompile method, which donates the call's gas to the next attempt. ArbOS will enqueue the redeem, which is its own special ArbitrumRetryTx type, to its list of redeems that ArbOS guarantees to exhaust before moving on to the next non-redeem transaction in the block its forming. In this manner redeems are scheduled to happen as soon as possible, and will always be in the same block as the transaction that scheduled it. Note that the redeem attempt's gas comes from the call to redeem, so there's no chance the block's gas limit is reached before execution.\n\nOne can redeem live tickets using the Arbitrum Retryables Transaction Panel\nThe calldata of a ticket is saved on L2 until it is redeemed or expired\nRedeeming cost of a ticket will not increase over time, it only depends on the current gas price and gas required for execution\nReceipts​\n\nIn the lifecycle of a retryable ticket, two types of L2 transaction receipts will be emitted:\n\nTicket Creation Receipt: This receipt indicates that a ticket was successfully created; any successful L1 call to the Inbox's createRetryableTicket method is guaranteed to create a ticket. The ticket creation receipt includes a TicketCreated event (from ArbRetryableTx), which includes a ticketId field. This ticketId is computable via RLP encoding and hashing the transaction; see calculateSubmitRetryableId.\nRedeem Attempt: A redeem attempt receipt represents the result of an attempted L2 execution of a ticket, i.e, success / failure of that specific redeem attempt. It includes a RedeemScheduled event from ArbRetryableTx, with a ticketId field. At most, one successful redeem attempt can ever exist for a given ticket; if, e.g., the auto-redeem upon initial creation succeeds, only the receipt from the auto-redeem will ever get emitted for that ticket. If the auto-redeem fails (or was never attempted — i.e., the provided L2 gas limit * L2 gas price = 0), each initial attempt will emit a redeem attempt receipt until one succeeds.\nAlternative \"unsafe\" Retryable Ticket Creation​\n\nThe Inbox.createRetryableTicket convenience method includes sanity checks to help minimize the risk of user error: the method will ensure that enough funds are provided directly from L1 to cover the current cost of ticket creation. It also will convert the provided callValueRefundAddress and excessFeeRefundAddress to their address alias (see below) if either is a contract (determined by if the address has code during the call), providing a path for the L1 contract to recover funds. A power-user may bypass these sanity-check measures via the Inbox's unsafeCreateRetryableTicket method; as the method's name desperately attempts to warn you, it should only be accessed by a user who truly knows what they're doing.\n\nEth deposits​\n\nA special message type exists for simple Eth deposits; i.e., sending Eth from L1 to L2. Eth can be deposited via a call to the Inbox's depositEth method. If the L1 caller is EOA, the Eth will be deposited to the same EOA address on L2; the L1 caller is a contract, the funds will deposited to the contract's aliased address (see below).\n\nNote that depositing Eth via depositEth into a contract on L2 will not trigger the contract's fallback function.\n\nIn principle, retryable tickets can alternatively be used to deposit Ether; this could be preferable to the special eth-deposit message type if, e.g., more flexibility for the destination address is needed, or if one wants to trigger the fallback function on the L2 side.\n\nTransacting via the Delayed Inbox​\n\nWhile retryables and Eth deposits must be submitted through the delayed inbox, in principle, any message can be included this way; this is a necessary recourse to ensure the Arbitrum chain preserves censorship resistance even if the Sequencer misbehaves (see The Sequencer and Censorship Resistance). However, under ordinary/happy circumstances, the expectation/recommendation is that clients use the delayed inbox only for Retryables and Eth deposits, and transact via the Sequencer for all other messages.\n\nAddress Aliasing​\n\nUnsigned messages submitted via the Delayed Inbox get their sender's addressed \"aliased\": when these messages are executed on L2, the sender's address —i.e., that which is returned by msg.sender — will not simply be the L1 address that sent the message; rather it will be the address's \"L2 Alias.\" An address's L2 alias is its value increased by the hex value 0x1111000000000000000000000000000000001111:\n\nL2_Alias = L1_Contract_Address + 0x1111000000000000000000000000000000001111\n\nTRY IT OUT\n\nThe Arbitrum protocol's usage of L2 Aliases for L1-to-L2 messages prevents cross-chain exploits that would otherwise be possible if we simply reused the same L1 addresses as the L2 sender; i.e., tricking an L2 contract that expects a call from a given contract address by sending retryable ticket from the expected contract address on L1.\n\nIf for some reason you need to compute the L1 address from an L2 alias on chain, you can use our AddressAliasHelper library:\n\nmodifier onlyFromMyL1Contract() override {\n    require(AddressAliasHelper.undoL1ToL2Alias(msg.sender) == myL1ContractAddress, \"ONLY_COUNTERPART_CONTRACT\");\n    _;\n}\n\nSigned Messages​\n\nThe delayed inbox can also accept messages that include a signature. In this case, the message will execute with the msg.sender address equal to the address that produced the included signature (i.e., not its alias). Intuitively, the signature proves that the sender address is not a contract, and thus is safe from cross-chain exploit concerns described above. Thus, it can safely execute from signer's address, similar to a transaction included in a Sequencer's batch. For these messages, the address of the L1 sender is effectively ignored at L2.\n\nThese signed messages submitted through the delayed inbox can be used to execute messages that bypass the Sequencer and require EOA authorization at L2, e.g., force-including an Ether withdrawal (see \"withdraw eth tutorial\").\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nNitro vs. Classic\nNext\nL2-to-L1 messaging\nRetryable Tickets\nRetryable Tickets Lifecycle\nSubmission\nAutomatic Redemption\nManual Redemption\nReceipts\nAlternative \"unsafe\" Retryable Ticket Creation\nEth deposits\nTransacting via the Delayed Inbox\nAddress Aliasing\nSigned Messages\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "The Assertion Tree | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/assertion-tree",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nThe Assertion Tree\nOverview​\n\nThe state of an Arbitrum chain is confirmed back on Ethereum via \"assertions,\" aka \"disputable assertions\" or \"DAs.\" These are claims made by Arbitrum validators about the chain's state. To make an assertion, a validator must post a bond in Ether.\n\nIn the happy / common case, all outstanding assertions will be valid; i.e., a valid assertion will build on another valid assertion, which builds on another valid assertion, and so on. After the dispute period (~ 1 week) passes and an assertion goes unchallenged, it can be confirmed back on L1.\n\nIf, however, two or more conflicting assertions exist, the Assertion Tree bifurcates into multiple branches:\n\nCrucially, the rules of advancing an Arbitrum chain are deterministic; this means that given a chain state and some new inputs, there is only one valid output. Thus, if the Assertion Tree contains more than one leaf, then at most only one leaf can represent the valid chain-state; if we assume there is at least one honest active validator, exactly one leaf will be valid.\n\nTwo conflicting assertions can be put into a dispute; see Interactive Challenges for details on the dispute process. For the sake of understanding the Assertion Tree protocol, suffice it to say that 2-party disputes last at most a fixed amount of time (1 week), at the end of which one of the two conflicting assertions will be rejected, and the validator who posted it will lose their stake.\n\nIn order for an assertion to be confirmed and for its stake to be recovered, two conditions must be met: sufficient time for disputes must have passed, and no other conflicting branches in the Assertion Tree can exist (i.e., they've all been disputed / \"pruned\" off.)\n\nThese properties together ensure that as long as at least one honest, active validator exists, the valid chain state will ultimately be confirmed.\n\nDelays​\n\nEven if the Assertion Tree has multiple conflicting leaves and, say, multiple disputes are in progress, validators can continue making assertions; honest validators will simply build on the one valid leaf (intuitively: an assertion is also an implicit claim of the validity of all of its parent-assertions.) Likewise, users can continue transacting on L2, since transactions continue to be posted in the chain's inbox.\n\nThe only delay that users experience during a dispute is of their L2 to L1 messages (i.e., \"their withdrawals\"). Note that a \"delay attacker\" who seeks to grief the system by deliberately causing such delays will find this attack quite costly, since each bit of delay-time gained requires the attacker lose another stake.\n\nDetailed Spec​\n\nFor a more detailed breakdown / specification of the assertion tree protocol, see Inside Arbitrum.\n\nEdit this page\nLast updated on Nov 22, 2024\nPrevious\nDeep dive: Inside Arbitrum\nNext\nNitro vs. Classic\nOverview\nDelays\nDetailed Spec\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/fraud-proofs/wasm-wavm",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nInteractive challenges\nOne step proof assumptions\nWasm To WAVM\nCustom WAVM opcodes\nWAVM floats\nWAVM modules\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nWASM to WAVM\n\nNot all WASM instructions are 1:1 with WAVM opcodes. This document lists those which are not, and explains how they're expressed in WAVM. Many of the WAVM representations use opcodes not in WASM, which are documented in wavm-custom-opcodes.mdx.\n\nblock and loop​\n\nIn WASM, a block contains instructions. Branch instructions exit a fixed number of blocks, jumping to their destination. A normal block's destination is the end of the block, whereas a loop's destination is the start of the loop.\n\nIn WAVM, instructions are flat. At transpilation time, any branch instructions are replaced with jumps to the corresponding block's destination. This means that WAVM interpreters don't need to track blocks, and thus block instructions are unnecessary.\n\nif and else​\n\nThese are translated to a block with an ArbitraryJumpIf as follows:\n\nbegin block with endpoint end\n  conditional jump to else\n  [instructions inside if statement]\n  branch\n  else: [instructions inside else statement]\nend\n\nbr and br_if​\n\nbr and br_if are translated into ArbitraryJump and ArbitraryJumpIf respectively. The jump locations can be known at transpilation time, making blocks obsolete.\n\nbr_table​\n\nbr_table is translated to a check for each possible branch in the table, and then if none of the checks hit, a branch of the default level.\n\nEach of the non-default branches has a conditional jump to a section afterwards, containing a drop for the selector, and then a jump to the target branch.\n\nlocal.tee​\n\nlocal.tee is translated to a WAVM Dup and then a LocalSet.\n\nreturn​\n\nTo translate a return, the number of return values must be known from the function signature. A WAVM MoveFromStackToInternal is added for each return value. Then, a loop checks IsStackBoundary (which implicitly pops a value) until it's true and the stack boundary has been popped. Next, a MoveFromInternalToStack is added for each return value to put the return values back on the stack. Finally, a WAVM Return is added, returning control flow to the caller.\n\nFloating point instructions​\n\nA floating point library module must be present to translate floating point instructions. They are translated by bitcasting f32 and f64 arguments to i32s and i64s, then a cross module call to the floating point library, and finally bitcasts of any return values from i32s and i64s to f32s and f64s.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nOne step proof assumptions\nNext\nCustom WAVM opcodes\nblock and loop\nif and else\nbr and br_if\nbr_table\nlocal.tee\nreturn\nFloating point instructions\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "One Step Proof Assumptions | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/fraud-proofs/osp-assumptions",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nInteractive challenges\nOne step proof assumptions\nWasm To WAVM\nCustom WAVM opcodes\nWAVM floats\nWAVM modules\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nOne Step Proof Assumptions\n\nThe One Step Proof (OSP) implementation makes certain assumptions about the cases that can arise in a correct execution. This documents those assumptions about what's being executed.\n\nIf a case is \"unreachable\", that is, the case is assumed to never arise in correct execution, then the OSP can implement any instruction semantics in that case.\n\nIn a challenge between malicious parties, any case can arise. The challenge protocol must do something safe in every case. But the instruction semantics can be weird in such cases because if both parties to a challenge are malicious, the protocol doesn't care who wins the challenge.\nIn a challenge with one honest party, the honest party will never need to one-step prove an unreachable case. The honest party will only assert correct executions, so it will only have to prove reachable cases.\nIn a challenge with one honest party, the dishonest party could assert an execution that transitions into an unreachable case, but such an execution must include an invalid execution of a reachable case earlier in the assertion. Because a challenge involving an honest party will eventually require an OSP over the first instruction where the parties disagree, the eventual OSP will be over the earlier point of divergence, and not over the later execution from an unreachable case.\n\nIn general, some unreachable cases will be detectable by the OSP checker and some will not. For safety, the detectable unreachable cases should be defined by transition the machine into an error state, allowing governance to eventually push an upgrade to recover from the error. An undetectable unreachable case, if such a case were reached in correct execution, could lead to a security failure.\n\nThe following assumptions, together, must prevent an unreachable case from arising in correct execution.\n\nThe WAVM code is generated by Arbitrator from valid WASM​\n\nWAVM is the name of the custom instruction set similar to WASM used for proving. Arbitrator transpiles WASM code into WAVM. It also invokes wasm-validate from wabt (the WebAssembly Binary Toolkit) to ensure the input WASM is valid. WAVM produced otherwise may not be executable, as it may try to close a non-existent block, mismatch types, or do any other number of invalid things which are prevented by WASM validation.\n\nWAVM code generated from by Arbitrator from valid WASM is assumed to never encounter an unreachable case.\n\nInbox messages must not be too large​\n\nThe current method of inbox hashing requires the full inbox message be available for proving. That message must not be too large as to prevent it from being supplied for proving, which is enforced by the inboxes.\n\nThe current length limit is 117,964 bytes, which is 90% of the max transaction size Geth will accept, leaving 13,108 bytes for other proving data.\n\nRequested preimages must be known and not too large​\n\nWAVM has an opcode which resolves the preimage of a Keccak-256 hash. This can only be executed if the preimage is already known to all nodes, and can only be proven if the preimage isn't too long. Violations of this assumption are undetectable by the OSP checker.\n\nThe current length limit is 117,964 bytes for the reasons mentioned above. Here's a list of which preimages may be requested by Nitro, and why they're known to all parties, and not too large:\n\nBlock headers​\n\nNitro may request up to the last 256 L2 block headers. The last block header is required to determine the current state, and blocks before it are required to implement the BLOCKHASH evm instruction.\n\nThis is safe as previous block headers are a fixed size, and are known to all nodes.\n\nState trie access​\n\nTo resolve state, Nitro traverses the state trie by resolving preimages.\n\nThis is safe as validators retain archive state of unconfirmed blocks, each trie branch is of a fixed size, and the only variable sized entry in the trie is contract code, which is limited by EIP-170 to about 24KB.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nInteractive challenges\nNext\nWasm To WAVM\nThe WAVM code is generated by Arbitrator from valid WASM\nInbox messages must not be too large\nRequested preimages must be known and not too large\nBlock headers\nState trie access\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "ArbOS | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/arbos/introduction",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nArbOS\nGeth\nFraud proofs\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nArbOS\n\nArbOS is the Layer 2 EVM hypervisor that facilitates the execution environment of L2 Arbitrum. ArbOS accounts for and manages network resources, produces blocks from incoming messages, and operates its instrumented instance of Geth for smart contract execution.\n\nPrecompiles​\n\nArbOS provides L2-specific precompiles with methods smart contracts can call the same way they can solidity functions. Visit the precompiles conceptual page for more information about how these work, and the precompiles reference page for a full reference of the precompiles available in Arbitrum chains.\n\nA precompile consists of a solidity interface in contracts/src/precompiles/ and a corresponding Golang implementation in precompiles/. Using Geth's ABI generator, solgen/gen.go generates solgen/go/precompilesgen/precompilesgen.go, which collects the ABI data of the precompiles. The runtime installer uses this generated file to check the type safety of each precompile's implementer.\n\nThe installer uses runtime reflection to ensure each implementer has all the right methods and signatures. This includes restricting access to stateful objects like the EVM and statedb based on the declared purity. Additionally, the installer verifies and populates event function pointers to provide each precompile the ability to emit logs and know their gas costs. Additional configuration like restricting a precompile's methods to only be callable by chain owners is possible by adding precompile wrappers like ownerOnly and debugOnly to their installation entry.\n\nThe calling, dispatching, and recording of precompile methods are done via runtime reflection as well. This avoids any human error manually parsing and writing bytes could introduce, and uses Geth's stable APIs for packing and unpacking values.\n\nEach time a transaction calls a method of an L2-specific precompile, a call context is created to track and record the gas burnt. For convenience, it also provides access to the public fields of the underlying TxProcessor. Because sub-transactions could revert without updates to this struct, the TxProcessor only makes public that which is safe, such as the amount of L1 calldata paid by the top level transaction.\n\nMessages​\n\nAn L1IncomingMessage represents an incoming sequencer message. A message includes one or more user transactions depending on load, and is made into a unique L2 block. The L2 block may include additional system transactions added in while processing the message's user transactions, but ultimately the relationship is still bijective: for every L1IncomingMessage there is an L2 block with a unique L2 block hash, and for every L2 block after chain initialization there was an L1IncomingMessage that made it. A sequencer batch may contain more than one L1IncomingMessage.\n\nRetryables​\n\nA Retryable is a special message type for creating atomic L1 to L2 messages; for details, see L1 To L2 Messaging.\n\nArbOS State​\n\nArbOS's state is viewed and modified via ArbosState objects, which provide convenient abstractions for working with the underlying data of its backingStorage. The backing storage's keyed subspace strategy makes possible ArbosState's convenient getters and setters, minimizing the need to directly work with the specific keys and values of the underlying storage's stateDB.\n\nBecause two ArbosState objects with the same backingStorage contain and mutate the same underlying state, different ArbosState objects can provide different views of ArbOS's contents. Burner objects, which track gas usage while working with the ArbosState, provide the internal mechanism for doing so. Some are read-only, causing transactions to revert with vm.ErrWriteProtection upon a mutating request. Others demand the caller have elevated privileges. While yet others dynamically charge users when doing stateful work. For safety the kind of view is chosen when OpenArbosState() creates the object and may never change.\n\nMuch of ArbOS's state exists to facilitate its precompiles. The parts that aren't are detailed below.\n\narbosVersion, upgradeVersion and upgradeTimestamp​\n\nArbOS upgrades are scheduled to happen when finalizing the first block after the upgradeTimestamp.\n\nblockhashes​\n\nThis component maintains the last 256 L1 block hashes in a circular buffer. This allows the TxProcessor to implement the BLOCKHASH and NUMBER opcodes as well as support precompile methods that involve the outbox. To avoid changing ArbOS state outside of a transaction, blocks made from messages with a new L1 block number update this info during an InternalTxUpdateL1BlockNumber ArbitrumInternalTx that is included as the first transaction in the block.\n\nl1PricingState​\n\nIn addition to supporting the ArbAggregator precompile, the L1 pricing state provides tools for determining the L1 component of a transaction's gas costs. This part of the state tracks both the total amount of funds collected from transactions in L1 gas fees, as well as the funds spent by batch posters to post data batches on L1.\n\nBased on this information, ArbOS maintains an L1 data fee, also tracked as part of this state, which determines how much transactions will be charged for L1 fees. ArbOS dynamically adjusts this value so that fees collected are approximately equal to batch posting costs, over time.\n\nl2PricingState​\n\nThe L2 pricing state tracks L2 resource usage to determine a reasonable L2 gas price. This process considers a variety of factors, including user demand, the state of Geth, and the computational speed limit. The primary mechanism for doing so consists of a pair of pools, one larger than the other, that drain as L2-specific resources are consumed and filled as time passes. L1-specific resources like L1 calldata are not tracked by the pools, as they have little bearing on the actual work done by the network actors that the speed limit is meant to keep stable and synced.\n\nWhile much of this state is accessible through the ArbGasInfo and ArbOwner precompiles, most changes are automatic and happen during block production and the transaction hooks. Each of an incoming message's transactions removes from the pool the L2 component of the gas it uses, and afterward the message's timestamp informs the pricing mechanism of the time that's passed as ArbOS finalizes the block.\n\nArbOS's larger gas pool determines the per-block gas limit, setting a dynamic upper limit on the amount of compute gas an L2 block may have. This limit is always enforced, though for the first transaction it's done in the GasChargingHook to avoid sharp decreases in the L1 gas price from over-inflating the compute component purchased to above the gas limit. This improves UX by allowing the first transaction to succeed rather than requiring a resubmission. Because the first transaction lowers the amount of space left in the block, subsequent transactions do not employ this strategy and may fail from such compute-component inflation. This is acceptable because such transactions are only present in cases where the system is under heavy load and the result is that the user's transaction is dropped without charges since the state transition fails early. Those trusting the sequencer can rely on the transaction being automatically resubmitted in such a scenario.\n\nThe reason we need a per-block gas limit is that Arbitrator WAVM execution is much slower than native transaction execution. This means that there can only be so much gas -- which roughly translates to wall-clock time -- in an L2 block. It also provides an opportunity for ArbOS to limit the size of blocks should demand continue to surge even as the price rises.\n\nArbOS's per-block gas limit is distinct from Geth's block limit, which ArbOS sets sufficiently high so as to never run out. This is safe since Geth's block limit exists to constrain the amount of work done per block, which ArbOS already does via its own per-block gas limit. Though it'll never run out, a block's transactions use the same Geth gas pool to maintain the invariant that the pool decreases monotonically after each tx. Block headers use the Geth block limit for internal consistency and to ensure gas estimation works. These are both distinct from the gasLeft variable, which ephemerally exists outside of global state to both keep L2 blocks from exceeding ArbOS's per-block gas limit and to deduct space in situations where the state transition failed or used negligible amounts of compute gas. ArbOS does not need to persist gasLeft because it is its pool that induces a revert and because transactions use the Geth block limit during EVM execution.\n\nEdit this page\nLast updated on Nov 22, 2024\nPrevious\nL2-to-L1 messaging\nNext\nGeth\nPrecompiles\nMessages\nRetryables\nArbOS State\narbosVersion, upgradeVersion and upgradeTimestamp\nblockhashes\nl1PricingState\nl2PricingState\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Nitro vs. Classic | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/why-nitro",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nNitro vs. Classic\n\nWhy Nitro?\n\nNitro represents the latest step in the evolution of Arbitrum technology; it is an upgrade from the tech stack first released on the mainnet Arbitrum One chain, which we now refer to as “Arbitrum Classic” (and several steps beyond what was described in the initial Arbitrum whitepaper back in 2018). Here, we’ll explain the rationale behind the Nitro upgrade, and outline Nitro’s core benefits over the classic system.\n\nViewed from a distance, the Classic and Nitro systems do similar things: both seek to create an execution environment as close to the EVM as possible which operates as a second layer to Ethereum; i.e., safety of the L2 virtual machine’s state updates can be guaranteed and enforced via succinct fraud proofs on Ethereum itself.\n\nIn Arbitrum Classic, this was achieved via a custom-made virtual machine, which we call the Arbitrum Virtual Machine (AVM). The implementation of Arbitrum’s L2 state machine—known as “ArbOS” — is effectively a program that is compiled and uploaded to the AVM; ArbOS includes (among other things) the ability to emulate EVM execution.\n\nIn Nitro, instead of using the AVM for low-level instructions, we use WebAssembly (Wasm). Since Go code can be compiled down to Wasm, we can implement the ArbOS program in Go, and include within it (as a sub-module) Geth itself, the most widely used Ethereum implementation.\n\nThis architecture—in which Geth’s EVM implementation can be used directly—is Nitro’s defining feature, and is principally what we’re talking about when we talk about “Nitro.” Most of Nitro’s benefits are a direct or indirect consequence of this design choice. We can summarize these benefits as follows: lower fees, better Ethereum compatibility, and simplicity.\n\nLower Fees​\n(Optimistic)^2 Execution​\n\nTo understand the core of Nitro’s efficiency, we have to dig a little deeper into the classic AVM. In classic, high-level code (Solidity, Vyper, etc.) would be initially compiled down to the EVM bytecode (as though it were to be deployed on Ethereum). This bytecode would then be transpiled to its corresponding AVM instructions by ArbOS; this AVM bytecode would function both as the instructions for running the L2 VM, and the inputs used to prove fraud; in an interactive fraud proof, two validators dissect a segment of AVM bytecode until a “one step proof” — i.e., a state transition that represents a single AVM opcode — would be executed in the EVM of the L1 itself.\n\nNitro has a similar bytecode-sandwich-like structure; to prove fraud in Nitro, the node’s Go code is compiled into WebAssembly (Wasm), the individual instructions of which are ultimately similarly dissected over to zero-in on an invalid state update. There is, however, a crucial difference: Nitro, being essentially the EVM, periodically produces Ethereum-esque blocks; we can think of these blocks as natural state-checkpoints within a larger assertion of an L2 state update. Nitro takes advantage of this by splitting the interactive fraud proof game into 2 phases: first, two disputing parties narrow down their disagreement to a single block; then (and only then) do they compile the block to Wasm, and thereby continue to narrow down their dispute to Wasm instruction. Thus, this Wasm compilation step only needs to happen when a dispute occurs.\n\nIt’s worth reiterating this distinction: in classic, the code executed in the happy/common case is equivalent to the code used in a fraud proof, whereas in Nitro, we can have different contexts for the two cases for execution and for proving. When a claim is being disputed, we ultimately compile down to Wasm bytecode, but in the happy/common case, we can execute the node’s Go code natively, i.e., in whatever execution environment one’s machine uses. Essentially, Nitro is capable of being even more “optimistic” in its execution, compiling to Wasm only just-in-time as required. The common case of native execution is happily far faster and more performant, and better node performance, of course, translates to lower fees for end users.\n\nCalldata Compression​\n\nTypically, the bulk of an Arbitrum Rollup transaction’s fee is covering the cost to post its data on Ethereum. Fundamentally, any rollup must post data on L1 sufficient for reconstruction and validation of the L2 state; beyond that, L2s can be flexible in deciding on what data format to use. Given the relatively high cost of posting data to L1, a natural optimization is to (losslessly) compress data before posting it on L1, and have the L2 environment handle decompressing it.\n\nThe flexibility that Arbitrum core architecture offers meant that even in the classic AVM, such decompression could have been implemented in principle. However, given that the AVM was custom-built for Arbitrum, this would have meant building a custom, hand-rolled implementation of a compression algorithm, which, practically speaking, represented a prohibitively high technical risk.\n\nThe Nitro architecture, however, fundamentally requires only that its VM can be compiled down to Wasm; so not just Geth, but any Go code can be incorporated. Thus, Nitro can (and does) use widely used, battle-tested compression libraries for calldata compression, and thus significantly reduces the cost of posting transaction batches.\n\nNote that supporting calldata compression also requires a more sophisticated mechanism for determining the price of calldata and ensuring that batch posters are ultimately properly compensated, a mechanism which Nitro also introduces.\n\nCloser EVM Compatibility​\n\nThe classic AVM achieved a strong degree of EVM compatibility with its ability to handle any EVM opcodes. However, being a distinct VM, the AVM’s internal behavior in some ways diverged with that of the EVM. Most noticeable for smart contract developers was the denomination of “ArbGas”, whose units didn’t correspond to Ethereum L1 gas; e.g., a simple transfer takes 21,000 gas on L1 but over 100,000 ArbGas in the AVM. This meant that contracts that included gas calculation logic that were initially built for L1 had to be modified accordingly to be deployed on L2, and likewise with any client-side tooling with similar hardcoded expectations about a chain’s gas. With Nitro, gas on L1 and L2 essentially correspond 1:1.\n\n(Note that transactions have to cover the total cost of both L2 execution and L1 calldata; the value returned by Arbitrum nodes' eth_estimateGas RPC — and in turn, the value users will see in their wallets — is calculated to be sufficient to cover this total cost. See 2-D fees for more.)\n\nAdditionally, node functionality peripheral to execution itself, but still important / expected by much tooling and infrastructure — e.g. support for transaction tracing — is essentially inherited out-of-the-box in Nitro, giving Nitro stronger compatibility with Ethereum not just within its virtual machine, but also with how clients interact with it.\n\nIn short, there’s no better way to achieve Ethereum compatibility than to reuse the Ethereum software itself.\n\nSimplicity​\n\nHaving code that is as simple and easy to reason about as possible is important for L2 systems, which are inevitably complex. The classic stack represents a large codebase built in-house, which requires a fair amount of time and overhead to understand. The AVM together with ArbOS effectively constitute a full blockchain protocol built from the ground up. Since the AVM was custom-built, with no high-level languages yet created for it, the ArbOS logic had to be implemented in what was essentially a custom language — called “mini” — along with a mini-to-AVM compiler.\n\nNitro’s direct usage of Geth means most of the work of creating an L2 VM is inherited right out of the box. The ArbOS custom logic (which, happily, can now be written in Go instead of mini), is much slimmer than in the classic stack; since the work of emulating the EVM is now handled by the Geth software, ArbOS needs only to implement the things specific and necessary for layer 2 (i.e., L1/L2 gas accounting, special message types for cross-chain transactions, etc.) Leaner, simpler code — much of which directly inherits engineering hours that have been put into an Ethereum-Geth itself — makes it a system that’s far more accessible for auditors and contributors, giving us strong confidence in its implementation security that will only harden as the ecosystem grows.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nAssertion tree\nNext\nL1-to-L2 messaging\nLower Fees\nCloser EVM Compatibility\nSimplicity\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "RPC endpoints and providers | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/reference/node-providers",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nRPC endpoints and providers\nContract addresses\nChain parameters\nDevelopment frameworks\nWeb3 libraries and tools\nMonitoring tools and block explorers\nDebugging tools\nMainnet risks\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nRPC endpoints and providers\nArbitrum public RPC endpoints​\nCAUTION\nUnlike the RPC Urls, the Sequencer endpoints only support eth_sendRawTransaction and eth_sendRawTransactionConditional calls.\nArbitrum public RPCs do not provide Websocket support.\nVisit Quicknode's Arbitrum Sepolia faucet for testnet Sepolia tokens on L2.\n\nThis section provides an overview of the available public RPC endpoints for different Arbitrum chains and necessary details to interact with them.\n\nName\tRPC Url(s)\tChain ID\tBlock explorer\tUnderlying chain\tTech stack\tSequencer feed URL\tSequencer endpoint⚠️\nArbitrum One\thttps://arb1.arbitrum.io/rpc\t42161\tArbiscan, Blockscout\tEthereum\tNitro (Rollup)\twss://arb1.arbitrum.io/feed\thttps://arb1-sequencer.arbitrum.io/rpc\nArbitrum Nova\thttps://nova.arbitrum.io/rpc\t42170\tArbiscan, Blockscout\tEthereum\tNitro (AnyTrust)\twss://nova.arbitrum.io/feed\thttps://nova-sequencer.arbitrum.io/rpc\nArbitrum Sepolia (Testnet)\thttps://sepolia-rollup.arbitrum.io/rpc\t421614\tArbiscan, Blockscout\tSepolia\tNitro (Rollup)\twss://sepolia-rollup.arbitrum.io/feed\thttps://sepolia-rollup-sequencer.arbitrum.io/rpc\nMORE RPC ENDPOINTS\n\nMore Arbitrum chain RPC endpoints can be found in Chain Connect: Arbitrum One and Arbitrum Nova.\n\nAlternatively, to interact with public Arbitrum chains, you can rely on many of the same popular node providers that you are already using on Ethereum:\n\nThird-party RPC providers​\nWANT TO BE LISTED HERE?\n\nComplete this form , if you'd like to see your project added to this list (and the Arbitrum portal).\n\nProvider\tArb One?\tArb Nova?\tArb Sepolia?\tWebsocket?\tStylus Tracing?\n1RPC\t✅\t\t\t\t\nAlchemy\t✅\t✅\t✅\t✅\tAvailable on paid plans\nAllnodes\t✅\t✅\t\t✅\t\nAnkr\t✅\t\t\t✅\tAvailable on paid plans\nBlast\t✅\t✅\t\t✅\t\nBlockPi\t✅\t✅\t\t\t\nBlockVision\t✅\t\t\t\t\nChainbase\t✅\t\t\t✅\t\nChainnodes\t✅\t\t\t\t\nChainstack\t✅\t\t\t✅\tAvailable on paid plans\nDataHub\t✅\t\t\t\t\nDRPC\t✅\t✅\t\t✅\t\nGetBlock\t✅\t\t\t✅\t\nInfura\t✅\t\t✅\t✅\tEnabled on request\nLava\t✅\t✅\t\t\t\nMoralis\t✅\t\t\t\t\nNirvana Labs\t✅\t✅\t✅\t✅\t\nNodeReal\t✅\t✅\t\t\t\nNOWNodes\t✅\t\t\t\t\nPocket Network\t✅\t\t\t\t\nQuicknode\t✅\t✅\t✅\t✅\tTestnet supported in free tier\nUnifra\t✅\t\t\t\t\nTenderly\t✅\t✅\t✅\t✅\tTestnet supported in free tier\nLast updated on Nov 18, 2024\nPrevious\nUse the custom gateway\nNext\nContract addresses\nArbitrum public RPC endpoints\nThird-party RPC providers\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Troubleshooting: Run a node | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/troubleshooting",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nTroubleshooting: Run a node\n\nThe guidance displayed on this page will change based on your selected configuration:\n\nOperating system:\nLinux, MacOS, Arm64\nWindows\nNetwork:\nArbitrum One (Nitro)\nArbitrum One (Classic)\nArbitrum Nova\nArbitrum Sepolia\nLocalhost\nNode type:\nFull node\nArchive node\nValidator node\nTHANK YOU!\n\nAt the end of this troubleshooting guide, you'll find a \"Generate troubleshooting report\" button. Clicking this button will generate a report that includes your selected configuration. You can include this report when asking for help.\n\nUsing this page to generate a troubleshooting report is helpful because it gathers the information that we need in order to resolve your issue.\n\nStep 1: Try the troubleshooting checklist​\n\nIf you're running into unexpected outputs or errors, the following checklist may help you independently resolve your issue.\n\n\t\n1. Select an Operating system, Network, and Node type above\n\nThe guidance displayed on this page will change based on your selected configuration.\n\n\t\n2. Review the docs\n\nThe How to run a full node (Nitro) may address your issue.\n\n\t\n3. Review the FAQ\n\nAnswers to frequently asked questions can be found in Frequently asked questions: Run a node.\n\nStep 2: Look for your scenario​\n\nCommon troubleshooting scenarios and solutions are detailed below.\n\nScenario\tSolution\n\n\nYou see Unindex transactions.\n\n\t\n\nThis is expected behavior. You'll see this when your node removes old txlookup indices. This is emitted from the base Geth node, so you'd see the same output from a mainnet Geth node.\n\n\n\n\nYou see Head state missing, repairing.\n\n\t\n\nThis is usually because your node shut down ungracefully. In most cases it will recover in few minutes, but if it not, you may have to re-sync your node. Remember to shut down your node gracefully with the following command: docker stop —time=300 $(docker ps -aq).\n\n\n\n\nYou see failed to read inbox messages\n\n\t\n\nThis is usually because either A) your L1 RPC is unreachable or B) your L1 node hasn't finished syncing and an old L1 node's state that doesn't have our inbox contracts deployed is being used. Check your L1 RPC sync status and connection status, or consider using another L1 RPC to isolate the issue.\n\n\nYour local machine is running out of memory\t\n\nNitro (and Geth) can consume a lot of memory depending on request load. It's possible that your machine may run out of memory when receiving tons of requests.\n\n\n\n\nYour Arbitrum node can’t connect to your L1 node on localhost:8545\n\n\t\n\nThis is often because of a Docker port configuration issue. See https://stackoverflow.com/questions/43884981/unable-to-connect-localhost-in-docker.\n\n\n\n\nYou specified your snapshot file path via the --init.url parameter, but the snapshot file isn't found.\n\n\t\n\nThis is usually because the snapshot file isn't mounted to your Docker container. Mount it and change the file path to your Docker container’s mount point.\n\n\n\n\nYou get 403 errors from the feed URL.\n\n\t\n\nThis often happens when Cloudflare attempts to block botnets and other malicious actors, but accidentally ends up blocking node runners.\n\n\n\n\nYou see\n\nfailed to get blobs: expected at least 6 blobs for slot [slot_number] but only got 0\n\n\t\n\nThis often happens when you connect to a beacon chain endpoint while the blob you are querying is expired. To resolve this error, connect to a beacon endpoint which supports historical blob data (see\n\nList of Ethereum beacon chain RPC providers\n\n).\n\nStep 3: Generate a troubleshooting report​\nComplete the above troubleshooting checklist.\nFill in the below form.\nClick Generate troubleshooting report.\nCopy and paste the generated report text when asking for support on Discord or any other support channel.\n\n\n\nNode startup command (make sure to remove any sensitive information like, i.e., private keys)\n\nUnexpected output\n\nTip: Paste the ~100 lines of output before and including the unexpected output you're asking about. You can use the following command to get the logs:\n\ndocker logs --tail 100 YOUR_CONTAINER_ID\n\nGenerate troubleshooting report\n\nComplete the checklist above before generating...\n\nLast updated on Nov 19, 2024\nPrevious\nDatabase snapshots\nNext\nFAQ\nStep 1: Try the troubleshooting checklist\nStep 2: Look for your scenario\nStep 3: Generate a troubleshooting report\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Frequently asked questions: Run a node | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/node-running/faq",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nFrequently asked questions: Run a node\nHow do I run a node?​\n\nSee instructions here!\n\nHow to verify the integrity of the Nitro database I currently have?​\n\nWe have an accumulator hash on all messages, which means that a message can't be added to the database without the previous message being correct.\n\nTo confirm that everything's working properly, you could just make sure that it's syncing and that the latest block is consistent with other Arbitrum nodes; e.g., you could check it against Arbiscan (note that Arbiscan's search field doesn't support searching by block hash).\n\nHow can I check if the node is running properly and diagnose the issue if it is not?​\n\nWe have trace-level logging RPC request implemented on our node. You could use it to log all requests and responses at the trace level. (The performance impact of this should be negligible compared to the network overhead of an RPC request in the first place, especially considering that the request/response will only be serialized for logging if that log level is enabled.)\n\nWhy do I need an L1 node to run an Arbitrum node?​\n\nOn the node syncing stage, Arbitrum nodes read transactions from batches that were previously posted on L1 and have been executed. They then connect to the Sequencer feed to receive new incoming batched transactions that have not yet been posted on L1.\n\nWhen fully synced, the Arbitrum node uses the State Transition Function (STF) to consume transactions coming from the Sequencer feed and creates a new state. It also waits for the L1 batch to be posted. If the L1 batch that is finalized on L1 is different from what the Sequencer published, the node will change the state based on the L1 batched transactions.\n\nCan I run an Arbitrum node in p2p mode?​\n\nArbitrum doesn't have a consensus mechanism, so \"p2p mode\" doesn't apply. For nodes to sync to the latest chain state, they connect to an L1 node to sync the chain's history that's been posted in calldata and connect to the Sequencer feed for the transactions that have yet to be posted in batches. In no case do nodes need to peer up and sync with each other.\n\nHow do I read messages from the Sequencer feed?​\n\nRunning an Arbitrum relay locally as a Feed Relay lets you subscribe to the Sequencer feed for real-time data as the Sequencer accepts and orders transactions off-chain. Visit How to read the sequencer feed for a detailed how-to.\n\nHow do I run a node locally for development?​\n\nSee instructions here.\n\nWe recommend running nitro nodes via docker; to compile directly / run without docker, you can follow the steps in How to build Nitro locally.\n\nIs there any way to retrieve pre-Nitro archive data from a Nitro node?​\n\nThe pre-nitro stack is also referred to as the \"classic\" stack. Full nitro nodes start with a database that contains the information from the \"classic\" era.\n\nHowever, it is not possible for a nitro node to query archive information contained in \"classic\" blocks right away. To do that, you need to also run a classic node (instructions here) and set the parameter —node.rpc.classic-redirect=your-classic-node-RPC.\n\nKeep in mind that this information only applies to Arbitrum One nodes. Arbitrum Nova and Arbitrum Sepolia nodes started with a Nitro stack from the beginning, so they don't have \"classic\" data.\n\nHow can I verify that my node is syncing at a desirable speed?​\n\nSyncing speed can vary depending on multiple factors. You can find the minimum hardware requirements to run your node in this page. You should also verify your network and disk speed, and make sure that the L1 node is running correctly.\n\nHow can I verify that my node is fully synced?​\n\nYou can make an eth_syncing RPC call to your node. When a nitro node is fully synced, eth_syncing returns the value false (just like a normal Geth node).\n\nWhen a nitro node is still syncing, eth_syncing returns a map of values to help understand why the node is not synced. Nitro execution and bottleneck are different from a normal Geth node, so eth_syncing output is unique to nitro.\n\nYou can find information to understand the output of eth_syncing in the RPC methods page.\n\nIs there an alternative to Docker when running a node?​\n\nWe recommend running Nitro nodes via Docker, using the guides provided within our documentation. However, you can try to compile the code directly by following the steps described in this guide.\n\nWhat are the minimum hardware requirements to run a full node?​\n\nYou can see the minimum hardware configuration in this section.\n\nHow can I migrate the date of one synced node to a new one?​\n\nFrom a fully synced node, you can copy its database (the .arbitrum directory in a default setup) to the same database folder of the new node, and it will start from the same state.\n\nKeep in mind that this must be done after a clean shutdown, while the node is not running.\n\nWhen querying Classic transactions from a Nitro node, I sometimes get incorrect data, like the zero address as the sender. Why is that?​\n\nSome old Nitro genesis database snapshots didn't properly set the retry sender for Classic blocks and contain said error. If you need to access that information, you can either resync your nitro node with one of the current snapshots, or run a Classic node along with your nitro node and configure a redirection for requests to Classic blocks. Please note that this only happens on Arbitrum One.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nTroubleshooting\nNext\nQuickstart\nHow do I run a node?\nHow to verify the integrity of the Nitro database I currently have?\nHow can I check if the node is running properly and diagnose the issue if it is not?\nWhy do I need an L1 node to run an Arbitrum node?\nCan I run an Arbitrum node in p2p mode?\nHow do I read messages from the Sequencer feed?\nHow do I run a node locally for development?\nIs there any way to retrieve pre-Nitro archive data from a Nitro node?\nHow can I verify that my node is syncing at a desirable speed?\nHow can I verify that my node is fully synced?\nIs there an alternative to Docker when running a node?\nWhat are the minimum hardware requirements to run a full node?\nHow can I migrate the date of one synced node to a new one?\nWhen querying Classic transactions from a Nitro node, I sometimes get incorrect data, like the zero address as the sender. Why is that?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "ERC-20 token bridging | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/token-bridging/token-bridge-erc20",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nOverview\nETH bridging\nERC-20 token bridging\nBridge tokens programmatically\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nERC-20 token bridging\n\nThe Arbitrum protocol itself technically has no native notion of any token standards, and gives no built-in advantage or special recognition to any particular token bridge. In this page we describe the \"canonical bridge\", which was implemented by Offchain Labs, and should be the primary bridge most users and applications use; it is (effectively) a decentralized app (dApp) with contracts on both Ethereum (the Layer 1, or L1) and Arbitrum (the Layer 2, or L2) that leverages Arbitrum's cross-chain message passing system to achieve basic desired token-bridging functionality. We recommend that you use it!\n\nDesign rationale​\n\nIn our token bridge design, we use the term \"gateway\" as per this proposal; i.e., one of a pair of contracts on two different domains (i.e., Ethereum and an Arbitrum chain), used to facilitate cross-domain asset transfers.\n\nWe now describe some core goals that motivated the design of our bridging system.\n\nCustom gateway functionality​\n\nFor many ERC-20 tokens, \"standard\" bridging functionality is sufficient, which entails the following: a token contract on Ethereum is associated with a \"paired\" token contract on Arbitrum.\n\nDepositing a token entails escrowing some amount of the token in an L1 bridge contract, and minting the same amount at the paired token contract on L2. On L2, the paired contract behaves much like a normal ERC-20 token contract. Withdrawing entails burning some amount of the token in the L2 contract, which then can later be claimed from the L1 bridge contract.\n\nMany tokens, however, require custom gateway systems, the possibilities of which are hard to generalize, e.g.:\n\nTokens which accrue interest to their holders need to ensure that the interest is dispersed properly across layers, and doesn't simply accrue to the bridge contracts\nOur cross-domain WETH implementations requires tokens be wrapped and unwrapped as they move across layers.\n\nThus, our bridge architecture must allow not just the standard deposit and withdraw functionalities, but for new, custom gateways to be dynamically added over time.\n\nCanonical L2 representation per L1 token contract​\n\nHaving multiple custom gateways is well and good, but we also want to avoid a situation in which a single L1 token that uses our bridging system can be represented at multiple addresses/contracts on the L2 as this adds significant friction and confusion for users and developers. Thus, we need a way to track which L1 token uses which gateway, and in turn, to have a canonical address oracle that maps the tokens addresses across the Ethereum and Arbitrum domains.\n\nCanonical token bridge implementation​\n\nWith this in mind, we provide an overview of our token bridging architecture.\n\nOur architecture consists of three types of contracts:\n\nAsset contracts: These are the token contracts themselves, i.e., an ERC-20 on L1 and it's counterpart on Arbitrum.\nGateways: Pairs of contracts (one on L1, one on L2) that implement a particular type of cross-chain asset bridging.\nRouters: Exactly two contracts (one on L1, one on L2) that route each asset to its designated gateway.\n\nAll Ethereum to Arbitrum token transfers are initiated via the router contract on L1, the L1GatewayRouter contract. L1GatewayRouter forwards the token's deposit call to the appropriate gateway contract on L1, the L1ArbitrumGateway contract. L1GatewayRouter is responsible for mapping L1 token addresses to L1Gateway contracts, thus acting as an L1/L2 address oracle, and ensuring that each token corresponds to only one gateway. The L1ArbitrumGateway then communicates to its counterpart gateway contract on L2, the L2ArbitrumGateway contract (typically/expectedly via retryable tickets).\n\nSimilarly, Arbitrum to Ethereum transfers are initiated via the router contract on L2, the L2GatewayRouter contract, which calls the token's gateway contract on L2, the L2ArbitrumGateway contract, which in turn communicates to its corresponding gateway contract on L1, the L1ArbitrumGateway contract (typically/expectedly via sending L2-to-L1 messages to the outbox).\n\nFor any given gateway pairing, we require that calls be initiated through the corresponding router (L1GatewayRouter or L2GatewayRouter), and that the gateways conform to the TokenGateway interfaces; the TokenGateway interfaces should be flexible and extensible enough to support any bridging functionality a particular token may require.\n\nThe standard ERC-20 gateway​\n\nBy default, any ERC-20 token on L1 that isn't registered to a gateway can be permissionlessly bridged through the StandardERC20Gateway.\n\nYou can use the bridge UI or follow the instructions in How to bridge tokens via Arbitrum’s standard ERC-20 gateway to bridge a token to L2 via this gateway.\n\nExample: Standard Arb-ERC20 deposit and withdraw​\n\nTo help illustrate what this all looks like in practice, let's go through the steps of what depositing and withdrawing SomeERC20Token via our standard ERC-20 gateway looks like. Here, we're assuming that SomeERC20Token has already been registered in the L1GatewayRouter to use the standard ERC-20 gateway.\n\nDeposits​\nA user calls L1GatewayRouter.outboundTransferCustomRefund [1] (with SomeERC20Token's L1 address as an argument).\nL1GatewayRouter looks up SomeERC20Token's gateway, and finds that it's the standard ERC-20 gateway (the L1ERC20Gateway contract).\nL1GatewayRouter calls L1ERC20Gateway.outboundTransferCustomRefund, forwarding the appropriate parameters.\nL1ERC20Gateway escrows the tokens sent and creates a retryable ticket to trigger L2ERC20Gateway's finalizeInboundTransfer method on L2.\nL2ERC20Gateway.finalizeInboundTransfer mints the appropriate amount of tokens at the arbSomeERC20Token contract on L2.\n\n❗️ [1] Please keep in mind that some older custom gateways might not have outboundTransferCustomRefund implemented and L1GatewayRouter.outboundTransferCustomRefund does not fallback to outboundTransfer. In those cases, please use function L1GatewayRouter.outboundTransfer.\n\nNote that arbSomeERC20Token is an instance of StandardArbERC20, which includes bridgeMint and bridgeBurn methods only callable by the L2ERC20Gateway.\n\nWithdrawals​\nOn Arbitrum, a user calls L2GatewayRouter.outBoundTransfer, which in turn calls outBoundTransfer on arbSomeERC20Token's gateway (i.e., L2ERC20Gateway).\nThis burns arbSomeERC20Token tokens, and calls ArbSys with an encoded message to L1ERC20Gateway.finalizeInboundTransfer, which will be eventually executed on L1.\nAfter the dispute window expires and the assertion with the user's transaction is confirmed, a user can call Outbox.executeTransaction, which in turn calls the encoded L1ERC20Gateway.finalizeInboundTransfer message, releasing the user's tokens from the L1ERC20Gateway contract's escrow.\nThe Arbitrum generic-custom gateway​\n\nJust because a token has requirements beyond what are offered via the standard ERC-20 gateway, that doesn't necessarily mean that a unique gateway needs to be tailor-made for the token in question. Our generic-custom gateway is designed to be flexible enough to be suitable for most (but not necessarily all) custom fungible token needs. As a general rule:\n\nIf your custom token has the ability to increase its supply (i.e., mint) directly on the L2, and you want the L2-minted tokens be withdrawable back to L1 and recognized by the L1 contract, it will probably require its own special gateway. Otherwise, the generic-custom gateway is likely the right solution for you!\n\nSome examples of token features suitable for the generic-custom gateway:\n\nAn L2 token contract upgradable via a proxy\nAn L2 token contract that includes address whitelisting/blacklisting\nThe deployer determines the address of the L2 token contract\nSetting up your token with the generic-custom gateway​\n\nFollow the following steps to get your token set up to use the generic-custom gateway. You can also find more detailed instructions in the page How to bridge tokens via Arbitrum’s generic-custom gateway.\n\n0. Have an L1 token\n\nYour token on L1 should conform to the ICustomToken interface (see TestCustomTokenL1 for an example implementation). Crucially, it must have an isArbitrumEnabled method in its interface.\n\n1. Deploy your token on Arbitrum\n\nYour token should conform to the minimum IArbToken interface; i.e., it should have bridgeMint and bridgeBurn methods only callable by the L2CustomGateway contract, and the address of its corresponding Ethereum token accessible via l1Address. For an example implementation, see L2GatewayToken.\n\nTOKEN COMPATIBILITY WITH AVAILABLE TOOLING\n\nIf you want your token to be compatible out of the box with all the tooling available (e.g., the Arbitrum bridge), we recommend that you keep the implementation of the IArbToken interface as close as possible to the L2GatewayToken implementation example.\n\nFor example, if an allowance check is added to the bridgeBurn() function, the token will not be easily withdrawable through the Arbitrum bridge UI, as the UI does not prompt an approval transaction of tokens by default (it expects the tokens to follow the recommended L2GatewayToken implementation).\n\n2. Register your token on L1 to your token on L2 via the L1CustomGateway contract\n\nHave your L1 token's contract make an external call to L1CustomGateway.registerTokenToL2. This registration can alternatively be performed as a chain-owner registration via an Arbitrum DAO proposal.\n\n3. Register your token on L1 to the L1GatewayRouter\n\nAfter your token's registration to the generic-custom gateway is complete, have your L1 token's contract make an external call to L1GatewayRouter.setGateway; this registration can also alternatively be performed as a chain-owner registration via an Arbitrum DAO proposal.\n\nWE ARE HERE TO HELP\n\nIf you have questions about your custom token needs, feel free to reach out on our Discord server.\n\nOther flavors of gateways​\n\nNote that in the system described above, one pair of gateway contracts handles the bridging of many ERC-20s; i.e., many ERC-20s on L1 are each paired with their own ERC-20s on Arbitrum via a single gateway contract pairing. Other gateways may well bear different relations with the contracts that they bridge.\n\nTake our wrapped Ether implementation for example: here, a single WETH contract on L1 is connected to a single WETH contract on L2. When transferring WETH from one domain to another, the L1/L2 gateway architecture is used to unwrap the WETH on domain A, transfer the now-unwrapped Ether, and then re-wrap it on domain B. This ensures that WETH can behave on Arbitrum the way users are used to it behaving on Ethereum, while ensuring that all WETH tokens are always fully collateralized on the layer in which they reside.\n\nNo matter the complexity of a particular token's bridging needs, a gateway can in principle be created to accommodate it within our canonical bridging system.\n\nYou can find an example of implementation of a custom gateway in the page How to bridge tokens via a custom gateway.\n\nDemos​\n\nOur How to bridge tokens section provides example of interacting with Arbitrum's token bridge via the Arbitrum SDK.\n\nA word of caution on bridges (aka, \"I've got a bridge to sell you\")​\n\nCross chain bridging is an exciting design space; alternative bridge designs can potentially offer faster withdrawals, interoperability with other chains, different trust assumptions with their own potentially valuable UX tradeoffs, etc. They can also potentially be completely insecure and/or outright scams. Users should treat other, non-canonical bridge applications the same way they treat any application running on Arbitrum, and exercise caution and due diligence before entrusting them with their value.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nETH bridging\nNext\nGet started\nDesign rationale\nCustom gateway functionality\nCanonical L2 representation per L1 token contract\nCanonical token bridge implementation\nThe standard ERC-20 gateway\nExample: Standard Arb-ERC20 deposit and withdraw\nThe Arbitrum generic-custom gateway\nSetting up your token with the generic-custom gateway\nOther flavors of gateways\nDemos\nA word of caution on bridges (aka, \"I've got a bridge to sell you\")\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to run a local full chain simulation | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/run-local-full-chain-simulation",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to run a local full chain simulation\nOverview​\n\nA local full-chain simulation allows you to deploy and test smart contracts in a fully controlled environment. This how-to walks you through the process of setting up and running a complete development environment on your local machine, including a Nitro node, a dev-mode Geth L1, and multiple instances with different roles.\n\nNote that the node is now Stylus-enabled by default, and the setup instructions remain the same as for running a Stylus dev node.\n\nStep 1. Install prerequisites​\n\nYou'll need docker and docker compose to run your node. Follow the instructions in their site to install them.\n\nStep 2. Clone the nitro-testnode repo​\n\nYou'll need the release branch.\n\n  `git clone -b release --recurse-submodules https://github.com/OffchainLabs/nitro-testnode.git && cd nitro-testnode`\n\nStep 3. Run your node​\n./test-node.bash --init\n\nStep 4. Successive runs​\n\nTo relaunch the node after the first installation, run the following command.\n\n./test-node.bash\n\nCLEAR LOCAL DATA\n\nNote that running with the --init flag will clear all chain data and redeploy!\n\nRollup contract addresses and chain configuration​\n\nYou can obtain the rollup chain configuration by running the following command. The chain configuration also includes the addresses of the core contracts.\n\ndocker exec nitro-testnode-sequencer-1 cat /config/l2_chain_info.json\n\n\nYou can find other available configuration files by running:\n\ndocker exec nitro-testnode-sequencer-1 ls /config\n\nToken bridge​\n\nAn L1-L2 token bridge can be deployed by using the parameter --tokenbridge. The list of contracts can be found by running:\n\ndocker compose run --entrypoint sh tokenbridge -c \"cat l1l2_network.json\"\n\nRunning an L3 chain​\n\nAn L3 chain can be deployed on top of the L2 chain, by using the parameter --l3node. Its chain configuration can be found by running:\n\ndocker exec nitro-testnode-sequencer-1 cat /config/l3_chain_info.json\n\n\nWhen deploying an L3 chain, the following parameters are also available:\n\n--l3-fee-token: Uses a custom gas token for the L3 (symbol $APP), deployed on L2 at address 0x9b7c0fcc305ca36412f87fd6bd08c194909a7d4e --l3-token-bridge: Deploys an L2-L3 token bridge. The list of contracts can be found by running docker compose run --entrypoint sh tokenbridge -c \"cat l2l3_network.json\".\n\nAdditional arguments​\n\nYou can find a list of additional arguments to use with test-node.bash by using --help.\n\n./test-node.bash --help\n\nHelper scripts​\n\nThe repository includes a set of helper scripts for basic actions like funding accounts or bridging funds. You can see a list of the available scripts by running:\n\n./test-node.bash script --help\n\n\nIf you want to see information of a particular script, you can add the name of the script to the help command.\n\n./test-node.bash script send-l1 --help\n\n\nHere's an example of how to run the script that funds an address on L2. Replace 0x11223344556677889900 with the address you want to fund.\n\n./test-node.bash script send-l2 --to address_0x11223344556677889900 --ethamount 5\n\nBlockscout​\n\nNitro comes with a local Blockscout block explorer. To access it, add the param --blockscout when running your node.\n\n./test-node.bash --blockscout\n\n\nThe block explorer will be available at http://localhost:4000\n\nDefault endpoints and addresses​\n\nNode RPC endpoints are available at:\n\nNode\tChain id\tRPC endpoint\nL1 geth devnet\t1337\thttp://localhost:8545\nL2 nitro devnet\t412346\thttp://localhost:8547 and ws://localhost:8548\nL3 nitro (if enabled)\t333333\thttp://localhost:3347\n\nSome important addresses:\n\nRole\tPublic address\tPrivate key\nSequencer\t0xe2148eE53c0755215Df69b2616E552154EdC584f\t0xcb5790da63720727af975f42c79f69918580209889225fa7128c92402a6d3a65\nValidator\t0x6A568afe0f82d34759347bb36F14A6bB171d2CBe\t0x182fecf15bdf909556a0f617a63e05ab22f1493d25a9f1e27c228266c772a890\nL2 rollup owner\t0x5E1497dD1f08C87b2d8FE23e9AAB6c1De833D927\t0xdc04c5399f82306ec4b4d654a342f40e2e0620fe39950d967e1e574b32d4dd36\nL3 rollup owner (if enabled)\t0x863c904166E801527125D8672442D736194A3362\t0xecdf21cb41c65afb51f91df408b7656e2c8739a5877f2814add0afd780cc210e\nL3 sequencer (if enabled)\t0x3E6134aAD4C4d422FF2A4391Dc315c4DDf98D1a5\t0x90f899754eb42949567d3576224bf533a20857bf0a60318507b75fcb3edc6f5f\nDev account (prefunded with ETH in all networks)\t0x3f1Eae7D46d88F08fc2F8ed27FCb2AB183EB2d0E\t0xb6b15c8cb491557369f3c7d2c287b053eb229daa9c22138887752191c9520659\n\nYou can fund other addresses by using the scripts send-l1 and send-l2 as explained here.\n\nPRIVATE KEYS PUBLICLY KNOWN\n\nDo not use any of these addresses in a production environment.\n\nOptional parameters​\n\nHere, We show a list of the parameters that might be useful when running a local devnode. You can also use the flag ./test-node.bash --help to get them.\n\nFlag\tDescription\n--init\tRemoves all the data, rebuilds, and deploys a new rollup\nproof-of-stake chain (using Prysm for consensus)\t\nheavy computation\t\nup the L3 chain to use a custom fee token. Only valid if --l3node flag is provided\t\n--l3-fee-token-decimals\tNumber of decimals to use for a custom fee token. Only valid if\n--l3-fee-token flag is provided\t\nvalid if --l3node flag is provided\t\n--redundantsequencers\tRedundant sequencers [0-3]\nrunning them\t\nconfiguration: one node as a sequencer/batch-poster/staker (default unless using --dev)\t\n--tokenbridge\tDeploy an L1-L2 token bridge\nlaunching the token bridge\t\n--no-simple\tRuns a full configuration with separate sequencer/batch-poster/validator/relayer\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nRun a full node\nNext\nRun a local dev node\nOverview\nStep 1. Install prerequisites\nStep 2. Clone the nitro-testnode repo\nStep 3. Run your node\nStep 4. Successive runs\nRollup contract addresses and chain configuration\nToken bridge\nRunning an L3 chain\nAdditional arguments\nHelper scripts\nBlockscout\nDefault endpoints and addresses\nOptional parameters\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/welcome/get-started",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nGet started with Arbitrum\n\nArbitrum is a suite of Ethereum scaling solutions that make it easy to build and use decentralized applications. This document provides a high-level overview of the Arbitrum suite along with onboarding guidance tailored to specific audiences.\n\nThe Arbitrum suite​\n\nThe Arbitrum suite includes the protocols, chains, services, and SDKs that power the Arbitrum ecosystem:\n\nComponent\tDescription\nArbitrum Rollup\tA protocol for scaling Ethereum smart contracts.\nArbitrum AnyTrust\tA protocol for scaling Ethereum smart contracts even further, with a mild trust assumption.\nArbitrum Nitro\tThe node software that codifies the Rollup and AnyTrust protocols.\nArbitrum nodes\tMachines that run Nitro in order to service and/or interact with an Arbitrum chain.\nArbitrum One\tA public Rollup chain.\nArbitrum Nova\tA public AnyTrust chain.\nArbitrum bridge\tLets you move ETH and ERC-20 tokens between Ethereum, Arbitrum, and select Orbit chains.\nArbitrum Orbit\tLets you run your own Rollup and AnyTrust chains.\nArbitrum Stylus\tLets you write EVM-compatible smart contracts in Rust and any other language that compiles to Wasm.\nArbitrum for users​\n\nUsers interact with Arbitrum either through the Arbitrum bridge or by using dApps that have been deployed to an Arbitrum chain.\n\nResource\tDescription\nArbitrum bridge\tLets you move ETH and ERC-20 tokens between Ethereum, Arbitrum, and select Orbit chains.\nArbitrum Portal\tA directory of dApps on Arbitrum.\nQuickstart (bridge)\tProvides step-by-step instructions for first-time bridge users.\nArbitrum for developers​\n\nDevelopers build Arbitrum dApps by deploying smart contracts to an Arbitrum chain.\n\nResource\tDescription\nA gentle introduction to Arbitrum\tA technical introduction to Arbitrum's suite of scaling solutions.\nQuickstart (Solidity)\tTargeted at web2 developers who want to deploy their first Solidity smart contract to Arbitrum.\nQuickstart (Rust)\tTargeted at web3 developers who want to deploy their first Rust smart contract to Arbitrum using Stylus.\nArbitrum for node runners​\n\nNode runners run the machines that support the Arbitrum ecosystem.\n\nResource\tDescription\nRun a full node\tTargeted at node runners who want to access Arbitrum chains without having to connect to a third-party node.\nConfigure a Data Availability Committee\tTargeted at Data Availability Committee members and Orbit chain operators who want to run a Data Availability Server.\nArbitrum for chain operators​\n\nChain operators use Arbitrum Orbit to run special-purpose Rollup and AnyTrust chains.\n\nResource\tDescription\nOrbit gentle introduction\tTargeted at readers who want to understand Orbit's value proposition and use cases.\nOrbit quickstart\tTargeted at chain operators who want to deploy their first Arbitrum chain using Arbitrum Orbit.\nHow it works​\nResource\tDescription\nInside Nitro\tA technical deep dive into Nitro's architecture.\nInside AnyTrust\tA technical deep dive into the AnyTrust protocol.\nArbitrum whitepaper\tThe original whitepaper that introduced Nitro.\nDAO docs\tDocs that support members of the Arbitrum DAO.\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nA gentle introduction\nNext\nChain info\nThe Arbitrum suite\nArbitrum for users\nArbitrum for developers\nArbitrum for node runners\nArbitrum for chain operators\nHow it works\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/third-party-docs/TheGraph/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nThe Graph\n\nGetting historical data on a smart contract can be frustrating when building a dApp. The Graph provides an easy way to query smart contract data through APIs known as subgraphs, which utilize GraphQL.  The Graph's infrastructure relies on a decentralized network of indexers, enabling your dApp to become truly decentralized.\n\nQuick start​\n\nThese subgraphs only take a few minutes to set up and get running. To get started, follow these three steps:\n\nInitialize your subgraph project\nDeploy & publish\nQuery from your dApp\n\nPricing: All developers receive 100K free monthly queries on the decentralized network. After these free queries, you only pay based on usage at $4 for every 100K queries.\n\nHere's a step by step walkthrough:\n\n1. Initialize your subgraph project​\nCreate a subgraph on Subgraph Studio⁠​\n\nGo to the Subgraph Studio and connect your wallet. Once your wallet is connected, you can begin by clicking \"Create a Subgraph\". Please choose a good name for the subgraph: this name can't be edited later. It is recommended to use Title Case: \"Subgraph Name Chain Name.\"\n\nYou will then land on your subgraph's page. All the CLI commands you need will be visible on the right side of the page:\n\nInstall the Graph CLI⁠​\n\nOn your local machine, run the following:\n\nnpm install -g @graphprotocol/graph-cli\n\nInitialize your Subgraph⁠​\n\nYou can copy this directly from your subgraph page to include your specific subgraph slug:\n\ngraph init --studio <SUBGRAPH_SLUG>\n\n\nYou'll be prompted to provide some info on your subgraph like this:\n\nSimply have your contract verified on the block explorer, and the CLI will automatically obtain the ABI and set up your subgraph. The default settings will generate an entity for each event.\n\n2. Deploy & publish​\nDeploy to Subgraph Studio⁠​\n\nFirst, run these commands in your terminal\n\ngraph codegen\ngraph build\n\n\nThen, invoke these commands to authenticate and deploy your subgraph. You can copy these commands directly from your subgraph's page in Studio to include your specific deploy key and subgraph slug:\n\ngraph auth --studio <DEPLOY_KEY>\ngraph deploy --studio <SUBGRAPH_SLUG>\n\n\nYou will be asked for a version label. You can enter something like V0.0.1, but you're free to choose the format.\n\nTest your subgraph⁠​\n\nYou can test your subgraph by making a sample query in the playground section. The Details tab will show you an API endpoint. You can use that endpoint to test from your dApp.\n\nPublish your subgraph to The Graph's decentralized network​\n\nOnce your subgraph is ready for production, you can publish it to the decentralized network. On your subgraph's page in Subgraph Studio, click on the Publish button:\n\nBefore you can query your subgraph, Indexers need to begin serving queries on it. In order to streamline this process, you can curate your own subgraph using $GRT.\n\nWhen publishing, you'll see the option to curate your subgraph. As of May 2024, it is recommended that you curate your own subgraph with at least 3,000 $GRT to ensure that it is indexed and available for querying as soon as possible.\n\n3. Query your Subgraph​\n\nCongratulations! You can now query your subgraph on the decentralized network!\n\nYou can start querying any subgraph on the decentralized network by passing a GraphQL query into the subgraph's query URL, which can be found at the top of its Explorer page.\n\nHere's an example from the CryptoPunks Ethereum subgraph by Messari:\n\nThe query URL for this subgraph is:\n\nhttps://gateway-arbitrum.network.thegraph.com/api/**[api-key]**/subgraphs/id/HdVdERFUe8h61vm2fDyycHgxjsde5PbB832NHgJfZNqK\n\n\nNow, you simply need to  fill in your own API Key to start sending GraphQL queries to this endpoint.\n\nGetting your own API key​\n\nIn Subgraph Studio, you'll see the \"API Keys\" menu at the top of the page. Here, you can create API Keys.\n\nAppendix​\nSample query​\n\nThis query shows the most expensive CryptoPunks sold.\n\n{\n  trades(orderBy: priceETH, orderDirection: desc) {\n    priceETH\n    tokenId\n  }\n}\n\n\nPassing this into the query URL returns this result:\n\n{\n  \"data\": {\n    \"trades\": [\n      {\n        \"priceETH\": \"124457.067524886018255505\",\n        \"tokenId\": \"9998\"\n      },\n      {\n        \"priceETH\": \"8000\",\n        \"tokenId\": \"5822\"\n      },\n//      ...\n\n\n💡 Trivia: Looking at the top sales on CryptoPunks website it looks like the top sale is Punk #5822, not #9998. Why? Because they censored the flash-loan sale that happened.\n\nSample code​\nconst axios = require('axios');\n\nconst graphqlQuery = `{\n  trades(orderBy: priceETH, orderDirection: desc) {\n    priceETH\n    tokenId\n  }\n}`;\nconst queryUrl =\n  'https://gateway-arbitrum.network.thegraph.com/api/[api-key]/subgraphs/id/HdVdERFUe8h61vm2fDyycHgxjsde5PbB832NHgJfZNqK';\n\nconst graphQLRequest = {\n  method: 'post',\n  url: queryUrl,\n  data: {\n    query: graphqlQuery,\n  },\n};\n\n// Send the `GraphQL` query\naxios(graphQLRequest)\n  .then((response) => {\n    // Handle the response here\n    const data = response.data.data;\n    console.log(data);\n  })\n  .catch((error) => {\n    // Handle any errors\n    console.error(error);\n  });\n\nAdditional resources:​\nTo explore all the ways you can optimize & customize your subgraph for better performance, read more about creating a subgraph here.\nYou can find more information in our article about querying data from your subgraph.\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nBackfill Templates\nNext\nContribute docs\nQuick start\n1. Initialize your subgraph project\nCreate a subgraph on Subgraph Studio⁠\nInstall the Graph CLI⁠\nInitialize your Subgraph⁠\n2. Deploy & publish\nDeploy to Subgraph Studio⁠\nTest your subgraph⁠\nPublish your subgraph to The Graph's decentralized network\n3. Query your Subgraph\nGetting your own API key\nAppendix\nSample query\nSample code\nAdditional resources:\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/third-party-docs/QuickNode/backfill-templates",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nBackfill Templates\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nQuickNode Backfill Templates\nWhat are Backfill Templates?​\n\nBackfill Templates are pre-built solutions within Streams (our ETL/streaming tool) designed to simplify the process of acquiring historical blockchain data. With just one click, users can backfill extensive datasets across various chains, including blocks, transactions, receipts, traces, and more.\n\nKey Benefits​\nSpeed: Start backfilling in less than 10 minutes.\nTransparency: Immediate cost and time estimates for your selected datasets.\nReliability: Guaranteed data delivery to platforms like Snowflake, Amazon S3, Webhooks, etc.\nAvailable Backfill Templates​\n\nBelow is a table of available Backfill Templates for the Arbitrum network:\n\nTemplate Name\tDescription\tLink\nBackfill Blocks and Transactions\tBackfill historical Arbitrum blocks and transactions data.\tUse template\nBackfill Blocks, Transactions, and Receipts\tBackfill historical Arbitrum blocks, transactions, and receipts data.\tUse template\nBackfill Receipts\tBackfill historical Arbitrum receipts data.\tUse template\nBackfill Traces (debug_trace)\tBackfill historical Arbitrum traces (debug_trace) data.\tUse template\nBackfill Blocks, Transactions, Receipts, Traces\tBackfill historical Arbitrum blocks, transactions, receipts, and traces (debug_trace).\tUse template\nBackfill all ERC20/721/1155 Transfers\tBackfill historical Arbitrum ERC20/721/1155 transfers data.\tUse template\nBackfill all Uniswap V2/V3 Swaps\tBackfill historical Arbitrum Uniswap V2/V3 swaps data.\tUse template\n\nFor detailed pricing and timing information, visit our Streams Backfills - Arbitrum page.\n\nAdditional Resources​\nQuickNode - Arbitrum Chain Page\nQuickNode - Arbitrum Documentation\nQuickNode Builders Guide - Arbitrum Orbits\nQuickNode - Arbitrum Faucet\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nParticle Network\nNext\nThe Graph\nWhat are Backfill Templates?\nKey Benefits\nAvailable Backfill Templates\nAdditional Resources\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to implement Particle Network's Smart Wallet-as-a-Service for AA-enabled social logins | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/third-party-docs/Particle/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nHow to implement Particle Network's Smart Wallet-as-a-Service for AA-enabled social logins\nCOMMUNITY MEMBER CONTRIBUTION\n\nShoutout to @TABASCOatw for contributing the following third-party document!\n\nParticle Network's Wallet Abstraction services enable universal, Web2-adjacent onboarding and interactions through social logins. Its core technology, Smart Wallet-as-a-Service (WaaS) aims to onboard users into MPC-secured smart accounts supporting any chain. It also allows developers to offer an improved user experience through modular, fully customizable EOA/AA embedded wallets. Particle supports its Smart Wallet-as-a-Service through a Modular L1 powering chain abstraction, acting as a settlement layer across chains for a seamless multi-chain experience.\n\nArbitrum was one of the first blockchains supported by Particle Network's Smart Wallet-as-a-Service. Because of this, Particle Network has extensive support for:\n\nArbitrum One, through:\nEOA (non-AA social login)\nSimpleAccount\nBiconomy (V1 and V2)\nLight Account\nCyber Account\nArbitrum Nova, through:\nEOA (non-AA social login)\nSimpleAccount\nBiconomy (V1 and V2)\n\nAlongside a similar degree of support for Arbitrum Goerli and Sepolia.\n\nGiven its modular architecture, developers have the liberty to choose which of the above smart account implementations they onboard a user into after the social login process.\n\nThe user flow with Particle Network begins with social logins (using either a custom authentication or preset login methods provided by Particle Network), which leads to the generation of an EOA through MPC-TSS. This EOA is then used as a Signer for a smart account implementation that best fits the needs of the application in question (natively, this means a choice between SimpleAccount, Biconomy V1/V2, Light Account, and Cyber Account). A visualization of this process can be found below:\n\nThis document will go through the high-level process of creating a demo application on Arbitrum Sepolia using Particle Network's Smart Wallet-as-a-Service (specifically the Particle Auth Core SDK alongside Particle's AA SDK). Within the app, we'll onboard a user into a SimpleAccount instance via a social login and execute a gasless (sponsored) transaction.\n\nGetting started​\n\nThroughout this guide, we'll be segmenting the configuration and utilization of these SDKs between two files: index.tsx and App.tsx. Thus, we'll be building an application through a standard create-react-app structure. However, if you intend to use an alternative framework, such as Next.js, this same process will be largely applicable (extrapolating to your setup).\n\nDependencies​\n\nBefore installing your dependencies, it's important to note that Particle Network's Modular Smart Wallet-as-a-Service isn't contained in one singular SDK. Rather, it refers to the combined usage of Particle Auth Core (to facilitate social logins leading to EOAs) and Particle's AA SDK (to take the EOA returned by Particle Auth Core and use it as a Signer for a smart account).\n\nUnderstanding this, you'll need to install the following libraries:\n\n@particle-network/auth-core-modal, for social logins (can be substituted by @particle-network/connectkit for a RainbowKit-like connection modal).\n@particle-network/aa, to assign and interact with a smart account.\n@particle-network/chains, for connecting with Arbitrum Sepolia.\n\nTo do this, run one of the two following commands at the root of your project:\n\nyarn add @particle-network/auth-core-modal @particle-network/aa @particle-network/chains\n\n# OR\n\nnpm install @particle-network/auth-core-modal @particle-network/aa @particle-network/chains\n\nSetting up the Particle dashboard​\n\nBefore jumping into the configuration process, you'll need to go to the Particle dashboard to retrieve three values required for your project.\n\nWhen using any SDK offered by Particle Network, you'll routinely need a projectId, clientKey, and appId. These exist to authenticate your project and create a connection between your instance of Particle Auth and the Particle dashboard (which allows you to customize the application-embedded modals, track users, fund your Paymaster, and so on).\n\nOnce you've navigated to the Particle dashboard, follow the process below:\n\nCreate a new project through \"Add New Project\".\nClick \"Web\" under \"Your Apps\" (if you intend to use an alternative platform, take a look at the platform-specific guides on Particle's documentation)\nChoose a name and domain for your application (if you have yet to deploy or decide on a domain where you intend to deploy, feel free to use any filler one).\nCopy the Project ID, Client Key and App ID.\n\nGiven the nature of these values, it's recommended that you store them within .env variables, such as REACT_APP_PROJECT_ID, REACT_APP_CLIENT_KEY, and REACT_APP_APP_ID (or NEXT_PUBLIC_{}_ID).\n\nConfiguring Particle Auth Core​\n\nAs mentioned, we'll break the integration process into two components, each attached to a file within a standard create-react-app structure.\n\nindex.tsx, our starting point In this example, the index file will be used as the source file for the configuration/initialization of Particle Auth Core.\nApp.tsx. After setting up index.tsx, we'll organize all of the core application-level logic (such as the facilitation of social login) within our App component.\n\nParticle Auth Core is configured by one component: AuthCoreContextProvider, which takes a number of required (projectId, clientKey, appId) and optional values.\n\nAuthCoreContextProvider should wrap the primary component where you intend to use Particle Auth Core. In this case, that's our App component (from App.tsx).\n\nTherefore, within our index file, we'll render a constructed instance of AuthCoreContextProvider so that we can (as the name suggests) provide context to the component wrapped within it (App).\n\nIn this example, we'll be defining the following parameters for AuthCoreContextProvider.\n\nprojectId, clientKey, and appId. We previously retrieved these from the Particle dashboard.\nerc4337, to dictate which type of smart account will be shown on the (optional) embedded wallet modal after login.\nname, the name of the smart account implementation you intend on using. In this example, we'll be using \"SIMPLE\".\nversion, the version of the smart account implementation you intend on using. This should generally be 1.0.0 unless you're using Biconomy V2 (in which this should be 2.0.0).\nwallet, for customizing the (optional) embedded wallet modal.\nvisible, a Boolean determining whether or not the embedded wallet modal is shown or not. If set to false, the user will rely on the functions you provide them within your application to interact with the generated wallet.\ncustomStyle, for more targeted, narrowly-defined customizations (ignore this if you're setting visible to false).\nsupportChains, the chains you'd like the modal to support. In this case, we'll be using ArbitrumSepolia, imported from @particle-network/chains.\n\nWith these configurations set, Particle Auth Core will be initialized and, therefore, ready to be utilized within your App.tsx file. At this point, your index.tsx file (or its equivalent) should look similar to the example below.\n\nimport React from 'react';\nimport ReactDOM from 'react-dom/client';\nimport { ArbitrumSepolia } from '@particle-network/chains';\nimport { AuthCoreContextProvider } from '@particle-network/auth-core-modal';\nimport App from './App';\n\n// Optional, not always needed\nimport('buffer').then(({ Buffer }) => {\n  window.Buffer = Buffer;\n});\n\nReactDOM.createRoot(document.getElementById('root') as HTMLElement).render(\n  <React.StrictMode>\n    <AuthCoreContextProvider\n      options={{\n        projectId: process.env.REACT_APP_PROJECT_ID, // --\n        clientKey: process.env.REACT_APP_CLIENT_KEY, // Retrieved from https://dashboard.particle.network\n        appId: process.env.REACT_APP_APP_ID, // --\n        erc4337: {\n          // Optional\n          name: 'SIMPLE', // The smart account you intend to use\n          version: '1.0.0', // Leave as 1.0.0 unless you're using Biconomy V2\n        },\n        wallet: {\n          // Optional\n          visible: true, // Whether or not the embedded wallet modal is shown\n          customStyle: {\n            supportChains: [ArbitrumSepolia], // Locking the modal to Arbitrum Sepolia\n          },\n        },\n      }}\n    >\n      <App /> // Where you're utilizing Particle Auth Core\n    </AuthCoreContextProvider>\n  </React.StrictMode>,\n);\n\nBuilding the application​\n\nNow that you've set up your project, installed the relevant dependencies, and configured Particle Auth Core, you're ready to move over to your App.tsx file.\n\nWithin App.tsx, you'll be defining all of the login methods for the application itself (such as the initiation of social login). As mentioned, this will be done by combining @particle-network/auth-core-modal and @particle-network/aa.\n\nManaging hooks​\n\n@particle-network/auth-core-modal operates off of hooks such as useEthereum (used to pull an EIP-1193 provider in this example), useConnect (to facilitate social login), useAuthCore (here used for retrieving user information post-login), etc.\n\nTherefore, within the first few lines of your App component, you'll need to define the following objects derived from the hooks mentioned above:\n\nprovider from useEthereum.\nconnect and disconnect from useConnect.\nuserInfo from useAuthCore.\nDefining SmartAccount​\n\nWhile we could use these hooks on their own to facilitate interaction with the associated EOA directly, we'll be using a smart account here. Therefore, we'll need to create a SmartAccount object (imported from @particle-network/aa) using our provider (which is attached to our EOA) object to define a Signer.\n\nOutside of provider, we'll pass the following parameters into our new instance of SmartAccount:\n\nprojectId, clientKey, and appId. These will be the same values you used within AuthCoreContextProvider, retrieved from the Particle dashboard.\naaOptions, used to configure the smart account implementation you'd like to use. This contains accountContracts, which takes:\nSIMPLE (or BICONOMY, LIGHT, CYBERCONNECT), containing:\nchainIds, the chains you plan on using. In this case, we'll use ArbitrumSepolia.id.\nversion, the version of the smart account you're using. Similar to AuthCoreContextProvider, this should be 1.0.0 unless you use Biconomy V2.\n\nTherefore, your instance of SmartAccount should follow the structure within the example below.\n\nconst smartAccount = new SmartAccount(provider, {\n  projectId: process.env.REACT_APP_PROJECT_ID,\n  clientKey: process.env.REACT_APP_CLIENT_KEY,\n  appId: process.env.REACT_APP_APP_ID,\n  aaOptions: {\n    accountContracts: {\n      SIMPLE: [{ chainIds: [ArbitrumSepolia.id], version: '1.0.0' }],\n    },\n  },\n});\n\n\nThe object you save this instance within (smartAccount in the snippet above) can be used alone to construct and execute UserOperations; although, in this example, we'll be plugging it into a custom Ethers object. By doing this, we'll be able to construct and send transactions as within any other standard application scenario, although instead routing them through an MPC-powered smart account.\n\nThis will be done through AAWrapProvider from @particle-network/aa, allowing us to convert smartAccount into an EIP-1193 provider object to be used within ethers.providers.Web3Provider, as shown below.\n\nconst customProvider = new ethers.providers.Web3Provider(\n  new AAWrapProvider(smartAccount, SendTransactionMode.Gasless),\n  'any',\n);\n\n\nWithin the constructor of AAWrapProvider, we're also using SendTransactionMode.Gasless (which can be imported from @particle-network/aa) to ensure that all UserOperations sent through this object (customProvider) will be sponsored (or attempted to be).\n\nInitiating social login​\n\nUsing Particle Auth Core, facilitating social logins is quite simple. Calling back to the connect function defined from useConnect earlier, we'll be wrapping this within a simple function, handleLogin.\n\nconnect will work on its own, handling the entire social login process; although to prevent it from being called while a user may already be logged in, we'll place it behind a conditional within handleLogin.\n\nThis conditional will check the truthy/falsy value of userInfo (from useAuthCore), which will remain undefined until a user has successfully logged in. Thus, we can call connect on the condition that userInfo is undefined (indicating that they have yet to log in).\n\nWithin connect, we'll need to define two key parameters:\n\nsocialType, the social login mechanism you'd like to use (such as 'google', 'twitter', 'email', 'phone', 'github'). If this is left as an empty string, a generalized authentication modal aggregating every option will be shown.\nchain, the chain we'll be connecting to. This should be ArbitrumSepolia (or ArbitrumOne, ArbitrumNova, ArbitrumGoerli).\n\nUpon calling handleLogin, the user will be taken through the defined social login mechanism, after which an EOA will be generated (using MPC-TSS) and assigned to the smart account configured previously.\n\nYour usage of connect may look something like this (although, as mentioned, it can be used in isolation if preferred).\n\nconst handleLogin = async (authType) => {\n  if (!userInfo) {\n    await connect({\n      socialType: authType,\n      chain: ArbitrumSepolia,\n    });\n  }\n};\n\nExecuting a gasless transaction​\n\nAt this point, a user has logged in through their social account and been assigned a smart account. We'll need to build a simple function to test it, specifically through a gasless transaction.\n\nBecause we're using Ethers, this can be a simple transaction construction and execution, using the sendTransaction method on a signer object from {your provider object}.getSigner().\n\nThis method will take a standard transaction object. In this case, we'll simply define an object containing:\n\nto, the recipient of the transaction. We can set this to 0x000000000000000000000000000000000000dEaD for the sake of the demo.\nvalue, the amount of ETH you'd like to send to the recipient address.\n\nThis object (we'll define it as tx) can then be passed into signer.sendTransaction(tx). Upon calling, the user will be asked to confirm a transaction (sign a UserOperation hash) through an embedded popup within your application. After doing so, the transaction will be executed on-chain.\n\nFollowing the example described above, your function may look similar to the snippet shown below.\n\nconst executeUserOp = async () => {\n  const signer = customProvider.getSigner();\n\n  const tx = {\n    to: '0x000000000000000000000000000000000000dEaD',\n    value: ethers.utils.parseEther('0.001'),\n  };\n\n  const txResponse = await signer.sendTransaction(tx);\n  const txReceipt = await txResponse.wait();\n\n  notification.success({\n    message: 'Transaction Successful',\n    description: (\n      <div>\n        Transaction Hash:{' '}\n        <a\n          href={`https://sepolia.arbiscan.io/tx/${txReceipt.transactionHash}`}\n          target=\"_blank\"\n          rel=\"noopener noreferrer\"\n        >\n          {txReceipt.transactionHash}\n        </a>\n      </div>\n    ),\n  });\n};\n\n\nThis transaction will be gasless because we're meeting two conditions. The first is whether or not we've expressed that this transaction should be sponsored (done earlier by including SendTransactionMode.Gasless within AAWrapProvider). The second condition is the existence of adequate funds to sponsor the transaction. Because we're on a Testnet (Arbitrum Sepolia), all transactions are automatically sponsored without the need to deposit USDT. However, if this were on Arbitrum One or Arbitrum Nova, the Paymaster shown on the Particle dashboard would need to be funded.\n\nConclusion​\n\nBuilding an application on Arbitrum that takes advantage of social logins and smart accounts simultaneously only takes a few lines of code, and is even more succinct if you're already using Ethers, Web3.js, or any other standard library that supports EIP-1193 providers.\n\nTo view the complete demo application leveraging the code snippets covered throughout this document, take a look at the GitHub repository here.\n\nAdditionally, to learn more about Particle Network, explore the following resources:\n\nWebsite: https://particle.network\nBlog: https://blog.particle.network\nDocumentation: https://developers.particle.network\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nPARSIQ\nNext\nBackfill Templates\nGetting started\nDependencies\nSetting up the Particle dashboard\nConfiguring Particle Auth Core\nBuilding the application\nManaging hooks\nDefining SmartAccount\nInitiating social login\nExecuting a gasless transaction\nConclusion\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Quickstart: PARSIQ (blockchain data API & SDK) | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/third-party-docs/PARSIQ/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nQuickstart: PARSIQ (blockchain data API & SDK)\n\nPARSIQ is a reliable, fully customizable blockchain data indexer, helping developers to seamlessly access, process and utilize Web3 data - both raw and custom.\n\nPARSIQ API allows querying blockchain data such as transactions, token transfers, events, internal function calls, blocks, etc.\n\nPARSIQ SDK allows accumulating, processing, and storing this data according to the developer-specified logic, as well as building your own API endpoints.\n\nCheck out this introduction video to get started.\n\nPARSIQ Tsunami API​\n\nPARSIQ Tsunami API is a highly efficient API to fetch raw Web3 data:\n\nEvents, calls, transactions (internal included), transfers, contracts, blocks - you name it. Possibility to use unlimited blockrange makes Tsunami a hard-to-beat solution for reliably getting large amounts of data from the blockchain. CSV Export is available.\nGet decoded, human readable data right out of the box.\nNeed an up to date feeds of data streamed to you in real time? Give our low latency Real Time Streaming service a try.\nENDPOINTS\n\nPlease check out our PARSIQ API Reference to see all the available endpoints.\n\nPARSIQ SDK​\n\nSome more complicated cases where custom data needs to be stored, accumulated, and calculated, cannot be covered by an API. In that cases, use PARSIQ SDK or go for a Custom Data Lake. They allow you to set up data bases and data processing logic to solve your specific use case.\n\nSDK DOCUMENTATION\n\nPlease see PARSIQ SDK documentation for more details.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nOpenfort\nNext\nParticle Network\nPARSIQ Tsunami API\nPARSIQ SDK\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to onboard users in your game and make a gasless transaction | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/third-party-docs/Openfort/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nHow to onboard users in your game and make a gasless transaction\nCOMMUNITY MEMBER CONTRIBUTION\n\nThe following document was contributed by @joalavedra. Give them a shoutout if you find it useful!\n\nOpenfort is a headless wallet solution that helps developers integrate authentication, private key management, and account abstraction into their dApps. By abstracting away the complexities of blockchain interactions, Openfort allows you to build Web3 applications with a Web2-like user experience without requiring end users to manage private keys or hold cryptocurrency.\n\nOpenfort enables you to:\n\nImplement secure authentication and key management\nCreate and manage smart contract wallets\nEnable gasless and sponsored transactions\n\nCheck out Openfort's Documentation to get started.\n\nOpenfort dashboard​\n\nThe Openfort dashboard allows you to:\n\nCreate and manage projects\nGenerate API keys\nConfigure authentication providers\nMonitor transactions and analytics\nSet up webhooks for real-time notifications\nOPENFORT DASHBOARD\n\nPlease check out the docs to learn more about using the Openfort Dashboard. Click here to access the Openfort Dashboard.\n\nHow to implement a gasless transaction on Arbitrum using Openfort​\n\nWith Openfort, you can sponsor transactions for your users, meaning that in-game wallets don't need native tokens to execute transactions, such as minting an NFT. This guide will walk you through the process of implementing a gasless transaction to mint an NFT on Arbitrum.\n\n1. Import the NFT Contract​\n\nFirst, you need to import the smart contract you'll be interacting with. In this case, we'll use an NFT contract with a 'mint' function.\n\ncurl https://api.openfort.xyz/v1/contracts \\\n  -u \"$YOUR_SECRET_KEY:\" \\\n  -d 'name=NFT Contract' \\\n  -d 'chainId=42161' \\\n  -d 'address=YOUR_CONTRACT_ADDRESS'\n\n\nReplace YOUR_CONTRACT_ADDRESS with the address of your NFT contract on Arbitrum.\n\n2. Set up the Gas Policy​\n\nCreate a new policy to sponsor gas fees for users:\n\ncurl https://api.openfort.xyz/v1/policies \\\n  -H \"Authorization: Bearer $YOUR_SECRET_KEY\" \\\n  -d chainId=42161 \\\n  -d name=\"Arbitrum NFT Sponsor\" \\\n  -d \"strategy[sponsorSchema]=pay_for_user\"\n\n\nThen, add a policy rule for the NFT contract:\n\ncurl https://api.openfort.xyz/v1/policies/:id/policy_rules \\\n  -H \"Authorization: Bearer $YOUR_SECRET_KEY\" \\\n  -d type=\"contract_functions\" \\\n  -d functionName=\"mint\" \\\n  -d contract=\"con_...\"\n\n\nReplace :id with the policy ID returned from the previous step, and con_... with your contract ID.\n\n3. Create a gasless transaction​\n\nNow, let's create a transaction to mint an NFT without the user paying for gas:\n\nconst Openfort = require('@openfort/openfort-node').default;\nconst openfort = new Openfort(YOUR_SECRET_KEY);\n\nconst policyId = 'pol_...'; // Your policy ID from step 2\n\nconst transactionIntent = await openfort.transactionIntents.create({\n  chainId: 42161, // Arbitrum One\n  policy: policyId,\n  optimistic: true,\n  interactions: {\n    contract: 'con_....', // Your NFT contract ID\n    functionName: 'mint',\n    functionArgs: ['0x...'], // Address to receive the NFT\n  },\n});\n\n4. Optional: specify the player​\n\nIf you want to associate the transaction with a specific player:\n\nconst Openfort = require('@openfort/openfort-node').default;\nconst openfort = new Openfort(YOUR_SECRET_KEY);\n\nconst playerId = 'pla_...'; // Your player ID\nconst policyId = 'pol_...'; // Your policy ID from step 2\n\nconst transactionIntent = await openfort.transactionIntents.create({\n  player: playerId,\n  chainId: 42161, // Arbitrum One\n  policy: policyId,\n  optimistic: true,\n  interactions: {\n    contract: 'con_....', // Your NFT contract ID\n    functionName: 'mint',\n    functionArgs: [playerId], // Minting to the player's address\n  },\n});\n\n\nBy following these steps, you've created a gasless transaction on Arbitrum using Openfort. The user can now mint an NFT without needing to hold ETH for gas fees. Remember to handle the response from the transactionIntents.create call in your application to provide feedback to the user about the minting process.\n\nDETAILED TUTORIAL\n\nFor a more detailed tutorial, please refer to the Openfort Quick Start Guide.\n\nConnect with Openfort​\n\nNeed further assistance? Reach out to Openfort for support and stay updated:\n\nVisit Openfort's official website at openfort.xyz\nRead the Documentation\nFor support, contact the Openfort team via Discord\nFollow Openfort on Twitter\nCheck out Openfort on GitHub\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nMoralis\nNext\nPARSIQ\nOpenfort dashboard\nHow to implement a gasless transaction on Arbitrum using Openfort\n1. Import the NFT Contract\n2. Set up the Gas Policy\n3. Create a gasless transaction\n4. Optional: specify the player\nConnect with Openfort\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/third-party-docs/Gelato/gelato-vrf",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nGelato VRF\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nWhat is Gelato VRF?\n\nGelato VRF offers real randomness for blockchain applications on Arbitrum by leveraging Drand, a trusted decentralized source for random numbers. With Gelato VRF, developers on Arbitrum get random values that are both genuine and can be checked for authenticity. Explore Gelato VRF's support for all supported networks here.\n\nApplications of Gelato VRF​\n\nThe potential applications of a reliable and transparent random number generator on the blockchain are vast. Here are just a few use cases:\n\nGaming and Gambling: Determine fair outcomes for online games or decentralized gambling applications.\nDecentralized Finance (DeFi): Use in protocols where random selections, like lottery systems, are required.\nNFT Generation: Randomly generate traits or characteristics for unique digital assets.\nProtocol Decision Making: In protocols where decisions need to be randomized, such as selecting validators or jurors.\nHow does Gelato VRF work?\n\nGelato VRF (Verifiable Random Function) provides trustable randomness on EVM-compatible blockchains. Here's a brief overview:\n\nCore Components:\n\nDrand: Gelato VRF utilizes Drand, a decentralized randomness beacon ensuring unpredictability and unbiased randomness.\n\nTop-level Flow:\n\nContract Deployment: Use GelatoVRFConsumerBase.sol as an interface for requesting random numbers.\nRequesting Randomness: Emit the RequestedRandomness event to signal the need for a random number.\nProcessing: Web3 functions fetch the random number from Drand.\nDelivery: The fulfillRandomness function delivers the random number to the requesting contract.\nQuick start guide\n\nIn order to get your VRF up and running with Gelato, you need to make your contract VRF Compatible.\n\nStep 1: Setup your development environment​\n\nEnsure you have either Foundry or Hardhat set up in your development environment.\n\nStep 2: Install the Gelato VRF contracts​\nFor hardhat users:\n npm install --save-dev @gelatodigital/vrf-contracts\n\nFor Foundry users:\n forge install gelatodigital/vrf-contracts --no-commit\n\nStep 3: Inherit GelatoVRFConsumerBase in your contract​\n// SPDX-License-Identifier: MIT\npragma solidity 0.8.18;\n\nimport {GelatoVRFConsumerBase} from \"./GelatoVRFConsumerBase.sol\";\n\ncontract YourContract is GelatoVRFConsumerBase {\n    // Your contract's code goes here\n}\n\nStep 4: Request randomness​\nfunction requestRandomness(bytes memory data) external {\n        require(msg.sender == ...);\n        uint64 requestId = _requestRandomness(data);\n    }\n\n\nStep 5: Implement the fulfillRandomness function\n\n function _fulfillRandomness(\n        bytes32 randomness,\n        uint64 requestId,\n        bytes memory data,\n    ) internal override {\n    }\n}\n\nStep 6: Pass dedicated msg.sender​\n\nWhen you're ready to deploy your Gelato VRF-compatible contract, an important step is to include the dedicated msg.sender as a constructor parameter. This ensures your contract is set up to work with the correct operator to fulfill the randomness requests. It's crucial to ensure that only authorized requests are processed.\n\n// SPDX-License-Identifier: MIT\npragma solidity 0.8.18;\n\nimport {GelatoVRFConsumerBase} from \"./GelatoVRFConsumerBase.sol\";\n\ncontract YourContract is GelatoVRFConsumerBase {\n    constructor(address operator)\n        GelatoVRFConsumerBase(operator) {\n        // Additional initializations\n    }\n\n    // The rest of your contract code\n}\n\n\nOnce your contract is ready & deployed, grab the address and Deploy your VRF instance!\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nFlair\nNext\nMoralis\nApplications of Gelato VRF\nStep 1: Setup your development environment\nStep 2: Install the Gelato VRF contracts\nStep 3: Inherit GelatoVRFConsumerBase in your contract\nStep 4: Request randomness\nStep 6: Pass dedicated msg.sender\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Moralis Quickstart - Crypto Data APIs for Arbitrum | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/third-party-docs/Moralis/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nMoralis Quickstart - Crypto Data APIs for Arbitrum\n\nMoralis is a blockchain data platform that provides developers with all the data they need to build better blockchain applications. From NFT data, token data and price data, through to raw blockchain data and RPC nodes, Moralis offers a wide range of products that cover all major crypto and blockchain use cases, and it supports Arbitrum together with all other major EVM chains.\n\nQuickstart Guide​\n\nGet started with Moralis APIs on Arbitrum by checking out our Get Started Guide, or watch some of our popular Youtube tutorials.\n\nMoralis APIs​\n\nAll Moralis APIs have support for Arbitrum and across all other major EVM blockchains. All endpoints have powerful filtering capabilities.\n\nENDPOINTS\n\nPlease check out the Moralis API Reference to see all the available API endpoints.\n\nWallet API​\n\nWith Moralis Wallet API you can get Wallet balances for tokens, NFTs and native assets, get full wallet history, net worth and a lot more.\n\nNFT API​\n\nWith Moralis NFT API you can get NFT data like collections, owners, prices, images and metadata.\n\nToken API​\n\nWith Moralis Token API you can get ERC20 token data like prices, ownership, metadata, transfers, approvals, liquidity, mints and burns.\n\nRPC Nodes​\n\nGet access to powerful RPC nodes on all major chains with Moralis Nodes.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nGelato VRF\nNext\nOpenfort\nQuickstart Guide\nMoralis APIs\nWallet API\nNFT API\nToken API\nRPC Nodes\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Quickstart: Indexing Arbitrum custom data via Flair | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/third-party-docs/Flair/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nQuickstart: Indexing Arbitrum custom data via Flair\n\nFlair, Real-time and historical custom data indexing for any evm chain.\n\nFlair offers reusable indexing primitives (such as fault-tolerant RPC ingestors, custom processors, re-org aware database integrations) to make it easy to receive, transform, store and access your on-chain data.\n\nWhy Flair?​\n\nCompared to other alternatives the main reasons are:\n\n🚀 Adopting parallel and distributed processing paradigm means high scalability and resiliency for your indexing stack. Instead of constrained sequential processing (e.g Subgraph).\n🧩 Focused on primitives, which means on the left you plug-in an RPC and on the right you output the data to any destination database.\n🚄 Native real-time stream processing for certain data workload (such as aggregations, rollups) for things like total volume per pool, or total portfolio per user wallet.\n☁️ Managed cloud services avoid DevOps and irrelevant engineering costs for dApp developers.\n🧑‍💻 Avoid decentralization overhead (consensus, network hops, etc) since we believe to enable best UX for dApps reading data must be as close to the developers as possible.\nFeatures​\n✅ Listen to any EVM chain with just an RPC URL.\nFree managed RPC URLs for +8 popular chains already included.\nWorks with both websocket and https-only RPCs.\n✅ Track and ingest any contract for any event topic.\nAuto-track new contracts deployed from factory contracts.\n✅ Custom processor scripts with Javascript runtime (with Typescript support)\nMake external API or Webhook calls to third-party or your backend.\nGet current or historical USD value of any ERC20 token amount of any contract address on any chain.\nUse any external NPM library.\n✅ Stream any stored data to your destination database (Postgres, MongoDB, MySQL, Kafka, Elasticsearch, Timescale, etc).\nGetting Started​\n\n1️⃣ Clone the starter boilerplate template and follow the instructions\n\ngit clone https://github.com/flair-sdk/starter-boilerplate.git\n# ... follow instructions in README.md\n\nINFO\n\nBoilerplate instructions will create a new cluster, generate an API Key, and set up a manifest.yml to index your first contract with sample custom processor scripts.\n\nLearn more about the structure of manifest.yml.\n\n2️⃣ Configure Arbitrum RPC nodes\n\nSet a unique namespace, Arbitrum chainId and RPC endpoint in your config. Remember that you can add up to 10 RPC endpoints for resiliency.\n\n{\n  'cluster': 'dev',\n  'namespace': 'my-awesome-arbitrum-indexing-dev',\n  'indexers':\n    [\n      {\n        'chainId': 42161,\n        'enabled': true,\n        'ingestionFilterGroup': 'default',\n        'processingFilterGroup': 'default',\n        'sources': [\n            # Highly-recommended to have at least 1 websocket endpoint\n            'wss://arbitrum-one.publicnode.com',\n            # You can put multiple endpoints for failover\n            'https://arbitrum.llamarpc.com',\n          ],\n      },\n    ],\n}\n\n\n3️⃣ Sync some historical data using backfill command. Remember that enabled: true flag in your config enabled your indexer to capture data in real-time already.\n\n# backfill certain contracts or block ranges\npnpm flair backfill --chain 42161 --address\n0x22dc069183f85a8473553e32b59efc9fec506baf -d backward --max-blocks 10000\n# backfill for a specific block number, if you have certain events you wanna test with\npnpm flair backfill --chain 42161 -b 132763420\n# backfill for the recent data in the last X minute\npnpm flair backfill --chain 42161 --min-timestamp=\"30 mins ago\" -d backward\n\n\n4️⃣ Query your custom indexed data.\n\n5️⃣ Stream the data to your own database.\n\nExamples​\n\nExplore real-world usage of Flair indexing primitives for various use-cases.\n\nDeFi​\nAggregate protocol fees in USD across multiple chains\nCalculate \"Health Factor\" of positions with contract factory tracking\nIndex Uniswap v2 swaps with USD price for all addresses\nNFT​\nIndex ERC721 and ERC1155 NFTs on any EVM chain with an RPC URL\nNeed help?​\n\nOur engineers are available to help you at any stage.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nEnvio\nNext\nGelato VRF\nWhy Flair?\nFeatures\nGetting Started\nExamples\nDeFi\nNFT\nNeed help?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Quickstart: Blazing-fast indexing and data analytics using Envio | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/third-party-docs/Envio/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nEnvio HyperIndex\n\nEnvio HyperIndex is a feature-rich indexing solution that provides developers with a seamless and efficient way to index and aggregate real-time or historical blockchain data for any EVM. The indexed data is easily accessible through custom GraphQL queries, providing developers with the flexibility and power to retrieve specific information.\n\nEnvio offers native support for Arbitrum One (testnet & mainnet), Aribitrum Nova (testnet & mainnet), and Arbitrum Orbit chains, and has been designed to support high-throughput blockchain applications that rely on real-time data for their business requirements.\n\nDesigned to optimize the user experience, Envio offers automatic code generation, flexible language support, quickstart templates, and a reliable cost-effective hosted service.\n\nIndexers on Envio can be written in JavaScript, TypeScript, or ReScript.\n\nEnvio HyperSync​\n\nEnvio supports HyperSync on Arbitrum.\n\nHyperSync is an accelerated data query layer for the Arbitrum networks, providing APIs that bypass JSON-RPC for 20-100x faster syncing of historical data. HyperSync is used by default in Envio HyperIndex, with the use of RPC being optional. Using HyperSync, application developers do not need to worry about RPC URLs, rate-limiting, or managing infrastructure and can easily sync large datasets in a few minutes, something that would usually take hours or days via RPC.\n\nHyperSync is also available as a standalone API for data analytic use cases. Data analysts can interact with the HyperSync API using JavaScript, Python, or Rust clients and extract data in JSON, Arrow, or Parquet formats. For more information, visit the HyperSync documentation here.\n\nHyperIndex key features​\n\nContract Import: Autogenerate the key boilerplate for an entire Indexer project off a single or multiple smart contracts. Deploy within minutes.\n\nMulti-chain Support: Aggregate data across multiple networks into a single database. Query all your data with a unified GraphQL API.\n\nAsynchronous Mode: Fetch data from off-chain storage such as IPFS, or contract state (e.g. smart contract view functions).\n\nQuickstart Templates: Use pre-defined indexing logic for popular OpenZeppelin contracts (e.g. ERC-20).\n\nGetting started​\n\nUsers can choose whether they want to start from a quickstart template, perform a subgraph migration, or use the contract import feature to get started with Envio HyperIndex.\n\nThe following files are required to run the Envio indexer:\n\nConfiguration (defaults to config.yaml)\nGraphQL Schema (defaults to schema.graphql)\nEvent Handlers (defaults to src/EventHandlers.* depending on the language chosen)\n\nThese files are auto-generated according to the template and language chosen by running the envio init command.\n\nContract import tutorial​\n\nThis walkthrough explains how to initialize an indexer using a single or multiple contracts that are already deployed on Arbitrum. This process allows a user to quickly and easily start up a basic indexer and a queryable GraphQL API for their application in less than 3 minutes.\n\nInitialize your indexer​\n\ncd into the folder of your choice and run\n\nenvio init\n\n\nName your indexer\n\n? Name your indexer:\n\n\nChoose the directory where you would like to setup your project (default is the current directory)\n\n? Set the directory:  (.) .\n\n\nSelect Contract Import as the initialization option.\n\n? Choose an initialization option\n  Template\n> ContractImport\n  SubgraphMigration\n[↑↓ to move, enter to select, type to filter]\n\n? Would you like to import from a block explorer or a local abi?\n> Block Explorer\n  Local ABI\n[↑↓ to move, enter to select, type to filter]\n\n\nBlock Explorer option only requires user to input the contracts address and chain of the contract. If the contract is verified and deployed on one of the supported chains, this is the quickest setup as it will retrieve all needed contract information from a block explorer.\n\nLocal ABI option will allow you to point to a JSON file containing the smart contract ABI. The Contract Import process will then populate the required files from the ABI.\n\nSelect the blockchain that the contract is deployed on​\n? Which blockchain would you like to import a contract from?\n  ethereum-mainnet\n  goerli\n> arbitrum-one\n  arbitrum-nova\n  bsc\n  gnosis\nv polygon\n[↑↓ to move, enter to select, type to filter]\n\nEnter the address of the contract to import​\n? What is the address of the contract?\n[Use the proxy address if your abi is a proxy implementation]\n\n\nNote if you are using a proxy contract with an implementation, the address should be for the proxy contract.\n\nChoose which events to include in the config.yaml file​\n? Which events would you like to index?\n> [x] ClaimRewards(address indexed from, address indexed reward, uint256 amount)\n  [x] Deposit(address indexed from, uint256 indexed tokenId, uint256 amount)\n  [x] NotifyReward(address indexed from, address indexed reward, uint256 indexed epoch, uint256 amount)\n  [x] Withdraw(address indexed from, uint256 indexed tokenId, uint256 amount)\n[↑↓ to move, space to select one, → to all, ← to none, type to filter]\n\nSelect the continuation option​\n? Would you like to add another contract?\n> I'm finished\n  Add a new address for same contract on same network\n  Add a new network for same contract\n  Add a new contract (with a different ABI)\n[Current contract: BribeVotingReward, on network: arbitrum-one]\n\n\nThe Contract Import process will prompt the user whether they would like to finish the import process or continue adding more addresses for same contract on same network, addresses for same contract on different network or a different contract.\n\nFor more information on contract import feature, visit the documentation here.\n\nEnvio examples​\n\nClick here for Envio HyperIndex examples. Click here for Envio HyperSync examples.\n\nGetting help​\n\nIndexing can be a rollercoaster, especially for more complex use cases. Our engineers are available to help you with your data availability needs.\n\nJoin our growing community of elite builders, and find peace of mind with Envio.\n\nDiscord\nEmail: hello@envio.dev\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nCrossmint\nNext\nFlair\nEnvio HyperSync\nHyperIndex key features\nGetting started\nContract import tutorial\nInitialize your indexer\nEnvio examples\nGetting help\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/third-party-docs/Covalent/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\n\nCovalent is a hosted blockchain data solution providing access to historical and current onchain data for 200+ supported blockchains, including Arbitrum One, Nova and Orbit chains.\n\nCovalent maintains a full replica of every supported blockchain, meaning you have access to:\n\nCurrent and historical account balances\nFull transaction histories\nEvery contract log event\nAll NFTs including assets and metadata\n\nUse Covalent if you need:\n\nWallet, Transactions, NFT, DEX, Staking or core blockchain data (log events, blocks)\nNormalized, aggregated and enhanced multichain data, well beyond what you get from RPC providers\nEnterprise-grade performance\n\nSign up to start building on Arbitrum\n\nAPIs\n\nThe Covalent APIs enables developers to quickly and easily access structured onchain data. This means consistent response schemas regardless of the blockchain. Available APIs and corresponding use cases include:\n\nWallet API​\nFeatures: All token balances (ERC20, 721, 1155, native), token transfers and prices (spot & historical) for a wallet.\nUse cases: Wallets, portfolio trackers, token gating, airdrop snapshots.\nNFT API​\nFeatures: Media assets, metadata, sales, owners, trait & attribute filters, thumbnails & previews.\nUse cases: NFT galleries & marketplaces, real world asset (RWA) tracking, token gating.\nDEX API​\nFeatures: Positions, rewards, pool and token details for major DEX protocols.\nUse cases: Analytics dashboards, leaderboards, reward calculators.\nCross-Chain Activity API​\nFeatures: Single API call to fetch a list of active chains and the latest transaction date on each for an address.\nUse cases: App onboarding.\nTransactions API​\nFeatures: All historical transactions with human-readable log events. Includes gas usage/spend summaries.\nUse cases: Accounting and tax tools, branded in-app transaction receipts.\nSecurity API​\nFeatures: NFT and ERC20 token allowances, including value-at-risk.\nUse cases: Revoke features in wallets, security applications.\nBlockchain API​\nFeatures: Block details, log events by contract address or topic hash, gas prices.\nUse cases: Custom block explorers.\nDeveloper Tools​\n\nThere are 3 primary developer tools for using the APIs:\n\nUnified API - enterprise-grade endpoints to use with any programming language. Switch blockchains with one path parameter.\n\ncurl -X GET https://api.covalenthq.com/v1/arbitrum-mainnet/address/0xf977814e90da44bfa03b6295a0616a897441acec/balances_v2/ \\\n    -H 'Content-Type: application/json' \\\n    -u YOUR_API_KEY:\n\n\nClient SDKs - official client libraries including TypeScript, Go and Python.\n\nTypeScript example:\n\nnpm install @covalenthq/client-sdk\n\n\nor:\n\nyarn add @covalenthq/client-sdk\n\nimport { CovalentClient } from \"@covalenthq/client-sdk\";\n\n(async () => {\ntry {\n    const client = new CovalentClient(\"YOUR_API_KEY\");\n    const transactions = client.TransactionService.getAllTransactionsForAddress(\"arbitrum-mainnet\", \"0xf977814e90da44bfa03b6295a0616a897441acec\");\n\n    for await (const tx of transactions) {\n    console.log(\"tx\", tx);\n    }\n} catch (error) {\n    console.log(error.message);\n}\n})();\n\n\nGoldRush Kit - beautifully designed React components for your dApp frontend \n\nGet started​\nAPI Key - sign up for free\nDocs - comprehensive knowledge base for all things Covalent\nGuides - learn how to build for various use cases and expand your onchain knowledge\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nusdc\nNext\nCrossmint\nWallet API\nNFT API\nDEX API\nCross-Chain Activity API\nTransactions API\nSecurity API\nBlockchain API\nDeveloper Tools\nGet started\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/third-party-docs/Crossmint/",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nHow to deploy an NFT smart contract and enable credit card and cross-chain payments with no-code\nCOMMUNITY MEMBER CONTRIBUTION\n\nShoutout to @rohit-710 for contributing the following third-party document!\n\nCrossmint is an enterprise-grade web3 development platform that lets you deploy smart contracts, create email wallets, enable credit-card and cross chain payments, and use APIs to create, distribute, sell, store, and edit NFTs.\n\nBy abstracting away the core complexities of the Blockchain, Crossmint allows you to build NFT applications without requiring any blockchain experience or holding cryptocurrency, and making the blockchain invisible to end users.\n\nCrossmint enables you to provide a Web2 experience for for your Web3 apps.\n\nCheck out Crossmint's Docs to get started.\n\nCrossmint Console​\n\nWhat you can achieve using Crossmint Console:\n\nCreate and deploy NFT Collections.\nCreate and airdrop NFTs.\nGenerate No-code Storefront and No-code claims page.\nAccept credit card and cross-chain payments for your NFT Collections.\nCreate and configure API Keys for Wallets and Minting.\nCreate Webhooks to listen to your Crossmint collections's endpoint URL's triggered events.\nWhitelist domains and set up Redirect URls for your NFT Collections' checkout.\nCROSSMINT CONSOLE\n\nPlease check out the docs to learn more. Click here to use Crossmint's Production Console and click here to use Crossmint's Staging Console.\n\nHow to deploy an NFT smart contract on Arbitrum and enable credit card and cross-chain payments with no-code​\n\nPlease checkout the step-by-step tutorial on the docs here and here.\n\nVIDEO TUTORIAL\n\nYou can find a YouTube video for the same here.\n\nConnect with Crossmint!​\n\nNeed further help? We got you! Check out all the ways you can reach Crossmint for further questions and support:\n\nVisit Crossmint's official website at crossmint.com\nRead developer Docs\nFor assistance, contact the Crossmint team via the Support forum\nFollow Crossmint on Twitter\nJoin the official Discord server\nCheck out Crossmint on Youtube\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nCovalent\nNext\nEnvio\nCrossmint Console\nHow to deploy an NFT smart contract on Arbitrum and enable credit card and cross-chain payments with no-code\nConnect with Crossmint!\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "usdc | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/third-party-docs/Circle/usdc-quickstart-guide/usdc",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nusdc-quickstart-guide\nusdc\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nusdc\nQuickStart​\n\nUSDC provides the ability to transfer dollars over the Arbitrum network using a smart contract. The smart contract enables users to send, receive, and store dollars on-chain with a wallet.\n\nThis guide will walk you through using the viem framework to build a simple app that enables a user to connect their wallet and interact with the blockchain by sending a USDC transaction from their address.\n\nPrerequisites​\n\nBefore you start building the sample app to perform a USDC transfer, ensure you meet the following prerequisites:\n\nNode.js and npm: Ensure that you have Node.js and npm installed on your machine. You can download and install Node.js from nodejs.org. npm comes with Node.js.\n\nMetaMask: Install the MetaMask browser extension and set up your wallet. Ensure that your wallet is funded with:\n\nSome native gas tokens (e.g., ETH on the Sepolia network) to cover transaction fees.\nUSDC tokens for the transfer. (USDC Testnet Faucet)\n\nProject Setup: Create a new project directory and initialize it with npm:\n\nmkdir usdc-transfer-app\ncd usdc-transfer-app\nnpm init -y\n\nDependencies: Install the required dependencies using the following command:\n   npm install react@^18.2.0 react-dom@^18.2.0 @types/react@^18.0.27 @types/react-dom@^18.0.10 @vitejs/plugin-react@^3.1.0 typescript@^5.0.3 vite@^4.4.5\n\n\nThis will set up your development environment with the necessary libraries and tools for building a React application with TypeScript and Vite.\n\nInstallation​\n\nTo install viem run the following command.\n\nnpm i viem\n\nSetup public client​\n\nThe public client is used to interact with your desired blockchain network.\n\nimport { http, createPublicClient } from 'viem';\nimport { arbitrumSepolia } from 'viem/chains';\n\nconst publicClient = createPublicClient({\n  chain: arbitrumSepolia,\n  transport: http(),\n});\n\nSetup wallet client​\n\nThe wallet client is used to interact with Arbitrum accounts to retrieve accounts, execute transactions, and sign messages.\n\nimport { createWalletClient } from 'viem';\nimport { arbitrumSepolia } from 'viem/chains';\n\nconst walletClient = createWalletClient({\n  chain: arbitrumSepolia,\n  transport: custom(window.ethereum!),\n});\n\nDefine USDC contract details​\n\nDefine the USDC contract address and ABI (Application Binary Interface). The ABI specifies the functions available in the contract. (The USDC Token Contract Address referenced in the code is on Ethereum Sepolia)\n\nconst USDC_CONTRACT_ADDRESS = '0x75faf114eafb1BDbe2F0316DF893fd58CE46AA4d';\nconst USDC_ABI = [\n  {\n    constant: false,\n    inputs: [\n      { name: '_to', type: 'address' },\n      { name: '_value', type: 'uint256' },\n    ],\n    name: 'transfer',\n    outputs: [{ name: '', type: 'bool' }],\n    type: 'function',\n  },\n];\n\nConnect wallet​\n\nCreate a function to connect the user's wallet and retrieve their account address.\n\nconst connect = async () => {\n  const [address] = await walletClient.requestAddresses();\n  setAccount(address);\n};\n\nSend transaction​\n\nCreate a function to send the USDC transfer transaction. This function encodes the transfer function data and sends the transaction using the wallet client.\n\nconst data = encodeFunctionData({\n  abi: USDC_ABI,\n  functionName: 'transfer',\n  args: [to, valueInWei],\n});\n\nconst hash = await walletClient.sendTransaction({\n  account,\n  to: USDC_CONTRACT_ADDRESS,\n  data,\n});\n\nWait for transaction receipt​\n\nUse the public client to wait for the transaction receipt, which confirms that the transaction has been mined.\n\nuseEffect(() => {\n  (async () => {\n    if (hash) {\n      const receipt = await publicClient.waitForTransactionReceipt({ hash });\n      setReceipt(receipt);\n    }\n  })();\n}, [hash]);\n\nFinal step: build your USDC transfer sample app​\n\nNow that you understand the core components for programmatically performing your first USDC transaction, create the following index.tsx and index.html files to build a sample app. This app will enable you to send USDC from one wallet to another. Ensure that your wallet is funded with both the native gas token and USDC.\n\nindex.tsx\nimport React, { useEffect, useState } from 'react';\nimport ReactDOM from 'react-dom/client';\nimport {\n  http,\n  type Address,\n  type Hash,\n  type TransactionReceipt,\n  createPublicClient,\n  createWalletClient,\n  custom,\n  stringify,\n  encodeFunctionData,\n} from 'viem';\nimport { arbitrumSepolia } from 'viem/chains';\nimport 'viem/window';\n\nconst publicClient = createPublicClient({\n  chain: arbitrumSepolia,\n  transport: http()\n});\n\nconst walletClient = createWalletClient({\n  chain: arbitrumSepolia,\n  transport: custom(window.ethereum!)\n});\n\nconst USDC_CONTRACT_ADDRESS = '0x75faf114eafb1BDbe2F0316DF893fd58CE46AA4d';\nconst USDC_ABI = [\n  {\n    constant: false,\n    inputs: [\n      { name: '_to', type: 'address' },\n      { name: '_value', type: 'uint256' },\n    ],\n    name: 'transfer',\n    outputs: [{ name: '', type: 'bool' }],\n    type: 'function',\n  },\n];\n\nfunction Example() {\n  const [account, setAccount] = useState<Address>();\n  const [hash, setHash] = useState<Hash>();\n  const [receipt, setReceipt] = useState<TransactionReceipt>();\n\n  const addressInput = React.createRef<HTMLInputElement>();\n  const valueInput = React.createRef<HTMLInputElement>();\n\n  const connect = async () => {\n    const [address] = await walletClient.requestAddresses();\n    setAccount(address);\n  };\n\n  const sendTransaction = async () => {\n    if (!account) return;\n    const to = addressInput.current!.value as Address;\n    const value = valueInput.current!.value as `${number}`;\n    const valueInWei = BigInt(value) * BigInt(10 ** 6); // Assuming USDC has 6 decimals\n\n    const data = encodeFunctionData({\n      abi: USDC_ABI,\n      functionName: 'transfer',\n      args: [to, valueInWei],\n    });\n\n    const hash = await walletClient.sendTransaction({\n      account,\n      to: USDC_CONTRACT_ADDRESS,\n      data,\n    });\n    setHash(hash);\n  };\n\n  useEffect(() => {\n    (async () => {\n      if (hash) {\n        const receipt = await publicClient.waitForTransactionReceipt({ hash });\n        setReceipt(receipt);\n      }\n    })();\n  }, [hash]);\n\n  if (account) {\n    return (\n      <>\n        <div>Connected: {account}</div>\n        <input ref={addressInput} placeholder=\"address\" />\n        <input ref={valueInput} placeholder=\"value (USDC)\" />\n        <button onClick={sendTransaction}>Send</button>\n        {receipt && (\n          <div>\n            Receipt: <pre><code>{stringify(receipt, null, 2)}</code></pre>\n          </div>\n        )}\n      </>\n    );\n  }\n  return <button onClick={connect}>Connect Wallet</button>;\n}\n\nReactDOM.createRoot(document.getElementById('root') as HTMLElement).render(\n<Example />\n);\n\nindex.html\n<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"UTF-8\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <title>USDC Transfer Sample App</title>\n  </head>\n  <body>\n    <h1>USDC Transfer Sample App</h1>\n    <div id=\"root\"></div>\n    <script type=\"module\" src=\"/index.tsx\"></script>\n  </body>\n</html>\n\n\nBy combining these index.tsx and index.html files, you will have a complete setup that allows you to perform a USDC transfer from your wallet. Simply connect your wallet, input the recipient's address and the amount of USDC to transfer, and click the “Send” button to execute the transaction. You will receive a transaction receipt once the transaction is confirmed on the blockchain.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nContribute third-party docs\nNext\nCovalent\nQuickStart\nPrerequisites\nInstallation\nSetup public client\nSetup wallet client\nDefine USDC contract details\nConnect wallet\nSend transaction\nWait for transaction receipt\nFinal step: build your USDC transfer sample app\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Contribute third-party docs | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/third-party-docs/contribute",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nContribute third-party docs\n\nThird-party docs are documents that help readers of Arbitrum docs use other products, services, and protocols (like the ones listed in the Arbitrum portal) with Arbitrum products.\n\nThese documents are usually authored by partner teams, but can be authored by anyone. They follow the same general process that core docs follow, in addition to the following guidelines:\n\nEligibility\nThird-party docs are intended to support products listed in the Arbitrum portal, or infrastructure and services that those products use.\nTo submit your project to the Arbitrum portal, apply using this Google form.\nPurpose\nThe purpose of our Third-party docs sections is to meet Arbitrum developer (or user) demand for guidance that helps them use non-Arbitrum products with Arbitrum products.\nIt's not meant to drive traffic to your product (although that may happen); it's meant to solve problems that our readers are actually facing, which are directly related to Arbitrum products.\nMaintenance expectations\nOffchain Labs can't commit to maintaining third-party docs, but we make it easy for you to maintain them.\nEnsure that your document's YAML frontmatter contains a third_party_content_owner property, with the Github username of the designated maintainer. This person will be assigned to your document's issues and PRs, and will be expected to resolve them in a timely manner.\nOrganization\nThird-party docs are organized within the Third-party content node located at the bottom of each documentation section's sidebar.\nThis node's content is grouped by third-party product. If/when this becomes unwieldy, we'll begin grouping products by portal category.\nLimited document types\nTo manage our team's limited capacity, third-party documents must be either Quickstarts, How-tos, or Concepts. See document types.\nIncremental contributions: One document at a time, procedures first\nThird-party document PRs should contain at most one new document.\nAny given product's first docs contribution should be a Quickstart or How-to.\nAdditional documents will be merged only if we can verify that our readers are deriving value from your initial contribution.\nThe way that we verify this isn't yet formally established, and it isn't publicly disclosed. Our current approach combines a number of objective and subjective measures.\nPolicy acknowledgment\nBefore merging third-party documentation PRs, we ask contributors to acknowledge that they've read, understood, and agree with the following policies:\nContent ownership: As the author, you retain ownership of and responsibility for the content you contribute. You're free to use your content in any way you see fit outside of Arbitrum's docs. Remember that when contributing content to our documentation, you must ensure you have the necessary rights to do so, and that the content doesn't infringe on the intellectual property rights of others.\nLicense for use: By contributing your content to our documentation, you grant Offchain Labs a non-exclusive, royalty-free license to use, reproduce, adapt, translate, distribute, and display the content in our documentation. This allows us to integrate your content into our docs and make it available to all users.\nRight to modify or remove: Offchain Labs reserves the right to modify or remove third-party content from our documentation at any time. This might be necessary due to a range of reasons, such as content becoming outdated, receiving very low pageviews over an extended period, or misalignment with our guidelines or goals.\nEdit this page\nLast updated on Nov 21, 2024\nPrevious\nTrellor\nNext\nusdc\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Public preview: What to expect | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/bold/public-preview-expectations",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nThe BoLD dispute protocol\nA gentle introduction\nDeploy a validator on testnet\nBoLD Whitepaper\nTechnical deep dive\nEconomics of Disputes\nSpecification on Github\nAudit Report by Trail of Bits\nAudit Report by Code4rena\nPublic preview\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nPublic preview: What to expect\n\nBoLD, Arbitrum's new dispute protocol, is currently tagged as an alpha release supported by public preview documentation. This concept document explains what \"public preview\" means, what to expect from public preview capabilities, and how to engage with our team as you tinker.\n\nHow products are developed at Offchain Labs​\n\nOffchain Labs builds products in a way that aligns loosely with the spirit of \"building in public\". We like to release things early and often so that we can capture feedback and iterate in service of your needs, as empirically as possible.\n\nTo do this, some of our product offerings are documented with public preview disclaimers that look like this:\n\nThis banner's purpose is to set expectations while inviting readers like you to express your needs so that we can incorporate them into the way that we iterate on product.\n\nWhat to expect when using public preview offerings​\n\nAs you tinker and provide feedback, we'll be listening. Sometimes, we'll learn something non-obvious that will result in a significant change. More commonly, you'll experience incremental improvements to the developer experience as the offering grows out of its public preview status, towards stable status.\n\nPublic preview offerings are evolving rapidly, so don't expect the degree of release notes discipline that you'd expect from a stable offering. Keep your eyes open for notifications regarding patch, minor, and major changes, along with corresponding relnotes that highlight breaking changes and new capabilities.\n\nHow to provide feedback​\n\nOur product team primarily uses three feedback channels while iterating on public preview capabilities:\n\nDocs: Click on the Request an update button located in the top-right corner of any document to provide feedback on the docs and/or developer experience. This will lead you to a prefilled Github issue that members of our product team periodically review.\nDiscord: Join the Arbitrum Discord to engage with members of the Arbitrum community and product team.\nGoogle form: Complete this form to ask for support.\nWhat to expect when providing feedback​\n\nOur ability to respond to feedback is determined by our ever-evolving capacity and priorities. We can't guarantee responses to all feedback submissions, but our small-but-mighty team is listening, and we'll try our best to acknowledge and respond to your feedback. No guarantees though!\n\nPS, our small-but-mighty team is hiring.\n\nThank you!​\n\nThanks for helping us build things that meet your needs! We're excited to engage with OGs and newcomers alike; please don't hesitate to reach out.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nEconomics of Disputes\nNext\nFAQ\nHow products are developed at Offchain Labs\nWhat to expect when using public preview offerings\nHow to provide feedback\nWhat to expect when providing feedback\nThank you!\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "RPC methods | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/arbitrum-vs-ethereum/rpc-methods#blocks",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nComparison overview\nBlock gas limit, numbers and time\nRPC methods\nSolidity support\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nRPC methods\n\nAlthough the majority of RPC methods follow the same behavior as in Ethereum, some methods might produce a different result, or add more information, when used on an Arbitrum chain. This page covers the differences in response body fields you'll find when calling RPC methods on an Arbitrum chain vs on Ethereum.\n\nINFO\n\nComprehensive documentation on all generally available JSON-RPC methods for Ethereum can be found at ethereum.org. As Arbitrum has go-ethereum at its core, most of the documented methods there can be used with no modifications.\n\nTransactions​\n\nWhen calling eth_getTransactionByHash and other methods that return a transaction, Arbitrum includes a few additional fields and leverages some existing fields in different ways than Ethereum.\n\nTransaction types​\n\nIn addition to the three transaction types currently supported on Ethereum, Arbitrum adds additional types listed below and documented in full detail here.\n\nOn RPC calls that return transactions, the type field will reflect the custom codes where applicable.\n\nTransaction type code\tTransaction type name\tDescription\n100\tArbitrumDepositTxType\tUsed to deposit ETH from L1 to L2 via the Arbitrum bridge\n101\tArbitrumUnsignedTxType\tUsed to call an L2 contract from L1, originated by a user through the Arbitrum bridge\n102\tArbitrumContractTxType\tUsed to call an L2 contract from L1, originated by a contract through the Arbitrum bridge\n104\tArbitrumRetryTxType\tUsed to manually redeem a retryable ticket on L2 that failed to execute automatically (usually due to low gas)\n105\tArbitrumSubmitRetryableTxType\tUsed to submit a retryable ticket via the Arbitrum bridge on L1\n106\tArbitrumInternalTxType\tInternal transactions created by the ArbOS itself for certain state updates, like the L1 base fee and the block number\nAdditional fields​\n\nOn RPC calls that return transactions, the following fields are added to the returned object.\n\nField name\tDescription\nrequestId\tOn L1 to L2 transactions, this field is added to indicate position in the Inbox queue\nExisting fields with different behavior​\n\nOn RPC calls that return transactions, the following fields will have a different content than what's received on Ethereum.\n\nField name\tDescription\nfrom\tOn L1 to L2 transactions, this field will contain the aliased version of the L1's msg.sender\nTransaction receipts​\n\nWhen calling eth_getTransactionReceipt, Arbitrum includes a few additional fields and leverages some existing fields in different ways than Ethereum.\n\nAdditional fields​\n\nOn RPC calls that return transaction receipts, the following fields are added to the returned object.\n\nField name\tDescription\nl1BlockNumber\tThe L1 block number that would be used for block.number calls. More information in Block numbers and time\ngasUsedForL1\tAmount of gas spent on L1 calldata in units of L2 gas. More information in Gas and fees\nBlocks​\n\nWhen calling eth_getBlockByHash and other methods that return a block, Arbitrum includes a few additional fields and leverages some existing fields in different ways than Ethereum.\n\nAdditional fields​\n\nOn RPC calls that return a block, the following fields are added to the returned object.\n\nField name\tDescription\nl1BlockNumber\tAn approximate L1 block number that occurred before this L2 block. More information in Block numbers and time\nsendCount\tThe number of L2 to L1 messages since Nitro genesis\nsendRoot\tThe Merkle root of the outbox tree state\nExisting fields with different behavior​\n\nOn RPC calls that return a block, the following fields will have a different content than what's received on Ethereum.\n\nField name\tDescription\nextraData\tThis field is equivalent to sendRoot\nmixHash\tFirst 8 bytes is equivalent to sendCount, second 8 bytes is equivalent to l1BlockNumber\ndifficulty\tFixed at 0x1\ngasLimit\tValue is fixed at 0x4000000000000, but it's important to note that Arbitrum One currently has a 32M gas limit per block. See Chain params for the gas limit of other chains\nOther methods that are slightly different​\neth_syncing​\n\nCalling eth_syncing returns false when the node is fully synced (just like on Ethereum). If the node is still syncing, eth_syncing returns an object with data about the synchronization status. Here, we provide more details.\n\nUnderstanding messages, batches, and blocks​\n\nNitro nodes receive transactions from their parent chain and the sequencer feed in the form of messages. These messages may contain multiple transactions that are executed by the node, which then produces blocks. Each message produces exactly one block. In most Nitro chains, the message number and the block number are the same. However, Arbitrum One has pre-Nitro (classic) blocks, so for that chain, message 0 produced block 22207818 (blocks prior to that one are 'classic' blocks). Keep in mind that the offset between message and block number is constant in the chain.\n\nOn the parent chain, messages appear in batches. The number of messages per batch changes between batches.\n\nCustom eth_syncing fields​\nINFO\n\nNote that the exact output for the eth_syncing RPC call of an out-of-sync Nitro node is not considered a stable API. It is still being actively developed and can be modified without notice between versions.\n\nField name\tDescription\nbatchSeen\tLast batch number observed on the parent chain\nbatchProcessed\tLast batch that was processed on the parent chain. Processing means dividing the batch into messages\nmessageOfProcessedBatch\tLast message in the last processed batch\nmsgCount\tNumber of messages known/queued by the Nitro node\nblockNum\tLast block created by the Nitro node (up-to-date L2 block the node is synced to)\nmessageOfLastBlock\tMessage that was used to produce the block above\nbroadcasterQueuedMessagesPos\tIf different than 0, this is expected to be greater than msgCount. This field notes a message that was read from the feed but not processed because earlier messages are still missing\nlastL1BlockNum\tLast block number from the parent chain that Nitro sees. This is used to debug the connection with the parent chain\nlastl1BlockHash\tLast block hash from the parent chain that Nitro sees. This is used to debug the connection with the parent chain\nINFO\n\nNote that if the sync process encounters an error while trying to collect the data above (not expected) this error will be added to the response.\n\nUnderstanding common scenarios​\nIf batchSeen > batchProcessed, some batches have still not been processed\nIf msgCount > messageOfLastBlock, some messages have been processed, but not all relevant blocks have been built (this is usually the longest stage while syncing a new node)\nIf broadcasterQueuedMessagesPos > msgCount, the feed is ahead of the last message known to the node\ndebug_traceTransaction​\n\nThe Nitro node provides a native tracer for debugging Stylus contracts called stylusTracer, which returns a JSON array with objects containing the metadata for each executed HostIO. HostIOs are calls the WasmVM makes to read and write data in the EVM. With the result of this tracer and the code for the Stylus contract, you have all the data to understand what happened in a Stylus transaction.\n\nINFO\n\nThe cargo-stylus command-line tool uses the stylusTracer to replay transactions locally inside a debugger. More information can be found on How to debug Stylus transactions using Cargo Stylus Replay.\n\nThe table below describes each field of the stylusTracer return value.\n\nField Name\tDescription\nname\tName of the execute HostIO.\nargs\tArguments of the HostIO encoded as hex.\nouts\tOutputs of the HostIO encoded as hex.\nstartInk\tAmount of Ink before executing the HostIO.\nendInk\tAmount of Ink after executing the HostIO.\naddress\tFor *call HostIOs, the address of the called contract.\nsteps\tFor *call HostIOs, the steps performed by the called contract.\n\nFor example, the command below illustrates how to call this tracer for a transaction.\n\ncurl -s \\\n    -X POST \\\n    -H \"Content-Type: application/json\" \\\n    -d '{\"jsonrpc\":\"2.0\",\"method\":\"debug_traceTransaction\",\"params\":[\"<transaction-hash>\", {\"tracer\": \"stylusTracer\"}],\"id\":1}' \\\n    <nitro-node-rpc>\n\n\nThe result of this call will be something along the lines of.\n\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 1,\n  \"result\": [\n    {\n      \"args\": \"0x00000024\",\n      \"endInk\": 116090000,\n      \"name\": \"user_entrypoint\",\n      \"outs\": \"0x\",\n      \"startInk\": 116090000\n    },\n    {\n      \"args\": \"0x\",\n      \"endInk\": 116057558,\n      \"name\": \"msg_reentrant\",\n      \"outs\": \"0x00000000\",\n      \"startInk\": 116065958\n    },\n    {\n      \"args\": \"0x\",\n      \"endInk\": 115937952,\n      \"name\": \"read_args\",\n      \"outs\": \"0x6c5283490000000000000000000000003bdff922e18bc03f1cf7b2a8b65a070cbec944f2\",\n      \"startInk\": 115951512\n    },\n    ...\n  ]\n}\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nBlock gas limit, numbers and time\nNext\nSolidity support\nTransactions\nTransaction types\nAdditional fields\nExisting fields with different behavior\nTransaction receipts\nAdditional fields\nBlocks\nAdditional fields\nExisting fields with different behavior\nOther methods that are slightly different\neth_syncing\ndebug_traceTransaction\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/sequencer#unhappyuncommon-case-sequencer-isnt-doing-its-job",
    "html": "Skip to main content\nArbitrum Docs\nPage Not Found\n\nWe could not find what you were looking for.\n\nPlease contact the owner of the site that linked you to the original URL and let them know their link is broken.\n\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/inside-arbitrum-nitro",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nInside Arbitrum Nitro\n\nThis document is a deep-dive explanation of Arbitrum Nitro’s design and the rationale for it. This isn’t API documentation, nor is it a guided tour of the code--look elsewhere for those. “Inside Arbitrum Nitro” is for people who want to understand Nitro's design.\n\nThe body of this document will describe Arbitrum Rollup, the primary use case of the Nitro technology and the one used on the Arbitrum One chain. There is a variant use case, called AnyTrust, which is used by the Arbitrum Nova chain. AnyTrust is covered by a section at the end of this document.\n\nWhy use Arbitrum? Why use Nitro?​\n\nArbitrum is an L2 scaling solution for Ethereum, offering a unique combination of benefits:\n\nTrustless security: security rooted in Ethereum, with any one party able to ensure correct Layer 2 results\nCompatibility with Ethereum: able to run unmodified EVM contracts and unmodified Ethereum transactions\nScalability: moving contracts’ computation and storage off of the main Ethereum chain, allowing much higher throughput\nMinimum cost: designed and engineered to minimize the L1 gas footprint of the system, minimizing per-transaction cost.\n\nSome other Layer 2 systems provide some of these features, but to our knowledge no other system offers the same combination of features at the same cost.\n\nNitro is a major upgrade to Arbitrum, improving over \"classic\" Arbitrum in several ways:\n\nAdvanced Calldata Compression, which further drives down transaction costs on Arbitrum by reducing the amount of data posted to L1.\nSeparate Contexts For Common Execution and Fault Proving, increasing the performance of L1 nodes, and thus offering lower fees.\nEthereum L1 Gas Compatibility, bringing pricing and accounting for EVM operations perfectly in line with Ethereum.\nAdditional L1 Interoperability, including tighter synchronization with L1 Block numbers, and full support for all Ethereum L1 precompiles.\nSafe Retryables, eliminating the failure mode where a retryable ticket fails to get created.\nGeth Tracing, for even broader debugging support.\nAnd many, many more changes.\nThe Big Picture​\n\nAt the most basic level, an Arbitrum chain works like this:\n\nOriginal napkin sketch drawn by Arbitrum co-founder Ed Felten\n\nUsers and contracts put messages into the inbox. The chain reads the messages one at a time, and processes each one. This updates the state of the chain and produces some outputs.\n\nIf you want an Arbitrum chain to process a transaction for you, you need to put that transaction into the chain’s inbox. Then the chain will see your transaction, execute it, and produce some outputs: a transaction receipt, and any withdrawals that your transaction initiated.\n\nExecution is deterministic -- which means that the chain’s behavior is uniquely determined by the contents of its inbox. Because of this, the result of your transaction is knowable as soon as your transaction has been put in the inbox. Any Arbitrum node will be able to tell you the result. (And you can run an Arbitrum node yourself if you want.)\n\nAll of the technical detail in this document is connected to this diagram. To get from this diagram to a full description of Arbitrum, we’ll need to answer questions like these:\n\nWho keeps track of the inbox, chain state, and outputs?\nHow does Arbitrum make sure that the chain state and outputs are correct?\nHow can Ethereum users and contracts interact with Arbitrum?\nHow does Arbitrum support Ethereum-compatible contracts and transactions?\nHow are ETH and tokens transferred into and out of Arbitrum chains, and how are they managed while on the chain?\nHow can I run my own Arbitrum node or validator?\nNitro's Design: The Four Big Ideas​\n\nThe essence of Nitro, and its key innovations, lie in four big ideas. We'll list them here with a very quick summary of each, then we'll unpack them in more detail in later sections.\n\nBig Idea: Sequencing, Followed by Deterministic Execution: Nitro processes transactions with a two-phase strategy. First, the transactions are organized into a single ordered sequence, and Nitro commits to that sequence. Then the transactions are processed, in that sequence, by a deterministic state transition function.\n\nBig Idea: Geth at the Core: Nitro supports Ethereum's data structures, formats, and virtual machine by compiling in the core code of the popular go-ethereum (\"Geth\") Ethereum node software. Using Geth as a library in this way ensures a very high degree of compatibility with Ethereum.\n\nBig Idea: Separate Execution from Proving: Nitro takes the same source code and compiles it twice, once to native code for execution in a Nitro node, optimized for speed, and again to WASM for use in proving, optimized for portability and security.\n\nBig Idea: Optimistic Rollup with Interactive Fraud Proofs: Nitro settles transactions to the Layer 1 Ethereum chain using an optimistic rollup protocol, including the interactive fraud proofs pioneered by Arbitrum.\n\nSequencing, Followed by Deterministic Execution​\n\nThis diagram summarizes how transactions are processed in Nitro.\n\nLet's follow a user's transaction through this process.\n\nFirst, the user creates a transaction, uses their wallet to sign it, and sends it to the Nitro chain's Sequencer. The Sequencer's job, as its name implies, is to take the arriving transactions, put them into an ordered sequence, and publish that sequence.\n\nOnce the transactions are sequenced, they are run through the state transition function, one by one, in order. The state transition function takes as input the current state of the chain (account balances, contract code, and so on), along with the next transaction. It updates the state and sometimes emits a new Layer 2 block on the Nitro chain.\n\nBecause the protocol doesn't trust the Sequencer not to put garbage into its sequence, the state transition function will detect and discard any invalid (e.g., improperly formed) transactions in the sequence. A well-behaved Sequencer will filter out invalid transactions so the state transition function never sees them--and this reduces cost and therefore keeps transactions fees low--but Nitro will still work correctly no matter what the Sequencer puts into its feed. (Transactions in the feed are signed by their senders, so the Sequencer can't create forged transactions.)\n\nThe state transition function is deterministic, which means that its behavior depends only on the current state and the contents of the next transaction--and nothing else. Because of this determinism, the result of a transaction T will depend only on the genesis state of the chain, the transactions before T in the sequence, and T itself.\n\nIt follows that anyone who knows the transaction sequence can compute the state transition function for themselves--and all honest parties who do this are guaranteed to get identical results. This is the normal way that Nitro nodes operate: get the transaction sequence, and run the state transition function locally. No consensus mechanism is needed for this.\n\nHow the Sequencer Publishes the Sequence​\n\nSo how do nodes get the sequence? The Sequencer publishes it in two ways: a real-time feed, and batches posted on L1 Ethereum.\n\nThe real-time feed is published by the Sequencer so that anyone who subscribes to the feed receives instant notifications of each transaction as it is sequenced. Nitro nodes can subscribe to the feed directly from the Sequencer, or through a relay that forwards the feed. The feed represents the Sequencer's promise that it will record transactions in a particular order. If the Sequencer is honest and doesn't have a long downtime, this promise will be kept. So anyone who trusts the Sequencer to keep its promises can rely on the feed to get instant information about the transaction sequence--and they can run the sequenced transactions through the state transition function to learn the results of each transaction immediately. This is \"soft finality\" for transactions; it's \"soft\" because it depends on the Sequencer keeping its promises.\n\nThe Sequencer also publishes its sequence on the L1 Ethereum chain. Periodically--perhaps every few minutes in production--the Sequencer concatenates the next group of transactions in the feed, compresses them for efficiency, and posts the result as calldata on Ethereum. This is the final and official record of the transaction sequence. As soon as this Ethereum transaction has finality on Ethereum, the Layer 2 Nitro transactions it records will have finality. These transactions are final because their position in the sequence has finality, and the outcome of the transactions is deterministic and knowable to any party. This is \"hard finality\".\n\nThe Sequencer's batches are compressed using a general-purpose data compression algorithm called \"brotli\", on its highest-compression setting.\n\nGeth at the Core​\n\nThe second key design idea in Nitro is \"geth at the core.\" Here \"geth\" refers to go-ethereum, the most common node software for Ethereum. As its name would suggest, go-ethereum is written in the Go programming language, as is almost all of Nitro.\n\nThe software that makes up a Nitro node can be thought of as built in three main layers, which are shown above:\n\nThe base layer is the core of geth--the parts of Geth that emulate the execution of EVM contracts and maintain the data structures that make up the Ethereum state. Nitro compiles in this code as a library, with a few minor modifications to add necessary hooks.\nThe middle layer, which we call ArbOS, is custom software that provides additional functions associated with Layer 2 functionality, such as decompressing and parsing the Sequencer's data batches, accounting for Layer 1 gas costs and collecting fees to reimburse for them, and supporting cross-chain bridge functionalities such as deposits of Ether and tokens from L1 and withdrawals of the same back to L1. We'll dig in to the details of ArbOS below.\nThe top layer consists of node software, mostly drawn from geth. This handles connections and incoming RPC requests from clients and provides the other top-level functionality required to operate an Ethereum-compatible blockchain node.\n\nBecause the top and bottom layers rely heavily on code from geth, this structure has been dubbed a \"geth sandwich.\" Strictly speaking, Geth plays the role of the bread in the sandwich, and ArbOS is the filling, but this sandwich is named for the bread.\n\nThe State Transition Function consists of the bottom Geth layer, and a portion of the middle ArbOS layer. In particular, the STF is a designated function in the source code, and implicitly includes all of the code called by that function. The STF takes as input the bytes of a transaction received in the inbox, and has access to a modifiable copy of the Ethereum state tree. Executing the STF may modify the state, and at the end will emit the header of a new block (in Ethereum's block header format) which will be appended to the Nitro chain.\n\nSeparating Execution from Proving​\n\nOne of the challenges in designing a practical rollup system is the tension between wanting the system to perform well in ordinary execution, versus being able to reliably prove the results of execution. Nitro resolves this tension by using the same source code for both execution and proving, but compiling it to different targets for the two cases.\n\nWhen compiling the Nitro node software for execution, the ordinary Go compiler is used, producing native code for the target architecture, which of course will be different for different node deployments. (The node software is distributed in source code form, and as a Docker image containing a compiled binary.)\n\nSeparately, for proving, the portion of the code that is the State Transition Function is compiled by the Go compiler to WebAssembly (wasm), which is a typed, portable machine code format. The wasm code then goes through a simple transformation into a format we call WAVM, which is detailed below. If there is a dispute about the correct result of computing the STF, it is resolved with reference to the WAVM code.\n\nWAVM​\n\nThe wasm format has many features that make it a good vehicle for fraud proofs---it is portable, structured, well-specified, and has reasonably good tools and support---but it needs a few modifications to do the job completely. Nitro uses a slightly modified version of wasm, which we call WAVM. A simple transformation stage turns the wasm code produced by the Go compiler into WAVM code suitable for proving.\n\nWAVM differs from wasm in three main ways. First, WAVM removes some features of wasm that are not generated by the Go compiler; the transformation phase verifies that these features are not present.\n\nSecond, WAVM restricts a few features of wasm. For example, WAVM does not contain floating-point instructions, so the transformer replaces floating-point instructions with calls to the Berkeley SoftFloat library. (We use software floating-point to reduce the risk of floating-point incompatibilities between architectures. The core Nitro functions never use floating-point, but the Go runtime does use some floating-point operations.) WAVM does not contain nested control flow, so the transformer flattens control flow constructs, turning control flow instructions into jumps. Some wasm instructions take a variable amount of time to execute, which we avoid in WAVM by transforming them into constructs using fixed cost instructions. These transformations simplify proving.\n\nThird, WAVM adds a few opcodes to enable interaction with the blockchain environment. For example, new instructions allow the WAVM code to read and write the chain's global state, to get the next message from the chain's inbox, or to signal a successful end to executing the State Transition Function.\n\nReadPreImage and the Hash Oracle Trick​\n\nThe most interesting new instruction is ReadPreImage which takes as input a hash H and an offset I, and returns the word of data at offset I in the preimage of H (and the number of bytes written, which is zero if I is at or after the end of the preimage). Of course, it is not feasible in general to produce a preimage from an arbitrary hash. For safety, the ReadPreImage instruction can only be used in a context where the preimage is publicly known, and where the size of the preimage is known to be less than a fixed upper bound of about 110 kbytes.\n\n(In this context, \"publicly known\" information is information that can be derived or recovered efficiently by any honest party, assuming that the full history of the L1 Ethereum chain is available. For convenience, a hash preimage can also be supplied by a third party such as a public server, and the correctness of the supplied value is easily verified.)\n\nAs an example, the state of a Nitro chain is maintained in Ethereum's state tree format, which is organized as a Merkle tree. Nodes of the tree are stored in a database, indexed by the Merkle hash of the node. In Nitro, the state tree is kept outside of the State Transition Function's storage, with the STF only knowing the root hash of the tree. Given the hash of a tree node, the STF can recover the tree node's contents by using ReadPreImage, relying on the fact that the full contents of the tree are publicly known and that nodes in the Ethereum state tree will always be smaller than the upper bound on preimage size. In this manner, the STF is able to arbitrarily read and write to the state tree, despite only storing its root hash.\n\nThe only other use of ReadPreImage is to fetch the contents of recent L2 block headers, given the header hash. This is safe because the block headers are publicly known and have bounded size.\n\nThis \"hash oracle trick\" of storing the Merkle hash of a data structure, and relying on protocol participants to store the full structure and thereby support fetch-by-hash of the contents, goes back to the original Arbitrum design.\n\nOptimistic Rollup​\n\nArbitrum is an optimistic rollup. Let’s unpack that term.\n\nRollup\n\nArbitrum is a rollup, which means that the inputs to the chain -- the messages that are put into the inbox -- are all recorded on the Ethereum chain as calldata. Because of this, everyone has the information they would need to determine the current correct state of the chain -- they have the full history of the inbox, and the results are uniquely determined by the inbox history, so they can reconstruct the state of the chain based only on public information, if needed.\n\nThis also allows anyone to be a full participant in the Arbitrum protocol, to run an Arbitrum node or participate as a validator. Nothing about the history or state of the chain is a secret.\n\nOptimistic\n\nArbitrum is optimistic, which means that Arbitrum advances the state of its chain by letting any party (a “validator”) post on Layer 1 a rollup block that that party claims is correct, and then giving everyone else a chance to challenge that claim. If the challenge period (6.4 days) passes and nobody has challenged the claimed rollup block, Arbitrum confirms the rollup block as correct. If someone challenges the claim during the challenge period, then Arbitrum uses an efficient dispute resolution protocol (detailed below) to identify which party is lying. The liar will forfeit a deposit, and the truth-teller will take part of that deposit as a reward for their efforts (some of the deposit is burned, guaranteeing that the liar is punished even if there's some collusion going on).\n\nBecause a party who tries to cheat will lose a deposit, attempts to cheat should be very rare, and the normal case will be a single party posting a correct rollup block, and nobody challenging it.\n\nResolving disputes using interactive fraud proofs​\n\nAmong optimistic rollups, the most important design decision is how to resolve disputes. Suppose Alice claims that the chain will produce a certain result, and Bob disagrees. How will the protocol decide which version to accept?\n\nThere are basically two choices: interactive proving, or re-executing transactions. Arbitrum uses interactive proving, which we believe is more efficient and more flexible. Much of the design of Arbitrum follows from this fact.\n\nInteractive proving​\n\nThe idea of interactive proving is that Alice and Bob will engage in a back-and-forth protocol, refereed by an L1 contract, to resolve their dispute with minimal work required from any L1 contract.\n\nArbitrum's approach is based on dissection of the dispute. If Alice's claim covers N steps of execution, she posts two claims of size N/2 which combine to yield her initial N-step claim, then Bob picks one of Alice's N/2-step claims to challenge. Now the size of the dispute has been cut in half. This process continues, cutting the dispute in half at each stage, until they are disagreeing about a single step of execution. Note that so far the L1 referee hasn't had to think about execution \"on the merits\". It is only once the dispute is narrowed down to a single step that the L1 referee needs to resolve the dispute by looking at what the instruction actually does and whether Alice's claim about it is correct.\n\nThe key principle behind interactive proving is that if Alice and Bob are in a dispute, Alice and Bob should do as much off-chain work as possible needed to resolve their dispute, rather than putting that work onto an L1 contract.\n\nRe-executing transactions​\n\nThe alternative to interactive proving would be to have a rollup block contain a claimed machine state hash after every individual transaction. Then in case of a dispute, the L1 referee would emulate the execution of an entire transaction, to see whether the outcome matches Alice's claim.\n\nWhy interactive proving is better​\n\nWe believe strongly that interactive proving is the superior approach, for the following reasons.\n\nMore efficient in the optimistic case: Because interactive proving can resolve disputes that are larger than one transaction, it can allow a rollup block to contain only a single claim about the end state of the chain after all of the execution covered by the block. By contrast, reexecution requires posting a state claim for each transaction within the rollup block. With hundred or thousands of transactions per rollup block, this is a substantial difference in L1 footprint -- and L1 footprint is the main component of cost.\n\nMore efficient in the pessimistic case: In case of a dispute, interactive proving requires the L1 referee contract only to check that Alice and Bob's actions \"have the right shape\", for example, that Alice has divided her N-step claim into two claims half as large. (The referee doesn't need to evaluate the correctness of Alice's claims--Bob does that, off-chain.) Only one instruction needs to be reexecuted. By contrast, reexecution requires the L1 referee to emulate the execution of an entire transaction.\n\nHigher per-tx gas limit: Interactive proving can escape from Ethereum's tight per-transaction gas limit. The gas limit isn't infinite, for obvious reasons, but it can be larger than on Ethereum. As far as Ethereum is concerned, the only downside of a gas-heavy Arbitrum transaction is that it may require an interactive fraud proof with slightly more steps (and only if indeed it is fraudulent). By contrast, reexecution must impose a lower gas limit than Ethereum, because it must be possible to emulate execution of the transaction (which is more expensive than executing it directly) within a single Ethereum transaction.\n\nMore implementation flexibility: Interactive proving allows more flexibility in implementation. All that is necessary is the ability to verify a one-step proof on Ethereum. By contrast, reexecution approaches are tethered to limitations of the EVM.\n\nInteractive proving drives the design of Arbitrum​\n\nMuch of the design of Arbitrum is driven by the opportunities opened up by interactive proving. If you're reading about some feature of Arbitrum, and you're wondering why it exists, two good questions to ask are: \"How does this support interactive proving?\" and \"How does this take advantage of interactive proving?\" The answers to most \"why\" questions about Arbitrum relate to interactive proving.\n\nArbitrum Rollup Protocol​\n\nBefore diving into the rollup protocol, there are two things we need to cover.\n\nFirst, if you’re an Arbitrum user or developer, you don’t need to understand the rollup protocol. You don’t ever need to think about it, unless you want to. Your relationship with it can be like a train passenger’s relationship with the train’s engine: you know it exists, you rely on it to keep working, but you don’t spend your time monitoring it or studying its internals.\n\nYou’re welcome to study, observe, and even participate in the rollup protocol, but you don’t need to, and most people won’t. So if you’re a typical train passenger who just wants to read or talk to your neighbor, you can skip right to the next section of this document. If not, read on!\n\nThe second thing to understand about the rollup protocol is that the protocol doesn’t decide the results of transactions, it only confirms the results. The results are uniquely determined by the sequence of messages in the chain’s inbox. So once your transaction message is in the chain’s inbox, its result is knowable--and Arbitrum nodes will report that your transaction is done. The role of the rollup protocol is to confirm transaction results that, as far as Arbitrum users are concerned, have already occurred. (This is why Arbitrum users can effectively ignore the rollup protocol.)\n\nYou might wonder why we need the rollup protocol. If everyone knows the results of transactions already, why bother confirming them? The rollup protocol exists for two reasons. First, somebody might lie about a result, and we need a definitive, trustless way to tell who is lying. Second, Ethereum doesn’t know the results. The whole point of a Layer 2 scaling system is to run transactions without Ethereum needing to do all of the work--and indeed Arbitrum can go fast enough that Ethereum couldn’t hope to monitor every Arbitrum transaction. But once a result is confirmed, Ethereum knows about it and can rely on it, enabling operations on Ethereum such as processing withdrawals of funds from Nitro back to L1.\n\nWith those preliminaries behind us, let’s jump into the details of the rollup protocol.\n\nThe parties who participate in the protocol are called validators. Some validators will choose to be bonders--they will place an ETH deposit which they’ll be able to recover if they’re not caught cheating. In the common case, it's expected that only one validator will be bonded, since as long as it's bonded on the current outcome, and there are no conflicting claims, there's no need for other parties to bond/take any action. The protocol allows for these roles to be permissionless in principle; currently on Arbitrum One, validators/bonders are allowlisted (see \"State of Progressive Decentralization\"). \"Watchtower validators,\" who monitor the chain but don't take any on-chain actions, can be run permissionlessly (see \"validators\" below).\n\nThe key security property of the rollup protocol is that any one honest validator can force the correct execution of the chain to be confirmed. This means that execution of an Arbitrum chain is as trustless as Ethereum. You, and you alone (or someone you hire) can force your transactions to be processed correctly. And that is true no matter how many malicious people are trying to stop you.\n\nThe Rollup Chain​\n\nThe rollup protocol tracks a chain of rollup blocks---we'll call these \"RBlocks\" for clarity. They're not the same as Layer 1 Ethereum blocks, and also not the same as Layer 2 Nitro blocks. You can think of the RBlocks as forming a separate chain, which the Arbitrum rollup protocol manages and oversees.\n\nValidators can propose RBlocks. New RBlocks will be unresolved at first. Eventually every RBlock will be resolved, by being either confirmed or rejected. The confirmed RBlocks make up the confirmed history of the chain.\n\nNOTE\n\nValidators and proposers serve different roles. Validators validate transactions to the State Transition Function (STF) and chain state, whereas proposers can also assert and challenge the chain state.\n\nEach RBlock contains:\n\nthe RBlock number\nthe predecessor RBlock number: RBlock number of the last RBlock before this one that is (claimed to be) correct\nthe number of L2 blocks that have been created in the chain's history\nthe number of inbox messages that have been consumed in the chain’s history\na hash of the outputs produced over the chain’s history.\n\nExcept for the RBlock number, the contents of the RBlock are all just claims by the RBlock's proposer. Arbitrum doesn’t know at first whether any of these fields are correct. If all of these fields are correct, the protocol should eventually confirm the RBlock. If one or more of these fields are incorrect, the protocol should eventually reject the RBlock.\n\nAn RBlock is implicitly claiming that its predecessor RBlock is correct. This implies, transitively, that an RBlock implicitly claims the correctness of a complete history of the chain: a sequence of ancestor RBlocks that reaches all the way back to the birth of the chain.\n\nAn RBlock is also implicitly claiming that its older siblings (older RBlocks with the same predecessor), if there are any, are incorrect. If two RBlocks are siblings, and the older sibling is correct, then the younger sibling is considered incorrect, even if everything else in the younger sibling is true.\n\nThe RBlock is assigned a deadline, which says how long other validators have to respond to it. If you’re a validator, and you agree that an RBlock is correct, you don’t need to do anything. If you disagree with an RBlock, you can post another RBlock with a different result, and you’ll probably end up in a challenge against the first RBlock's bonder. (More on challenges below.)\n\nIn the normal case, the rollup chain will look like this:\n\nOn the left, representing an earlier part of the chain’s history, we have confirmed RBlocks. These have been fully accepted and recorded by the Layer 1 contracts that manage the chain. The newest of the confirmed RBlocks, RBlock 94, is called the “latest confirmed RBlock.” On the right, we see a set of newer proposed RBlocks. The protocol can’t yet confirm or reject them, because their deadlines haven’t run out yet. The oldest RBlock whose fate has yet to be determined, RBlock 95, is called the “first unresolved RBlock.”\n\nNotice that a proposed RBlock can build on an earlier proposed RBlock. This allows validators to continue proposing RBlocks without needing to wait for the protocol to confirm the previous one. Normally, all of the proposed RBlocks will be valid, so they will all eventually be accepted.\n\nHere’s another example of what the chain state might look like, if several validators are being malicious. It’s a contrived example, designed to illustrate a variety of cases that can come up in the protocol, all smashed into a single scenario.\n\nThere’s a lot going on here, so let’s unpack it.\n\nRBlock 100 has been confirmed.\nRBlock 101 claimed to be a correct successor to RBlock 100, but 101 was rejected (hence it is orange).\nRBlock 102 was eventually confirmed as the correct successor to 100.\nRBlock 103 was confirmed and is now the latest confirmed RBlock.\nRBlock 104 was proposed as a successor to RBlock 103, and 105 was proposed as a successor to 104. 104 was rejected as incorrect, and as a consequence 105 was rejected because its predecessor was rejected.\nRBlock 106 is unresolved. It claims to be a correct successor to RBlock 103 but the protocol hasn’t yet decided whether to confirm or reject it. It is the first unresolved RBlock.\nRBlocks 107 and 108 claim to chain from 106. They are also unresolved. If 106 is rejected, they will be automatically rejected too.\nRBlock 109 disagrees with RBlock 106, because they both claim the same predecessor. At least one of them will eventually be rejected, but the protocol hasn’t yet resolved them.\nRBlock 110 claims to follow 109. It is unresolved. If 109 is rejected, 110 will be automatically rejected too.\nRBlock 111 claims to follow 104. 111 will inevitably be rejected because its predecessor has already been rejected. But it hasn’t been rejected yet, because the protocol resolves RBlocks in RBlock number order, so the protocol will have to resolve 106 through 110, in order, before it can resolve 111. After 110 has been resolved, 111 can be rejected immediately.\n\nAgain: this sort of thing is very unlikely in practice. In this diagram, at least four parties must have bonded on wrong RBlocks, and when the dust settles at least four parties will have lost their bonds. The protocol handles these cases correctly, of course, but they’re rare corner cases. This diagram is designed to illustrate the variety of situations that are possible in principle, and how the protocol would deal with them.\n\nStaking​\n\nAt any given time, some validators will be bonders, and some will not. Bonders deposit funds that are held by the Arbitrum Layer 1 contracts and will be confiscated if the bonder loses a challenge. Nitro chains accept bonds in ETH.\n\nA single bond can cover a chain of RBlocks. Every bonder is bonded on the latest confirmed RBlock; and if you’re bonded on an RBlock, you can also bond on one successor of that RBlock. So you might be bonded on a sequence of RBlocks that represent a single coherent claim about the correct history of the chain. A single bond suffices to commit you to that sequence of RBlocks.\n\nIn order to create a new RBlock, you must be a bonder, and you must already be bonded on the predecessor of the new RBlock you’re creating. The bond requirement for RBlock creation ensures that anyone who creates a new RBlock has something to lose if that RBlock is eventually rejected.\n\nThe protocol keeps track of the current required bond amount. Normally this will equal the base bond amount, which is a parameter of the Nitro chain. But if the chain has been slow to make progress lately, the required bond will increase, as described in more detail below.\n\nThe rules for staking are as follows:\n\nIf you’re not bonded, you can bond on the latest confirmed RBlock. When doing this, you deposit the current minimum bond amount.\nIf you’re bonded on an RBlock, you can also add your bond to any one successor of that RBlock. (The protocol tracks the maximum RBlock number you’re bonded on, and lets you add your bond to any successor of that RBlock, updating your maximum to that successor.) This doesn’t require you to place a new bond.\nA special case of adding your bond to a successor RBlock is when you create a new RBlock as a successor to an RBlock you’re already bonded on.\nIf you’re bonded only on the latest confirmed RBlock (and possibly earlier RBlocks), you or anyone else can ask to have your bond refunded. Your bonded funds will be returned to you, and you will no longer be a bonder.\nIf you lose a challenge, your bond is removed from all RBlocks and you forfeit your bonded funds.\n\nNotice that once you are bonded on an RBlock, there is no way to unbond. You are committed to that RBlock. Eventually one of two things will happen: that RBlock will be confirmed, or you will lose your bond. The only way to get your bond back is to wait until all of the RBlocks you are bonded on are confirmed.\n\nSetting the current minimum bond amount​\n\nOne detail we deferred earlier is how the current minimum bond amount is set. Normally, this is just equal to the base bond amount, which is a parameter of the Nitro chain. However, if the chain has been slow to make progress in confirming RBlocks, the bond requirement will escalate temporarily. Specifically, the base bond amount is multiplied by a factor that is exponential in the time since the deadline of the first unresolved RBlock passed. This ensures that if malicious parties are placing false bonds to try to delay progress (despite the fact that they’re losing those bonds), the bond requirement goes up so that the cost of such a delay attack increases exponentially. As RBlock resolution starts advancing again, the bond requirement will go back down.\n\nRules for Confirming or Rejecting RBlocks​\n\nThe rules for resolving RBlocks are fairly simple.\n\nThe first unresolved RBlock can be confirmed if:\n\nthe RBlock's predecessor is the latest confirmed RBlock, and\nthe RBlock's deadline has passed, and\nthere is at least one bonder, and\nAll bonders are bonded to the RBlock.\n\nThe first unresolved RBlock can be rejected if:\n\nthe RBlock's predecessor has been rejected, or\nall of the following are true:\nthe RBlock's deadline has passed, and\nthere is at least one bonder, and\nno bonder is bonded on the RBlock.\n\nA consequence of these rules is that once the first unresolved RBlock's deadline has passed (and assuming there is at least one bonder bonded on something other than the latest confirmed RBlock), the only way the RBlock can be unresolvable is if at least one bonder is bonded on it and at least one bonder is bonded on a different RBlock with the same predecessor. If this happens, the two bonders are disagreeing about which RBlock is correct. It’s time for a challenge, to resolve the disagreement.\n\nChallenges​\n\nSuppose the rollup chain looks like this:\n\nRBlocks 93 and 95 are siblings (they both have 92 as predecessor). Alice is bonded on 93 and Bob is bonded on 95.\n\nAt this point we know that Alice and Bob disagree about the correctness of RBlock 93, with Alice committed to 93 being correct and Bob committed to 93 being incorrect. (Bob is bonded on 95, and 95 implicitly claims that 92 is the last correct RBlock before it, which implies that 93 must be incorrect.)\n\nWhenever two bonders are bonded on sibling RBlocks, and neither of those bonders is already in a challenge, anyone can start a challenge between the two. The rollup protocol will record the challenge and referee it, eventually declaring a winner and confiscating the loser’s bond. The loser will be removed as a bonder.\n\nThe challenge is a game in which Alice and Bob alternate moves, with an Ethereum contract as the referee. Alice, the defender, moves first.\n\nThe game will operate in two phases: dissection, followed by one-step proof. Dissection will narrow down the size of the dispute until it is a dispute about just one instruction of execution. Then the one-step proof will determine who is right about that one instruction.\n\nWe’ll describe the dissection part of the protocol twice. First, we’ll give a simplified version which is easier to understand but less efficient. Then we’ll describe how the real version differs from the simplified one.\n\nDissection Protocol: Simplified Version​\n\nAlice is defending the claim that starting with the state in the predecessor RBlock, the state of the Virtual Machine can advance to the state specified in RBlock A. Essentially she is claiming that the Virtual Machine can execute N instructions, and that that execution will consume M inbox messages and transform the hash of outputs from H’ to H.\n\nAlice’s first move requires her to dissect her claims about intermediate states between the beginning (0 instructions executed) and the end (N instructions executed). So we require Alice to divide her claim in half, and post the state at the half-way point, after N/2 instructions have been executed.\n\nNow Alice has effectively bisected her N-step assertion into two (N/2)-step assertions. Bob has to point to one of those two half-size assertions and claim it is wrong.\n\nAt this point we’re effectively back in the original situation: Alice having made an assertion that Bob disagrees with. But we have cut the size of the assertion in half, from N to N/2. We can apply the same method again, with Alice bisecting and Bob choosing one of the halves, to reduce the size to N/4. And we can continue bisecting, so that after a logarithmic number of rounds Alice and Bob will be disagreeing about a single step of execution. That’s where the dissection phase of the protocol ends, and Alice must make a one-step proof which will be checked by the EthBridge.\n\nWhy Dissection Correctly Identifies a Cheater​\n\nBefore talking about the complexities of the real challenge protocol, let’s stop to understand why the simplified version of the protocol is correct. Here correctness means two things: (1) if Alice’s initial claim is correct, Alice can always win the challenge, and (2) if Alice’s initial claim is incorrect, Bob can always win the challenge.\n\nTo prove (1), observe that if Alice’s initial claim is correct, she can offer a truthful midpoint claim, and both of the implied half-size claims will be correct. So whichever half Bob objects to, Alice will again be in the position of defending a correct claim. At each stage of the protocol, Alice will be defending a correct claim. At the end, Alice will have a correct one-step claim to prove, so that claim will be provable and Alice can win the challenge.\n\nTo prove (2), observe that if Alice’s initial claim is incorrect, this can only be because her claimed endpoint after N steps is incorrect. Now when Alice offers her midpoint state claim, that midpoint claim is either correct or incorrect. If it’s incorrect, then Bob can challenge Alice’s first-half claim, which will be incorrect. If Alice’s midpoint state claim is correct, then her second-half claim must be incorrect, so Bob can challenge that. So whatever Alice does, Bob will be able to challenge an incorrect half-size claim. At each stage of the protocol, Bob can identify an incorrect claim to challenge. At the end, Alice will have an incorrect one-step claim to prove, which she will be unable to do, so Bob can win the challenge.\n\n(If you’re a stickler for mathematical precision, it should be clear how these arguments can be turned into proofs by induction on N.)\n\nThe Real Dissection Protocol​\n\nThe real dissection protocol is conceptually similar to the simplified one described above, but with several changes that improve efficiency or deal with necessary corner cases. Here is a list of the differences.\n\nDissection over L2 blocks, then over instructions: Alice's assertion is over an RBlock, which asserts the result of creating some number of Layer 2 Nitro blocks. Dissection first occurs over these Layer 2 blocks, to narrow the dispute down to a dispute about a single Layer 2 Nitro block. At this point, the dispute transforms into a dispute about a single execution of the State Transition Function or in other words about the execution of a sequence of WAVM instructions. The protocol then executes the recursive dissection sub-protocol again, this time over WAVM instructions, to narrow the dispute to a single instruction. The dispute concludes with a one-step proof of a single instruction (or a party failing to act and losing by timeout).\n\nK-way dissection: Rather than dividing a claim into two segments of size N/2, we divide it into K segments of size N/K. This requires posting K-1 intermediate claims, at points evenly spaced through the claimed execution. This reduces the number of rounds by a factor of log(K)/log(2).\n\nAnswer a dissection with a dissection: Rather than having each round of the protocol require two moves, where Alice dissects and Bob chooses a segment to challenge, we instead require Bob, in challenging a segment, to post his own claimed endpoint state for that segment (which must differ from Alice’s) as well as his own dissection of his version of the segment. Alice will then respond by identifying a subsegment, posting an alternative endpoint for that segment, and dissecting it. This reduces the number of moves in the game by an additional factor of 2, because the size is cut by a factor of K for every move, rather than for every two moves.\n\nDeal With the Empty-Inbox Case: The real AVM can’t always execute N units of gas without getting stuck. The machine might halt, or it might have to wait because its inbox is exhausted so it can’t go on until more messages arrive. So Bob must be allowed to respond to Alice’s claim of N units of execution by claiming that N steps are not possible. The real protocol thus allows any response (but not the initial claim) to claim a special end state that means essentially that the specified amount of execution is not possible under the current conditions.\n\nTime Limits: Each player is given a time allowance. The total time a player uses for all of their moves must be less than the time allowance, or they lose the game. Think of the time allowance as being about a week.\n\nIt should be clear that these changes don’t affect the basic correctness of the challenge protocol. They do, however, improve its efficiency and enable it to handle all of the cases that can come up in practice.\n\nEfficiency​\n\nThe challenge protocol is designed so that the dispute can be resolved with a minimum of work required by the protocol (via its Layer 1 Ethereum contracts) in its role as referee. When it is Alice’s move, the protocol only needs to keep track of the time Alice uses, and ensure that her move does include K-1 intermediate points as required. The protocol doesn’t need to pay attention to whether those claims are correct in any way; it only needs to know whether Alice’s move “has the right shape”.\n\nThe only point where the protocol needs to evaluate a move “on the merits” is at the one-step proof, where it needs to look at Alice’s proof and determine whether the proof that was provided does indeed establish that the virtual machine moves from the before state to the claimed after state after one step of computation.\n\nValidators​\n\nSome Arbitrum nodes will choose to act as validators. This means that they watch the progress of the rollup protocol and participate in that protocol to advance the state of the chain securely.\n\nNot all nodes will choose to do this. Because the rollup protocol doesn’t decide what the chain will do but merely confirms the correct behavior that is fully determined by the inbox messages, a node can ignore the rollup protocol and simply compute for itself the correct behavior. For more on what such nodes might do, see the Full Nodes section.\n\nOffchain Labs provides open source validator software, including a pre-built Docker image.\n\nEvery validator can choose their own approach, but we expect validators to follow three common strategies:\n\nThe active validator strategy tries to advance the state of the chain by proposing new RBlocks. An active validator is always bonded, because creating an RBlock requires being bonded. A chain really only needs one honest active validator; any more is an inefficient use of resources. For the Arbitrum One chain, Offchain Labs runs an active validator.\nThe defensive validator strategy watches the rollup protocol operate. If only correct RBlocks are proposed, this strategy doesn't bond. But if an incorrect RBlock is proposed, this strategy intervenes by posting a correct RBlock or staking on a correct RBlock that another party has posted. This strategy avoids staking when things are going well, but if someone is dishonest it bonds in order to defend the correct outcome.\nThe watchtower validator strategy never bonds. It simply watches the rollup protocol and if an incorrect RBlock is proposed, it raises the alarm (by whatever means it chooses) so that others can intervene. This strategy assumes that other parties who are willing to bond will be willing to intervene in order to take some of the dishonest proposer’s bond, and that that can happen before the dishonest RBlock’s deadline expires. (In practice this will allow several days for a response.)\n\nUnder normal conditions, validators using the defensive and watchtower strategies won’t do anything except observe. A malicious actor who is considering whether to try cheating won’t be able to tell how many defensive and watchtower validators are operating incognito. Perhaps some defensive validators will announce themselves, but others probably won’t, so a would-be attacker will always have to worry that defenders are waiting to emerge.\n\nThe underlying protocol supports permissionless validation, i.e.,--anyone can do it. Currently on Arbitrum One, validators that require bond (i.e., active and defensive validators) are whitelisted; see \"State of Progressive Decentralization\".\n\nWho will be validators? Anyone will be able to do it, but most people will choose not to. In practice we expect people to validate a chain for several reasons.\n\nValidators could be paid for their work, by the party that created the chain or someone else. A chain could be configured such that a portion of the funds from user transaction fees are paid directly to validators.\nParties who have significant assets at bond on a chain, such as dapp developers, exchanges, power-users, and liquidity providers, may choose to validate in order to protect their investment.\nAnyone who chooses to validate can do so. Some users will probably choose to validate in order to protect their own interests or just to be good citizens. But ordinary users don’t need to validate, and we expect that the vast majority of users won’t.\nArbOS​\n\nArbOS is a trusted \"system glue\" component that runs at Layer 2 as part of the State Transition Function. ArbOS provides functions needed for a Layer 2 system, such as cross-chain communication, resource accounting and Layer 2 related fee economics, and chain management.\n\nWhy ArbOS?​\n\nIn Arbitrum, much of the work that would otherwise have to be done expensively at Layer 1 is instead done by ArbOS, trustlessly performing these functions at the speed and low cost of Layer 2.\n\nSupporting these functions in Layer 2 trusted software, rather than building them in to the L1-enforced rules of the architecture as Ethereum does, offers significant advantages in cost because these operations can benefit from the lower cost of computation and storage at Layer 2, instead of having to manage those resources as part of a Layer 1 contract. Having a trusted operating system at Layer 2 also has significant advantages in flexibility, because Layer 2 code is easier to evolve, or to customize for a particular chain, than a Layer-1 enforced architecture would be.\n\nFull Nodes​\n\nAs the name suggests, full nodes in Arbitrum play the same role that full nodes play in Ethereum: they know the state of the chain and they provide an API that others can use to interact with the chain.\n\nArbitrum full nodes normally \"live at Layer 2\" which means that they don’t worry about the rollup protocol but simply treat their Arbitrum chain as a mechanism that feeds inbox messages to the State Transition Function to evolve the Layer 2 chain and produce outputs.\n\nThe Sequencer​\n\nThe Sequencer is a specially designated full node, which is given limited power to control the ordering of transactions. This allows the Sequencer to guarantee the results of user transactions immediately, without needing to wait for anything to happen on Ethereum. So no need to wait five minutes or so for block confirmations--and no need to even wait 15 seconds for Ethereum to make a block.\n\nClients interact with the Sequencer in exactly the same way they would interact with any full node, for example by giving their wallet software a network URL that happens to point to the Sequencer.\n\nCurrently, on the Arbitrum One and Arbitrum Nova chains, the Sequencer is run by Offchain Labs.\n\nInstant confirmation​\n\nWithout a Sequencer, a node can predict what the results of a client transaction will be, but the node can't be sure, because it can't know or control how the transactions it submits will be ordered in the inbox, relative to transactions submitted by other nodes.\n\nThe Sequencer is given more control over ordering, so it has the power to assign its clients' transactions a position in the inbox queue, thereby ensuring that it can determine the results of client transactions immediately. The Sequencer's power to reorder has limits (see below for details) but it does have more power than anyone else to influence transaction ordering.\n\nInboxes, fast and slow​\n\nWhen we add a Sequencer, the operation of the inbox changes.\n\nOnly the Sequencer can put new messages directly into the inbox. The Sequencer tags the messages it is submitting with an Ethereum block number and timestamp. (ArbOS ensures that these are non-decreasing, adjusting them upward if necessary to avoid decreases.)\nAnyone else can submit a message, but messages submitted by non-Sequencer nodes will be put into the \"delayed inbox\" queue, which is managed by an L1 Ethereum contract.\nMessages in the delayed inbox queue will wait there until the Sequencer chooses to \"release\" them into the main inbox, where they will be added to the end of the inbox. A well-behaved Sequencer will typically release delayed messages after about ten minutes, for reasons explained below.\nAlternatively, if a message has been in the delayed inbox queue for longer than a maximum delay interval (currently 24 hours on Arbitrum One) then anyone can force it to be promoted into the main inbox. (This ensures that the Sequencer can only delay messages but can't censor them.)\nIf the Sequencer is well-behaved...​\n\nA well-behaved Sequencer will accept transactions from all requesters and treat them fairly, giving each one a promised transaction result as quickly as it can.\n\nIt will also minimize the delay it imposes on non-Sequencer transactions by releasing delayed messages promptly, consistent with the goal of providing strong promises of transaction results. Specifically, if the Sequencer believes that 40 confirmation blocks are needed to have good confidence of finality on Ethereum, then it will release delayed messages after 40 blocks. This is enough to ensure that the Sequencer knows exactly which transactions will precede its current transaction, because those preceding transactions have finality. There is no need for a benign Sequencer to delay non-Sequencer messages more than that, so it won't.\n\nThis does mean that transactions that go through the delayed inbox will take longer to get finality. Their time to finality will roughly double, because they will have to wait one finality period for promotion, then another finality period for the Ethereum transaction that promoted them to achieve finality.\n\nThis is the basic tradeoff of having a Sequencer: if your message uses the Sequencer, finality is C blocks faster; but if your message doesn't use the Sequencer, finality is C blocks slower. This is usually a good tradeoff, because most transactions will use the Sequencer; and because the practical difference between instant and 10-minute finality is bigger than the difference between 10-minute and 20-minute finality.\n\nSo a Sequencer is generally a win, if the Sequencer is well behaved.\n\nIf the Sequencer is malicious...​\n\nA malicious Sequencer, on the other hand, could cause some pain. If it refuses to handle your transactions, you're forced to go through the delayed inbox, with longer delay. And a malicious Sequencer has great power to front-run everyone's transactions, so it could profit greatly at users' expense.\n\nOn Arbitrum One, Offchain Labs currently runs a Sequencer which is well-behaved--we promise!. This will be useful but it's not decentralized. Over time, we'll switch to decentralized, fair sequencing, as described below.\n\nBecause the Sequencer will be run by a trusted party at first, and will be decentralized later, we haven't built in a mechanism to directly punish a misbehaving Sequencer. We're asking users to trust the centralized Sequencer at first, until we switch to decentralized fair sequencing later.\n\nDecentralized fair sequencing​\n\nViewed from 30,000 feet, decentralized fair sequencing isn't too complicated. Instead of being a single centralized server, the Sequencer is a committee of servers, and as long as a large enough supermajority of the committee is honest, the Sequencer will establish a fair ordering over transactions.\n\nHow to achieve this is more complicated. Research by a team at Cornell Tech, including Offchain Labs CEO and Co-founder Steven Goldfeder, developed the first-ever decentralized fair sequencing algorithm. With some improvements that are under development, these concepts will form the basis for our longer-term solution, of a fair decentralized Sequencer.\n\nBridging​\n\nWe have already covered how users interact with L2 contracts--they submit transactions by putting messages into the chain’s inbox, or having a full node Sequencer or aggregator do so on their behalf. Let’s talk about how contracts interact between L1 and L2--how an L1 contract calls an L2 contract, and vice versa.\n\nThe L1 and L2 chains run asynchronously from each other, so it is not possible to make a cross-chain call that produces a result within the same transaction as the caller. Instead, cross-chain calls must be asynchronous, meaning that the caller submits the call at some point in time, and the call runs later. As a consequence, a cross-chain contract-to-contract call can never produce a result that is available to the calling contract (except for acknowledgement that the call was successfully submitted for later execution).\n\nL1 contracts can submit L2 transactions​\n\nAn L1 contract can submit an L2 transaction, just like a user would, by calling the Nitro chain's inbox contract on Ethereum. This L2 transaction will run later, producing results that will not be available to the L1 caller. The transaction will execute at L2, but the L1 caller won’t be able to see any results from the L2 transaction.\n\nThe advantage of this method is that it is simple and has relatively low latency. The disadvantage, compared to the other method we’ll describe soon, is that the L2 transaction might revert if the L1 caller doesn’t get the L2 gas price and max gas amount right. Because the L1 caller can’t see the result of its L2 transaction, it can’t be absolutely sure that its L2 transaction will succeed.\n\nThis would introduce a serious a problem for certain types of L1 to L2 interactions. Consider a transaction that includes depositing a token on L1 to be made available at some address on L2. If the L1 side succeeds, but the L2 side reverts, you've just sent some tokens to the L1 inbox contract that are unrecoverable on either L2 or L1. Not good.\n\nL1 to L2 ticket-based transactions​\n\nFortunately, we have another method for L1 to L2 calls, which is more robust against gas-related failures, that uses a ticket-based system. The idea is that an L1 contract can submit a “retryable” transaction. The Nitro chain will try to run that transaction. If the transaction succeeds, nothing else needs to happen. But if the transaction fails, Nitro will create a “ticketID” that identifies that failed transaction. Later, anyone can call a special pre-compiled contract at L2, providing the ticketID, to try redeeming the ticket and re-executing the transaction.\n\nWhen saving a transaction for retry, Nitro records the sender’s address, destination address, callvalue, and calldata. All of this is saved, and the callvalue is deducted from the sender’s account and (logically) attached to the saved transaction.\n\nIf the redemption succeeds, the transaction is done, a receipt is issued for it, and the ticketID is canceled and can’t be used again. If the redemption fails, for example because the packaged transaction fails, the redemption reports failure and the ticketID remains available for redemption.\n\nNormally the original submitter will try to cause their transaction to succeed immediately, so it never needs to be recorded or retried. As an example, our \"token deposit\" use case above should, in the happy, common case, still only require a single signature from the user. If this initial execution fails, the ticketID will still exist as a backstop which others can redeem later.\n\nSubmitting a transaction in this way carries a price in ETH which the submitter must pay, which varies based on the calldata size of the transaction. Once submitted, the ticket is valid for about a week. If the ticket has not been redeemed in that period, it is deleted.\n\nWhen the ticket is redeemed, the pre-packaged transaction runs with sender and origin equal to the original submitter, and with the destination, callvalue, and calldata the submitter provided at the time of submission.\n\nThis mechanism is a bit more cumbersome than ordinary L1 to L2 transactions, but it has the advantage that the submission cost is predictable and the ticket will always be available for redemption if the submission cost is paid. As long as there is some user who is willing to redeem the ticket, the L2 transaction will eventually be able to execute and will not be silently dropped.\n\nL2 to L1 ticket-based calls​\n\nCalls from L2 to L1 operate in a similar way, with a ticket-based system. An L2 contract can call a method of the precompiled ArbSys contract, to send a transaction to L1. When the execution of the L2 transaction containing the submission is confirmed at L1 (some days later), a ticket is created in the L1 outbox contract. That ticket can be triggered by anyone who calls a certain L1 outbox method and submits the ticketID. The ticket is only marked as redeemed if the L1 transaction does not revert.\n\nThese L2-to-L1 tickets have unlimited lifetime, until they’re successfully redeemed. No rent is required, as the tickets (actually a Merkle hash of the tickets) are recorded in Ethereum storage, which does not require rent. (The cost of allocating storage for the ticket Merkle roots is covered by L2 transaction fees.)\n\nGas and Fees​\n\nNitroGas (so-called to avoid confusion with Layer 1 Ethereum gas) is used by Arbitrum to track the cost of execution on a Nitro chain. It works the same as Ethereum gas, in the sense that every EVM instruction costs the same amount of gas that it would on Ethereum.\n\nThe Speed Limit​\n\nThe security of Nitro chains depends on the assumption that when one validator creates an RBlock, other validators will check it, and respond with a correct RBlock and a challenge if it is wrong. This requires that the other validators have the time and resources to check each RBlock quickly enough to issue a timely challenge. The Arbitrum protocol takes this into account in setting deadlines for RBlocks.\n\nThis sets an effective speed limit on execution of a Nitro chain: in the long run the chain cannot make progress faster than a validator can emulate its execution. If RBlocks are published at a rate faster than the speed limit, their deadlines will get farther and farther in the future. Due to the limit, enforced by the rollup protocol contracts, on how far in the future a deadline can be, this will eventually cause new RBlocks to be slowed down, thereby enforcing the effective speed limit.\n\nBeing able to set the speed limit accurately depends on being able to estimate the time required to validate an RBlock, with some accuracy. Any uncertainty in estimating validation time will force us to set the speed limit lower, to be safe. And we do not want to set the speed limit lower, so we try to enable accurate estimation.\n\nFees​\n\nUser transactions pay fees, to cover the cost of operating the chain. These fees are assessed and collected by ArbOS at L2. They are denominated in ETH.\n\nFees are charged for two resources that a transaction can use:\n\nL2 gas: an Ethereum-equivalent amount of gas, as required to execute the transaction on the Nitro chain,\nL1 calldata: a fee per unit of L1 calldata attributable to the transaction, which is charged only if the transaction came in via the Sequencer, and is paid to the Sequencer to cover its costs,\nL2 gas fees​\n\nL2 gas fees work very similarly to gas on Ethereum. A transaction uses some amount of gas, and this is multiplied by the current basefee to get the L2 gas fee charged to the transaction.\n\nThe L2 basefee is set by a version of the \"exponential mechanism\" which has been widely discussed in the Ethereum community, and which has been shown equivalent to Ethereum's EIP-1559 gas pricing mechanism.\n\nThe algorithm compares gas usage against a parameter called the \"speed limit\" which is the target amount of gas per second that the chain can handle sustainably over time. (Currently the speed limit on Arbitrum One is 7,000,000 gas per second.) The algorithm tracks a gas backlog. Whenever a transaction consumes gas, that gas is added to the backlog. Whenever the clock ticks one second, the speed limit is subtracted from the backlog; but the backlog can never go below zero.\n\nIntuitively, if the backlog grows, the algorithm should increase the gas price, to slow gas usage, because usage is above the sustainable level. If the backlog shrinks, the price should decrease again because usage has been below the below the sustainable limit so more gas usage can be welcomed.\n\nTo make this more precise, the basefee is an exponential function of the backlog, F = exp(-a(B-b)), where a and b are suitably chosen constants: a controls how rapidly the price escalates with backlog, and b allows a small backlog before the basefee escalation begins.\n\nL1 calldata fees​\n\nL1 calldata fees exist because the Sequencer, or the batch poster which posts the Sequencer's transaction batches on Ethereum, incurs costs in L1 gas to post transactions on Ethereum as calldata. Funds collected in L1 calldata fees are credited to the batch poster to cover its costs.\n\nEvery transaction that comes in through the Sequencer will pay an L1 calldata fee. Transactions that come in through the delayed inbox do not pay this fee because they don't add to batch posting costs--but these transactions pay gas fees to Ethereum when they are put into the delayed inbox.\n\nThe L1 pricing algorithm assigns an L1 calldata fee to each Sequencer transaction. First, it computes the transaction's size, which is an estimate of how many bytes the transaction will add to the compressed batch it is in; the formula for this includes an estimate of how compressible the transaction is. Second, it multiplies the computed size estimate by the current price per estimated byte, to determine the transaction's L1 calldata wei, in wei. Finally, it divides this cost by the current L2 basefee to translate the fee into L2 gas units. The result is reported as the \"poster fee\" for the transaction.\n\nThe price per estimated byte is set by a dynamic algorithm that compares the total L1 calldata fees collected to the total fees actually paid by batch posters, and tries to bring the two as close to equality as possible. If the batch posters' costs have been less than fee receipts, the price will increase, and if batch poster costs have exceeded fee receipts, the price will decrease.\n\nTotal fee and gas estimation​\n\nThe total fee charged to a transaction is the L2 basefee, multiplied by the sum of the L2 gas used plus the L1 calldata charge. As on Ethereum, a transaction will fail if it fails to supply enough gas, or if it specifies a basefee limit that is below the current basefee. Ethereum also allows a \"tip\" but Nitro ignores this field and never collects any tips.\n\nInside AnyTrust​\n\nAnyTrust is a variant of Arbitrum Nitro technology that lowers costs by accepting a mild trust assumption.\n\nThe Arbitrum protocol requires that all Arbitrum nodes, including validators (nodes that verify correctness of the chain and are prepared to bond on correct results), have access to the data of every L2 transaction in the Arbitrum chain's inbox. An Arbitrum rollup provides data access by posting the data (in batched, compressed form) on L1 Ethereum as calldata. The Ethereum gas to pay for this is the largest component of cost in Arbitrum.\n\nAnyTrust relies instead on an external Data Availability Committee (hereafter, \"the Committee\") to store data and provide it on demand. The Committee has N members, of which AnyTrust assumes at least two are honest. This means that if N - 1 Committee members promise to provide access to some data, at least one of the promising parties must be honest. Since there are two honest members, and only one failed to make the promise, it follows that at least one of the promisers must be honest — and that honest member will provide data when it is needed to ensure the chain can properly function.\n\nKeysets​\n\nA Keyset specifies the public keys of Committee members and the number of signatures required for a Data Availability Certificate to be valid. Keysets make Committee membership changes possible and provide Committee members the ability to change their keys.\n\nA Keyset contains\n\nthe number of Committee members, and\nfor each Committee member, a BLS public key, and\nthe number of Committee signatures required.\n\nKeysets are identified by their hashes.\n\nAn L1 KeysetManager contract maintains a list of currently valid Keysets. The L2 chain's Owner can add or remove Keysets from this list. When a Keyset becomes valid, the KeysetManager contract emits an L1 Ethereum event containing the Keyset's hash and full contents. This allows the contents to be recovered later by anyone, given only the Keyset hash.\n\nAlthough the API does not limit the number of Keysets that can be valid at the same time, normally only one Keyset will be valid.\n\nData Availability Certificates​\n\nA central concept in AnyTrust is the Data Availability Certificate (hereafter, a \"DACert\"). A DACert contains:\n\nthe hash of a data block, and\nan expiration time, and\nproof that N-1 Committee members have signed the (hash, expiration time) pair, consisting of\nthe hash of the Keyset used in signing, and\na bitmap saying which Committee members signed, and\na BLS aggregated signature (over the BLS12-381 curve) proving that those parties signed.\n\nBecause of the 2-of-N trust assumption, a DACert constitutes proof that the block's data (i.e., the preimage of the hash in the DACert) will be available from at least one honest Committee member, at least until the expiration time.\n\nIn ordinary (non-AnyTrust) Nitro, the Arbitrum sequencer posts data blocks on the L1 chain as calldata. The hashes of the data blocks are committed by the L1 Inbox contract, allowing the data to be reliably read by L2 code.\n\nAnyTrust gives the sequencer two ways to post a data block on L1: it can post the full data as above, or it can post a DACert proving availability of the data. The L1 inbox contract will reject any DACert that uses an invalid Keyset; the other aspects of DACert validity are checked by L2 code.\n\nThe L2 code that reads data from the inbox reads a full-data block as in ordinary Nitro. If it sees a DACert instead, it checks the validity of the DACert, with reference to the Keyset specified by the DACert (which is known to be valid because the L1 Inbox verified that). The L2 code verifies that\n\nthe number of signers is at least the number required by the Keyset, and\nthe aggregated signature is valid for the claimed signers, and\nthe expiration time is at least two weeks after the current L2 timestamp.\n\nIf the DACert is invalid, the L2 code discards the DACert and moves on to the next data block. If the DACert is valid, the L2 code reads the data block, which is guaranteed to be available because the DACert is valid.\n\nData Availability Servers​\n\nCommittee members run Data Availability Server (DAS) software. The DAS exposes two APIs:\n\nThe Sequencer API, which is meant to be called only by the Arbitrum chain's Sequencer, is a JSON-RPC interface allowing the Sequencer to submit data blocks to the DAS for storage. Deployments will typically block access to this API from callers other than the Sequencer.\nThe REST API, which is meant to be available to the world, is a RESTful HTTP(S) based protocol that allows data blocks to be fetched by hash. This API is fully cacheable, and deployments may use a caching proxy or CDN to increase scale and protect against DoS attacks.\n\nOnly Committee members have reason to support the Sequencer API. We expect others to run the REST API, and that is helpful. (More on that below.)\n\nThe DAS software, based on configuration options, can store its data in local files, or in a Badger database, or on Amazon S3, or redundantly across multiple backing stores. The software also supports optional caching in memory (using Bigcache) or in a Redis instance.\n\nSequencer-Committee Interaction​\n\nWhen the Arbitrum sequencer produces a data batch that it wants to post using the Committee, it sends the batch's data, along with an expiration time (normally three weeks in the future) via RPC to all Committee members in parallel. Each Committee member stores the data in its backing store, indexed by the data's hash. Then the member signs the (hash, expiration time) pair using its BLS key, and returns the signature with a success indicator to the sequencer.\n\nOnce the Sequencer has collected enough signatures, it can aggregate the signatures and create a valid DACert for the (hash, expiration time) pair. The Sequencer then posts that DACert to the L1 inbox contract, making it available to the AnyTrust chain software at L2.\n\nIf the Sequencer fails to collect enough signatures within a few minutes, it will abandon the attempt to use the Committee, and will \"fall back to rollup\" by posting the full data directly to the L1 chain, as it would do in a non-AnyTrust chain. The L2 software can understand both data posting formats (via DACert or via full data) and will handle each one correctly.\n\nEdit this page\nLast updated on Nov 20, 2024\nPrevious\nL1 pricing\nNext\nAssertion tree\nWhy use Arbitrum? Why use Nitro?\nThe Big Picture\nNitro's Design: The Four Big Ideas\nSequencing, Followed by Deterministic Execution\nHow the Sequencer Publishes the Sequence\nGeth at the Core\nSeparating Execution from Proving\nOptimistic Rollup\nResolving disputes using interactive fraud proofs\nInteractive proving\nRe-executing transactions\nWhy interactive proving is better\nInteractive proving drives the design of Arbitrum\nArbitrum Rollup Protocol\nThe Rollup Chain\nStaking\nRules for Confirming or Rejecting RBlocks\nChallenges\nDissection Protocol: Simplified Version\nWhy Dissection Correctly Identifies a Cheater\nThe Real Dissection Protocol\nEfficiency\nValidators\nArbOS\nWhy ArbOS?\nFull Nodes\nThe Sequencer\nInstant confirmation\nInboxes, fast and slow\nIf the Sequencer is well-behaved...\nIf the Sequencer is malicious...\nDecentralized fair sequencing\nBridging\nL1 contracts can submit L2 transactions\nL1 to L2 ticket-based transactions\nL2 to L1 ticket-based calls\nGas and Fees\nThe Speed Limit\nFees\nInside AnyTrust\nKeysets\nData Availability Certificates\nData Availability Servers\nSequencer-Committee Interaction\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/troubleshooting-building-orbit",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nOrbit FAQ\nCan I use Orbit to deploy a mainnet chain?​\n\nYes! Arbitrum Orbit's core technology has undergone a comprehensive audit and is now able to support deployments to mainnet. You can read more about it here.\n\nHow can I deploy an Orbit-based Layer 3 (L3) chain?​\n\nCheck our Quickstart to learn how to launch your own Orbit chain today.\n\nDo I need permission/license to launch an Orbit chain?​\n\nYou can permissionlessly launch an L3 Orbit chain that settles to one of Arbitrum's Layer 2 (L2) chains. There is an emerging licensing structure will soon make it possible to permissionlessly launch an L2 Orbit chain that settles directly to Ethereum. Please get in touch with the Arbitrum Foundation or Offchain Labs for more information.\n\nNote that launching a testnet doesn't require any license.\n\nDoes Arbitrum officially deploy and/or maintain L3s for external teams?​\n\nNo. Teams are required to deploy and maintain their Orbit chains. There are, however, several RaaS (Rollup as a Service) providers that can deploy and maintain the Orbit chain for you.\n\nCan I modify Orbit's underlying technology to customize my chain?​\n\nYes, you can make any changes you require to the underlying Nitro code base.\n\nWhat Data Availability (DA) solutions are currently available for Orbit chains?​\n\nArbitrum Orbit currently supports 3 different DA solutions:\n\nRollup, posting data to the parent chain which ultimately posts the data to Ethereum.\nAnyTrust, posting data to a Data Availability Committee, selected by the chain owner.\nCelestia, posting data to Celestia network.\n\nNote that using AnyTrust gives the chain owner the most flexibility and cheapest fees.\n\nWhat token is used to pay gas fees on Orbit chains?​\n\nBy default, Orbit chains pay gas in ETH. However, Orbit chains using AnyTrust can be configured to use any ERC-20 token as the gas fee token of the chain.\n\nCan I use Ethereum toolkits to develop on my Orbit chain?​\n\nOrbit chains are fully EVM-compatible. Most tools that support Ethereum should be able to support an Orbit chain. There are, however, certain differences that developers need to keep in mind when building on an Orbit chain. You can find them here.\n\nDo Orbit chains have any built-in AA solution?​\n\nNot by default, but they can be customized to have native AA.\n\nIs there any cross-chain bridging solution between two Orbit chains?​\n\nThere is currently no Orbit-to-Orbit native bridging solution, other than going through the parent chain (if they share the same parent chain). However, there are many third-party bridges that have expressed interest in supporting Orbit chains.\n\nIs there an official block explorer for Orbit chains?​\n\nOrbit chains deployments usually come with an open-source blockscout explorer by default, but there are many third-party solutions that have expressed interest in supporting Orbit chains.\n\nIs there any indexing solution that supports Orbit chains?​\n\nSimilar to bridges and block explorers, there are many third-party indexing solutions that have expressed interest in supporting Orbit chains.\n\nCan I increase the maximum contract size for my Orbit chain?​\n\nYes, Orbit supports an increased smart contract size limit of up to 96kB. You can use our Orbit SDK and configure the parameters MaxCodeSize and MaxInitCodeSize when calling prepareNodeConfig. Note that the smart contract size limit parameters can't be changed via upgrade after deployment.\n\nHow can I modify Nitro to force posting an invalid assertion and test the fraud proof mechanism?​\n\nForcing an invalid assertion in the chain is not supported at the moment. However, if you're building Nitro locally, you can run the following test that goes through the whole rollup/challenge mechanism:\n\ngo test ./system_tests/ -tags=challengetest -run=TestChallenge\n\n\n\nWhat fee collectors can be configured on my chain?​\n\nThere are 4 fee types that can be configured on an Orbit chain:\n\nL2 base fee: L2 execution fees corresponding to the minimum base price of the chain. This is paid to the infraFeeAccount, which can be set by calling ArbOwner.setInfraFeeAccount().\nL2 surplus fee: L2 execution fees above the minimum base price (in the case of congestion). This is paid to the networkFeeAccount, which can be set by calling ArbOwner.setNetworkFeeAccount().\nL1 base fee: Relative fees for posting a transaction on the parent chain. This is paid ultimately to the fee collector of the active batch poster. The batch poster can be set by calling SequencerInbox.setIsBatchPoster() on the parent chain. And a different fee collector for that batch poster can be specified by calling ArbAggregator.setFeeCollector().\nL1 surplus fee: Any extra fees rewarded to the batch poster. This is paid to a specific L1RewardRecipient, which can be set by calling ArbOwner.setL1PricingRewardRecipient()\n\nMore detailed information about fees can be found in the L1 fees and L2 fees pages.\n\nInformation about the precompiles methods can be found in the Precompiles reference page.\n\nLast updated on Nov 18, 2024\nPrevious\nThird-party infrastructure providers\nNext\nWrite Stylus contracts\nCan I use Orbit to deploy a mainnet chain?\nHow can I deploy an Orbit-based Layer 3 (L3) chain?\nDo I need permission/license to launch an Orbit chain?\nDoes Arbitrum officially deploy and/or maintain L3s for external teams?\nCan I modify Orbit's underlying technology to customize my chain?\nWhat Data Availability (DA) solutions are currently available for Orbit chains?\nWhat token is used to pay gas fees on Orbit chains?\nCan I use Ethereum toolkits to develop on my Orbit chain?\nDo Orbit chains have any built-in AA solution?\nIs there any cross-chain bridging solution between two Orbit chains?\nIs there an official block explorer for Orbit chains?\nIs there any indexing solution that supports Orbit chains?\nCan I increase the maximum contract size for my Orbit chain?\nHow can I modify Nitro to force posting an invalid assertion and test the fraud proof mechanism?\nWhat fee collectors can be configured on my chain?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/reference/stylus-sdk",
    "html": "Skip to main content\nArbitrum Docs\nStylus SDK repositories\n\nIf you are looking to write and deploy Stylus contracts, please see the following SDKs.\n\nRepo\tUse cases\tLicense\nRust SDK\tEverything!\tApache 2.0 or MIT\nC/C++ SDK\tCryptography and algorithms\tApache 2.0 or MIT\nBf SDK\tEducational\tApache 2.0 or MIT\nCargo Stylus CLI Tool\tProgram deployment\tApache 2.0 or MIT\n\nThe Stylus SDKs are open-source, allowing anyone to build their own! The following SDKs have been developed from the ecosystem of Stylus developers.\n\nRepo\nZig SDK\nEdit this page\nLast updated on Nov 18, 2024\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/reference/rust-sdk-guide",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nStylus Rust SDK advanced features\n\nThis document provides information about advanced features included in the Stylus Rust SDK, that are not described in the previous pages. For information about deploying Rust smart contracts, see the cargo stylus CLI Tool. For a conceptual introduction to Stylus, see Stylus: A Gentle Introduction. To deploy your first Stylus smart contract using Rust, refer to the Quickstart.\n\nINFO\n\nMany of the affordances use macros. Though this section details what each does, it may be helpful to use cargo expand to see what they expand into if you’re doing advanced work in Rust.\n\nStorage​\n\nThis section provides extra information about how the Stylus Rust SDK handles storage. You can find more information and basic examples in Variables.\n\nRust smart contracts may use state that persists across transactions. There’s two primary ways to define storage, depending on if you want to use Rust or Solidity definitions. Both are equivalent, and are up to the developer depending on their needs.\n\n#[storage]​\n\nThe #[storage] macro allows a Rust struct to be used in persistent storage.\n\n#[storage]\npub struct Contract {\n    owner: StorageAddress,\n    active: StorageBool,\n    sub_struct: SubStruct,\n}\n\n#[storage]\npub struct SubStruct {\n    // types implementing the `StorageType` trait.\n}\n\n\nAny type implementing the StorageType trait may be used as a field, including other structs, which will implement the trait automatically when #[storage] is applied. You can even implement StorageType yourself to define custom storage types. However, we’ve gone ahead and implemented the common ones.\n\nType\tInfo\nStorageBool\tStores a bool\nStorageAddress\tStores an Alloy Address\nStorageUint\tStores an Alloy Uint\nStorageSigned\tStores an Alloy Signed\nStorageFixedBytes\tStores an Alloy FixedBytes\nStorageBytes\tStores a Solidity bytes\nStorageString\tStores a Solidity string\nStorageVec\tStores a vector of StorageType\nStorageMap\tStores a mapping of StorageKey to StorageType\nStorageArray\tStores a fixed-sized array of StorageType\n\nEvery Alloy primitive has a corresponding StorageType implementation with the word Storage before it. This includes aliases, like StorageU256 and StorageB64.\n\nsol_storage!​\n\nThe types in #[storage] are laid out in the EVM state trie exactly as they are in Solidity. This means that the fields of a struct definition will map to the same storage slots as they would in EVM programming languages.\n\nBecause of this, it is often nice to define your types using Solidity syntax, which makes that guarantee easier to see. For example, the earlier Rust struct can re-written to:\n\nsol_storage! {\n    pub struct Contract {\n        address owner;                      // becomes a StorageAddress\n        bool active;                        // becomes a StorageBool\n        SubStruct sub_struct,\n    }\n\n    pub struct SubStruct {\n        // other solidity fields, such as\n        mapping(address => uint) balances;  // becomes a StorageMap\n        Delegate delegates[];               // becomes a StorageVec\n    }\n}\n\n\nThe above will expand to the equivalent definitions in Rust, each structure implementing the StorageType trait. Many contracts, like our example ERC 20, do exactly this.\n\nBecause the layout is identical to Solidity’s, existing Solidity smart contracts can upgrade to Rust without fear of storage slots not lining up. You simply copy-paste your type definitions.\n\nSTORAGE LAYOUT IN CONTRACTS USING INHERITANCE\n\nNote that one exception to this storage layout guarantee is contracts which utilize inheritance. The current solution in Stylus using #[borrow] and #[inherits(...)] packs nested (inherited) structs into their own slots. This is consistent with regular struct nesting in solidity, but not inherited structs. We plan to revisit this behavior in an upcoming release.\n\nTIP\n\nExisting Solidity smart contracts can upgrade to Rust if they use proxy patterns.\n\nConsequently, the order of fields will affect the JSON ABIs produced that explorers and tooling might use. Most developers won’t need to worry about this though and can freely order their types when working on a Rust contract from scratch.\n\nReading and writing storage​\n\nYou can access storage types via getters and setters. For example, the Contract struct from earlier might access its owner address as follows.\n\nimpl Contract {\n    /// Gets the owner from storage.\n    pub fn owner(&self) -> Address {\n        self.owner.get()\n    }\n\n    /// Updates the owner in storage\n    pub fn set_owner(&mut self, new_owner: Address) {\n        if msg::sender() == self.owner.get() { // we'll discuss msg::sender later\n            self.owner.set(new_owner);\n        }\n    }\n}\n\n\nIn Solidity, one has to be very careful about storage access patterns. Getting or setting the same value twice doubles costs, leading developers to avoid storage access at all costs. By contrast, the Stylus SDK employs an optimal storage-caching policy that avoids the underlying SLOAD or SSTORE operations.\n\nTIP\n\nStylus uses storage caching, so multiple accesses of the same variable is virtually free.\n\nHowever it must be said that storage is ultimately more expensive than memory. So if a value doesn’t need to be stored in state, you probably shouldn’t do it.\n\nCollections​\n\nCollections like StorageVec and StorageMap are dynamic and have methods like push, insert, replace, and similar.\n\nimpl SubStruct {\n   pub fn add_delegate(&mut self, delegate: Address) {\n        self.delegates.push(delegate);\n    }\n\n    pub fn track_balance(&mut self, address: Address) {\n        self.balances.insert(address, address.balance());\n    }\n}\n\n\nYou may notice that some methods return types like StorageGuard and StorageGuardMut. This allows us to leverage the Rust borrow checker for storage mistakes, just like it does for memory. Here’s an example that will fail to compile.\n\nfn mistake(vec: &mut StorageVec<StorageU64>) -> U64 {\n    let value = vec.setter(0);\n    let alias = vec.setter(0);\n    value.set(32.into());\n    alias.set(48.into());\n    value.get() // uh, oh. what value should be returned?\n}\n\n\nUnder the hood, vec.setter() returns a StorageGuardMut instead of a &mut StorageU64. Because the guard is bound to a &mut StorageVec lifetime, value and alias cannot be alive simultaneously. This causes the Rust compiler to reject the above code, saving you from entire classes of storage aliasing errors.\n\nIn this way the Stylus SDK safeguards storage access the same way Rust ensures memory safety. It should never be possible to alias Storage without unsafe Rust.\n\nSimpleStorageType​\n\nYou may run into scenarios where a collection’s methods like push and insert aren’t available. This is because only primitives, which implement a special trait called SimpleStorageType, can be added to a collection by value. For nested collections, one instead uses the equivalent grow and setter.\n\nfn nested_vec(vec: &mut StorageVec<StorageVec<StorageU8>>) {\n    let mut inner = vec.grow();  // adds a new element accessible via `inner`\n    inner.push(0.into());        // inner is a guard to a StorageVec<StorageU8>\n}\n\nfn nested_map(map: &mut StorageMap<u32, StorageVec<U8>>) {\n    let mut slot = map.setter(0);\n    slot.push(0);\n}\n\nErase and #[derive(Erase)]​\n\nSome StorageType values implement Erase, which provides an erase() method for clearing state. We’ve implemented Erase for all primitives, and for vectors of primitives, but not maps. This is because a solidity mapping does not provide iteration, and so it’s generally impossible to know which slots to set to zero.\n\nStructs may also be Erase if all of the fields are. #[derive(Erase)] lets you do this automatically.\n\nsol_storage! {\n    #[derive(Erase)]\n    pub struct Contract {\n        address owner;              // can erase primitive\n        uint256[] hashes;           // can erase vector of primitive\n    }\n\n    pub struct NotErase {\n        mapping(address => uint) balances; // can't erase a map\n        mapping(uint => uint)[] roots;     // can't erase vector of maps\n    }\n}\n\n\nYou can also implement Erase manually if desired. Note that the reason we care about Erase at all is that you get storage refunds when clearing state, lowering fees. There’s also minor implications for patterns using unsafe Rust.\n\nThe storage cache​\n\nThe Stylus SDK employs an optimal storage-caching policy that avoids the underlying SLOAD or SSTORE operations needed to get and set state. For the vast majority of use cases, this happens in the background and requires no input from the user.\n\nHowever, developers working with unsafe Rust implementing their own custom StorageType collections, the StorageCache type enables direct control over this data structure. Included are unsafe methods for manipulating the cache directly, as well as for bypassing it altogether.\n\nImmutables and PhantomData​\n\nSo that generics are possible in sol_interface!, core::marker::PhantomData implements StorageType and takes up zero space, ensuring that it won’t cause storage slots to change. This can be useful when writing libraries.\n\npub trait Erc20Params {\n    const NAME: &'static str;\n    const SYMBOL: &'static str;\n    const DECIMALS: u8;\n}\n\nsol_storage! {\n    pub struct Erc20<T> {\n        mapping(address => uint256) balances;\n        PhantomData<T> phantom;\n    }\n}\n\n\nThe above allows consumers of Erc20 to choose immutable constants via specialization. See our WETH sample contract for a full example of this feature.\n\nFunctions​\n\nThis section provides extra information about how the Stylus Rust SDK handles functions. You can find more information and basic examples in Functions, Bytes in, bytes out programming, Inheritance and Sending ether.\n\nPure, View, and Write functions​\n\nFor non-payable methods the #[public] macro can figure state mutability out for you based on the types of the arguments. Functions with &self will be considered view, those with &mut self will be considered write, and those with neither will be considered pure. Please note that pure and view functions may change the state of other contracts by calling into them, or even this one if the reentrant feature is enabled.\n\n#[entrypoint]​\n\nThis macro allows you to define the entrypoint, which is where Stylus execution begins. Without it, the contract will fail to pass cargo stylus check. Most commonly, the macro is used to annotate the top level storage struct.\n\nsol_storage! {\n    #[entrypoint]\n    pub struct Contract {\n        ...\n    }\n\n    // only one entrypoint is allowed\n    pub struct SubStruct {\n        ...\n    }\n}\n\n\nThe above will make the public methods of Contract the first to consider during invocation.\n\nReentrancy​\n\nIf a contract calls another that then calls the first, it is said to be reentrant. By default, all Stylus contracts revert when this happens. However, you can opt out of this behavior by enabling the reentrant feature flag.\n\nstylus-sdk = { version = \"0.6.0\", features = [\"reentrant\"] }\n\n\nThis is dangerous, and should be done only after careful review — ideally by 3rd party auditors. Numerous exploits and hacks have in Web3 are attributable to developers misusing or not fully understanding reentrant patterns.\n\nIf enabled, the Stylus SDK will flush the storage cache in between reentrant calls, persisting values to state that might be used by inner calls. Note that preventing storage invalidation is only part of the battle in the fight against exploits. You can tell if a call is reentrant via msg::reentrant, and condition your business logic accordingly.\n\nTopLevelStorage​\n\nThe #[entrypoint] macro will automatically implement the TopLevelStorage trait for the annotated struct. The single type implementing TopLevelStorage is special in that mutable access to it represents mutable access to the entire program’s state. This idea will become important when discussing calls to other programs in later sections.\n\nInheritance, #[inherit], and #[borrow].​\nINFO\n\nStylus doesn't support contract multi-inheritance yet.\n\nComposition in Rust follows that of Solidity. Types that implement Router, the trait that #[public] provides, can be connected via inheritance.\n\n#[public]\n#[inherit(Erc20)]\nimpl Token {\n    pub fn mint(&mut self, amount: U256) -> Result<(), Vec<u8>> {\n        ...\n    }\n}\n\n#[public]\nimpl Erc20 {\n    pub fn balance_of() -> Result<U256> {\n        ...\n    }\n}\n\n\nBecause Token inherits Erc20 in the above, if Token has the #[entrypoint], calls to the contract will first check if the requested method exists within Token. If a matching function is not found, it will then try the Erc20. Only after trying everything Token inherits will the call revert.\n\nNote that because methods are checked in that order, if both implement the same method, the one in Token will override the one in Erc20, which won’t be callable. This allows for patterns where the developer imports a crate implementing a standard, like the ERC 20, and then adds or overrides just the methods they want to without modifying the imported Erc20 type.\n\nWARNING\n\nStylus does not currently contain explicit override or virtual keywords for explicitly marking override functions. It is important, therefore, to carefully ensure that contracts are only overriding the functions.\n\nInheritance can also be chained. #[inherit(Erc20, Erc721)] will inherit both Erc20 and Erc721, checking for methods in that order. Erc20 and Erc721 may also inherit other types themselves. Method resolution finds the first matching method by Depth First Search.\n\nNote that for the above to work, Token must implement Borrow<Erc20>. You can implement this yourself, but for simplicity, #[storage] and sol_storage! provide a #[borrow] annotation.\n\nsol_storage! {\n    #[entrypoint]\n    pub struct Token {\n        #[borrow]\n        Erc20 erc20;\n        ...\n    }\n\n    pub struct Erc20 {\n        ...\n    }\n}\n\nCalls​\n\nJust as with storage and functions, Stylus SDK calls are Solidity ABI equivalent. This means you never have to know the implementation details of other contracts to invoke them. You simply import the Solidity interface of the target contract, which can be auto-generated via the cargo stylus CLI tool.\n\nTIP\n\nYou can call contracts in any programming language with the Stylus SDK.\n\nsol_interface!​\n\nThis macro defines a struct for each of the Solidity interfaces provided.\n\nsol_interface! {\n    interface IService {\n        function makePayment(address user) payable returns (string);\n        function getConstant() pure returns (bytes32)\n    }\n\n    interface ITree {\n        // other interface methods\n    }\n}\n\n\nThe above will define IService and ITree for calling the methods of the two contracts.\n\nINFO\n\nCurrently only functions are supported, and any other items in the interface will cause an error.\n\nFor example, IService will have a make_payment method that accepts an Address and returns a B256.\n\npub fn do_call(&mut self, account: IService, user: Address) -> Result<String, Error> {\n    account.make_payment(self, user)  // note the snake case\n}\n\n\nObserve the casing change. sol_interface! computes the selector based on the exact name passed in, which should almost always be CamelCase. For aesthetics, the rust functions will instead use snake_case.\n\nConfiguring gas and value with Call​\n\nCall lets you configure a call via optional configuration methods. This is similar to how one would configure opening a File in Rust.\n\npub fn do_call(account: IService, user: Address) -> Result<String, Error> {\n    let config = Call::new_in()\n        .gas(evm::gas_left() / 2)       // limit to half the gas left\n        .value(msg::value());           // set the callvalue\n\n    account.make_payment(config, user)\n}\n\n\nBy default Call supplies all gas remaining and zero value, which often means Call::new_in() may be passed to the method directly. Additional configuration options are available in cases of reentrancy.\n\nReentrant calls​\n\nContracts that opt into reentrancy via the reentrant feature flag require extra care. When the storage-cache feature is enabled, cross-contract calls must flush or clear the StorageCache to safeguard state. This happens automatically via the type system.\n\nsol_interface! {\n    interface IMethods {\n        function pureFoo() external pure;\n        function viewFoo() external view;\n        function writeFoo() external;\n        function payableFoo() external payable;\n    }\n}\n\n#[public]\nimpl Contract {\n    pub fn call_pure(&self, methods: IMethods) -> Result<(), Vec<u8>> {\n        Ok(methods.pure_foo(self)?)    // `pure` methods might lie about not being `view`\n    }\n\n    pub fn call_view(&self, methods: IMethods) -> Result<(), Vec<u8>> {\n        Ok(methods.view_foo(self)?)\n    }\n\n    pub fn call_write(&mut self, methods: IMethods) -> Result<(), Vec<u8>> {\n        methods.view_foo(self)?;       // allows `pure` and `view` methods too\n        Ok(methods.write_foo(self)?)\n    }\n\n    #[payable]\n    pub fn call_payable(&mut self, methods: IMethods) -> Result<(), Vec<u8>> {\n        methods.write_foo(Call::new_in(self))?;   // these are the same\n        Ok(methods.payable_foo(self)?)            // ------------------\n    }\n}\n\n\nIn the above, we’re able to pass &self and &mut self because Contract implements TopLevelStorage, which means that a reference to it entails access to the entirety of the contract’s state. This is the reason it is sound to make a call, since it ensures all cached values are invalidated and/or persisted to state at the right time.\n\nWhen writing Stylus libraries, a type might not be TopLevelStorage and therefore &self or &mut self won’t work. Building a Call from a generic parameter via new_in is the usual solution.\n\npub fn do_call(\n    storage: &mut impl TopLevelStorage,  // can be generic, but often just &mut self\n    account: IService,                   // serializes as an Address\n    user: Address,\n) -> Result<String, Error> {\n\n    let config = Call::new_in(storage)   // take exclusive access to all contract storage\n        .gas(evm::gas_left() / 2)        // limit to half the gas left\n        .value(msg::value());            // set the callvalue\n\n    account.make_payment(config, user)   // note the snake case\n}\n\n\nNote that in the context of a #[public] call, the &mut impl argument will correctly distinguish the method as being write or payable. This means you can write library code that will work regardless of whether the reentrant feature flag is enabled.\n\nNote too that code that previously compiled with reentrancy disabled may require modification in order to type-check. This is done to ensure storage changes are persisted and that the storage cache is properly managed before calls.\n\ncall, static_call, and delegate_call​\n\nThough sol_interface! and Call form the most common idiom to invoke other contracts, their underlying call and static_call are exposed for direct access.\n\nlet return_data = call(Call::new_in(self), contract, call_data)?;\n\n\nIn each case the calldata is supplied as a Vec<u8>. The return result is either the raw return data on success, or a call Error on failure.\n\ndelegate_call is also available, though it's unsafe and doesn't have a richly-typed equivalent. This is because a delegate call must trust the other contract to uphold safety requirements. Though this function clears any cached values, the other contract may arbitrarily change storage, spend ether, and do other things one should never blindly allow other contracts to do.\n\ntransfer_eth​\n\nThis method provides a convenient shorthand for transferring ether.\n\nNote that this method invokes the other contract, which may in turn call others. All gas is supplied, which the recipient may burn. If this is not desired, the call function may be used instead.\n\ntransfer_eth(recipient, value)?;                 // these two are equivalent\n\ncall(Call::new_in().value(value), recipient, &[])?; // these two are equivalent\n\nRawCall and unsafe calls​\n\nOccasionally, an untyped call to another contract is necessary. RawCall lets you configure an unsafe call by calling optional configuration methods. This is similar to how one would configure opening a File in Rust.\n\nlet data = RawCall::new_delegate()   // configure a delegate call\n    .gas(2100)                       // supply 2100 gas\n    .limit_return_data(0, 32)        // only read the first 32 bytes back\n    .flush_storage_cache()           // flush the storage cache before the call\n    .call(contract, calldata)?;      // do the call\n\n\nNote that the call method is unsafe when reentrancy is enabled. See flush_storage_cache and clear_storage_cache for more information.\n\nRawDeploy and unsafe deployments​\n\nRight now the only way to deploy a contract from inside Rust is to use RawDeploy, similar to RawCall. As with RawCall, this mechanism is inherently unsafe due to reentrancy concerns, and requires manual management of the StorageCache.\n\nNote that the EVM allows init code to make calls to other contracts, which provides a vector for reentrancy. This means that this technique may enable storage aliasing if used in the middle of a storage reference's lifetime and if reentrancy is allowed.\n\nWhen configured with a salt, RawDeploy will use CREATE2 instead of the default CREATE, facilitating address determinism.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nRecommended libraries\nNext\nOverview\nStorage\n#[storage]\nsol_storage!\nReading and writing storage\nCollections\nSimpleStorageType\nErase and #[derive(Erase)]\nThe storage cache\nImmutables and PhantomData\nFunctions\nPure, View, and Write functions\n#[entrypoint]\nReentrancy\nTopLevelStorage\nInheritance, #[inherit], and #[borrow].\nCalls\nsol_interface!\nConfiguring gas and value with Call\nReentrant calls\ncall, static_call, and delegate_call\ntransfer_eth\nRawCall and unsafe calls\nRawDeploy and unsafe deployments\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Stylus testnet information | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/reference/testnet-information",
    "html": "Skip to main content\nArbitrum Docs\nStylus testnet information\nArbitrum public RPC endpoints​\nCAUTION\nUnlike the RPC Urls, the Sequencer endpoints only support eth_sendRawTransaction and eth_sendRawTransactionConditional calls.\nArbitrum public RPCs do not provide Websocket support.\nStylus testnets v1 and v2 have been spun down and are not accessible anymore.\nVisit Quicknode's Arbitrum Sepolia faucet, Alchemy's Arbitrum sepolia faucet, or Getblock's Arbitrum Sepolia faucet for testnet Sepolia tokens on L2.\n\nThis section provides an overview of the available public RPC endpoints for different Arbitrum chains that have Stylus enabled, and the necessary details to interact with them.\n\nName\tRPC Url(s)\tChain ID\tBlock explorer\tUnderlying chain\tTech stack\tSequencer feed URL\tSequencer endpoint⚠️\nArbitrum Sepolia (Testnet)\thttps://sepolia-rollup.arbitrum.io/rpc\t421614\thttps://sepolia.arbiscan.io\tSepolia\tNitro (Rollup)\twss://sepolia-rollup.arbitrum.io/feed\thttps://sepolia-rollup-sequencer.arbitrum.io/rpc\nFaucets​\n\nBelow you can find faucets for obtaining testnet ETH. If using a faucet on Ethereum Sepolia or Arbitrum Sepolia, your testnet ETH can be bridged to the Stylus testnet on the Arbitrum Bridge.\n\nFaucet Operator\tFaucet URL\tChain\nQuickNode\thttps://faucet.quicknode.com/arbitrum/sepolia\tArbitrum Sepolia\nAlchemy\thttps://www.alchemy.com/faucets/arbitrum-sepolia\tArbitrum Sepolia\nSepolia PoW Faucet\thttps://sepolia-faucet.pk910.de/\tEthereum Sepolia\n\nThe following information may be useful to those building on Arbitrum. We list the addresses of the smart contracts related to the protocol, the token bridge and precompiles of the different Arbitrum chains.\n\nProtocol smart contracts​\nCore contracts​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nRollup\t0x5eF0...Ba35\t0xFb20...AD88\t0xd808...81C8\nSequencer Inbox\t0x1c47...82B6\t0x211E...c21b\t0x6c97...be0D\nCoreProxyAdmin\t0x5547...2dbD\t0x71D7...7148\t0x1ed7...0686\nCross-chain messaging contracts​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nDelayed Inbox\t0x4Dbd...AB3f\t0xc444...3949\t0xaAe2...ae21\nBridge\t0x8315...ed3a\t0xC1Eb...76Bd\t0x38f9...33a9\nOutbox\t0x0B98...4840\t0xD4B8...cc58\t0x65f0...B78F\nClassic Outbox***\t0x7607...1A40\n0x667e...337a\t\t\n\n***Migrated Network Only\n\nFraud proof contracts​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nChallengeManager\t0xe589...6f58\t0xA590...af0D\t0x84ED...0700\nOneStepProver0\t0x499A...EfcC\t0x8323...d236\t0xAF57...0ddA\nOneStepProverMemory\t0xb556...B676\t0x7a6C...9979\t0xA6Ac...f0c5\nOneStepProverMath\t0xd315...7970\t0x1efb...f2F5\t0xfEe5...42F4\nOneStepProverHostIo\t0xb965...D13A\t0x9CBC...7613\t0xA53a...752a\nOneStepProofEntry\t0x3E1f...A1DF\t0x7Adc...0Fc5\t0x08a2...5961\nToken bridge smart contracts​\nCore contracts​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nL1 Gateway Router\t0x72Ce...31ef\t0xC840...cD48\t0xcE18...8264\nL1 ERC20 Gateway\t0xa3A7...0EeC\t0xB253...21bf\t0x902b...3aFF\nL1 Arb-Custom Gateway\t0xcEe2...180d\t0x2312...232f\t0xba2F...40F3\nL1 Weth Gateway\t0xd920...e2db\t0xE4E2...0BaE\t0xA8aD...0e1E\nL1 Weth\t0xC02a...6Cc2\t0xC02a...6Cc2\t0x7b79...E7f9\nL1 Proxy Admin\t0x9aD4...0aDa\t0xa8f7...e560\t0xDBFC...44b0\n\nThe following contracts are deployed on the corresponding L2 chain\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nL2 Gateway Router\t0x5288...F933\t0x2190...DFa8\t0x9fDD...43C7\nL2 ERC20 Gateway\t0x09e9...1EEe\t0xcF9b...9257\t0x6e24...b502\nL2 Arb-Custom Gateway\t0x0967...5562\t0xbf54...51F4\t0x8Ca1...42C5\nL2 Weth Gateway\t0x6c41...623B\t0x7626...D9eD\t0xCFB1...556D\nL2 Weth\t0x82aF...Bab1\t0x722E...5365\t0x980B...7c73\nL2 Proxy Admin\t0xd570...2a86\t0xada7...d92C\t0x715D...5FdF\nThird party gateways​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\nL1 Dai Gateway\t0xD3B5...3011\nL1 Livepeer Gateway\t0x6142...0676\n\nThe following contracts are deployed on the corresponding L2 chain\n\n\tArbitrum One\nL2 Dai Gateway\t0x4671...6C65\nL2 Livepeer Gateway\t0x6D24...D318\nPrecompiles​\n\nThe following precompiles are deployed on every L2 chain and always have the same address\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nArbAddressTable\t0x0000...0066\t0x0000...0066\t0x0000...0066\nArbAggregator\t0x0000...006D\t0x0000...006D\t0x0000...006D\nArbFunctionTable\t0x0000...0068\t0x0000...0068\t0x0000...0068\nArbGasInfo\t0x0000...006C\t0x0000...006C\t0x0000...006C\nArbInfo\t0x0000...0065\t0x0000...0065\t0x0000...0065\nArbOwner\t0x0000...0070\t0x0000...0070\t0x0000...0070\nArbOwnerPublic\t0x0000...006b\t0x0000...006b\t0x0000...006b\nArbRetryableTx\t0x0000...006E\t0x0000...006E\t0x0000...006E\nArbStatistics\t0x0000...006F\t0x0000...006F\t0x0000...006F\nArbSys\t0x0000...0064\t0x0000...0064\t0x0000...0064\nArbWasm\t-\t-\t0x0000...0071\nArbWasmCache\t-\t-\t0x0000...0072\nNodeInterface\t0x0000...00C8\t0x0000...00C8\t0x0000...00C8\nMisc​\n\nThe following contracts are deployed on the corresponding L2 chain\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nL2 Multicall\t0x842e...4EB2\t0x5e1e...cB86\t0xA115...d092\nEdit this page\nLast updated on Nov 18, 2024\nArbitrum public RPC endpoints\nFaucets\nProtocol smart contracts\nCore contracts\nCross-chain messaging contracts\nFraud proof contracts\nToken bridge smart contracts\nCore contracts\nThird party gateways\nPrecompiles\nMisc\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/concepts/public-preview-expectations",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nPublic preview: What to expect\n\nStylus is currently tagged as a release-candidate supported by public preview documentation. This concept document explains what \"public preview\" means, what to expect from public preview capabilities, and how to engage with our team as you tinker.\n\nHow products are developed at Offchain Labs​\n\nOffchain Labs builds products in a way that aligns loosely with the spirit of \"building in public\". We like to release things early and often so that we can capture feedback and iterate in service of your needs, as empirically as possible.\n\nTo do this, some of our product offerings are documented with public preview disclaimers that look like this:\n\nThis banner's purpose is to set expectations while inviting readers like you to express your needs so that we can incorporate them into the way that we iterate on product.\n\nWhat to expect when using public preview offerings​\n\nAs you tinker and provide feedback, we'll be listening. Sometimes, we'll learn something non-obvious that will result in a significant change. More commonly, you'll experience incremental improvements to the developer experience as the offering grows out of its public preview status, towards stable status.\n\nPublic preview offerings are evolving rapidly, so don't expect the degree of release notes discipline that you'd expect from a stable offering. Keep your eyes open for notifications regarding patch, minor, and major changes, along with corresponding relnotes that highlight breaking changes and new capabilities.\n\nHow to provide feedback​\n\nOur product team primarily uses three feedback channels while iterating on public preview capabilities:\n\nDocs: Click on the Request an update button located in the top-right corner of any document to provide feedback on the docs and/or developer experience. This will lead you to a prefilled Github issue that members of our product team periodically review.\nDiscord: Join the Arbitrum Discord to engage with members of the Arbitrum community and product team.\nGoogle form: Complete this form to ask for support.\nWhat to expect when providing feedback​\n\nOur ability to respond to feedback is determined by our ever-evolving capacity and priorities. We can't guarantee responses to all feedback submissions, but our small-but-mighty team is listening, and we'll try our best to acknowledge and respond to your feedback. No guarantees though!\n\nPS, our small-but-mighty team is hiring.\n\nThank you!​\n\nThanks for helping us build things that meet your needs! We're excited to engage with OGs and newcomers alike; please don't hesitate to reach out.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nTroubleshooting\nNext\nOverview\nHow products are developed at Offchain Labs\nWhat to expect when using public preview offerings\nHow to provide feedback\nWhat to expect when providing feedback\nThank you!\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/run-local-dev-node",
    "html": "Skip to main content\nArbitrum Docs\nPage Not Found\n\nWe could not find what you were looking for.\n\nPlease contact the owner of the site that linked you to the original URL and let them know their link is broken.\n\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/troubleshooting-building-stylus",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nTroubleshooting Stylus\nHow does Stylus manage security issues in smart contracts when interacting with so many different languages?​\n\nAll languages are compiled to WASM for them to be able to work with Stylus. So it just needs to verify that the produced WASM programs behave as they should inside the new virtual machine.\n\nIs there any analogue of the fallback function from Solidity in the Rust Stylus SDK?​\n\nCurrently there isn't any analogue. However, you can use a minimal entrypoint and perform raw delegate calls, forwarding your calldata. You can find more information in Bytes-in, bytes-out programming and call, static_call and delegate_call.\n\nWhy are constructors not yet supported for Stylus contracts?​\n\nConstructors use EVM bytecode to initialize state. While one could add EVM bytecode manually to their Stylus deployment, we don't allow WASM execution in the constructor so there's no way to express this in the SDK.\n\nWe're working on models that will make init easier, so there might be better solutions available in the future. For now, we suggest calling an init method after deploying.\n\nIs it possible to verify Stylus contracts on the block explorer?​\n\nCurrently it is not possible to verify contracts compiled to WASM on the block explorer, but we are actively working with providers to have the verification process ready for when Stylus reaches mainnet-ready status.\n\nDo Stylus contracts compile down to EVM bytecode like prior other attempts?​\n\nNo. Stylus contracts are compiled down to WASM. The user writes a program in Rust / C / C++ which is then compiled down to WebAssembly.\n\nHow is a Stylus contract deployed?​\n\nStylus contracts are deployed on chain as a blob of bytes, just like EVM ones. The only difference is that when the contract is executed, instead of invoking the EVM, we invoke a separate WASM runtime. Note that a special EOF-inspired prefix distinguishes Stylus contracts from traditional EVM contracts: when a contract's bytecode starts with the magic 0xEF000000 prefix, it's a Stylus WASM contract.\n\nIs there a new transaction type to deploy Stylus contracts?​\n\nYou deploy a Stylus contract the same way that Solidity contracts are deployed. There are no special transaction types. As a UX note: a WASM will revert until a special instrumentation operation is performed by a call to the new  ArbWasm precompile, which readies the program for calls on-chain.\n\nYou can find instructions for deploying a Stylus contract in our Quickstart.\n\nDo Stylus contracts use a different type of ABI?​\n\nStylus contracts use solidity ABIs. Methods, signatures, logs, calls, etc. work exactly as in the EVM. From a user's / explorer's perspective, it all just looks and behaves like solidity.\n\nDoes the Stylus SDK for Rust support custom data structures?​\n\nFor in-memory usage, you should be able to use any implementation of custom data structures without problems.\n\nFor storage usage, it might be a bit more complicated. Stylus uses the EVM storage system, so you'll need to define the data structure on top of it. However, in the SDK there's a storage trait that custom types can implement to back their collections with the EVM state trie. The SDK macros are compatible with them too, although fundamentally it's still a global key-value system.\n\nYou can read more about it in the Stylus Rust SDK page.\n\nAs an alternative solution, you can use entrypoint-style contracts for your custom data structures.\n\nWhy do I get an error \"no library targets found in package\" when trying to compile and old example?​\n\nSome of the first Stylus examples were built and deployed using a previous version of cargo-stylus (0.1.x). In that version, Stylus projects were structured as regular Rust binaries.\n\nSince cargo-stylus v0.2.1, Stylus projects are structured as libraries, so when trying to compile old projects you might get an error no library targets found in package.\n\nTo solve this, it's usually enough to rename the main.rs file to a lib.rs file.\n\nHow can I generate the ABI of my Stylus contract?​\n\nThe cargo-stylus tool has a command that allows you to export the ABI of your Stylus contract: cargo stylus export-abi.\n\nIf you're using the Stylus Rust SDK, you'll need to enable the export-abi feature in your Cargo.toml file like so:\n\n[features]\nexport-abi = [\"stylus-sdk/export-abi\"]\n\n\nYou'll also need to have a main.rs file that selects that feature.\n\nThis is an example of a main.rs file that allows you to export the abi of the stylus-hello-world example project:\n\n#![cfg_attr(not(feature = \"export-abi\"), no_main)]\n\n#[cfg(feature = \"export-abi\")]\nfn main() {\n    stylus_hello_world::main();\n}\n\n\nLast updated on Nov 18, 2024\nPrevious\nAdd a new smart contract language\nNext\nPublic preview\nHow does Stylus manage security issues in smart contracts when interacting with so many different languages?\nIs there any analogue of the fallback function from Solidity in the Rust Stylus SDK?\nWhy are constructors not yet supported for Stylus contracts?\nIs it possible to verify Stylus contracts on the block explorer?\nDo Stylus contracts compile down to EVM bytecode like prior other attempts?\nHow is a Stylus contract deployed?\nIs there a new transaction type to deploy Stylus contracts?\nDo Stylus contracts use a different type of ABI?\nDoes the Stylus SDK for Rust support custom data structures?\nWhy do I get an error \"no library targets found in package\" when trying to compile and old example?\nHow can I generate the ABI of my Stylus contract?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/reference/other-language-frameworks",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nAdd a new smart contract language\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nOther language frameworks (non-Rust)\n\nIf you are looking to write and deploy Stylus contracts without using Rust, please see the following SDKs.\n\nRepo\tUse cases\tLicense\nC/C++ SDK\tCryptography and algorithms\tApache 2.0 or MIT\nBf SDK\tEducational\tApache 2.0 or MIT\n\nThe Stylus SDKs are open-source, allowing anyone to build their own! The following SDKs have been developed from the ecosystem of Stylus developers.\n\nRepo\nZig SDK\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nVerify contracts\nNext\nAdd a new smart contract language\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/run-nitro-dev-node",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to run a local Nitro dev node\nOverview​\n\nThis page provides step-by-step instructions for setting up and running a local Nitro node in --dev mode. This mode is ideal for developers who want to quickly test contracts using a single node, as it offers a simpler and faster setup compared to more complex environments.\n\nWhile some teams use nitro-testnode for testing cross-layer messaging, which involves launching both Geth as L1 and Nitro as L2, this setup can be more complex and time-consuming. If your primary goal is to test contracts on a local node without needing cross-layer interactions, Nitro's --dev mode offers a lightweight and efficient alternative.\n\nHowever, if you need more advanced functionality—such as cross-layer messaging, working with both L1 and L2 chains, or testing interactions between different layers—nitro-testnode is the preferred option. The testnode setup allows you to simulate a full L1-L2 environment, which is critical for those scenarios. See here for instructions.\n\nNote that Nitro --dev mode is ideal for Stylus contract testing, as it is much lighter and faster to set up than the full nitro-testnode environment.\n\nPrerequisites​\n\nBefore beginning, ensure the following is installed and running on your machine:\n\nDocker: Required to run the Nitro dev node in a container. Install Docker by following the official installation guide for your operating system.\ncast: A command-line tool from Foundry for interacting with Ethereum smart contracts. You can install it via Foundry by following the installation instructions.\njq: A lightweight JSON parsing tool used to extract contract addresses from the script output. Install jq by following the official installation guide for your operating system.\nClone the nitro-devnode repository​\n\nUse the following command to clone the repository:\n\ngit clone https://github.com/OffchainLabs/nitro-devnode.git\ncd nitro-devnode\n\nRun the dev node script:​\n\nRun the script to start the Nitro dev node, deploy the Stylus Cache Manager contract, and register it as a WASM cache manager using the default development account:\n\n./run-dev-node.sh\n\n\nThe script will:\n\nStart the Nitro dev node in the background using Docker.\nDeploy the Stylus Cache Manager contract on the local Nitro network.\nRegister the Cache Manager contract as a WASM cache manager.\nDevelopment account (used by default)​\n\nIn --dev mode, the script uses a pre-funded development account by default. This account is pre-funded with ETH in all networks and is used to deploy contracts, interact with the chain, and assume chain ownership.\n\nAddress: 0x3f1Eae7D46d88F08fc2F8ed27FCb2AB183EB2d0E\nPrivate key: 0xb6b15c8cb491557369f3c7d2c287b053eb229daa9c22138887752191c9520659\n\nYou don’t need to set up a private key manually unless you prefer using your own key.\n\nChain ownership in --dev mode​\n\nIn Nitro --dev mode, the default chain owner is set to 0x0000000000000000000000000000000000000000. However, you can use the ArbDebug precompile to set the chain owner. This precompile includes the becomeChainOwner() function, which can be called to assume ownership of the chain.\n\nChain ownership is important because it allows the owner to perform certain critical functions within the Arbitrum environment, such as:\n\nAdding or removing other chain owners\nSetting the L1 and L2 base fees directly\nAdjusting the gas pricing inertia and backlog tolerance\nModifying the computational speed limit and transaction gas limits\nManaging network and infrastructure fee accounts\n\nThe script automatically sets the chain owner to the pre-funded dev account before registering the Cache Manager contract. Here’s how the becomeChainOwner() function is called within the script:\n\ncast send 0x00000000000000000000000000000000000000FF \"becomeChainOwner()\" --private-key 0xb6b15c8cb491557369f3c7d2c287b053eb229daa9c22138887752191c9520659 --rpc-url http://127.0.0.1:8547\n\n\nThis step ensures that the dev account has ownership of the chain, which is necessary to register the Cache Manager as a WASM cache manager.\n\nAt the end of the process, you'll have the Nitro dev mode running with the necessary components deployed. This environment is ready for testing and interacting with your contracts, including those written in Stylus, using the deployed Cache Manager to support enhanced functionality for Stylus-based smart contracts.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nRun a local full chain simulation\nNext\nL1 Ethereum RPC providers\nOverview\nPrerequisites\nClone the nitro-devnode repository\nRun the dev node script:\nDevelopment account (used by default)\nChain ownership in --dev mode\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/cli-tools-overview",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nCLI tools (cargo-stylus)\nCLI tools overview\nOptimize WASM binaries\nDebug Stylus transactions\nVerify contracts\ncargo-stylus repository\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nCLI tools (cargo-stylus)\n\nThe CLI tools provided for Stylus, specifically the cargo-stylus tool, are designed to help developers manage, compile, and optimize their Stylus contracts efficiently. This overview provides a summary of the tools available and how to use them effectively.\n\nAvailable tools​\n1. Optimize WASM binaries​\n\nThe cargo-stylus tool allows you to optimize WebAssembly (WASM) binaries, ensuring that your contracts are as efficient as possible.\n\nOptimize WASM binaries: Learn how to optimize your WASM binaries for performance and size.\n2. Debug Stylus transactions​\n\nGain insights into your Stylus contracts by debugging transactions.\n\nDebug Stylus transactions: A guide to debugging transactions, helping you identify and fix issues.\n3. Verify contracts​\n\nEnsure that your Stylus contracts are correctly verified.\n\nVerify contracts: Step-by-step instructions on how to verify your contracts using cargo-stylus.\nSource code repository​\n\nThe source code for cargo-stylus is available on GitHub. Explore the code, contribute, or use it as a reference.\n\ncargo-stylus repository: Visit the GitHub repository for more information.\nAdditional resources​\n\nFor more advanced usage and detailed guides, refer to the following resources:\n\nOptimize WASM binaries\nTroubleshooting\nRun a Stylus dev node\n\nThis overview page serves as the starting point for mastering the CLI tools available for Stylus development. From optimizing your contracts to debugging and verifying them, the cargo-stylus toolset is integral to a smooth development experience.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nCaching strategy\nNext\nOptimize WASM binaries\nAvailable tools\n1. Optimize WASM binaries\n2. Debug Stylus transactions\n3. Verify contracts\nSource code repository\nAdditional resources\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/concepts/stylus-gas",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nOverview\nGas and ink costs\nCaching strategy\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nGas and ink in Stylus\n\nGas and ink are the pricing primitives that are used to determine the cost of handling specific opcodes and host I/Os on Stylus. For an overview of specific opcode and host I/O costs, see Gas and ink costs.\n\nStylus gas costs​\n\nStylus introduces new pricing models for WASM programs. Intended for high-compute applications, Stylus makes the following more affordable:\n\nCompute, which is generally 10-100x cheaper depending on the program. This is primarily due to the efficiency of the WASM runtime relative to the EVM, and the quality of the code produced by Rust, C, and C++ compilers. Another factor that matters is the quality of the code itself. For example, highly optimized and audited C libraries that implement a particular cryptographic operation are usually deployable without modification and perform exceptionally well. The fee reduction may be smaller for highly optimized Solidity that makes heavy use of native precompiles vs. an unoptimized Stylus equivalent that doesn't do the same.\nMemory, which is 100-500x cheaper due to Stylus's novel exponential pricing mechanism intended to address Vitalik's concerns with the EVM's per-call, quadratic memory pricing policy. For the first time ever, high-memory applications are possible on an EVM-equivalent chain.\nStorage, for which the Rust SDK promotes better access patterns and type choices. Note that while the underlying SLOAD and SSTORE operations cost as they do in the EVM, the Rust SDK implements an optimal caching policy that minimizes their use. Exact savings depends on the program.\nVM affordances, including common operations like keccak and reentrancy detection. No longer is it expensive to make safety the default.\n\nThere are, however, minor overheads to using Stylus that may matter to your application:\n\nThe first time a WASM is deployed, it must be activated. This is generally a few million gas, though to avoid testnet DoS, we've set it to a fixed 14 million. Note that you do not have to activate future copies of the same program. For example, the same NFT template can be deployed many times without paying this cost more than once. We will soon make the fees paid depend on the program, so that the gas used is based on the complexity of the WASM instead of this very conservative, worst-case estimate.\nCalling a Stylus contract costs 128-2048 gas. We're working with Wasmer to improve setup costs, but there will likely always be some amount of gas one pays to jump into WASM execution. This means that if a contract does next to nothing, it may be cheaper in Solidity. However if a contract starts doing interesting work, the dynamic fees will quickly make up for this fixed-cost overhead.\n\nThough conservative bounds have been chosen for testnet, all of this is subject to change as pricing models mature and further optimizations are made. Since gas numbers will vary across updates, it may make more sense to clock the time it takes to perform an operation rather than going solely by the numbers reported in receipts.\n\nInk and gas​\n\nBecause WASM opcodes are orders of magnitude faster than their EVM counterparts, almost every operation that Stylus does costs less than 1 gas. “Fractional gas” isn’t an EVM concept, so the Stylus VM introduces a new unit of payment known as ink that’s orders of magnitude smaller.\n\n1 gas = 10,000 ink\n\nIntuition​\n\nTo build intuition for why this is the case, consider the ADD instruction.\n\nIn the EVM​\nPay for gas, requiring multiple look-ups of an in-memory table\nConsider tracing, even if disabled\nPop two items of the simulated stack\nAdd them together\nPush the result\nIn the Stylus VM​\nExecute a single x86 or ARM ADD instruction\n\nNote that unlike the EVM, which charges for gas before running each opcode, the Stylus VM strategically charges for many opcodes all at once. This cuts fees considerably, since the VM only rarely needs to execute gas charging logic. Additionally, gas charging happens inside the program, removing the need for an in-memory table.\n\nThe ink price​\n\nThe ink price, which measures the amount of ink a single EVM gas buys, is configurable by the chain owner. By default, the exchange rate is 1:10000, but this may be adjusted as the EVM and Stylus VM improve over time.\n\nFor example, if the Stylus VM becomes 2x faster, instead of cutting the nominal cost of each operation, the ink price may instead be halved, allowing 1 EVM gas to buy twice as much ink. This provides an elegant mechanism for smoothly repricing resources between the two VMs as each makes independent progress.\n\nUser experience​\n\nIt is important to note that users never need to worry about this notion of ink. Receipts will always be measured in gas, with the exchange rate applied automatically under the hood as the VMs pass execution back and forth.\n\nHowever, developers optimizing contracts may choose to measure performance in ink to pin down the exact cost of executing various routines. The ink_left function exposes this value, and various methods throughout the Rust SDK optionally accept ink amounts too.\n\nSee also​\nGas and ink costs: Detailed costs per opcode and host I/O\nCaching strategy: Description of the Stylus caching strategy and the CacheManager contract\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nAdvanced features\nNext\nGas and ink costs\nStylus gas costs\nInk and gas\nIntuition\nThe ink price\nUser experience\nSee also\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Stylus Rust SDK overview | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/reference/overview",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nOverview\nHello World\nPrimitive Data Types\nVariables\nConstants\nFunction\nErrors\nEvents\nInheritance\nVm Affordances\nSending Ether\nFunction Selector\nAbi Encode\nAbi Decode\nHashing\nBytes In Bytes Out\nRecommended libraries\nAdvanced features\nRust crate docs\nStylus by example\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nStylus Rust SDK overview\n\nThis section provides an in-depth overview of the features provided by the Stylus Rust SDK. For information about deploying Rust smart contracts, see the cargo stylus CLI Tool. For a conceptual introduction to Stylus, see Stylus: A Gentle Introduction. To deploy your first Stylus smart contract using Rust, refer to the Quickstart.\n\nThe Stylus Rust SDK is built on top of Alloy, a collection of crates empowering the Rust Ethereum ecosystem. Because the SDK uses the same Rust primitives for Ethereum types, Stylus is compatible with existing Rust libraries.\n\nThe Stylus Rust SDK has been audited in August 2024 at commit #62bd831 by Open Zeppelin which can be viewed on our audits page.\n\nThis section contains a set of pages that describe a certain aspect of the Stylus Rust SDK, like how to work with variables, or what ways are there to send ether. Additionally, there's also a page that compiles a set of advanced features that the Stylus Rust SDK provides.\n\nFinally, there's also a Stylus by example portal available that provides most of the information included in this section, as well as many different example contracts.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nArbiscan contract verification\nNext\nHello World\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Quickstart: Launch an Orbit chain | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/orbit-quickstart",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nQuickstart: Launch an Orbit chain\n\nThis quickstart is for developers who want to launch their own Arbitrum Orbit chain using the Orbit chain deployment portal.\n\nNOT FOR MAINNET PRODUCTION\n\nThis quickstart is intended for development purposes only and is not suitable for deploying production-grade mainnet chains.\n\nBy the end of this quickstart, you'll have a local devnet chain that hosts EVM-compatible smart contracts. Your chain will process transactions locally while settling to the public Arbitrum Sepolia testnet. Familiarity with Ethereum, Ethereum's testnets, and Arbitrum is expected.\n\nIf you're looking for a conceptual introduction to Orbit chains, see the Gentle introduction to Orbit chains.\n\nPrerequisites​\nDocker\nA browser-based Ethereum wallet (like MetaMask)\nAt least 1.2 testnet ETH (for custom gas token chains, 0.8 ETH and 0.4 native tokens)\nStep 1: Acquire Arbitrum Testnet $ETH (and the native token for Orbit chains with custom gas tokens)​\n\nYou'll need at least 1.2 testnet $ETH for regular Orbit chains or 0.8 $ETH plus 0.4 of your desired native token for Orbit chains with a custom gas token. The funds are needed to cover the cost of deploying your Orbit chain's base contracts to its base chain (Arbitrum Sepolia).\n\nAt the time of this quickstart's writing, the easiest way to acquire $ETH is to bridge testnet $ETH from Ethereum's L1 Sepolia network to Arbitrum Sepolia L2 testnet:\n\nUse an L1 testnet $ETH faucet like sepoliafaucet.com to acquire some testnet $ETH on an L1 testnet.\nBridge your L1 testnet $ETH into Arbitrum L2 using the Arbitrum bridge.\nStep 2: Choose your chain type: AnyTrust or Rollup​\n\nArbitrum Rollup is an Optimistic Rollup protocol; it's trustless and permissionless. These properties are achieved by requiring all chain data to be posted on Ethereum's \"Layer 1\" (L1) chain. This means the availability of this data follows directly from the security properties of Ethereum itself, and, in turn, that any party can participate in validating the chain and ensuring its safety.\n\nBy contrast, Arbitrum AnyTrust introduces a trust assumption in exchange for lower fees. Instead of requiring all Arbitrum nodes to have access to the data of every L2 transaction in the Arbitrum chain's inbox, AnyTrust relies on an external Data Availability Committee to store data and provide it on demand, reducing the costs of batching and posting all L2 transaction data to L1. Visit our FAQ docs to learn more.\n\nWe generally recommend using Rollup chains for use-cases that demand the highest level of security (like decentralized exchanges and other DeFi dApps). AnyTrust chains are suitable for use-cases that require lower fees and generate lots of transactions (like gaming and social dApps).\n\nStep 3: Configure your Orbit chain's deployment​\n\nVisit the Orbit chain deployment portal. You'll be prompted to connect your wallet. You may be prompted to add the Arbitrum Sepolia network to your wallet and/or to switch your wallet to this network; approve this.\n\nThe deployment portal will then display a form that looks like this:\n\nChain ID\nChain name\nChallenge period (blocks)\nStake token\nBase stake\nOwner\n\nThe below table provides a brief description of each of these configuration parameters. We recommend sticking to the defaults; to learn more about customizing your Orbit chain's deployment configuration, visit How (and when) to customize your Orbit chain's deployment config:\n\nParameter\tDescription\nChain ID\tA unique integer identifier that represents your chain's network. Your Chain ID can be submitted to chain indexes like Chainlist.org. For devnets, this is randomly generated for each deployment - don't worry about it for now.\nChain name\tA human-readable way to distinguish your Orbit chain from other Orbit chains. Users, developers and the wider community will refer to your chain by your Chain name and/or your Chain ID.\nChallenge period (blocks)\tThe amount of time that your Orbit chain's nodes have to dispute the current state of the chain before it's confirmed (and ultimately finalized) on the underlying L2 chain (e.g. Arbitrum Sepolia). Note that this refers to the number of blocks on the underlying L1 chain (e.g. Ethereum's Sepolia chain).\nStake token\tThe token that your chain's validators must stake in order to participate in your chain. This is hardcoded to $ETH for now, but future versions of Orbit chains will let you specify an arbitrary ERC-20 token contract here.\nBase stake\tThe amount of your configured Stake token that your chain's validators must stake in order to participate in your chain. Should be greater than 0.\nOwner\tThe administrative Ethereum address that will deploy, own, and update your chain's base contracts. This will default to your connected wallet's address. This needs to be a standard Ethereum wallet account - an EOA, not a contract address. Note that you'll have to specify this wallet's private key within a local JSON file later.\nGas token\tThe address of the ERC-20 token on the parent chain that is intended to be used as the native gas token on the Orbit chain. This token must already be deployed natively on the parent chain and is bridged to the Orbit chain during chain deployment. This feature is only supported on AnyTrust chains currently, and more information around token restrictions can be found here.\nStep 4: Configure your chain's validator(s)​\n\nYou should see a Configure Validators section appear, with a form that looks like this:\n\nNumber of Validators\nValidator 1 (0x...)\n[...]\nValidator n (0x...)\n\nThe first input field is an integer value that determines the number of validators that will support your initial deployment. Subsequent fields allow you to specify each of these validators' addresses.\n\nThe first validator address is randomly generated and can't be changed. Its private key will be automatically generated and stored within one of the JSON configuration files that will be generated in a moment.\n\nYour chain's validators are responsible for validating the integrity of transactions and posting assertions of the current state of your Orbit chain to its base chain. In production scenarios, your Orbit chain would likely be hosted by a network of validator nodes working together. For your local Orbit chain, you can stick to the auto-generated single validator address.\n\nEach of the validator addresses specified in this step will be added to an allow-list in one of your chain's base contracts, allowing them each to stake and validate transactions submitted to your Orbit chain.\n\nNEW TERMINOLOGY\n\nWhen we say \"base contracts\" and \"base chain\", we're referring to your Orbit chain's L2 contracts and the L2 chain that they're deployed to, respectively. We'll use these terms throughout the rest of this guide.\n\nOnce your validator addresses are configured, click Next to proceed the next step: batch poster configuration.\n\nStep 5: Configure your chain's batch poster​\n\nYou should see a Configure Batch Poster section appear, with a form that looks like this:\n\nBatch Poster Address\n\nYour batch poster address is responsible for posting batches of transactions from your Orbit chain to its base contracts on its base chain. An address will automatically be generated for you; its private key will be automatically generated and stored within one of the JSON configuration files that will be generated in a moment.\n\nOnce your batch poster address is configured, click Next to proceed to the next step: review & deploy your Orbit chain.\n\nStep 6: Review & Deploy your Orbit chain​\n\nDeploy your chain's base contracts to Arbitrum Sepolia\n\nClick the Deploy button located below the config form. Your wallet should prompt you to submit a transaction to the Arbitrum testnet. You'll have to pay a little gas; your wallet may denominate this in $ETH; as long as you see your chosen Arbitrum testnet in the transaction details, this gas fee will be paid in testnet $ETH.\n\nBefore proceeding, let's briefly review what just happened:\n\nYou submitted a deployment transaction to an Orbit \"factory\" smart contract on the Arbitrum testnet, the public L2 chain that your local Orbit chain will settle transactions to.\nThis Orbit smart contract then initialized your Orbit chain's base contracts with the values that you specified in the previous step, and deployed these base contracts to the Arbitrum testnet.\n\nYour Orbit chain's base contracts are responsible for facilitating the exchange of information between your chain's node(s) and its base chain's nodes. This includes the batch posting of transactions from your Orbit chain to its base chain, the staking of tokens by your Orbit chain's validators, the challenge mechanism, bridging mechanisms, and more.\n\nOnce your transaction is complete, if you deployed an AnyTrust chain, you'll next be asked to configure your keyset. Otherwise, continue to Step 8 to download your chain's configuration files and launch your chain.\n\nStep 7: Configure keyset (AnyTrust chains only)​\nNOT APPLICABLE TO ROLLUP CHAINS\n\nSkip this step if you're deploying a Rollup chain.\n\nFor the Batch Poster to function correctly, it's essential that the keyset corresponding to its current configuration is active within the SequencerInbox contract. The production of the keyset and keyset hash binary blobs is mandatory, which should then be used as inputs for the SetValidKeyset method on the SequencerInbox contract.\n\nThe current version of Orbit AnyTrust chains uses a single Data Availability Server and assigns a null value to its private key in order to generate an initial keyset. As part of this transaction process, you'll assign this initial keyset to your recently generated SequencerInbox contract.\n\nClick the Deploy button located below the Deployment Summary. Again, your wallet should prompt you to submit a transaction to the Arbitrum testnet. Gas fees will be handled similarly to the previous transaction.\n\nOnce the transaction completes, you'll be directed to the download page to continue your chain deployment.\n\nStep 8: Download your chain's configuration files and launch your chain​\n\nYou should see two JSON code blocks appear labeled Rollup Config and L3 Config. Use the download buttons at the top right of each code block to save it locally.\n\nDownload Rollup JSON: This will generate nodeConfig.json, which contains your chain's node configuration. Note that this includes the private keys for your validator (staker) and batch poster, which are used to sign transactions that post RBlocks and batches to your chain's base contracts on L2.\nDownload L3Config JSON: This will generate orbitSetupScriptConfig.json, which contains your chain's configuration, including that which supports your Token Bridge contracts.\nStep 9: Clone the setup script repository and add your configuration files​\nClone the orbit-setup-script repository: git clone https://github.com/OffchainLabs/orbit-setup-script.git\nMove the nodeConfig.json file that you downloaded into the config directory in the root of your cloned orbit-setup-script repository.\nMove the orbitSetupScriptConfig.json file you downloaded into the config directory in the root of your cloned orbit-setup-script repository.\nInstall dependencies by running yarn install from the root of the orbit-setup-script repository.\nStep 10: Run your chain's node and block explorer​\n\nRun Docker, then run docker-compose up -d from the root of the orbit-setup-script repository.\n\nA Nitro node and BlockScout explorer instance will be started. Visit http://localhost/ to access your BlockScout explorer instance - this will allow you to view your chain's transactions and blocks, which can be useful for debugging.\n\nStep 11: Finish setting up your chain​\n\nWe've provided a Hardhat script that handles the following tasks:\n\nFund the batch-poster and validator (staker) accounts on your underlying L2 chain.\nDeposit ETH into your account on the chain using your chain's newly deployed bridge.\nDeploy your Token Bridge contracts on both L2 and local Orbit chains.\nConfigure parameters on the chain.\n\nTo run this script, issue the following command from the root of the orbit-setup-script repository, replacing OxYourPrivateKey with the private key of the Owner account you used to deploy your chain's contracts, and replacing http://localhost:8449 with the RPC URL of your chain's node.\n\nUsing Arbitrum Sepolia:\n\nPRIVATE_KEY=\"0xYourPrivateKey\" L2_RPC_URL=\"https://sepolia-rollup.arbitrum.io/rpc\" L3_RPC_URL=\"http://localhost:8449\" yarn run setup\n\nCongratulations​\n\nYour local Orbit chain is now running. You'll see an outputInfo.json file in the main directory of your script folder - this contains more information about your chain, including the addresses of your chain's base contracts.\n\nAppendix A: Logging​\n\nRun this command in the root directory of your cloned orbit setup script repo to view your chain's logs:\n\ndocker-compose logs -f nitro\n\nAppendix B: Depositing ETH/native token​\n\nIf you need to deposit more ETH (or native tokens) into your Orbit chain account, run this command on the base directory of the setup script, replacing 0xYourPrivateKey with the private key of the originating account, and <AMOUNT> with the amount to send:\n\nUsing Arbitrum Sepolia:\n\nPRIVATE_KEY=\"0xYourPrivateKey\" L2_RPC_URL=\"https://sepolia-rollup.arbitrum.io/rpc\" L3_RPC_URL=\"http://localhost:8449\"\nAMOUNT=\"<AMOUNT>\" yarn run deposit\n\nAppendix C: Troubleshooting​\nYou may see error getting latest batch count in your node's output logs (from Appendix A). This is usually safe to ignore. It's usually displayed when your Orbit chain's base contract deployment isn't yet finalized on the L1 chain. This finalization can take 15-20 minutes, but don't worry - the deployment doesn't need to be L1-finalized in order for your chain to function properly.\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nA gentle introduction\nNext\nOrbit Licensing\nPrerequisites\nStep 1: Acquire Arbitrum Testnet $ETH (and the native token for Orbit chains with custom gas tokens)\nStep 2: Choose your chain type: AnyTrust or Rollup\nStep 3: Configure your Orbit chain's deployment\nStep 4: Configure your chain's validator(s)\nStep 5: Configure your chain's batch poster\nStep 6: Review & Deploy your Orbit chain\nStep 7: Configure keyset (AnyTrust chains only)\nStep 8: Download your chain's configuration files and launch your chain\nStep 9: Clone the setup script repository and add your configuration files\nStep 10: Run your chain's node and block explorer\nStep 11: Finish setting up your chain\nCongratulations\nAppendix A: Logging\nAppendix B: Depositing ETH/native token\nAppendix C: Troubleshooting\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to verify Stylus contracts on Arbiscan | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/how-tos/verifying-contracts-arbiscan",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to verify Stylus contracts on Arbiscan\n\nThis how-to will show you how to verify deployed contracts using Arbiscan, Arbitrum's block explorer.\n\nHere's an example of a verified contract: the English Auction Stylus contract, which has been verified on Arbitrum Sepolia. You can view the verified contract here.\n\nYou can also see a list of all Stylus contracts verified on Arbiscan by visiting:\n\nVerified Stylus Contracts on Arbitrum One.\nVerified Stylus Contracts on Arbitrum Sepolia.\n\nHere are the steps to take to verify a contract on Arbiscan:\n\nStep 1: Navigate to the verification page​\n\nYou have two options to access the contract verification page on Arbiscan:\n\nDirect link: Visit Arbiscan Verify Contract to go directly to the verification form. This option is ideal if you already have the contract address and details ready.\nFrom the contract page: If you're viewing the contract's page on Arbiscan:\nGo to the Contract tab.\nClick on Verify and Publish.\n\nBoth methods will take you to the contract verification form, where you can proceed to the next step.\n\nStep 2: Enter the contract's details​\n\nYou will need to fill in the following fields on the contract verification page:\n\nContract address: Enter the contract address you want to verify.\nCompiler type: Select Stylus for Stylus contracts.\nCompiler version: Choose the cargo stylus version that was used to deploy the contract.\nOpen source license type: Select the appropriate license for your contract.\n\nStep 3: Submit source code​\n\nAfter entering the contract details, you’ll need to provide the contract's source code:\n\nManual submission: Copy and paste the source code into the provided text box.\nFetch from GitHub (Recommended): It's recommended to use the Fetch from Git option, as it's easier and helps automate the process. However, note that contracts located in subdirectories of the repository cannot be verified. Ensure that the contract's code is placed directly in the repository's root for verification to succeed.\n\nStep 4: Set EVM version​\n\nThe EVM Version to Target can be left as default unless specific requirements dictate otherwise.\n\nStep 5: Verify and publish​\n\nClick Verify and Publish. The verification process will take a few seconds. Refresh the contract page, and if successful, the contract will be marked as verified.\n\nBehavior when deploying a verified contract​\n\nWhen deploying another instance of a previously verified contract, if the bytecode matches, Arbiscan will automatically link the new instance to the verified source code, displaying a message like:\n\n\"This contract matches the deployed Bytecode of the Source Code for Contract [verified contract address].\"\n\nHowever, the new contract will still appear as \"Not Verified\" until you explicitly verify it.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nChain info\nNext\nOverview\nStep 1: Navigate to the verification page\nStep 2: Enter the contract's details\nStep 3: Submit source code\nStep 4: Set EVM version\nStep 5: Verify and publish\nBehavior when deploying a verified contract\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/data-availability-committees/get-started",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nGet started\nDeploy a Data Availability Server (DAS)\nDeploy a mirror Data Availability Server\nConfigure a Data Availability Committee (DAC)\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to configure a Data Availability Committee: Introduction\n\nAnyTrust chains rely on an external Data Availability Committee (DAC) to store data and provide it on-demand instead of using its parent chain as the Data Availability (DA) layer. The members of the DAC run a Data Availability Server (DAS) to handle these operations.\n\nThis section offers information and a series of how-to guides to help you along the process of setting up a Data Availability Committee. These guides target two audiences: Committee members who wish to deploy a Data Availability Server, and chain owners who wish to configure their chain with the information of the Committee.\n\nBefore following the guides in this section, you should be familiarized with how the AnyTrust protocol works, and the role of the DAC in the protocol. Refer to Inside AnyTrust to learn more.\n\nIf you are a DAC member​\n\nCommittee members will need to run a DAS. To do that, they will first need to generate a pair of keys and deploy a DAS. They may also choose to deploy an additional mirror DAS. Find more information in How to deploy a DAS and How to deploy a mirror DAS.\n\nHere's a basic checklist of actions to complete for DAC members:\n\nDeploy a DAS. Send the following information to the chain owner:\nPublic BLS key\nThe https URL for the RPC endpoint which includes some random string (e.g. das.your-chain.io/rpc/randomstring123), communicated through a secure channel\nThe https URL for the REST endpoint (e.g. das.your-chain.io/rest)\nDeploy a mirror DAS if you want to complement your setup with a mirror DAS. Send the following information to the chain owner:\nThe https URL for the REST endpoint (e.g. das.your-chain.io/rest)\nIf you are a chain owner​\n\nChain owners will need to gather the information from the committee members to craft the necessary data to update their chain and the batch poster (more information in How to configure the DAC in your chain). They might also want to test each DAS individually, by following the testing guides available in How to deploy a DAS and How to deploy a mirror DAS.\n\nHere's a basic checklist of actions to complete for chain owners:\n\nGather the following information from every member of the committee:\nPublic BLS Key\nURL of the RPC endpoint\nURL(s) of the REST endpoint(s)\nEnsure that at least one DAS is running as an archive DAS\nGenerate the keyset and keyset hash with all the information from the servers\nUpdate the SequencerInbox contract\nCraft the new configuration for the batch poster\nCraft the new configuration for your chain's nodes\nAsk for help​\n\nConfiguring a DAC might be a complex process. If you need help setting it up, don't hesitate to ask us on Discord.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nUpgrade ArbOS\nNext\nDeploy a Data Availability Server (DAS)\nIf you are a DAC member\nIf you are a chain owner\nAsk for help\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/stylus-quickstart",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nQuickstart: write a smart contract in Rust using Stylus\n\nThis guide will get you started with Stylus' basics. We'll cover the following steps:\n\nSetting up your development environment\nCreating a Stylus project with cargo stylus\nChecking the validity of your contract\nDeploying your contract\nExporting your contract's ABIs\nCalling your contract\nSending a transaction to your contract\nSetting up your development environment​\nPrerequisites​\nRust toolchain\nVS Code\nDocker\nFoundry's Cast\nNitro devnode\nCreating a Stylus project with cargo stylus​\n\ncargo stylus is a CLI toolkit built to facilitate the development of Stylus contracts.\n\nIt is available as a plugin to the standard cargo tool used for developing Rust programs.\n\nInstalling cargo stylus​\n\nIn your terminal, run:\n\ncargo install --force cargo-stylus\n\n\nAdd WASM (WebAssembly) as a build target for the specific Rust toolchain you are using. The below example sets your default Rust toolchain to 1.80 as well as adding the WASM build target:\n\nrustup default 1.80\nrustup target add wasm32-unknown-unknown --toolchain 1.80\n\n\nYou can verify that cargo stylus is installed by running cargo stylus --help in your terminal, which will return a list of helpful commands, we will use some of them in this guide:\n\ncargo stylus --help returns:\nCargo command for developing Stylus projects\n\nUsage: cargo stylus <COMMAND>\n\nCommands:\n  new         Create a new Stylus project\n  init        Initializes a Stylus project in the current directory\n  export-abi  Export a Solidity ABI\n  activate    Activate an already deployed contract [aliases: a]\n  cache       Cache a contract using the Stylus CacheManager for Arbitrum chains\n  check       Check a contract [aliases: c]\n  deploy      Deploy a contract [aliases: d]\n  verify      Verify the deployment of a Stylus contract [aliases: v]\n  cgen        Generate c code bindings for a Stylus contract\n  replay      Replay a transaction in gdb [aliases: r]\n  trace       Trace a transaction [aliases: t]\n  help        Print this message or the help of the given command(s)\n\nOptions:\n  -h, --help     Print help\n  -V, --version  Print version\n\nCreating a project​\n\nLet's create our first Stylus project by running:\n\ncargo stylus new <YOUR_PROJECT_NAME>\n\n\ncargo stylus new generates a starter template that implements a Rust version of the Solidity Counter smart contract example.\n\nAt this point, you can move on to the next step of this guide or develop your first Rust smart contract. Feel free to use the Stylus Rust SDK reference section as a starting point; it offers many examples to help you quickly familiarize yourself with Stylus.\n\nChecking if your Stylus project is valid​\n\nBy running cargo stylus check against your first contract, you can check if your program can be successfully deployed and activated onchain.\n\nImportant: Ensure your Docker service runs so this command works correctly.\n\ncargo stylus check\n\n\ncargo stylus check executes a dry run on your project by compiling your contract to WASM and verifying if it can be deployed and activated onchain.\n\nIf the command above fails, you'll see detailed information about why your contract would be rejected:\n\nReading WASM file at bad-export.wat\nCompressed WASM size: 55 B\nStylus checks failed: program pre-deployment check failed when checking against\nARB_WASM_ADDRESS 0x0000…0071: (code: -32000, message: program activation failed: failed to parse program)\n\nCaused by:\n    binary exports reserved symbol stylus_ink_left\n\nLocation:\n    prover/src/binary.rs:493:9, data: None\n\n\nThe contract can fail the check for various reasons (on compile, deployment, etc...). Reading the Invalid Stylus WASM Contracts explainer can help you understand what makes a WASM contract valid or not.\n\nIf your contract succeeds, you'll see something like this:\n\nFinished release [optimized] target(s) in 1.88s\nReading WASM file at hello-stylus/target/wasm32-unknown-unknown/release/hello-stylus.wasm\nCompressed WASM size: 3 KB\nProgram succeeded Stylus onchain activation checks with Stylus version: 1\n\n\nNote that running cargo stylus check may take a few minutes, especially if you're verifying a contract for the first time.\n\nSee cargo stylus check --help for more options.\n\nDeploying your contract​\n\nOnce you're ready to deploy your contract onchain, cargo stylus deploy will help you with the deployment and its gas estimation.\n\nEstimating gas​\n\nNote: For every transaction, we'll use the testnode pre-funded wallet, you can use 0xb6b15c8cb491557369f3c7d2c287b053eb229daa9c22138887752191c9520659 as your private key.\n\nYou can estimate the gas required to deploy your contract by running:\n\ncargo stylus deploy \\\n  --endpoint='http://localhost:8547' \\\n  --private-key=\"0xb6b15c8cb491557369f3c7d2c287b053eb229daa9c22138887752191c9520659\" \\\n  --estimate-gas\n\n\nThe command should return something like this:\n\ndeployment tx gas: 7123737\ngas price: \"0.100000000\" gwei\ndeployment tx total cost: \"0.000712373700000000\" ETH\n\nDeployment​\n\nLet's move on to the contract's actual deployment. Two transactions will be sent onchain: the contract deployment and its activation.\n\ncargo stylus deploy \\\n  --endpoint='http://localhost:8547' \\\n  --private-key=\"0xb6b15c8cb491557369f3c7d2c287b053eb229daa9c22138887752191c9520659\"\n\n\nOnce the deployment and activations are successful, you'll see an output similar to this:\n\ndeployed code at address: 0x33f54de59419570a9442e788f5dd5cf635b3c7ac\ndeployment tx hash: 0xa55efc05c45efc63647dff5cc37ad328a47ba5555009d92ad4e297bf4864de36\nwasm already activated!\n\n\nMake sure to save the contract's deployment address for future interactions!\n\nMore options are available for sending and outputting your transaction data. See cargo stylus deploy --help for more details.\n\nExporting the Solidity ABI interface​\n\nThe cargo stylus tool makes it easy to export your contract's ABI using cargo stylus export-abi.\n\nThis command returns the Solidity ABI interface of your smart contract. If you have been running cargo stylus new without modifying the output, cargo stylus export-abi will return:\n\n/**\n * This file was automatically generated by Stylus and represents a Rust program.\n * For more information, please see [The Stylus SDK](https://github.com/OffchainLabs/stylus-sdk-rs).\n */\n\n// SPDX-License-Identifier: MIT-OR-APACHE-2.0\npragma solidity ^0.8.23;\n\ninterface ICounter {\n    function number() external view returns (uint256);\n\n    function setNumber(uint256 new_number) external;\n\n    function mulNumber(uint256 new_number) external;\n\n    function addNumber(uint256 new_number) external;\n\n    function increment() external;\n}\n\n\nEnsure you save the console output to a file that you'll be able to use with your dApp.\n\nInteracting with your Stylus contract​\n\nStylus contracts are EVM-compatible, you can interact with them with your tool of choice, such as Hardhat, Foundry's Cast, or any other Ethereum-compatible tool.\n\nIn this example, we'll use Foundry's Cast to send a call and then a transaction to our contract.\n\nCalling your contract​\n\nOur contract is a counter; in its initial state, it should store a counter value of 0. You can call your contract so it returns its current counter value by sending it the following command:\n\nCall to the function: number()(uint256)\ncast call --rpc-url 'http://localhost:8547' --private-key 0xb6b15c8cb491557369f3c7d2c287b053eb229daa9c22138887752191c9520659 \\\n[deployed-contract-address] \"number()(uint256)\"\n\n\nLet's break down the command:\n\ncast call command sends a call to your contract\nThe --rpc-url option is the RPC URL endpoint of our testnode: http://localhost:8547\nThe --private-key option is the private key of our pre-funded development account. It corresponds to the address 0x3f1eae7d46d88f08fc2f8ed27fcb2ab183eb2d0e\nThe [deployed-contract-address] is the address we want to interact with, it's the address that was returned by cargo stylus deploy\nnumber()(uint256) is the function we want to call in Solidity-style signature. The function returns the counter's current value\nCalling 'number()(uint256)' returns:\n0\n\n\nThe number()(uint256) function returns a value of 0, the contract's initial state.\n\nSending a transaction to your contract​\n\nLet's increment the counter by sending a transaction to your contract's increment() function. We'll use Cast's send command to send our transaction.\n\nSending a transaction to the function: increment()\ncast send --rpc-url 'http://localhost:8547' --private-key 0xb6b15c8cb491557369f3c7d2c287b053eb229daa9c22138887752191c9520659 \\\n[deployed-contract-address] \"increment()\"\n\nTransaction returns:\nblockHash               0xfaa2cce3b9995f3f2e2a2f192dc50829784da9ca4b7a1ad21665a25b3b161f7c\nblockNumber             20\ncontractAddress\ncumulativeGasUsed       97334\neffectiveGasPrice       100000000\nfrom                    0x3f1Eae7D46d88F08fc2F8ed27FCb2AB183EB2d0E\ngasUsed                 97334\nlogs                    []\nlogsBloom               0x00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000\nroot\nstatus                  1 (success)\ntransactionHash         0x28c6ba8a0b9915ed3acc449cf6c645ecc406a4b19278ec1eb67f5a7091d18f6b\ntransactionIndex        1\ntype                    2\nblobGasPrice\nblobGasUsed\nauthorizationList\nto                      0x11B57FE348584f042E436c6Bf7c3c3deF171de49\ngasUsedForL1             \"0x0\"\nl1BlockNumber             \"0x1223\"\n\n\nOur transactions returned a status of 1, indicating success, and the counter has been incremented (you can verify this by calling your contract's number()(uint256) function again).\n\nConclusion​\n\nCongratulations! You've successfully initialized, deployed, and interacted with your first contract using Stylus and Rust.\n\nFeel free to explore the Stylus Rust SDK reference for more information on using Stylus in your Arbitrum projects.\n\nEdit this page\nLast updated on Nov 22, 2024\nPrevious\nA gentle introduction\nNext\nChain info\nSetting up your development environment\nPrerequisites\nCreating a Stylus project with cargo stylus\nInstalling cargo stylus\nCreating a project\nChecking if your Stylus project is valid\nDeploying your contract\nEstimating gas\nDeployment\nExporting the Solidity ABI interface\nInteracting with your Stylus contract\nCalling your contract\nSending a transaction to your contract\nConclusion\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/inside-anytrust",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nTransaction lifecycle\nSequencer\nAnyTrust protocol\nGas / fees\nAdvanced concepts\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nInside AnyTrust\n\nAnyTrust is a variant of Arbitrum Nitro technology that lowers costs by accepting a mild trust assumption.\n\nThe Arbitrum protocol requires that all Arbitrum nodes, including validators (nodes that verify correctness of the chain and are prepared to stake on correct results), have access to the data of every L2 transaction in the Arbitrum chain's inbox. An Arbitrum rollup provides data access by posting the data (in batched, compressed form) on L1 Ethereum as calldata. The Ethereum gas to pay for this is the largest component of cost in Arbitrum.\n\nAnyTrust relies instead on an external Data Availability Committee (hereafter, \"the Committee\") to store data and provide it on demand. The Committee has N members, of which AnyTrust assumes at least two are honest. This means that if N - 1 Committee members promise to provide access to some data, at least one of the promising parties must be honest. Since there are two honest members, and only one failed to make the promise, it follows that at least one of the promisers must be honest — and that honest member will provide data when it is needed to ensure the chain can properly function.\n\nKeysets​\n\nA Keyset specifies the public keys of Committee members and the number of signatures required for a Data Availability Certificate to be valid. Keysets make Committee membership changes possible and provide Committee members the ability to change their keys.\n\nA Keyset contains\n\nthe number of Committee members, and\nfor each Committee member, a BLS public key, and\nthe number of Committee signatures required.\n\nKeysets are identified by their hashes.\n\nAn L1 KeysetManager contract maintains a list of currently valid Keysets. The L2 chain's Owner can add or remove Keysets from this list. When a Keyset becomes valid, the KeysetManager contract emits an L1 Ethereum event containing the Keyset's hash and full contents. This allows the contents to be recovered later by anyone, given only the Keyset hash.\n\nAlthough the API does not limit the number of Keysets that can be valid at the same time, normally only one Keyset will be valid.\n\nData Availability Certificates​\n\nA central concept in AnyTrust is the Data Availability Certificate (hereafter, a \"DACert\"). A DACert contains:\n\nthe hash of a data block, and\nan expiration time, and\nproof that N-1 Committee members have signed the (hash, expiration time) pair, consisting of\nthe hash of the Keyset used in signing, and\na bitmap saying which Committee members signed, and\na BLS aggregated signature (over the BLS12-381 curve) proving that those parties signed.\n\nBecause of the 2-of-N trust assumption, a DACert constitutes proof that the block's data (i.e., the preimage of the hash in the DACert) will be available from at least one honest Committee member, at least until the expiration time.\n\nIn ordinary (non-AnyTrust) Nitro, the Arbitrum sequencer posts data blocks on the L1 chain as calldata. The hashes of the data blocks are committed by the L1 Inbox contract, allowing the data to be reliably read by L2 code.\n\nAnyTrust gives the sequencer two ways to post a data block on L1: it can post the full data as above, or it can post a DACert proving availability of the data. The L1 inbox contract will reject any DACert that uses an invalid Keyset; the other aspects of DACert validity are checked by L2 code.\n\nThe L2 code that reads data from the inbox reads a full-data block as in ordinary Nitro. If it sees a DACert instead, it checks the validity of the DACert, with reference to the Keyset specified by the DACert (which is known to be valid because the L1 Inbox verified that). The L2 code verifies that\n\nthe number of signers is at least the number required by the Keyset, and\nthe aggregated signature is valid for the claimed signers, and\nthe expiration time is at least two weeks after the current L2 timestamp.\n\nIf the DACert is invalid, the L2 code discards the DACert and moves on to the next data block. If the DACert is valid, the L2 code reads the data block, which is guaranteed to be available because the DACert is valid.\n\nData Availability Servers​\n\nCommittee members run Data Availability Server (DAS) software. The DAS exposes two APIs:\n\nThe Sequencer API, which is meant to be called only by the Arbitrum chain's Sequencer, is a JSON-RPC interface allowing the Sequencer to submit data blocks to the DAS for storage. Deployments will typically block access to this API from callers other than the Sequencer.\nThe REST API, which is meant to be available to the world, is a RESTful HTTP(S) based protocol that allows data blocks to be fetched by hash. This API is fully cacheable, and deployments may use a caching proxy or CDN to increase scale and protect against DoS attacks.\n\nOnly Committee members have reason to support the Sequencer API. We expect others to run the REST API, and that is helpful. (More on that below.)\n\nThe DAS software, based on configuration options, can store its data in local files, or in a Badger database, or on Amazon S3, or redundantly across multiple backing stores. The software also supports optional caching in memory (using Bigcache) or in a Redis instance.\n\nSequencer-Committee Interaction​\n\nWhen the Arbitrum sequencer produces a data batch that it wants to post using the Committee, it sends the batch's data, along with an expiration time (normally three weeks in the future) via RPC to all Committee members in parallel. Each Committee member stores the data in its backing store, indexed by the data's hash. Then the member signs the (hash, expiration time) pair using its BLS key, and returns the signature with a success indicator to the sequencer.\n\nOnce the Sequencer has collected enough signatures, it can aggregate the signatures and create a valid DACert for the (hash, expiration time) pair. The Sequencer then posts that DACert to the L1 inbox contract, making it available to the AnyTrust chain software at L2.\n\nIf the Sequencer fails to collect enough signatures within a few minutes, it will abandon the attempt to use the Committee, and will \"fall back to rollup\" by posting the full data directly to the L1 chain, as it would do in a non-AnyTrust chain. The L2 software can understand both data posting formats (via DACert or via full data) and will handle each one correctly.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nSequencer\nNext\nL2 gas and fees\nKeysets\nData Availability Certificates\nData Availability Servers\nSequencer-Committee Interaction\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "How to run a full node (Nitro) | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/run-full-node",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nHow to run a full node (Nitro)\nINFO\n\nThere is no protocol-level incentive to run an Arbitum full node. If you’re interested in accessing an Arbitrum chain but don’t want to set up your own node, see our Node Providers to get RPC access to fully managed nodes hosted by a third-party provider.\n\nMinimum hardware configuration​\n\nMinimum hardware configuration required to set up a Nitro full node (not archival):\n\nRAM: 16 GB\nCPU: 4 core CPU\nSingle core performance is important. If the node is falling behind and a single core is 100% busy, it is recommended to update to a faster processor\nStorage (last updated on April 2024):\nArbitrum One: 560GB for a pruned node, growing at ~200GB per month (NVMe SSD drives are recommended)\nArbitrum Nova: 400GB for a pruned node, growing at ~1.6TB per month (NVMe SSD drives are recommended)\nINFO\n\nThese minimum requirements for RAM and CPU are recommended for nodes that process a small amount of RPC requests. For nodes that require processing multiple simultaneous requests, both RAM and number of CPU cores will need to be scaled with the amount of traffic being served.\n\nINFO\n\nThe minimum storage requirements will change over time as the Nitro chain grows. Using more than the minimum requirements to run a robust full node is recommended.\n\nPrerequisites​\nONLY USE RELEASED VERSIONS\n\nEven though there are alpha and beta versions of the Arbitrum Nitro software, only release versions should be used when running your node. Running alpha or beta versions is not supported and might lead to unexpected behaviors.\n\nLatest Docker Image: offchainlabs/nitro-node:v3.2.1-d81324d\nDatabase snapshot (required for Arbitrum One, optional for other chains)\nUse the parameter --init.latest <snapshot type>, accepted values: \"archive\" | \"pruned\" | \"genesis\".\nWhen running more than one node, it's easier to manually download the different parts of the snapshot, join them into a single archive, and host it locally for your nodes. You can then use --init.url=\"file:///path/to/snapshot/in/container/snapshot-file.tar\" to use it. (For how to manually download the snapshot parts, please see Downloading the snapshot manually)\nThis parameter is required when initializing an Arbitrum One node because the chain has classic blocks. For the other chains, this parameter is optional.\nThis parameter is ignored if the database already exists.\nFind more info in Nitro database snapshots\nYou can find more snapshots on our snapshot explorer\nRequired parameters​\nL1 RPC URL\nUse the parameter --parent-chain.connection.url=<Layer 1 Ethereum RPC URL> for execution layer.\nIf the chain is running ArbOS 20, additionally use the parameter --parent-chain.blob-client.beacon-url=<Layer 1 Ethereum Beacon RPC URL> for consensus layer. You can find a list of beacon chain RPC providers here.\nIt must provide a standard layer 1 node RPC endpoint that you run yourself or from a node provider.\nNote: historical blob data is required for chains running ArbOS 20 to properly sync up if they are new or have been offline for more than 18 days. This means the consensus layer RPC endpoint you use may also need to provide historical blob data. Please see Special notes on ArbOS 20: Atlas support for EIP-4844 for more details.\nNote: this parameter was called --l1.url in versions prior to v2.1.0\nNote: 8545 is usually the default port for the execution layer. For the Beacon endpoint port, you should connect to the correct port set on your parent chain's consensus client.\nL2 chain ID or name\nUse the parameter --chain.id=<L2 chain ID> to set the L2 chain from its chain id. See RPC endpoints and providers for a list of Arbitrum chains and their respective L2 chain IDs.\nAlternatively, you can use the parameter --chain.name=<L2 chain name> to set the L2 chain from its name (options are: arb1, nova and sepolia-rollup)\nNote: this parameter was called --l2.chain-id and only accepted chain IDs in versions before v2.1.0\nImportant ports​\nRPC: 8547\nSequencer Feed: 9642\nWebSocket: 8548\nWS port 8548 needs extra args to be opened. Please use these flags:\n--ws.port=8548\n--ws.addr=0.0.0.0\n--ws.origins=*\nPutting it all together​\n\nWhen running the Docker image, an external volume should be mounted to persist the database across restarts. The mount point inside the docker image should be /home/user/.arbitrum\n\nHere is an example of how to run nitro-node:\n\nNote that it is important that /some/local/dir/arbitrum already exists; otherwise, the directory might be created with root as owner, and the docker container won't be able to write to it\ndocker run --rm -it  -v /some/local/dir/arbitrum:/home/user/.arbitrum -p 0.0.0.0:8547:8547 -p 0.0.0.0:8548:8548 offchainlabs/nitro-node:v3.2.1-d81324d --parent-chain.connection.url https://l1-node:8545 --chain.id=<L2ChainId> --http.api=net,web3,eth --http.corsdomain=* --http.addr=0.0.0.0 --http.vhosts=*\n\n\nNote that if you are running an L1 node on localhost, you may need to add --network host right after docker run to use docker host-based networking\n\nWhen shutting down the Docker image, it is important to allow a graceful shutdown to save the current state to disk. Here is an example of how to do a graceful shutdown of all docker images currently running\n\ndocker stop --time=300 $(docker ps -aq)\n\nNote on permissions​\nThe Docker image is configured to run as non-root UID 1000. This means if you are running in Linux or OSX and you are getting permission errors when trying to run the docker image, run this command to allow all users to update the persistent folders\nmkdir /data/arbitrum\nchmod -fR 777 /data/arbitrum\n\nWatchtower mode​\nBy default, the full node will run in Watchtower mode. This means that the node watches the on-chain assertions, and if it disagrees with them, it will log an error containing the string found incorrect assertion in watchtower mode.\nWatchtower mode adds a small amount of execution and memory overhead. You can deactivate this mode using the parameter --node.staker.enable=false.\nPruning​\nPruning a full node refers to removing older, unnecessary data from the local copy of the blockchain that the node maintains to save disk space and slightly improve the node's efficiency. Pruning will remove all states from blocks older than the latest 128.\nYou can activate pruning by using the parameter --init.prune and using \"full\" or \"validator\" as the value (depending on the type of node you are running). Remember that this process will happen upon starting the node and will not serve RPC requests while pruning.\nOptional parameters​\n\nBelow, we listed the most commonly used parameters when running a node. You can also use the flag --help for a comprehensive list of the available parameters.\n\nFlag\tDescription\n--execution.rpc.classic-redirect=<RPC>\tRedirects archive requests for pre-nitro blocks to this RPC of an Arbitrum Classic node with archive database. Only for Arbitrum One.\n--http.api\tOffered APIs over the HTTP-RPC interface. Default: net,web3,eth,arb. Add debug for tracing.\n--http.corsdomain\tAccepts cross origin requests from these comma-separated domains (browser enforced).\n--http.vhosts\tAccepts requests from these comma-separated virtual hostnames (server enforced). Default: localhost. Accepts *.\n--http.addr\tAddress to bind RPC to. May require 0.0.0.0 for Docker networking.\n--execution.caching.archive\tRetains past block state. For archive nodes.\n--node.feed.input.url=<feed address>\tDefault: wss://<chainName>.arbitrum.io/feed. ⚠️ One feed relay per datacenter is advised. See feed relay guide.\n--execution.forwarding-target=<RPC>\tDefaults to the L2 Sequencer RPC based on provided L1 and L2 chain IDs.\n--execution.rpc.evm-timeout\tDefault: 5s. Timeout for eth_call. (0 == no timeout).\n--execution.rpc.gas-cap\tDefault: 50000000. Gas cap for eth_call/estimateGas. (0 = no cap).\n--execution.rpc.tx-fee-cap\tDefault: 1. Transaction fee cap (in ether) for RPC APIs. (0 = no cap).\n--ipc.path\tFilename for IPC socket/pipe within datadir. 🔉 Not supported on macOS. Note the path is within the Docker container.\n--init.prune\tPrunes database before starting the node. Can be \"full\" or \"validator\".\n--init.url=\"<snapshot file>\"\t(Non-Orbit Nitro nodes only) URL to download the genesis database from. Required only for the first startup of an Arbitrum One node. Reference to snapshots and archive node guide.\n--init.download-path=\"/path/to/dir\"\t(Non-Orbit Nitro nodes only) Temporarily saves the downloaded database snapshot. Defaults to /tmp/. Used with --init.url.\n--node.batch-poster.post-4844-blobs\tBoolean. Default: false. Used to enable or disable the posting of transaction data using Blobs to L1 Ethereum. If using calldata is more expensive and if the parent chain supports EIP4844 blobs, the batch poster will use blobs when this flag is set to true. Can be true or false.\n--node.batch-poster.ignore-blob-price\tBoolean. Default: false. If the parent chain supports EIP4844 blobs and ignore-blob-price is set to true, the batch poster will use EIP4844 blobs even if using calldata is cheaper. Can be true or false.\n--init.latest\tstring. if set, searches for the latest snapshot of the given kind (accepted values: \"archive\" , \"pruned\" , \"genesis\")\n--init.latest-base\tstring. Default: \"https://snapshot.arbitrum.foundation/\". Base url used when searching for the latest. (If you are running orbit chains you might need to check with orbit chain team to get the url)\n--init.then-quit\tAllows any --init.* parameters to complete, and then the node will automatically quit. It doesn't initiate pruning by itself but works in conjunction with other --init.* parameters, making it easier to script tasks like database backups after initialization processes finish.\nEdit this page\nLast updated on Nov 22, 2024\nPrevious\nQuickstart\nNext\nRun a local full chain simulation\nMinimum hardware configuration\nPrerequisites\nRequired parameters\nImportant ports\nPutting it all together\nNote on permissions\nWatchtower mode\nPruning\nOptional parameters\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/inside-arbitrum-nitro",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nInside Arbitrum Nitro\n\nThis document is a deep-dive explanation of Arbitrum Nitro’s design and the rationale for it. This isn’t API documentation, nor is it a guided tour of the code--look elsewhere for those. “Inside Arbitrum Nitro” is for people who want to understand Nitro's design.\n\nThe body of this document will describe Arbitrum Rollup, the primary use case of the Nitro technology and the one used on the Arbitrum One chain. There is a variant use case, called AnyTrust, which is used by the Arbitrum Nova chain. AnyTrust is covered by a section at the end of this document.\n\nWhy use Arbitrum? Why use Nitro?​\n\nArbitrum is an L2 scaling solution for Ethereum, offering a unique combination of benefits:\n\nTrustless security: security rooted in Ethereum, with any one party able to ensure correct Layer 2 results\nCompatibility with Ethereum: able to run unmodified EVM contracts and unmodified Ethereum transactions\nScalability: moving contracts’ computation and storage off of the main Ethereum chain, allowing much higher throughput\nMinimum cost: designed and engineered to minimize the L1 gas footprint of the system, minimizing per-transaction cost.\n\nSome other Layer 2 systems provide some of these features, but to our knowledge no other system offers the same combination of features at the same cost.\n\nNitro is a major upgrade to Arbitrum, improving over \"classic\" Arbitrum in several ways:\n\nAdvanced Calldata Compression, which further drives down transaction costs on Arbitrum by reducing the amount of data posted to L1.\nSeparate Contexts For Common Execution and Fault Proving, increasing the performance of L1 nodes, and thus offering lower fees.\nEthereum L1 Gas Compatibility, bringing pricing and accounting for EVM operations perfectly in line with Ethereum.\nAdditional L1 Interoperability, including tighter synchronization with L1 Block numbers, and full support for all Ethereum L1 precompiles.\nSafe Retryables, eliminating the failure mode where a retryable ticket fails to get created.\nGeth Tracing, for even broader debugging support.\nAnd many, many more changes.\nThe Big Picture​\n\nAt the most basic level, an Arbitrum chain works like this:\n\nOriginal napkin sketch drawn by Arbitrum co-founder Ed Felten\n\nUsers and contracts put messages into the inbox. The chain reads the messages one at a time, and processes each one. This updates the state of the chain and produces some outputs.\n\nIf you want an Arbitrum chain to process a transaction for you, you need to put that transaction into the chain’s inbox. Then the chain will see your transaction, execute it, and produce some outputs: a transaction receipt, and any withdrawals that your transaction initiated.\n\nExecution is deterministic -- which means that the chain’s behavior is uniquely determined by the contents of its inbox. Because of this, the result of your transaction is knowable as soon as your transaction has been put in the inbox. Any Arbitrum node will be able to tell you the result. (And you can run an Arbitrum node yourself if you want.)\n\nAll of the technical detail in this document is connected to this diagram. To get from this diagram to a full description of Arbitrum, we’ll need to answer questions like these:\n\nWho keeps track of the inbox, chain state, and outputs?\nHow does Arbitrum make sure that the chain state and outputs are correct?\nHow can Ethereum users and contracts interact with Arbitrum?\nHow does Arbitrum support Ethereum-compatible contracts and transactions?\nHow are ETH and tokens transferred into and out of Arbitrum chains, and how are they managed while on the chain?\nHow can I run my own Arbitrum node or validator?\nNitro's Design: The Four Big Ideas​\n\nThe essence of Nitro, and its key innovations, lie in four big ideas. We'll list them here with a very quick summary of each, then we'll unpack them in more detail in later sections.\n\nBig Idea: Sequencing, Followed by Deterministic Execution: Nitro processes transactions with a two-phase strategy. First, the transactions are organized into a single ordered sequence, and Nitro commits to that sequence. Then the transactions are processed, in that sequence, by a deterministic state transition function.\n\nBig Idea: Geth at the Core: Nitro supports Ethereum's data structures, formats, and virtual machine by compiling in the core code of the popular go-ethereum (\"Geth\") Ethereum node software. Using Geth as a library in this way ensures a very high degree of compatibility with Ethereum.\n\nBig Idea: Separate Execution from Proving: Nitro takes the same source code and compiles it twice, once to native code for execution in a Nitro node, optimized for speed, and again to WASM for use in proving, optimized for portability and security.\n\nBig Idea: Optimistic Rollup with Interactive Fraud Proofs: Nitro settles transactions to the Layer 1 Ethereum chain using an optimistic rollup protocol, including the interactive fraud proofs pioneered by Arbitrum.\n\nSequencing, Followed by Deterministic Execution​\n\nThis diagram summarizes how transactions are processed in Nitro.\n\nLet's follow a user's transaction through this process.\n\nFirst, the user creates a transaction, uses their wallet to sign it, and sends it to the Nitro chain's Sequencer. The Sequencer's job, as its name implies, is to take the arriving transactions, put them into an ordered sequence, and publish that sequence.\n\nOnce the transactions are sequenced, they are run through the state transition function, one by one, in order. The state transition function takes as input the current state of the chain (account balances, contract code, and so on), along with the next transaction. It updates the state and sometimes emits a new Layer 2 block on the Nitro chain.\n\nBecause the protocol doesn't trust the Sequencer not to put garbage into its sequence, the state transition function will detect and discard any invalid (e.g., improperly formed) transactions in the sequence. A well-behaved Sequencer will filter out invalid transactions so the state transition function never sees them--and this reduces cost and therefore keeps transactions fees low--but Nitro will still work correctly no matter what the Sequencer puts into its feed. (Transactions in the feed are signed by their senders, so the Sequencer can't create forged transactions.)\n\nThe state transition function is deterministic, which means that its behavior depends only on the current state and the contents of the next transaction--and nothing else. Because of this determinism, the result of a transaction T will depend only on the genesis state of the chain, the transactions before T in the sequence, and T itself.\n\nIt follows that anyone who knows the transaction sequence can compute the state transition function for themselves--and all honest parties who do this are guaranteed to get identical results. This is the normal way that Nitro nodes operate: get the transaction sequence, and run the state transition function locally. No consensus mechanism is needed for this.\n\nHow the Sequencer Publishes the Sequence​\n\nSo how do nodes get the sequence? The Sequencer publishes it in two ways: a real-time feed, and batches posted on L1 Ethereum.\n\nThe real-time feed is published by the Sequencer so that anyone who subscribes to the feed receives instant notifications of each transaction as it is sequenced. Nitro nodes can subscribe to the feed directly from the Sequencer, or through a relay that forwards the feed. The feed represents the Sequencer's promise that it will record transactions in a particular order. If the Sequencer is honest and doesn't have a long downtime, this promise will be kept. So anyone who trusts the Sequencer to keep its promises can rely on the feed to get instant information about the transaction sequence--and they can run the sequenced transactions through the state transition function to learn the results of each transaction immediately. This is \"soft finality\" for transactions; it's \"soft\" because it depends on the Sequencer keeping its promises.\n\nThe Sequencer also publishes its sequence on the L1 Ethereum chain. Periodically--perhaps every few minutes in production--the Sequencer concatenates the next group of transactions in the feed, compresses them for efficiency, and posts the result as calldata on Ethereum. This is the final and official record of the transaction sequence. As soon as this Ethereum transaction has finality on Ethereum, the Layer 2 Nitro transactions it records will have finality. These transactions are final because their position in the sequence has finality, and the outcome of the transactions is deterministic and knowable to any party. This is \"hard finality\".\n\nThe Sequencer's batches are compressed using a general-purpose data compression algorithm called \"brotli\", on its highest-compression setting.\n\nGeth at the Core​\n\nThe second key design idea in Nitro is \"geth at the core.\" Here \"geth\" refers to go-ethereum, the most common node software for Ethereum. As its name would suggest, go-ethereum is written in the Go programming language, as is almost all of Nitro.\n\nThe software that makes up a Nitro node can be thought of as built in three main layers, which are shown above:\n\nThe base layer is the core of geth--the parts of Geth that emulate the execution of EVM contracts and maintain the data structures that make up the Ethereum state. Nitro compiles in this code as a library, with a few minor modifications to add necessary hooks.\nThe middle layer, which we call ArbOS, is custom software that provides additional functions associated with Layer 2 functionality, such as decompressing and parsing the Sequencer's data batches, accounting for Layer 1 gas costs and collecting fees to reimburse for them, and supporting cross-chain bridge functionalities such as deposits of Ether and tokens from L1 and withdrawals of the same back to L1. We'll dig in to the details of ArbOS below.\nThe top layer consists of node software, mostly drawn from geth. This handles connections and incoming RPC requests from clients and provides the other top-level functionality required to operate an Ethereum-compatible blockchain node.\n\nBecause the top and bottom layers rely heavily on code from geth, this structure has been dubbed a \"geth sandwich.\" Strictly speaking, Geth plays the role of the bread in the sandwich, and ArbOS is the filling, but this sandwich is named for the bread.\n\nThe State Transition Function consists of the bottom Geth layer, and a portion of the middle ArbOS layer. In particular, the STF is a designated function in the source code, and implicitly includes all of the code called by that function. The STF takes as input the bytes of a transaction received in the inbox, and has access to a modifiable copy of the Ethereum state tree. Executing the STF may modify the state, and at the end will emit the header of a new block (in Ethereum's block header format) which will be appended to the Nitro chain.\n\nSeparating Execution from Proving​\n\nOne of the challenges in designing a practical rollup system is the tension between wanting the system to perform well in ordinary execution, versus being able to reliably prove the results of execution. Nitro resolves this tension by using the same source code for both execution and proving, but compiling it to different targets for the two cases.\n\nWhen compiling the Nitro node software for execution, the ordinary Go compiler is used, producing native code for the target architecture, which of course will be different for different node deployments. (The node software is distributed in source code form, and as a Docker image containing a compiled binary.)\n\nSeparately, for proving, the portion of the code that is the State Transition Function is compiled by the Go compiler to WebAssembly (wasm), which is a typed, portable machine code format. The wasm code then goes through a simple transformation into a format we call WAVM, which is detailed below. If there is a dispute about the correct result of computing the STF, it is resolved with reference to the WAVM code.\n\nWAVM​\n\nThe wasm format has many features that make it a good vehicle for fraud proofs---it is portable, structured, well-specified, and has reasonably good tools and support---but it needs a few modifications to do the job completely. Nitro uses a slightly modified version of wasm, which we call WAVM. A simple transformation stage turns the wasm code produced by the Go compiler into WAVM code suitable for proving.\n\nWAVM differs from wasm in three main ways. First, WAVM removes some features of wasm that are not generated by the Go compiler; the transformation phase verifies that these features are not present.\n\nSecond, WAVM restricts a few features of wasm. For example, WAVM does not contain floating-point instructions, so the transformer replaces floating-point instructions with calls to the Berkeley SoftFloat library. (We use software floating-point to reduce the risk of floating-point incompatibilities between architectures. The core Nitro functions never use floating-point, but the Go runtime does use some floating-point operations.) WAVM does not contain nested control flow, so the transformer flattens control flow constructs, turning control flow instructions into jumps. Some wasm instructions take a variable amount of time to execute, which we avoid in WAVM by transforming them into constructs using fixed cost instructions. These transformations simplify proving.\n\nThird, WAVM adds a few opcodes to enable interaction with the blockchain environment. For example, new instructions allow the WAVM code to read and write the chain's global state, to get the next message from the chain's inbox, or to signal a successful end to executing the State Transition Function.\n\nReadPreImage and the Hash Oracle Trick​\n\nThe most interesting new instruction is ReadPreImage which takes as input a hash H and an offset I, and returns the word of data at offset I in the preimage of H (and the number of bytes written, which is zero if I is at or after the end of the preimage). Of course, it is not feasible in general to produce a preimage from an arbitrary hash. For safety, the ReadPreImage instruction can only be used in a context where the preimage is publicly known, and where the size of the preimage is known to be less than a fixed upper bound of about 110 kbytes.\n\n(In this context, \"publicly known\" information is information that can be derived or recovered efficiently by any honest party, assuming that the full history of the L1 Ethereum chain is available. For convenience, a hash preimage can also be supplied by a third party such as a public server, and the correctness of the supplied value is easily verified.)\n\nAs an example, the state of a Nitro chain is maintained in Ethereum's state tree format, which is organized as a Merkle tree. Nodes of the tree are stored in a database, indexed by the Merkle hash of the node. In Nitro, the state tree is kept outside of the State Transition Function's storage, with the STF only knowing the root hash of the tree. Given the hash of a tree node, the STF can recover the tree node's contents by using ReadPreImage, relying on the fact that the full contents of the tree are publicly known and that nodes in the Ethereum state tree will always be smaller than the upper bound on preimage size. In this manner, the STF is able to arbitrarily read and write to the state tree, despite only storing its root hash.\n\nThe only other use of ReadPreImage is to fetch the contents of recent L2 block headers, given the header hash. This is safe because the block headers are publicly known and have bounded size.\n\nThis \"hash oracle trick\" of storing the Merkle hash of a data structure, and relying on protocol participants to store the full structure and thereby support fetch-by-hash of the contents, goes back to the original Arbitrum design.\n\nOptimistic Rollup​\n\nArbitrum is an optimistic rollup. Let’s unpack that term.\n\nRollup\n\nArbitrum is a rollup, which means that the inputs to the chain -- the messages that are put into the inbox -- are all recorded on the Ethereum chain as calldata. Because of this, everyone has the information they would need to determine the current correct state of the chain -- they have the full history of the inbox, and the results are uniquely determined by the inbox history, so they can reconstruct the state of the chain based only on public information, if needed.\n\nThis also allows anyone to be a full participant in the Arbitrum protocol, to run an Arbitrum node or participate as a validator. Nothing about the history or state of the chain is a secret.\n\nOptimistic\n\nArbitrum is optimistic, which means that Arbitrum advances the state of its chain by letting any party (a “validator”) post on Layer 1 a rollup block that that party claims is correct, and then giving everyone else a chance to challenge that claim. If the challenge period (6.4 days) passes and nobody has challenged the claimed rollup block, Arbitrum confirms the rollup block as correct. If someone challenges the claim during the challenge period, then Arbitrum uses an efficient dispute resolution protocol (detailed below) to identify which party is lying. The liar will forfeit a deposit, and the truth-teller will take part of that deposit as a reward for their efforts (some of the deposit is burned, guaranteeing that the liar is punished even if there's some collusion going on).\n\nBecause a party who tries to cheat will lose a deposit, attempts to cheat should be very rare, and the normal case will be a single party posting a correct rollup block, and nobody challenging it.\n\nResolving disputes using interactive fraud proofs​\n\nAmong optimistic rollups, the most important design decision is how to resolve disputes. Suppose Alice claims that the chain will produce a certain result, and Bob disagrees. How will the protocol decide which version to accept?\n\nThere are basically two choices: interactive proving, or re-executing transactions. Arbitrum uses interactive proving, which we believe is more efficient and more flexible. Much of the design of Arbitrum follows from this fact.\n\nInteractive proving​\n\nThe idea of interactive proving is that Alice and Bob will engage in a back-and-forth protocol, refereed by an L1 contract, to resolve their dispute with minimal work required from any L1 contract.\n\nArbitrum's approach is based on dissection of the dispute. If Alice's claim covers N steps of execution, she posts two claims of size N/2 which combine to yield her initial N-step claim, then Bob picks one of Alice's N/2-step claims to challenge. Now the size of the dispute has been cut in half. This process continues, cutting the dispute in half at each stage, until they are disagreeing about a single step of execution. Note that so far the L1 referee hasn't had to think about execution \"on the merits\". It is only once the dispute is narrowed down to a single step that the L1 referee needs to resolve the dispute by looking at what the instruction actually does and whether Alice's claim about it is correct.\n\nThe key principle behind interactive proving is that if Alice and Bob are in a dispute, Alice and Bob should do as much off-chain work as possible needed to resolve their dispute, rather than putting that work onto an L1 contract.\n\nRe-executing transactions​\n\nThe alternative to interactive proving would be to have a rollup block contain a claimed machine state hash after every individual transaction. Then in case of a dispute, the L1 referee would emulate the execution of an entire transaction, to see whether the outcome matches Alice's claim.\n\nWhy interactive proving is better​\n\nWe believe strongly that interactive proving is the superior approach, for the following reasons.\n\nMore efficient in the optimistic case: Because interactive proving can resolve disputes that are larger than one transaction, it can allow a rollup block to contain only a single claim about the end state of the chain after all of the execution covered by the block. By contrast, reexecution requires posting a state claim for each transaction within the rollup block. With hundred or thousands of transactions per rollup block, this is a substantial difference in L1 footprint -- and L1 footprint is the main component of cost.\n\nMore efficient in the pessimistic case: In case of a dispute, interactive proving requires the L1 referee contract only to check that Alice and Bob's actions \"have the right shape\", for example, that Alice has divided her N-step claim into two claims half as large. (The referee doesn't need to evaluate the correctness of Alice's claims--Bob does that, off-chain.) Only one instruction needs to be reexecuted. By contrast, reexecution requires the L1 referee to emulate the execution of an entire transaction.\n\nHigher per-tx gas limit: Interactive proving can escape from Ethereum's tight per-transaction gas limit. The gas limit isn't infinite, for obvious reasons, but it can be larger than on Ethereum. As far as Ethereum is concerned, the only downside of a gas-heavy Arbitrum transaction is that it may require an interactive fraud proof with slightly more steps (and only if indeed it is fraudulent). By contrast, reexecution must impose a lower gas limit than Ethereum, because it must be possible to emulate execution of the transaction (which is more expensive than executing it directly) within a single Ethereum transaction.\n\nMore implementation flexibility: Interactive proving allows more flexibility in implementation. All that is necessary is the ability to verify a one-step proof on Ethereum. By contrast, reexecution approaches are tethered to limitations of the EVM.\n\nInteractive proving drives the design of Arbitrum​\n\nMuch of the design of Arbitrum is driven by the opportunities opened up by interactive proving. If you're reading about some feature of Arbitrum, and you're wondering why it exists, two good questions to ask are: \"How does this support interactive proving?\" and \"How does this take advantage of interactive proving?\" The answers to most \"why\" questions about Arbitrum relate to interactive proving.\n\nArbitrum Rollup Protocol​\n\nBefore diving into the rollup protocol, there are two things we need to cover.\n\nFirst, if you’re an Arbitrum user or developer, you don’t need to understand the rollup protocol. You don’t ever need to think about it, unless you want to. Your relationship with it can be like a train passenger’s relationship with the train’s engine: you know it exists, you rely on it to keep working, but you don’t spend your time monitoring it or studying its internals.\n\nYou’re welcome to study, observe, and even participate in the rollup protocol, but you don’t need to, and most people won’t. So if you’re a typical train passenger who just wants to read or talk to your neighbor, you can skip right to the next section of this document. If not, read on!\n\nThe second thing to understand about the rollup protocol is that the protocol doesn’t decide the results of transactions, it only confirms the results. The results are uniquely determined by the sequence of messages in the chain’s inbox. So once your transaction message is in the chain’s inbox, its result is knowable--and Arbitrum nodes will report that your transaction is done. The role of the rollup protocol is to confirm transaction results that, as far as Arbitrum users are concerned, have already occurred. (This is why Arbitrum users can effectively ignore the rollup protocol.)\n\nYou might wonder why we need the rollup protocol. If everyone knows the results of transactions already, why bother confirming them? The rollup protocol exists for two reasons. First, somebody might lie about a result, and we need a definitive, trustless way to tell who is lying. Second, Ethereum doesn’t know the results. The whole point of a Layer 2 scaling system is to run transactions without Ethereum needing to do all of the work--and indeed Arbitrum can go fast enough that Ethereum couldn’t hope to monitor every Arbitrum transaction. But once a result is confirmed, Ethereum knows about it and can rely on it, enabling operations on Ethereum such as processing withdrawals of funds from Nitro back to L1.\n\nWith those preliminaries behind us, let’s jump into the details of the rollup protocol.\n\nThe parties who participate in the protocol are called validators. Some validators will choose to be bonders--they will place an ETH deposit which they’ll be able to recover if they’re not caught cheating. In the common case, it's expected that only one validator will be bonded, since as long as it's bonded on the current outcome, and there are no conflicting claims, there's no need for other parties to bond/take any action. The protocol allows for these roles to be permissionless in principle; currently on Arbitrum One, validators/bonders are allowlisted (see \"State of Progressive Decentralization\"). \"Watchtower validators,\" who monitor the chain but don't take any on-chain actions, can be run permissionlessly (see \"validators\" below).\n\nThe key security property of the rollup protocol is that any one honest validator can force the correct execution of the chain to be confirmed. This means that execution of an Arbitrum chain is as trustless as Ethereum. You, and you alone (or someone you hire) can force your transactions to be processed correctly. And that is true no matter how many malicious people are trying to stop you.\n\nThe Rollup Chain​\n\nThe rollup protocol tracks a chain of rollup blocks---we'll call these \"RBlocks\" for clarity. They're not the same as Layer 1 Ethereum blocks, and also not the same as Layer 2 Nitro blocks. You can think of the RBlocks as forming a separate chain, which the Arbitrum rollup protocol manages and oversees.\n\nValidators can propose RBlocks. New RBlocks will be unresolved at first. Eventually every RBlock will be resolved, by being either confirmed or rejected. The confirmed RBlocks make up the confirmed history of the chain.\n\nNOTE\n\nValidators and proposers serve different roles. Validators validate transactions to the State Transition Function (STF) and chain state, whereas proposers can also assert and challenge the chain state.\n\nEach RBlock contains:\n\nthe RBlock number\nthe predecessor RBlock number: RBlock number of the last RBlock before this one that is (claimed to be) correct\nthe number of L2 blocks that have been created in the chain's history\nthe number of inbox messages that have been consumed in the chain’s history\na hash of the outputs produced over the chain’s history.\n\nExcept for the RBlock number, the contents of the RBlock are all just claims by the RBlock's proposer. Arbitrum doesn’t know at first whether any of these fields are correct. If all of these fields are correct, the protocol should eventually confirm the RBlock. If one or more of these fields are incorrect, the protocol should eventually reject the RBlock.\n\nAn RBlock is implicitly claiming that its predecessor RBlock is correct. This implies, transitively, that an RBlock implicitly claims the correctness of a complete history of the chain: a sequence of ancestor RBlocks that reaches all the way back to the birth of the chain.\n\nAn RBlock is also implicitly claiming that its older siblings (older RBlocks with the same predecessor), if there are any, are incorrect. If two RBlocks are siblings, and the older sibling is correct, then the younger sibling is considered incorrect, even if everything else in the younger sibling is true.\n\nThe RBlock is assigned a deadline, which says how long other validators have to respond to it. If you’re a validator, and you agree that an RBlock is correct, you don’t need to do anything. If you disagree with an RBlock, you can post another RBlock with a different result, and you’ll probably end up in a challenge against the first RBlock's bonder. (More on challenges below.)\n\nIn the normal case, the rollup chain will look like this:\n\nOn the left, representing an earlier part of the chain’s history, we have confirmed RBlocks. These have been fully accepted and recorded by the Layer 1 contracts that manage the chain. The newest of the confirmed RBlocks, RBlock 94, is called the “latest confirmed RBlock.” On the right, we see a set of newer proposed RBlocks. The protocol can’t yet confirm or reject them, because their deadlines haven’t run out yet. The oldest RBlock whose fate has yet to be determined, RBlock 95, is called the “first unresolved RBlock.”\n\nNotice that a proposed RBlock can build on an earlier proposed RBlock. This allows validators to continue proposing RBlocks without needing to wait for the protocol to confirm the previous one. Normally, all of the proposed RBlocks will be valid, so they will all eventually be accepted.\n\nHere’s another example of what the chain state might look like, if several validators are being malicious. It’s a contrived example, designed to illustrate a variety of cases that can come up in the protocol, all smashed into a single scenario.\n\nThere’s a lot going on here, so let’s unpack it.\n\nRBlock 100 has been confirmed.\nRBlock 101 claimed to be a correct successor to RBlock 100, but 101 was rejected (hence it is orange).\nRBlock 102 was eventually confirmed as the correct successor to 100.\nRBlock 103 was confirmed and is now the latest confirmed RBlock.\nRBlock 104 was proposed as a successor to RBlock 103, and 105 was proposed as a successor to 104. 104 was rejected as incorrect, and as a consequence 105 was rejected because its predecessor was rejected.\nRBlock 106 is unresolved. It claims to be a correct successor to RBlock 103 but the protocol hasn’t yet decided whether to confirm or reject it. It is the first unresolved RBlock.\nRBlocks 107 and 108 claim to chain from 106. They are also unresolved. If 106 is rejected, they will be automatically rejected too.\nRBlock 109 disagrees with RBlock 106, because they both claim the same predecessor. At least one of them will eventually be rejected, but the protocol hasn’t yet resolved them.\nRBlock 110 claims to follow 109. It is unresolved. If 109 is rejected, 110 will be automatically rejected too.\nRBlock 111 claims to follow 104. 111 will inevitably be rejected because its predecessor has already been rejected. But it hasn’t been rejected yet, because the protocol resolves RBlocks in RBlock number order, so the protocol will have to resolve 106 through 110, in order, before it can resolve 111. After 110 has been resolved, 111 can be rejected immediately.\n\nAgain: this sort of thing is very unlikely in practice. In this diagram, at least four parties must have bonded on wrong RBlocks, and when the dust settles at least four parties will have lost their bonds. The protocol handles these cases correctly, of course, but they’re rare corner cases. This diagram is designed to illustrate the variety of situations that are possible in principle, and how the protocol would deal with them.\n\nStaking​\n\nAt any given time, some validators will be bonders, and some will not. Bonders deposit funds that are held by the Arbitrum Layer 1 contracts and will be confiscated if the bonder loses a challenge. Nitro chains accept bonds in ETH.\n\nA single bond can cover a chain of RBlocks. Every bonder is bonded on the latest confirmed RBlock; and if you’re bonded on an RBlock, you can also bond on one successor of that RBlock. So you might be bonded on a sequence of RBlocks that represent a single coherent claim about the correct history of the chain. A single bond suffices to commit you to that sequence of RBlocks.\n\nIn order to create a new RBlock, you must be a bonder, and you must already be bonded on the predecessor of the new RBlock you’re creating. The bond requirement for RBlock creation ensures that anyone who creates a new RBlock has something to lose if that RBlock is eventually rejected.\n\nThe protocol keeps track of the current required bond amount. Normally this will equal the base bond amount, which is a parameter of the Nitro chain. But if the chain has been slow to make progress lately, the required bond will increase, as described in more detail below.\n\nThe rules for staking are as follows:\n\nIf you’re not bonded, you can bond on the latest confirmed RBlock. When doing this, you deposit the current minimum bond amount.\nIf you’re bonded on an RBlock, you can also add your bond to any one successor of that RBlock. (The protocol tracks the maximum RBlock number you’re bonded on, and lets you add your bond to any successor of that RBlock, updating your maximum to that successor.) This doesn’t require you to place a new bond.\nA special case of adding your bond to a successor RBlock is when you create a new RBlock as a successor to an RBlock you’re already bonded on.\nIf you’re bonded only on the latest confirmed RBlock (and possibly earlier RBlocks), you or anyone else can ask to have your bond refunded. Your bonded funds will be returned to you, and you will no longer be a bonder.\nIf you lose a challenge, your bond is removed from all RBlocks and you forfeit your bonded funds.\n\nNotice that once you are bonded on an RBlock, there is no way to unbond. You are committed to that RBlock. Eventually one of two things will happen: that RBlock will be confirmed, or you will lose your bond. The only way to get your bond back is to wait until all of the RBlocks you are bonded on are confirmed.\n\nSetting the current minimum bond amount​\n\nOne detail we deferred earlier is how the current minimum bond amount is set. Normally, this is just equal to the base bond amount, which is a parameter of the Nitro chain. However, if the chain has been slow to make progress in confirming RBlocks, the bond requirement will escalate temporarily. Specifically, the base bond amount is multiplied by a factor that is exponential in the time since the deadline of the first unresolved RBlock passed. This ensures that if malicious parties are placing false bonds to try to delay progress (despite the fact that they’re losing those bonds), the bond requirement goes up so that the cost of such a delay attack increases exponentially. As RBlock resolution starts advancing again, the bond requirement will go back down.\n\nRules for Confirming or Rejecting RBlocks​\n\nThe rules for resolving RBlocks are fairly simple.\n\nThe first unresolved RBlock can be confirmed if:\n\nthe RBlock's predecessor is the latest confirmed RBlock, and\nthe RBlock's deadline has passed, and\nthere is at least one bonder, and\nAll bonders are bonded to the RBlock.\n\nThe first unresolved RBlock can be rejected if:\n\nthe RBlock's predecessor has been rejected, or\nall of the following are true:\nthe RBlock's deadline has passed, and\nthere is at least one bonder, and\nno bonder is bonded on the RBlock.\n\nA consequence of these rules is that once the first unresolved RBlock's deadline has passed (and assuming there is at least one bonder bonded on something other than the latest confirmed RBlock), the only way the RBlock can be unresolvable is if at least one bonder is bonded on it and at least one bonder is bonded on a different RBlock with the same predecessor. If this happens, the two bonders are disagreeing about which RBlock is correct. It’s time for a challenge, to resolve the disagreement.\n\nChallenges​\n\nSuppose the rollup chain looks like this:\n\nRBlocks 93 and 95 are siblings (they both have 92 as predecessor). Alice is bonded on 93 and Bob is bonded on 95.\n\nAt this point we know that Alice and Bob disagree about the correctness of RBlock 93, with Alice committed to 93 being correct and Bob committed to 93 being incorrect. (Bob is bonded on 95, and 95 implicitly claims that 92 is the last correct RBlock before it, which implies that 93 must be incorrect.)\n\nWhenever two bonders are bonded on sibling RBlocks, and neither of those bonders is already in a challenge, anyone can start a challenge between the two. The rollup protocol will record the challenge and referee it, eventually declaring a winner and confiscating the loser’s bond. The loser will be removed as a bonder.\n\nThe challenge is a game in which Alice and Bob alternate moves, with an Ethereum contract as the referee. Alice, the defender, moves first.\n\nThe game will operate in two phases: dissection, followed by one-step proof. Dissection will narrow down the size of the dispute until it is a dispute about just one instruction of execution. Then the one-step proof will determine who is right about that one instruction.\n\nWe’ll describe the dissection part of the protocol twice. First, we’ll give a simplified version which is easier to understand but less efficient. Then we’ll describe how the real version differs from the simplified one.\n\nDissection Protocol: Simplified Version​\n\nAlice is defending the claim that starting with the state in the predecessor RBlock, the state of the Virtual Machine can advance to the state specified in RBlock A. Essentially she is claiming that the Virtual Machine can execute N instructions, and that that execution will consume M inbox messages and transform the hash of outputs from H’ to H.\n\nAlice’s first move requires her to dissect her claims about intermediate states between the beginning (0 instructions executed) and the end (N instructions executed). So we require Alice to divide her claim in half, and post the state at the half-way point, after N/2 instructions have been executed.\n\nNow Alice has effectively bisected her N-step assertion into two (N/2)-step assertions. Bob has to point to one of those two half-size assertions and claim it is wrong.\n\nAt this point we’re effectively back in the original situation: Alice having made an assertion that Bob disagrees with. But we have cut the size of the assertion in half, from N to N/2. We can apply the same method again, with Alice bisecting and Bob choosing one of the halves, to reduce the size to N/4. And we can continue bisecting, so that after a logarithmic number of rounds Alice and Bob will be disagreeing about a single step of execution. That’s where the dissection phase of the protocol ends, and Alice must make a one-step proof which will be checked by the EthBridge.\n\nWhy Dissection Correctly Identifies a Cheater​\n\nBefore talking about the complexities of the real challenge protocol, let’s stop to understand why the simplified version of the protocol is correct. Here correctness means two things: (1) if Alice’s initial claim is correct, Alice can always win the challenge, and (2) if Alice’s initial claim is incorrect, Bob can always win the challenge.\n\nTo prove (1), observe that if Alice’s initial claim is correct, she can offer a truthful midpoint claim, and both of the implied half-size claims will be correct. So whichever half Bob objects to, Alice will again be in the position of defending a correct claim. At each stage of the protocol, Alice will be defending a correct claim. At the end, Alice will have a correct one-step claim to prove, so that claim will be provable and Alice can win the challenge.\n\nTo prove (2), observe that if Alice’s initial claim is incorrect, this can only be because her claimed endpoint after N steps is incorrect. Now when Alice offers her midpoint state claim, that midpoint claim is either correct or incorrect. If it’s incorrect, then Bob can challenge Alice’s first-half claim, which will be incorrect. If Alice’s midpoint state claim is correct, then her second-half claim must be incorrect, so Bob can challenge that. So whatever Alice does, Bob will be able to challenge an incorrect half-size claim. At each stage of the protocol, Bob can identify an incorrect claim to challenge. At the end, Alice will have an incorrect one-step claim to prove, which she will be unable to do, so Bob can win the challenge.\n\n(If you’re a stickler for mathematical precision, it should be clear how these arguments can be turned into proofs by induction on N.)\n\nThe Real Dissection Protocol​\n\nThe real dissection protocol is conceptually similar to the simplified one described above, but with several changes that improve efficiency or deal with necessary corner cases. Here is a list of the differences.\n\nDissection over L2 blocks, then over instructions: Alice's assertion is over an RBlock, which asserts the result of creating some number of Layer 2 Nitro blocks. Dissection first occurs over these Layer 2 blocks, to narrow the dispute down to a dispute about a single Layer 2 Nitro block. At this point, the dispute transforms into a dispute about a single execution of the State Transition Function or in other words about the execution of a sequence of WAVM instructions. The protocol then executes the recursive dissection sub-protocol again, this time over WAVM instructions, to narrow the dispute to a single instruction. The dispute concludes with a one-step proof of a single instruction (or a party failing to act and losing by timeout).\n\nK-way dissection: Rather than dividing a claim into two segments of size N/2, we divide it into K segments of size N/K. This requires posting K-1 intermediate claims, at points evenly spaced through the claimed execution. This reduces the number of rounds by a factor of log(K)/log(2).\n\nAnswer a dissection with a dissection: Rather than having each round of the protocol require two moves, where Alice dissects and Bob chooses a segment to challenge, we instead require Bob, in challenging a segment, to post his own claimed endpoint state for that segment (which must differ from Alice’s) as well as his own dissection of his version of the segment. Alice will then respond by identifying a subsegment, posting an alternative endpoint for that segment, and dissecting it. This reduces the number of moves in the game by an additional factor of 2, because the size is cut by a factor of K for every move, rather than for every two moves.\n\nDeal With the Empty-Inbox Case: The real AVM can’t always execute N units of gas without getting stuck. The machine might halt, or it might have to wait because its inbox is exhausted so it can’t go on until more messages arrive. So Bob must be allowed to respond to Alice’s claim of N units of execution by claiming that N steps are not possible. The real protocol thus allows any response (but not the initial claim) to claim a special end state that means essentially that the specified amount of execution is not possible under the current conditions.\n\nTime Limits: Each player is given a time allowance. The total time a player uses for all of their moves must be less than the time allowance, or they lose the game. Think of the time allowance as being about a week.\n\nIt should be clear that these changes don’t affect the basic correctness of the challenge protocol. They do, however, improve its efficiency and enable it to handle all of the cases that can come up in practice.\n\nEfficiency​\n\nThe challenge protocol is designed so that the dispute can be resolved with a minimum of work required by the protocol (via its Layer 1 Ethereum contracts) in its role as referee. When it is Alice’s move, the protocol only needs to keep track of the time Alice uses, and ensure that her move does include K-1 intermediate points as required. The protocol doesn’t need to pay attention to whether those claims are correct in any way; it only needs to know whether Alice’s move “has the right shape”.\n\nThe only point where the protocol needs to evaluate a move “on the merits” is at the one-step proof, where it needs to look at Alice’s proof and determine whether the proof that was provided does indeed establish that the virtual machine moves from the before state to the claimed after state after one step of computation.\n\nValidators​\n\nSome Arbitrum nodes will choose to act as validators. This means that they watch the progress of the rollup protocol and participate in that protocol to advance the state of the chain securely.\n\nNot all nodes will choose to do this. Because the rollup protocol doesn’t decide what the chain will do but merely confirms the correct behavior that is fully determined by the inbox messages, a node can ignore the rollup protocol and simply compute for itself the correct behavior. For more on what such nodes might do, see the Full Nodes section.\n\nOffchain Labs provides open source validator software, including a pre-built Docker image.\n\nEvery validator can choose their own approach, but we expect validators to follow three common strategies:\n\nThe active validator strategy tries to advance the state of the chain by proposing new RBlocks. An active validator is always bonded, because creating an RBlock requires being bonded. A chain really only needs one honest active validator; any more is an inefficient use of resources. For the Arbitrum One chain, Offchain Labs runs an active validator.\nThe defensive validator strategy watches the rollup protocol operate. If only correct RBlocks are proposed, this strategy doesn't bond. But if an incorrect RBlock is proposed, this strategy intervenes by posting a correct RBlock or staking on a correct RBlock that another party has posted. This strategy avoids staking when things are going well, but if someone is dishonest it bonds in order to defend the correct outcome.\nThe watchtower validator strategy never bonds. It simply watches the rollup protocol and if an incorrect RBlock is proposed, it raises the alarm (by whatever means it chooses) so that others can intervene. This strategy assumes that other parties who are willing to bond will be willing to intervene in order to take some of the dishonest proposer’s bond, and that that can happen before the dishonest RBlock’s deadline expires. (In practice this will allow several days for a response.)\n\nUnder normal conditions, validators using the defensive and watchtower strategies won’t do anything except observe. A malicious actor who is considering whether to try cheating won’t be able to tell how many defensive and watchtower validators are operating incognito. Perhaps some defensive validators will announce themselves, but others probably won’t, so a would-be attacker will always have to worry that defenders are waiting to emerge.\n\nThe underlying protocol supports permissionless validation, i.e.,--anyone can do it. Currently on Arbitrum One, validators that require bond (i.e., active and defensive validators) are whitelisted; see \"State of Progressive Decentralization\".\n\nWho will be validators? Anyone will be able to do it, but most people will choose not to. In practice we expect people to validate a chain for several reasons.\n\nValidators could be paid for their work, by the party that created the chain or someone else. A chain could be configured such that a portion of the funds from user transaction fees are paid directly to validators.\nParties who have significant assets at bond on a chain, such as dapp developers, exchanges, power-users, and liquidity providers, may choose to validate in order to protect their investment.\nAnyone who chooses to validate can do so. Some users will probably choose to validate in order to protect their own interests or just to be good citizens. But ordinary users don’t need to validate, and we expect that the vast majority of users won’t.\nArbOS​\n\nArbOS is a trusted \"system glue\" component that runs at Layer 2 as part of the State Transition Function. ArbOS provides functions needed for a Layer 2 system, such as cross-chain communication, resource accounting and Layer 2 related fee economics, and chain management.\n\nWhy ArbOS?​\n\nIn Arbitrum, much of the work that would otherwise have to be done expensively at Layer 1 is instead done by ArbOS, trustlessly performing these functions at the speed and low cost of Layer 2.\n\nSupporting these functions in Layer 2 trusted software, rather than building them in to the L1-enforced rules of the architecture as Ethereum does, offers significant advantages in cost because these operations can benefit from the lower cost of computation and storage at Layer 2, instead of having to manage those resources as part of a Layer 1 contract. Having a trusted operating system at Layer 2 also has significant advantages in flexibility, because Layer 2 code is easier to evolve, or to customize for a particular chain, than a Layer-1 enforced architecture would be.\n\nFull Nodes​\n\nAs the name suggests, full nodes in Arbitrum play the same role that full nodes play in Ethereum: they know the state of the chain and they provide an API that others can use to interact with the chain.\n\nArbitrum full nodes normally \"live at Layer 2\" which means that they don’t worry about the rollup protocol but simply treat their Arbitrum chain as a mechanism that feeds inbox messages to the State Transition Function to evolve the Layer 2 chain and produce outputs.\n\nThe Sequencer​\n\nThe Sequencer is a specially designated full node, which is given limited power to control the ordering of transactions. This allows the Sequencer to guarantee the results of user transactions immediately, without needing to wait for anything to happen on Ethereum. So no need to wait five minutes or so for block confirmations--and no need to even wait 15 seconds for Ethereum to make a block.\n\nClients interact with the Sequencer in exactly the same way they would interact with any full node, for example by giving their wallet software a network URL that happens to point to the Sequencer.\n\nCurrently, on the Arbitrum One and Arbitrum Nova chains, the Sequencer is run by Offchain Labs.\n\nInstant confirmation​\n\nWithout a Sequencer, a node can predict what the results of a client transaction will be, but the node can't be sure, because it can't know or control how the transactions it submits will be ordered in the inbox, relative to transactions submitted by other nodes.\n\nThe Sequencer is given more control over ordering, so it has the power to assign its clients' transactions a position in the inbox queue, thereby ensuring that it can determine the results of client transactions immediately. The Sequencer's power to reorder has limits (see below for details) but it does have more power than anyone else to influence transaction ordering.\n\nInboxes, fast and slow​\n\nWhen we add a Sequencer, the operation of the inbox changes.\n\nOnly the Sequencer can put new messages directly into the inbox. The Sequencer tags the messages it is submitting with an Ethereum block number and timestamp. (ArbOS ensures that these are non-decreasing, adjusting them upward if necessary to avoid decreases.)\nAnyone else can submit a message, but messages submitted by non-Sequencer nodes will be put into the \"delayed inbox\" queue, which is managed by an L1 Ethereum contract.\nMessages in the delayed inbox queue will wait there until the Sequencer chooses to \"release\" them into the main inbox, where they will be added to the end of the inbox. A well-behaved Sequencer will typically release delayed messages after about ten minutes, for reasons explained below.\nAlternatively, if a message has been in the delayed inbox queue for longer than a maximum delay interval (currently 24 hours on Arbitrum One) then anyone can force it to be promoted into the main inbox. (This ensures that the Sequencer can only delay messages but can't censor them.)\nIf the Sequencer is well-behaved...​\n\nA well-behaved Sequencer will accept transactions from all requesters and treat them fairly, giving each one a promised transaction result as quickly as it can.\n\nIt will also minimize the delay it imposes on non-Sequencer transactions by releasing delayed messages promptly, consistent with the goal of providing strong promises of transaction results. Specifically, if the Sequencer believes that 40 confirmation blocks are needed to have good confidence of finality on Ethereum, then it will release delayed messages after 40 blocks. This is enough to ensure that the Sequencer knows exactly which transactions will precede its current transaction, because those preceding transactions have finality. There is no need for a benign Sequencer to delay non-Sequencer messages more than that, so it won't.\n\nThis does mean that transactions that go through the delayed inbox will take longer to get finality. Their time to finality will roughly double, because they will have to wait one finality period for promotion, then another finality period for the Ethereum transaction that promoted them to achieve finality.\n\nThis is the basic tradeoff of having a Sequencer: if your message uses the Sequencer, finality is C blocks faster; but if your message doesn't use the Sequencer, finality is C blocks slower. This is usually a good tradeoff, because most transactions will use the Sequencer; and because the practical difference between instant and 10-minute finality is bigger than the difference between 10-minute and 20-minute finality.\n\nSo a Sequencer is generally a win, if the Sequencer is well behaved.\n\nIf the Sequencer is malicious...​\n\nA malicious Sequencer, on the other hand, could cause some pain. If it refuses to handle your transactions, you're forced to go through the delayed inbox, with longer delay. And a malicious Sequencer has great power to front-run everyone's transactions, so it could profit greatly at users' expense.\n\nOn Arbitrum One, Offchain Labs currently runs a Sequencer which is well-behaved--we promise!. This will be useful but it's not decentralized. Over time, we'll switch to decentralized, fair sequencing, as described below.\n\nBecause the Sequencer will be run by a trusted party at first, and will be decentralized later, we haven't built in a mechanism to directly punish a misbehaving Sequencer. We're asking users to trust the centralized Sequencer at first, until we switch to decentralized fair sequencing later.\n\nDecentralized fair sequencing​\n\nViewed from 30,000 feet, decentralized fair sequencing isn't too complicated. Instead of being a single centralized server, the Sequencer is a committee of servers, and as long as a large enough supermajority of the committee is honest, the Sequencer will establish a fair ordering over transactions.\n\nHow to achieve this is more complicated. Research by a team at Cornell Tech, including Offchain Labs CEO and Co-founder Steven Goldfeder, developed the first-ever decentralized fair sequencing algorithm. With some improvements that are under development, these concepts will form the basis for our longer-term solution, of a fair decentralized Sequencer.\n\nBridging​\n\nWe have already covered how users interact with L2 contracts--they submit transactions by putting messages into the chain’s inbox, or having a full node Sequencer or aggregator do so on their behalf. Let’s talk about how contracts interact between L1 and L2--how an L1 contract calls an L2 contract, and vice versa.\n\nThe L1 and L2 chains run asynchronously from each other, so it is not possible to make a cross-chain call that produces a result within the same transaction as the caller. Instead, cross-chain calls must be asynchronous, meaning that the caller submits the call at some point in time, and the call runs later. As a consequence, a cross-chain contract-to-contract call can never produce a result that is available to the calling contract (except for acknowledgement that the call was successfully submitted for later execution).\n\nL1 contracts can submit L2 transactions​\n\nAn L1 contract can submit an L2 transaction, just like a user would, by calling the Nitro chain's inbox contract on Ethereum. This L2 transaction will run later, producing results that will not be available to the L1 caller. The transaction will execute at L2, but the L1 caller won’t be able to see any results from the L2 transaction.\n\nThe advantage of this method is that it is simple and has relatively low latency. The disadvantage, compared to the other method we’ll describe soon, is that the L2 transaction might revert if the L1 caller doesn’t get the L2 gas price and max gas amount right. Because the L1 caller can’t see the result of its L2 transaction, it can’t be absolutely sure that its L2 transaction will succeed.\n\nThis would introduce a serious a problem for certain types of L1 to L2 interactions. Consider a transaction that includes depositing a token on L1 to be made available at some address on L2. If the L1 side succeeds, but the L2 side reverts, you've just sent some tokens to the L1 inbox contract that are unrecoverable on either L2 or L1. Not good.\n\nL1 to L2 ticket-based transactions​\n\nFortunately, we have another method for L1 to L2 calls, which is more robust against gas-related failures, that uses a ticket-based system. The idea is that an L1 contract can submit a “retryable” transaction. The Nitro chain will try to run that transaction. If the transaction succeeds, nothing else needs to happen. But if the transaction fails, Nitro will create a “ticketID” that identifies that failed transaction. Later, anyone can call a special pre-compiled contract at L2, providing the ticketID, to try redeeming the ticket and re-executing the transaction.\n\nWhen saving a transaction for retry, Nitro records the sender’s address, destination address, callvalue, and calldata. All of this is saved, and the callvalue is deducted from the sender’s account and (logically) attached to the saved transaction.\n\nIf the redemption succeeds, the transaction is done, a receipt is issued for it, and the ticketID is canceled and can’t be used again. If the redemption fails, for example because the packaged transaction fails, the redemption reports failure and the ticketID remains available for redemption.\n\nNormally the original submitter will try to cause their transaction to succeed immediately, so it never needs to be recorded or retried. As an example, our \"token deposit\" use case above should, in the happy, common case, still only require a single signature from the user. If this initial execution fails, the ticketID will still exist as a backstop which others can redeem later.\n\nSubmitting a transaction in this way carries a price in ETH which the submitter must pay, which varies based on the calldata size of the transaction. Once submitted, the ticket is valid for about a week. If the ticket has not been redeemed in that period, it is deleted.\n\nWhen the ticket is redeemed, the pre-packaged transaction runs with sender and origin equal to the original submitter, and with the destination, callvalue, and calldata the submitter provided at the time of submission.\n\nThis mechanism is a bit more cumbersome than ordinary L1 to L2 transactions, but it has the advantage that the submission cost is predictable and the ticket will always be available for redemption if the submission cost is paid. As long as there is some user who is willing to redeem the ticket, the L2 transaction will eventually be able to execute and will not be silently dropped.\n\nL2 to L1 ticket-based calls​\n\nCalls from L2 to L1 operate in a similar way, with a ticket-based system. An L2 contract can call a method of the precompiled ArbSys contract, to send a transaction to L1. When the execution of the L2 transaction containing the submission is confirmed at L1 (some days later), a ticket is created in the L1 outbox contract. That ticket can be triggered by anyone who calls a certain L1 outbox method and submits the ticketID. The ticket is only marked as redeemed if the L1 transaction does not revert.\n\nThese L2-to-L1 tickets have unlimited lifetime, until they’re successfully redeemed. No rent is required, as the tickets (actually a Merkle hash of the tickets) are recorded in Ethereum storage, which does not require rent. (The cost of allocating storage for the ticket Merkle roots is covered by L2 transaction fees.)\n\nGas and Fees​\n\nNitroGas (so-called to avoid confusion with Layer 1 Ethereum gas) is used by Arbitrum to track the cost of execution on a Nitro chain. It works the same as Ethereum gas, in the sense that every EVM instruction costs the same amount of gas that it would on Ethereum.\n\nThe Speed Limit​\n\nThe security of Nitro chains depends on the assumption that when one validator creates an RBlock, other validators will check it, and respond with a correct RBlock and a challenge if it is wrong. This requires that the other validators have the time and resources to check each RBlock quickly enough to issue a timely challenge. The Arbitrum protocol takes this into account in setting deadlines for RBlocks.\n\nThis sets an effective speed limit on execution of a Nitro chain: in the long run the chain cannot make progress faster than a validator can emulate its execution. If RBlocks are published at a rate faster than the speed limit, their deadlines will get farther and farther in the future. Due to the limit, enforced by the rollup protocol contracts, on how far in the future a deadline can be, this will eventually cause new RBlocks to be slowed down, thereby enforcing the effective speed limit.\n\nBeing able to set the speed limit accurately depends on being able to estimate the time required to validate an RBlock, with some accuracy. Any uncertainty in estimating validation time will force us to set the speed limit lower, to be safe. And we do not want to set the speed limit lower, so we try to enable accurate estimation.\n\nFees​\n\nUser transactions pay fees, to cover the cost of operating the chain. These fees are assessed and collected by ArbOS at L2. They are denominated in ETH.\n\nFees are charged for two resources that a transaction can use:\n\nL2 gas: an Ethereum-equivalent amount of gas, as required to execute the transaction on the Nitro chain,\nL1 calldata: a fee per unit of L1 calldata attributable to the transaction, which is charged only if the transaction came in via the Sequencer, and is paid to the Sequencer to cover its costs,\nL2 gas fees​\n\nL2 gas fees work very similarly to gas on Ethereum. A transaction uses some amount of gas, and this is multiplied by the current basefee to get the L2 gas fee charged to the transaction.\n\nThe L2 basefee is set by a version of the \"exponential mechanism\" which has been widely discussed in the Ethereum community, and which has been shown equivalent to Ethereum's EIP-1559 gas pricing mechanism.\n\nThe algorithm compares gas usage against a parameter called the \"speed limit\" which is the target amount of gas per second that the chain can handle sustainably over time. (Currently the speed limit on Arbitrum One is 7,000,000 gas per second.) The algorithm tracks a gas backlog. Whenever a transaction consumes gas, that gas is added to the backlog. Whenever the clock ticks one second, the speed limit is subtracted from the backlog; but the backlog can never go below zero.\n\nIntuitively, if the backlog grows, the algorithm should increase the gas price, to slow gas usage, because usage is above the sustainable level. If the backlog shrinks, the price should decrease again because usage has been below the below the sustainable limit so more gas usage can be welcomed.\n\nTo make this more precise, the basefee is an exponential function of the backlog, F = exp(-a(B-b)), where a and b are suitably chosen constants: a controls how rapidly the price escalates with backlog, and b allows a small backlog before the basefee escalation begins.\n\nL1 calldata fees​\n\nL1 calldata fees exist because the Sequencer, or the batch poster which posts the Sequencer's transaction batches on Ethereum, incurs costs in L1 gas to post transactions on Ethereum as calldata. Funds collected in L1 calldata fees are credited to the batch poster to cover its costs.\n\nEvery transaction that comes in through the Sequencer will pay an L1 calldata fee. Transactions that come in through the delayed inbox do not pay this fee because they don't add to batch posting costs--but these transactions pay gas fees to Ethereum when they are put into the delayed inbox.\n\nThe L1 pricing algorithm assigns an L1 calldata fee to each Sequencer transaction. First, it computes the transaction's size, which is an estimate of how many bytes the transaction will add to the compressed batch it is in; the formula for this includes an estimate of how compressible the transaction is. Second, it multiplies the computed size estimate by the current price per estimated byte, to determine the transaction's L1 calldata wei, in wei. Finally, it divides this cost by the current L2 basefee to translate the fee into L2 gas units. The result is reported as the \"poster fee\" for the transaction.\n\nThe price per estimated byte is set by a dynamic algorithm that compares the total L1 calldata fees collected to the total fees actually paid by batch posters, and tries to bring the two as close to equality as possible. If the batch posters' costs have been less than fee receipts, the price will increase, and if batch poster costs have exceeded fee receipts, the price will decrease.\n\nTotal fee and gas estimation​\n\nThe total fee charged to a transaction is the L2 basefee, multiplied by the sum of the L2 gas used plus the L1 calldata charge. As on Ethereum, a transaction will fail if it fails to supply enough gas, or if it specifies a basefee limit that is below the current basefee. Ethereum also allows a \"tip\" but Nitro ignores this field and never collects any tips.\n\nInside AnyTrust​\n\nAnyTrust is a variant of Arbitrum Nitro technology that lowers costs by accepting a mild trust assumption.\n\nThe Arbitrum protocol requires that all Arbitrum nodes, including validators (nodes that verify correctness of the chain and are prepared to bond on correct results), have access to the data of every L2 transaction in the Arbitrum chain's inbox. An Arbitrum rollup provides data access by posting the data (in batched, compressed form) on L1 Ethereum as calldata. The Ethereum gas to pay for this is the largest component of cost in Arbitrum.\n\nAnyTrust relies instead on an external Data Availability Committee (hereafter, \"the Committee\") to store data and provide it on demand. The Committee has N members, of which AnyTrust assumes at least two are honest. This means that if N - 1 Committee members promise to provide access to some data, at least one of the promising parties must be honest. Since there are two honest members, and only one failed to make the promise, it follows that at least one of the promisers must be honest — and that honest member will provide data when it is needed to ensure the chain can properly function.\n\nKeysets​\n\nA Keyset specifies the public keys of Committee members and the number of signatures required for a Data Availability Certificate to be valid. Keysets make Committee membership changes possible and provide Committee members the ability to change their keys.\n\nA Keyset contains\n\nthe number of Committee members, and\nfor each Committee member, a BLS public key, and\nthe number of Committee signatures required.\n\nKeysets are identified by their hashes.\n\nAn L1 KeysetManager contract maintains a list of currently valid Keysets. The L2 chain's Owner can add or remove Keysets from this list. When a Keyset becomes valid, the KeysetManager contract emits an L1 Ethereum event containing the Keyset's hash and full contents. This allows the contents to be recovered later by anyone, given only the Keyset hash.\n\nAlthough the API does not limit the number of Keysets that can be valid at the same time, normally only one Keyset will be valid.\n\nData Availability Certificates​\n\nA central concept in AnyTrust is the Data Availability Certificate (hereafter, a \"DACert\"). A DACert contains:\n\nthe hash of a data block, and\nan expiration time, and\nproof that N-1 Committee members have signed the (hash, expiration time) pair, consisting of\nthe hash of the Keyset used in signing, and\na bitmap saying which Committee members signed, and\na BLS aggregated signature (over the BLS12-381 curve) proving that those parties signed.\n\nBecause of the 2-of-N trust assumption, a DACert constitutes proof that the block's data (i.e., the preimage of the hash in the DACert) will be available from at least one honest Committee member, at least until the expiration time.\n\nIn ordinary (non-AnyTrust) Nitro, the Arbitrum sequencer posts data blocks on the L1 chain as calldata. The hashes of the data blocks are committed by the L1 Inbox contract, allowing the data to be reliably read by L2 code.\n\nAnyTrust gives the sequencer two ways to post a data block on L1: it can post the full data as above, or it can post a DACert proving availability of the data. The L1 inbox contract will reject any DACert that uses an invalid Keyset; the other aspects of DACert validity are checked by L2 code.\n\nThe L2 code that reads data from the inbox reads a full-data block as in ordinary Nitro. If it sees a DACert instead, it checks the validity of the DACert, with reference to the Keyset specified by the DACert (which is known to be valid because the L1 Inbox verified that). The L2 code verifies that\n\nthe number of signers is at least the number required by the Keyset, and\nthe aggregated signature is valid for the claimed signers, and\nthe expiration time is at least two weeks after the current L2 timestamp.\n\nIf the DACert is invalid, the L2 code discards the DACert and moves on to the next data block. If the DACert is valid, the L2 code reads the data block, which is guaranteed to be available because the DACert is valid.\n\nData Availability Servers​\n\nCommittee members run Data Availability Server (DAS) software. The DAS exposes two APIs:\n\nThe Sequencer API, which is meant to be called only by the Arbitrum chain's Sequencer, is a JSON-RPC interface allowing the Sequencer to submit data blocks to the DAS for storage. Deployments will typically block access to this API from callers other than the Sequencer.\nThe REST API, which is meant to be available to the world, is a RESTful HTTP(S) based protocol that allows data blocks to be fetched by hash. This API is fully cacheable, and deployments may use a caching proxy or CDN to increase scale and protect against DoS attacks.\n\nOnly Committee members have reason to support the Sequencer API. We expect others to run the REST API, and that is helpful. (More on that below.)\n\nThe DAS software, based on configuration options, can store its data in local files, or in a Badger database, or on Amazon S3, or redundantly across multiple backing stores. The software also supports optional caching in memory (using Bigcache) or in a Redis instance.\n\nSequencer-Committee Interaction​\n\nWhen the Arbitrum sequencer produces a data batch that it wants to post using the Committee, it sends the batch's data, along with an expiration time (normally three weeks in the future) via RPC to all Committee members in parallel. Each Committee member stores the data in its backing store, indexed by the data's hash. Then the member signs the (hash, expiration time) pair using its BLS key, and returns the signature with a success indicator to the sequencer.\n\nOnce the Sequencer has collected enough signatures, it can aggregate the signatures and create a valid DACert for the (hash, expiration time) pair. The Sequencer then posts that DACert to the L1 inbox contract, making it available to the AnyTrust chain software at L2.\n\nIf the Sequencer fails to collect enough signatures within a few minutes, it will abandon the attempt to use the Committee, and will \"fall back to rollup\" by posting the full data directly to the L1 chain, as it would do in a non-AnyTrust chain. The L2 software can understand both data posting formats (via DACert or via full data) and will handle each one correctly.\n\nEdit this page\nLast updated on Nov 20, 2024\nPrevious\nL1 pricing\nNext\nAssertion tree\nWhy use Arbitrum? Why use Nitro?\nThe Big Picture\nNitro's Design: The Four Big Ideas\nSequencing, Followed by Deterministic Execution\nHow the Sequencer Publishes the Sequence\nGeth at the Core\nSeparating Execution from Proving\nOptimistic Rollup\nResolving disputes using interactive fraud proofs\nInteractive proving\nRe-executing transactions\nWhy interactive proving is better\nInteractive proving drives the design of Arbitrum\nArbitrum Rollup Protocol\nThe Rollup Chain\nStaking\nRules for Confirming or Rejecting RBlocks\nChallenges\nDissection Protocol: Simplified Version\nWhy Dissection Correctly Identifies a Cheater\nThe Real Dissection Protocol\nEfficiency\nValidators\nArbOS\nWhy ArbOS?\nFull Nodes\nThe Sequencer\nInstant confirmation\nInboxes, fast and slow\nIf the Sequencer is well-behaved...\nIf the Sequencer is malicious...\nDecentralized fair sequencing\nBridging\nL1 contracts can submit L2 transactions\nL1 to L2 ticket-based transactions\nL2 to L1 ticket-based calls\nGas and Fees\nThe Speed Limit\nFees\nInside AnyTrust\nKeysets\nData Availability Certificates\nData Availability Servers\nSequencer-Committee Interaction\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/oracles/oracles-content-map",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nAPI3\nChainlink\nChronicle\nORA\nHow to use Supra price feed oracle\nHow to use Supra VRF\nTrellor\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nOracles providers\n\nLearn how to run an Arbitrum node.\n\nAPI3\n\nLearn out to use API3\n\nChainlink\n\nLearn out to use Chainlink\n\nChronicle\n\nLearn out to use Chronicle\n\nOra\n\nLearn out to use Ora\n\nSupra price feed\n\nQuerying price feeds with Supra\n\nSupra VRF\n\nUsing Supra VRF\n\nTrellor\n\nLearn out to use Trellor\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nContribute docs\nNext\nAPI3\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Overview: The Lifecycle of an Arbitrum Transaction | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/tx-lifecycle",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nTransaction lifecycle\nSequencer\nAnyTrust protocol\nGas / fees\nAdvanced concepts\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nOverview: The Lifecycle of an Arbitrum Transaction\n\nAs an introduction to the various components that compose the Arbitrum protocol, we'll go step-by-step over the phases an Arbitrum transaction goes through, starting with a client creating a signed transaction, to it ultimately being confirmed back on layer 1.\n\nWe'll also intersperse it with \"finality checks,\" explaining what guarantees the client has over their transaction's finality (i.e., assurances that their transaction's result is guaranteed and won't later be altered) over the course of a transaction's various stages.\n\nThis overview will be focused on the Arbitrum Rollup protocol; see Inside AnyTrust for differences in the Arbitrum AnyTrust protocol. Also, for convenience/simplicity, we'll be describing the security properties of the core system itself; see \"State of Progressive Decentralization\" for current decentralization status.\n\nFor clarity on any terminology that may be unfamiliar, see our glossary.\n\n1. Sequencer receives transaction​\n\nTypically, a transaction's lifecycle starts with the Sequencer, the entity designated with transaction ordering, receiving a transaction from a client. The Sequencer can receive a transaction one of two ways:\n\n1a. Directly / Offchain​\n\nFor typical transacting within the L2 environment (i.e., using an L2 native dapp), a client will connect their wallet to an L2 node and directly deliver a signed transaction.\n\n1b. ... or from L1 (via the Delayed Inbox).​\n\nAlternatively, a client can send a message to the Sequencer by signing and publishing an L1 transaction in the Arbitrum chain's Delayed Inbox. This functionality is most commonly used for depositing ETH or tokens via a bridge.\n\nSee:\n\nRetryables\nThe Sequencer\nToken Bridge\n2. Sequencer orders transaction (off-chain)​\n\nUpon receiving a transaction, the Sequencer will:\n\nOrder it in its off-chain Inbox\nLocally execute it using the Arbitrum Nitro VM (including collecting/allocating L1 and L2 fees, etc.)\n\"Instantly\" give a transaction receipt to the client (\"instant\" in that it doesn't require any additional on-chain confirmations, and typically takes less than a second - with the average user experiencing ~260ms).\n\nSee:\n\nArbOS\nGeth\nL1 pricing / L2 Gas\n~ ~ ~ FINALITY CHECK: Trusted / Soft Confirmation ~ ~ ~​\n\nAt this phase, the client's acceptance of finality relies on trusting the Sequencer. I.e., a malicious/faulty Sequencer could deviate between what it promised in the transaction receipt and what is ultimately published in a batch (see phase 3).\n\nNOTE\n\nEven a malicious/faulty Sequencer can only, at worst, reorder or temporarily delay transactions; it cannot, e.g., forge a client's transaction or propose an invalid state update. Given the degree of trust in the Sequencer at phase 2, we sometimes refer to the \"instant\" receipt that the Sequencer provides as a \"soft confirmation.\"\n\n3. Sequencer posts transaction in a batch (on-chain)​\n\nThe Sequencer will eventually post a batch of L2 transactions which includes our client's transaction onto the underlying L1 (as calldata); under normal conditions, the Sequencer will post batches every few minutes.\n\n3a. What if the Sequencer never includes our transaction?​\n\nEven if the Sequencer never includes our transaction in a batch, the client can include it in the L2 by posting in the delayed inbox and then \"force including\" it after some delay period (currently ~ 24 hours on Arbitrum One).\n\nNOTE\n\nThe Sequencer is forced to include messages from the delayed Inbox in the queued order that they appear on chain, i.e. it processes messages using the \"first in, first out\" method. Thus, it can't selectively delay particular messages while including others; i.e., delaying the message at the front of the queue means delaying all messages behind it as well.\n\nSee:\n\n\"The Sequencer / Censorship Resistance.\"\n~ ~ ~ FINALITY CHECK: Ethereum-Equivalent Finality! ~ ~ ~​\n\nAt this stage, assuming that a client believes there to be at least one well behaved active Arbitrum validator. Currently, the process of validation on the Arbitrum protocol is permissioned, but it's important to be aware that our latest dispute protocol, BoLD (Bounded Liquidity Delay), has the potential to allow validation on Arbitrum chains without requiring permission, thereby potentially eliminating the necessity for restricted validation. The client can treat their transaction's finality as equivalent to an ordinary Ethereum transaction. In other words, their L2 transaction has the same finality as the L1 transaction that recorded it in a batch. This means the client should use whatever finality heuristic they use for regular Ethereum transactions (i.e., waiting on L1 block confirmations, etc.), applied to the L1 batch-posting transaction. This also means that a client uncomfortable with the trust model of the Sequencer's soft confirmations (phase 2) can simply wait for the Sequencer to post their transaction in a batch (phase 3).\n\nHow are we able to make such bold a claim? A few (related) things:\n\nOnce the Sequencer posts a batch, its transactions' ordering is entirely determined by the L1; the Sequencer effectively has no more say in our transaction's lifecycle at all.\nThe Inbox contract on L1 ensures that when the Sequencer posts a batch, it posts data sufficient for any Arbitrum Node to reconstruct and validate the state of the L2 chain; i.e., the availability of this \"input\" data is guaranteed by Ethereum itself.\nExecution on Arbitrum is fully deterministic; i.e., a current chain state along with new input data is sufficient to compute the new chain state; thus, the moment this input data is available (i.e., when the Sequencer posts a batch), the L2 chain's state can be computed.\nArbitrum's fault-proof system is sound; i.e., if any validator (later) tries to deviate from the valid L2 state, an honest validator will ultimately be able to challenge this and win. Since we already know that valid state will ultimately win out, we can treat our transaction as L1-finalized now.\n4. Validator asserts RBlock that includes transaction​\n\nA staked, active validator will then run the Arbitrum VM over the inputs in the Inbox (just like the Sequencer did earlier, except now only over transactions posted on L1) and make an on-chain assertion about the chain's latest state, i.e., a rollup block or \"RBlock.\" RBlocks typically get asserted every 30-60 minutes.\n\nSee:\n\nArbOS\nGeth\nL1 pricing / L2 Gas\nNOTE\n\nRBlock assertions include claims about the state of the Outbox; if our transaction triggered any L2 to L1 messages, a RBlock will include an update to the Outbox to reflect its inclusion.\n\nSee:\n\nThe Outbox\n4a. RBlock is valid / goes unchallenged​\n\nIn the happy / common case, the validator asserted a valid RBlock, and over the course of the dispute window — 1 week on Arbitrum One — no other validators challenge it.\n\n4b. Assertion is challenged!​\n\nIf two validators assert different RBlocks, only (at most) one of them can be valid, so they are put into a dispute.\n\nA dispute consists of two staked validators dissecting their disagreement down to a single L2 block, and then dissecting the sequence of VM instructions within this block down to a single OPCODE, then finally, executing this single operation. The underlying VM the Arbitrum uses is WebAssembly (Wasm), or, more precisely, \"WAVM.\" This is all refereed by contracts on L1.\n\nSee:\n\nChallenges\nWasm/WAVM\n\nL1 contracts also keep track of the tree of all assertions; i.e., how many stakers are in disagreement, who is currently disputing with whom, etc. We refer to this level of Arbitrum's design architecture as its \"assertion tree protocol.\"\n\nSee:\n\nAssertion Tree Protocol\n~ ~ ~ FINALITY CHECK: STILL THE SAME Ethereum-Equivalent Finality! ~ ~ ~​\n\nRemember in phase 3 when said that once the L1 has committed to inputs, we can guarantee the L2 output? We meant it! Even during a dispute, Arbitrum nodes continue to execute and active validators continue to make assertions on the valid leaf in the state-tree; nothing that can happen in phase 4 has any effect on the L1-level finality we've already locked in at phase 3.\n\n5. RBlock is confirmed on L1​\n\nOnce any and all disputes have been resolved and sufficient time has passed, our RBlock can be confirmed on L1 (any Ethereum account on L1 can confirm it). Upon confirmation, the Outbox root on L1 gets updated.\n\n~ ~ ~ FINALITY CHECK: L2-to-L1 Messages Executable on L1 ~ ~ ~​\n\nIf our client's transaction didn't include any L2-to-L1 messages (e.g., withdrawals), phase 5 has no material effect on their transaction. If it did include an L2-to-L1 transaction, it is only after confirmation that the message can be executed in the Outbox on L1.\n\nNOTE\n\nEven before phase 5, the client has L1 finality on the result of their L2-to-L1 message, they just can't execute it yet; i.e., they have a guarantee that they'll eventually be able to, e.g., finalize their withdrawal, they just can't claim their funds on L1 until the RBlock is confirmed.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nTroubleshooting\nNext\nSequencer\n1. Sequencer receives transaction\n2. Sequencer orders transaction (off-chain)\n3. Sequencer posts transaction in a batch (on-chain)\n4. Validator asserts RBlock that includes transaction\n5. RBlock is confirmed on L1\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Quickstart: Arbitrum bridge | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/arbitrum-bridge/quickstart",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nQuickstart\nUSDC on Arbitrum One\nTroubleshooting\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nQuickstart: Arbitrum bridge\n\nThis quickstart is for users who want to \"deposit\" ETH or any ERC-20 tokens from a parent chain to a child chain (for example, from Ethereum to Arbitrum One, or from Arbitrum One to a Layer 3 Orbit chain), or \"withdraw\" from a child chain to a parent chain, using Arbitrum's bridge.\n\nWe will go through the whole process step by step with as much detail as possible. If you feel stuck in any of the steps, don't hesitate to contact us through our Discord and we will be happy to help you complete the process.\n\nThe only prerequisite for this quickstart is to have a web3 wallet installed, e.g. Metamask. If you don't have one, visit Arbitrum's portal page to download one.\n\nDeposit ETH or ERC-20 tokens (from parent chain to child chain)​\nStep 1: Get some native currency​\n\nYou'll need the native currency of the parent chain to be able to bridge your assets from it to the destination chain. For example, if you want to bridge assets from Ethereum to Arbitrum One, you'll need ETH on Ethereum to initiate the process.\n\nThere are several ways to obtain the native currency:\n\nUsing a supported centralized exchange, which allows you to purchase ETH and withdraw it to your wallet. Most of the major centralized exchanges support direct withdrawal from your centralized exchange wallet to Arbitrum.\nUsing an on-ramp service, which allows you to purchase ETH and send it directly to your wallet.\nIf you are using a testnet, requesting funds from a faucet for Sepolia or Arbitrum Sepolia.\nStep 2: Add the preferred network to your wallet​\n\nYou'll also need to add the desired chain's RPC endpoint to your wallet. Here we provide an example for doing this using MetaMask, although the process should be similar for other wallets. You need to first click on the MetaMask extension on your browser, click the network selector dropdown on the top-left corner, and then click the Add Network button at the bottom. Click \"Add a network manually\" and then provide the information corresponding to the chain you want to send your assets to.\n\nHere we display the information of the most common Arbitrum chains, but you can find a more exhaustive list in our RPC endpoints and providers page.\n\nParameter\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia (testnet)\nNetwork name\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nRPC URL\thttps://arb1.arbitrum.io/rpc\thttps://nova.arbitrum.io/rpc\thttps://sepolia-rollup.arbitrum.io/rpc\nChain ID\t42161\t42170\t421614\nCurrency symbol\tETH\tETH\tSepoliaETH\nBlock explorer URL\thttps://arbiscan.io\thttps://nova.arbiscan.io/\thttps://sepolia.arbiscan.io\nStep 3: Initiate the deposit​\n\nTo bridge your ETH or ERC-20 tokens to a different chain, start by visiting bridge.arbitrum.io. Log in to the bridge with your wallet and make sure you are connected to the source network (from where you want to deposit your assets) at the top of the page. Then, select the destination network (where you want your assets to go), e.g., Arbitrum One or Arbitrum Nova.\n\nCAUTION\n\nNote that testnets like Arbitrum Sepolia only appear if you are connected to the appropriate parent testnet network (Ethereum Sepolia).\n\nSelect the token you want to bridge in the token drop-down menu. You can also enable/disable the token lists by clicking Manage token lists button on the bottom right corner of the drop-down menu.\n\nEnter the amount of ETH or ERC-20 tokens you want to bridge over in the From box and then press Move funds. Follow the prompts on your web3 wallet.\n\nENSURE SUFFICIENT ETH BALANCE\n\nPlease make sure you leave enough ETH on your wallet to pay for the transaction, otherwise there will be no web3 wallet popup.\n\nAfter you submit the transaction through your web3 wallet you can expect your funds to arrive on the destination chain within roughly 15-30 minutes (depending on the chain congestion).\n\nAlso make sure your wallet is set to the destination chain so you can see your funds when they arrive.\n\nWithdraw ETH or ERC-20 tokens (from child chain to parent chain)​\nTHERE'S AT LEAST A 7 DAY WITHDRAWAL PERIOD FOR ARBITRUM ONE AND NOVA NETWORKS\n\nOnce you withdraw your funds from Arbitrum One or Nova through the Arbitrum bridge, you will have to wait for at least 7 days to receive them on Ethereum mainnet. For more details, see Arbitrum Bridge: Troubleshooting.\n\nTo bridge your funds back to the parent chain, you'll need to be logged in to the Arbitrum bridge with your wallet and make sure you are connected to the source network (from where you want to withdraw assets) at the top of the page. Then, select the destination network (where you want your assets to go), e.g., Ethereum mainnet.\n\nCAUTION\n\nNote that testnets like Ethereum Sepolia only appear if you are connected to the appropriate child testnet network (Arbitrum Sepolia).\n\nSelect the token you want to bridge in the token drop-down menu. You can also enable/disable the token lists by clicking Manage token lists button on the bottom right corner of the drop-down menu. Enter the amount of ETH or ERC-20 tokens you want to bridge over in the from box and then press Move funds. Follow the prompts on your web3 wallet.\n\nENSURE SUFFICIENT ETH BALANCE\n\nPlease make sure you leave enough ETH on your wallet to pay for the transaction, otherwise there will be no web3 wallet popup.\n\nA countdown will pop up stating that you’ll get your funds in 7-8 days.\n\nYou can check the status of your withdrawal by clicking on your profile on the top right and opening the Transactions tab, and claim it there when it’s ready.\n\nOnce the countdown is done, switch to the destination network on your wallet and press the Claim button, that has now turned blue, to receive your funds!\n\nWhat's next?​\n\nThe team working on Arbitrum is always interested and looking forward to engage with its users. Why not follow us on X (Twitter) or join our community on Discord?\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nFAQ\nNext\nUSDC on Arbitrum One\nDeposit ETH or ERC-20 tokens (from parent chain to child chain)\nStep 1: Get some native currency\nStep 2: Add the preferred network to your wallet\nStep 3: Initiate the deposit\nWithdraw ETH or ERC-20 tokens (from child chain to parent chain)\nWhat's next?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum nodes overview | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/run-arbitrum-node/overview",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nOverview\nQuickstart\nRun a full node\nRun a local full chain simulation\nRun a local dev node\nL1 Ethereum RPC providers\nRun a full Orbit node\n↑\nData Availability Committees\n↑\nArbOS software releases\nMore node types\nSequencer\nBuild Nitro locally\nMigrate to Nitro from Classic\nDatabase snapshots\nTroubleshooting\nFAQ\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nArbitrum nodes overview\n\nIn order to be able to interact with or build applications on any of the Arbitrum chains, you need access to the corresponding Arbitrum node. Options are:\n\nYou can use third party node providers (see the list here) to get RPC access to fully-managed nodes\nYou can run your own Arbitrum node, especially if you want to always know the state of the Arbitrum chain\n\nHere, you can find resources that help you run different types of Arbitrum nodes:\n\nStep-by-step instructions for running different Arbitrum nodes, including full Nitro node, full Classic node, local full chain simulation, Nitro dev node, feed relay, and validator\nStep-by-step instructions for how to read the sequencer feed, build the Nitro locally and run the sequencer coordinator manager UI tool\nStep-by-step instructions for how to configure a Data Availability Committee\nTroubleshooting page\nFrequently asked questions\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nPublic preview\nNext\nQuickstart\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/build-decentralized-apps/quickstart-solidity-hardhat",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nQuickstart (Solidity)\nEstimate gas\nChains and testnets\nCross-chain messaging\nArbitrum vs Ethereum\nOracles\nPrecompiles\nNodeInterface\nToken bridging\nReference\nTroubleshooting\nArbitrum SDK\nTutorials\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nQuickstart: Build a decentralized app (Solidity)\nWANT TO USE RUST INSTEAD?\n\nHead over to the Stylus quickstart if you'd like to use Rust instead of Solidity.\n\nThis quickstart is for web developers who want to start building decentralized applications (dApps) using Arbitrum. It makes no assumptions about your prior experience with Ethereum, Arbitrum, or Solidity. Familiarity with Javascript and yarn is expected. If you're new to Ethereum, consider studying the Ethereum documentation before proceeding.\n\nWhat we're building​\n\nWe're going to build a digital cupcake vending machine using Solidity smart contracts1. Our vending machine will follow two rules:\n\nThe vending machine will distribute a cupcake to anyone who hasn't recently received one.\nThe vending machine's rules can't be changed by anyone.\n\nHere's our vending machine implemented with Javascript. To use it, enter a name in the form below and press the 'Cupcake please!' button, you should see your cupcake balance go up.\n\nFree Cupcakes\nweb2NameContract addressCupcake please!Refresh balance🧁\n\nCupcake balance:0 (no name)\n\nNote that although this vending machine appears to follow the rules, it doesn't follow them as much as we'd like. The vending machine's business logic and data are hosted by a centralized service provider. We're trusting that this service provider isn't malicious, but:\n\nOur centralized service provider can deny access to particular users.\nA malicious actor can change the rules of the vending machine at any time, for example, to give their friends extra cupcakes.\n\nCentralized third-party intermediaries represent a single point of failure that malicious actors may become incentivized to exploit. To mitigate this type of risk, we can decentralize our vending machine's business logic and data, rendering this type of exploitation infeasible.\n\nThis is Arbitrum's core value proposition to you, dear developer. Arbitrum makes it easy for you to deploy your vending machines to Ethereum's permissionless, trustless, decentralized network of nodes2 while keeping costs low for you and your users.\n\nLet's implement the \"web3\" version of the above vending machine using Arbitrum.\n\nPrerequisites​\nVS Code: The IDE we'll use to build our vending machine. See code.visualstudio.com to install.\nMetamask: The wallet we'll use to interact with our vending machine. See metamask.io to install.\nYarn: The package manager we'll use to install our dependencies. See yarnpkg.com to install.\n\nWe'll address remaining dependencies as we go.\n\nEthereum and Arbitrum in a nutshell​\nEthereum\nEthereum is a decentralized network of nodes that use Ethereum's client software (like Offchain's Prysm) to maintain a public blockchain data structure.\nThe data within Ethereum's blockchain data structure changes one transaction at a time.\nSmart contracts are small programs that execute transactions according to predefined rules. Ethereum's nodes host and execute smart contracts.\nYou can use smart contracts to build decentralized apps (dApps) that use Ethereum's network to process transactions and store data.\nDApps let users carry their data and identity between applications without having to trust centralized service providers.\nPeople who run Ethereum validator nodes3 can earn $ETH for processing and validating transactions on behalf of users and dApps.\nThese transactions can be expensive when the network is under heavy load.\nArbitrum\nArbitrum is a suite of L2 scaling solutions for dApp developers.\nArbitrum One is an L2 chain that implements the Arbitrum Rollup protocol.\nYou can use Arbitrum One to build user-friendly dApps with high throughput, low latency, and low transaction costs while inheriting Ethereum's high security standards4.\n\nLet's review our vending machine's Javascript implementation, then convert it into a Solidity smart contract, then deploy it to Arbitrum One.\n\nWe'll ask your smart contract for cupcakes using the vending machines on this page.\n\nReview our Javascript vending machine​\n\nHere's our vending machine implemented as a Javascript class:\n\nVendingMachine.js\nclass VendingMachine {\n  // state variables = internal memory of the vending machine\n  cupcakeBalances = {};\n  cupcakeDistributionTimes = {};\n\n  // Vend a cupcake to the caller\n  giveCupcakeTo(userId) {\n    if (this.cupcakeDistributionTimes[userId] === undefined) {\n      this.cupcakeBalances[userId] = 0;\n      this.cupcakeDistributionTimes[userId] = 0;\n    }\n\n    // Rule 1: The vending machine will distribute a cupcake to anyone who hasn't recently received one.\n    const fiveSeconds = 5000;\n    const userCanReceiveCupcake = this.cupcakeDistributionTimes[userId] + fiveSeconds <= Date.now();\n    if (userCanReceiveCupcake) {\n      this.cupcakeBalances[userId]++;\n      this.cupcakeDistributionTimes[userId] = Date.now();\n      console.log(`Enjoy your cupcake, ${userId}!`);\n      return true;\n    } else {\n      console.error(\n        'HTTP 429: Too Many Cupcakes (you must wait at least 5 seconds between cupcakes)',\n      );\n      return false;\n    }\n  }\n\n  getCupcakeBalanceFor(userId) {\n    return this.cupcakeBalances[userId];\n  }\n}\n\n\nThe VendingMachine class uses state variables and functions to implement predefined rules. This implementation is useful because it automates cupcake distribution, but there's a problem: it's hosted by a centralized server controlled by a third-party service provider.\n\nLet's decentralize our vending machine's business logic and data by porting the above Javascript implementation into a Solidity smart contract.\n\nConfigure your project directory​\n\nCreate a decentralized-cupcakes directory for your project and install hardhat using VS Code's integrated terminal:\n\nmkdir decentralized-cupcakes\ncd decentralized-cupcakes\nyarn init -y\nyarn add hardhat @nomicfoundation/hardhat-toolbox -D\n\n\nThis installs two packages: hardhat lets us write, test and deploy our smart contracts, and hardhat-toolbox is a bundle of popular Hardhat plugins that we'll use later.\n\nNext, run yarn hardhat init to configure Hardhat. Select Create a JavaScript project when prompted. Make sure you specify your decentralized-cupcakes directory as the project root when asked.\n\nAt this point, you should see the following items (among others) in your decentralized-cupcakes project directory:\n\nItem\tDescription\ncontracts/\tContains your smart contracts. You should see the Lock.sol contract here.\nscripts/\tContains scripts that you can use to interact with your smart contracts. You should see deploy.js here.\nhardhat.config.js\tContains the configuration settings for Hardhat.\n\nReplace the contents of hardhat.config.js with the following:\n\nhardhat.config.js\nrequire('@nomicfoundation/hardhat-toolbox');\n\n// NEVER record important private keys in your code - this is for demo purposes\nconst SEPOLIA_TESTNET_PRIVATE_KEY = '';\nconst ARBITRUM_MAINNET_TEMPORARY_PRIVATE_KEY = '';\n\n/** @type import('hardhat/config').HardhatUserConfig */\nmodule.exports = {\n  solidity: '0.8.18',\n  networks: {\n    hardhat: {\n      chainId: 1337,\n    },\n    arbitrumSepolia: {\n      url: 'https://sepolia-rollup.arbitrum.io/rpc',\n      chainId: 421614,\n      //accounts: [Sepolia_TESTNET_PRIVATE_KEY]\n    },\n    arbitrumOne: {\n      url: 'https://arb1.arbitrum.io/rpc',\n      //accounts: [ARBITRUM_MAINNET_TEMPORARY_PRIVATE_KEY]\n    },\n  },\n};\n\n\nBefore compiling the default contracts, you will need to install additional dependencies. Run yarn hardhat compile and expect it to fail for the first time — follow those instructions, then run yarn hardhat compile again until it runs successfully. You should see Compiled 1 Solidity file successfully in the terminal output. You should also see a new decentralized-cupcakes/artifacts/ directory. This directory contains the compiled smart contract.\n\nOpen scripts/deploy.js and replace its contents with the following:\n\nscripts/deploy.js\nconst hre = require('hardhat');\n\nasync function main() {\n  const vendingMachine = await hre.ethers.deployContract('VendingMachine');\n  await vendingMachine.waitForDeployment();\n  console.log(`Cupcake vending machine deployed to ${vendingMachine.target}`);\n}\n\nmain().catch((error) => {\n  console.error(error);\n  process.exit(1);\n});\n\n\nWe'll use this to deploy our smart contract in a moment. Next, delete contracts/Lock.sol and replace it with contracts/VendingMachine.sol, the smarter alternative to our Javascript implementation:\n\nVendingMachine.sol\npragma solidity ^0.8.9;\n\n// Rule 2: The vending machine's rules can't be changed by anyone.\ncontract VendingMachine {\n    // state variables = internal memory of the vending machine\n    mapping(address => uint) private _cupcakeBalances;\n    mapping(address => uint) private _cupcakeDistributionTimes;\n\n    function giveCupcakeTo(address userAddress) public returns (bool) {\n        // this code is unnecessary, but we're keeping it here so you can compare it to the JS implementation\n        if (_cupcakeDistributionTimes[userAddress] == 0) {\n            _cupcakeBalances[userAddress] = 0;\n            _cupcakeDistributionTimes[userAddress] = 0;\n        }\n\n        // Rule 1: The vending machine will distribute a cupcake to anyone who hasn't recently received one.\n        uint fiveSecondsFromLastDistribution = _cupcakeDistributionTimes[userAddress] + 5 seconds;\n        bool userCanReceiveCupcake = fiveSecondsFromLastDistribution <= block.timestamp;\n        if (userCanReceiveCupcake) {\n            _cupcakeBalances[userAddress]++;\n            _cupcakeDistributionTimes[userAddress] = block.timestamp;\n            return true;\n        } else {\n            revert(\"HTTP 429: Too Many Cupcakes (you must wait at least 5 seconds between cupcakes)\");\n        }\n    }\n\n    // Getter function for the cupcake balance of a user\n    function getCupcakeBalanceFor(address userAddress) public view returns (uint) {\n        return _cupcakeBalances[userAddress];\n    }\n}\n\n\nNote that this smart contract is written in Solidity, a language that compiles to EVM bytecode. This means that it can be deployed to any Ethereum-compatible blockchain, including Ethereum mainnet, Arbitrum One, and Arbitrum Nova.\n\nRun yarn hardhat compile again. You should see Compiled 1 Solidity file successfully in the terminal output. You should also see a new decentralized-cupcakes/artifacts/contracts/VendingMachine.sol directory.\n\nDeploy the smart contract locally​\n\nTo deploy our VendingMachine smart contract locally, we'll use two terminal windows and a wallet:\n\nWe'll use the first terminal window to run Hardhat's built-in local Ethereum node\nWe'll then configure a wallet so we can interact with our smart contract after it's deployed to (1)\nWe'll then use the second terminal window to deploy our smart contract to (1)'s node\nRun a local Ethereum network and node​\n\nRun yarn hardhat node from your decentralized-cupcakes directory to begin running a local Ethereum network powered by a single node. This will mimic Ethereum's behavior on your local machine by using Hardhat's built-in Hardhat Network.\n\nYou should see something along the lines of Started HTTP and WebSocket JSON-RPC server at http://127.0.0.1:8545/ in your terminal. You should also see a number of test accounts automatically generated for you:\n\n...\nAccount #0: 0xf39Fd6e51aad88F6F4ce6aB8827279cffFb92266 (10000 ETH)\nPrivate Key: 0xac0974bec39a17e36ba4a6b4d238ff944bacb478cbed5efcae784d7bf4f2ff80\n...\n\nNEVER SHARE YOUR PRIVATE KEYS\n\nYour Ethereum Mainnet wallet's private key is the password to all of your money. Never share it with anyone; avoid copying it to your clipboard.\n\nNote that in the context of this quickstart, \"account\" refers to a public wallet address and its associated private key5.\n\nConfigure Metamask​\n\nNext, open Metamask and create or import a wallet by following the displayed instructions. By default, Metamask will connect to Ethereum mainnet. To connect to our local \"testnet\", enable test networks for Metamask by clicking Show/hide test networks from the network selector dropdown. Then select the Localhost 8545 network:\n\nYour mainnet wallet won't have a balance on your local testnet's node, but we can import one of the test accounts into Metamask to gain access to 10,000 fake ETH. Copy the private key of one of the test accounts (it works with or without the 0x prefix, so e.g. 0xac0..f80 or ac0..f80) and import it into Metamask:\n\nYou should see a balance of 10,000 ETH. Keep your private key handy; we'll use it again in a moment.\n\nNext, click Metamask's network selector dropdown, and then click the Add Network button. Click \"Add a network manually\" and then provide the following information:\n\nNetwork Name: Arbitrum Sepolia\nNew RPC URL: https://sepolia-rollup.arbitrum.io/rpc\nChain ID: 421614\nCurrency Symbol: ASPL\n\nAs we interact with our cupcake vending machine, we'll use Metamask's network selector dropdown to determine which network our cupcake transactions are sent to. For now, we'll leave the network set to Localhost 8545.\n\nDeploy the smart contract to your local testnet​\n\nFrom another terminal instance, run yarn add --dev @nomicfoundation/hardhat-ethers ethers hardhat-deploy hardhat-deploy-ethers to install additional dependencies needed for contract deployment. Then run yarn hardhat run scripts/deploy.js --network localhost. This command will deploy your smart contract to the local testnet's node. You should see something like Cupcake vending machine deployed to 0xe7f1725E7734CE288F8367e1Bb143E90bb3F0512 in your terminal. 0xe7...512 is the address of your smart contract in your local testnet.\n\nEnsure that the Localhost network is selected within Metamask. Then copy and paste your contract address below and click Get cupcake!. You should be prompted to sign a transaction that gives you a cupcake.\n\nFree Cupcakes\nweb3-localhostMetamask wallet addressContract addressCupcake please!Refresh balance🧁\n\nCupcake balance:0 (no name)\n\nWhat's going on here?​\n\nOur first VendingMachine is labeled WEB2 because it demonstrates traditional n-tier web application architecture:\n\nThe WEB3-LOCALHOST architecture is similar to the WEB2 architecture, with one key difference: with the WEB3 version, the business logic and data live in an (emulated for now) decentralized network of nodes instead of a centralized network of servers.\n\nLet's take a closer look at the differences between our VendingMachine implementations:\n\n\tWEB2\n\n\n(the first one)\n\n\tWEB3-LOCALHOST\n\n\n(the latest one)\n\n\tWEB3-ARB-SEPOLIA\n\n\n(the next one)\n\n\tWEB3-ARB-MAINNET\n\n\n(the final one)\n\n\n\n\nData (cupcakes)\n\n\t\n\nStored only in your browser. (Usually, stored by centralized infrastructure.)\n\n\t\n\nStored on your device in an emulated Ethereum network (via smart contract).\n\n\t\n\nStored on Ethereum's decentralized test network (via smart contract).\n\n\t\n\nStored on Ethereum's decentralized mainnet network (via smart contract).\n\n\n\n\nLogic (vending)\n\n\t\n\nServed from Offchain's servers. Executed by your browser.\n\n\t\n\nStored and executed by your locally emulated Ethereum network (via smart contract).\n\n\t\n\nStored and executed by Arbitrum's decentralized test network (via smart contract).\n\n\t\n\nStored and executed by Arbitrum's decentralized mainnet network (via smart contract).\n\n\n\n\nPresentation (UI)\n\n\t\n\nServed from Offchain's servers. Rendered and executed by your browser.\n\n\nMoney\t\n\nDevs and users pay centralized service providers for server access using fiat currency.\n\n\t\n\n← same, but only for the presentation-layer concerns (code that supports frontend UI/UX).\n\n\t\n\n← same, but devs and users pay testnet $ETH to testnet validators.\n\n\t\n\n← same, but instead of testnet $ETH, they use mainnet $ETH.\n\nNext, we'll deploy our smart contract to a network of real nodes: Arbitrum's Sepolia testnet.\n\nDeploy the smart contract to the Arbitrum Sepolia testnet​\n\nWe were able to deploy to a local testnet for free because we were using Hardhat's built-in Ethereum network emulator. Arbitrum's Sepolia testnet is powered by a real network of real nodes, so we'll need to pay a small transaction fee to deploy our smart contract. This fee can be paid with the Arbitrum Sepolia testnet's token, $ASPL.\n\n$ASPL IS SHORTHAND\n\n\"$ASPL\" isn't a canonical term. It's just shorthand for \"Arbitrum Sepolia testnet $ETH\" that we use for convenience.\n\nFirst, update the hardhat.config.js file to specify the private key of the test account that you'll use to deploy your smart contract (and pay the transaction fee):\n\nhardhat.config.js\n// ...\nconst SEPOLIA_TESTNET_PRIVATE_KEY = ''; // <- this should **not** begin with \"0x\"\n// ...\naccounts: [SEPOLIA_TESTNET_PRIVATE_KEY]; // <- uncomment this line\n// ...\n\nCAUTION\n\nNote that we're adding a private key to a config file. This is not a best practice; we're doing it here for convenience. Consider using environment variables when working on a real project.\n\nNext, let's deposit some $ASPL into the wallet corresponding to the private key we added to hardhat.config.js. At the time of this quickstart's writing, the easiest way to acquire $ASPL is to bridge Sepolia $ETH from Ethereum's L1 Sepolia network to Arbitrum's L2 Sepolia network:\n\nUse an L1 Sepolia $ETH faucet like sepoliafaucet.com to acquire some testnet $ETH on L1 Sepolia.\nBridge your L1 Sepolia $ETH into Arbitrum L2 using the Arbitrum bridge.\n\nOnce you've acquired some $ASPL, you'll be able to deploy your smart contract to Arbitrum's Sepolia testnet by issuing the following command:\n\nyarn hardhat run scripts/deploy.js --network arbitrumSepolia\n\n\nThis tells hardhat to deploy the compiled smart contract through the RPC endpoint corresponding to arbitrumSepolia in hardhat.config.js. You should see the following output:\n\nCupcake vending machine deployed to 0xff825139321bd8fB8b720BfFC5b9EfDB7d6e9AB3\n\n\nCongratulations! You've just deployed business logic and data to Arbitrum Sepolia. This logic and data will be hashed and submitted within a transaction to Ethereum's L1 Sepolia network, and then it will be mirrored across all nodes in the Sepolia network6.\n\nTo view your smart contract in a blockchain explorer, visit https://sepolia.arbiscan.io/address/0x...B3, but replace the 0x...B3 part of the URL with the full address of your deployed smart contract.\n\nSelect Arbitrum Sepolia from Metamask's dropdown, paste your contract address into the VendingMachine below, and click Get cupcake!. You should be prompted to sign a transaction that gives you a cupcake.\n\nFree Cupcakes\nweb3-arb-sepoliaMetamask wallet addressContract addressCupcake please!Refresh balance🧁\n\nCupcake balance:0 (no name)\n\nDeploy the smart contract to Arbitrum One Mainnet​\n\nNow that we've verified that our smart contract works on Arbitrum's Sepolia testnet, we're ready to deploy it to Arbitrum One Mainnet. This is the same process as deploying to Arbitrum's Sepolia testnet, except that we'll need to pay a transaction fee in real $ETH instead of $ASPL.\n\nExpect to see inconsistent $ETH gas fees in this step - the Gas and fees section contains more information about how gas fees are determined for Arbitrum transactions.\n\nFirst, update the hardhat.config.js file to specify the private key of the one-time-use deployment account that you'll use to deploy your smart contract (and pay the transaction fee):\n\nhardhat.config.js\n// ...\nconst ARBITRUM_MAINNET_TEMPORARY_PRIVATE_KEY = ''; // <- this should **not** begin with \"0x\"\n// ...\naccounts: [ARBITRUM_MAINNET_TEMPORARY_PRIVATE_KEY]; // <- uncomment this line\n// ...\n\nCAUTION\n\nNote that we're adding a private key to a config file. This is not a best practice. Consider using environment variables instead.\n\nNext, deposit some $ETH into the wallet corresponding to the private key we added to hardhat.config.js. You'll then be able to deploy your smart contract to Arbitrum One Mainnet by issuing the following command:\n\nyarn hardhat run scripts/deploy.js --network arbitrumOne\n\n\nYou should see the following output:\n\nCupcake vending machine deployed to 0xff825139321bd8fB8b720BfFC5b9EfDB7d6e9AB3\n\n\nCongratulations! You've just deployed business logic and data to Ethereum's decentralized network of nodes by way of Arbitrum One2.\n\nTo view your smart contract in a blockchain explorer, visit https://arbiscan.io/address/0x...B3, but replace the 0x...B3 part of the URL with the full address of your deployed smart contract.\n\nSelect Arbitrum One from Metamask's dropdown, paste your contract address into the VendingMachine below, and click Get cupcake!. You should be prompted to sign a transaction that gives you an immutable cupcake.\n\nFree Cupcakes\nweb3-arb-oneMetamask wallet addressContract addressCupcake please!Refresh balance🧁\n\nCupcake balance:0 (no name)\n\nSummary​\n\nIn this quickstart, we:\n\nIdentified two business rules: 1) fair and permissionless cupcake distribution, 2) immutable business logic and data.\nIdentified a challenge: These rules are difficult to follow in a centralized application.\nIdentified a solution: Arbitrum makes it easy for developers to decentralize business logic and data (using Ethereum mainnet as a settlement layer).\nConverted a vending machine's Javascript business logic into a Solidity smart contract.\nDeployed our smart contract to Hardhat's local development network, and then Arbitrum's Sepolia testnet, and then Arbitrum One Mainnet.\n\nIf you have any questions or feedback, reach out to us on Discord and/or click the Request an update button at the top of this page - we're listening!\n\nNext steps​\nVisit How to estimate gas to learn how to estimate the gas cost of your smart contract transactions.\nVisit RPC endpoints and providers for a list of public chains that you can deploy your smart contracts to.\nFootnotes​\n\nThe vending machine example was inspired by Ethereum.org's \"Introduction to Smart Contracts\", which was inspired by Nick Szabo's \"From vending machines to smart contracts\". ↩\n\nAlthough application front-ends are usually hosted by centralized services, smart contracts allow the underlying logic and data to be partially or fully decentralized. These smart contracts are hosted and executed by Ethereum's public, decentralized network of nodes. Arbitrum has its own network of nodes that use advanced cryptography techniques to \"batch process\" Ethereum transactions and then submit them to Ethereum L1, which significantly reduces the cost of using Ethereum. All without requiring developers to compromise on security or decentralization. ↩ ↩2\n\nThere are multiple types of Ethereum nodes. The ones that earn ETH for processing and validating transactions are called validators. See Nodes and Networks for a beginner-friendly introduction to Ethereum's node types. ↩\n\nWhen our VendingMachine contract is deployed to Ethereum, it'll be hosted by Ethereum's decentralized network of nodes. Generally speaking, we won't be able to modify the contract's code after it's deployed. ↩\n\nTo learn more about how Ethereum wallets work, see Ethereum.org's introduction to Ethereum wallets. ↩\n\nVisit the Gentle Introduction to Arbitrum for a beginner-friendly introduction to Arbitrum's rollup protocol. ↩\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nChain info\nNext\nEstimate gas\nWhat we're building\nPrerequisites\nEthereum and Arbitrum in a nutshell\nReview our Javascript vending machine\nConfigure your project directory\nDeploy the smart contract locally\nWhat's going on here?\nDeploy the smart contract to the Arbitrum Sepolia testnet\nDeploy the smart contract to Arbitrum One Mainnet\nSummary\nNext steps\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/launch-orbit-chain/orbit-gentle-introduction",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nA gentle introduction\nQuickstart\nOrbit Licensing\nGuidance for Orbit chain operators\nProduction Orbit chain setup\nCustomize your chain\nArbOS\nData Availability Committees\nAdd new validators to Orbit chain\n↓\nMonitoring tools and considerations\nRun a full Orbit node\nAdd your chain to the bridge\nOrbit chain ownership\nCustom gas token SDK\nBoLD for Orbit chains\nPublic preview\nThird-party infrastructure providers\nFAQ\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nA gentle introduction: Orbit chains\n\nThis document is for developers and decision-makers who want to learn more about Arbitrum Orbit, a new product offering that lets you create your own Arbitrum Rollup and AnyTrust chains.\n\nIf you'd prefer to learn by doing, see the Orbit quickstart for step-by-step instructions that walk you through the process of configuring and launching your own Orbit chain.\n\nIn a nutshell:​\nArbitrum Orbit is the permissionless path for launching customizable dedicated chains using Arbitrum technology.\nOrbit Chains can be a Layer 2 (L2) chain which settles directly to Ethereum, or a Layer 3 (L3) chain which can settle to any Ethereum L2, such as Arbitrum One.\nConfigure numerous components of the chain such as throughput, privacy, gas token, governance, precompiles, data availability layers and more, the possibilities are endless.\nYou own your Orbit chain and can decentralize its ownership, validation, and other dependencies.\nLeverage Arbitrum Nitro, the tech stack powering interactive fraud proofs, advanced compression, EVM+ compatibility via Stylus, and continuous improvements.\nWhat's Orbit?​\n\nArbitrum Orbit is a new product offering that lets you create your own customizable L2 or L3 chain.\n\nL3 Orbit chains can settle to other L2 chains, such as Arbitrum One, which settles to Ethereum.\n\nEthereum is a public Layer 1 (L1) chain.\n\nYou can think of Orbit chains as deployable, configurable instances of the Arbitrum Nitro tech stack.\nYou can also think of them as tailored chains - chains tailored precisely to your exact use-case and business needs.\nThis gives you another way to progressively decentralize your applications and incrementally adopt the properties and security assumptions of Ethereum's base layer.\nEvery Orbit chain can be configured to be either a Rollup or AnyTrust Chain.\nNote that Arbitrum One is an example of a rollup, and Arbitrum Nova is an example of an AnyTrust chain.\nArbitrum One and Arbitrum Nova are owned and governed by the Arbitrum DAO. With Orbit chains, you determine the way that your chain is governed.\nWhat problem does Orbit solve?​\n\nThe Ethereum ecosystem is supported by a decentralized network of nodes that each run Ethereum's Layer 1 (L1) client software. Ethereum's block space is in high demand, so users are often stuck waiting for the network to become less congested (and thus, less expensive).\n\nArbitrum's Rollup and AnyTrust protocols address this challenge by offloading some of the Ethereum network's heavy lifting to another decentralized network of nodes that support the Arbitrum One and Arbitrum Nova L2 chains, respectively.\n\nThere are important differences between these chains. The choice between Rollup and AnyTrust represents a tradeoff between decentralization and performance:\n\nArbitrum One implements the Rollup protocol, which stores raw transaction data on Ethereum L1, while\nArbitrum Nova implements the AnyTrust protocol, which uses a data availability committee (DAC) to store raw transaction data, expediting settlement and reducing costs by introducing a security assumption.\n\nThese two public chains will meet most projects' needs - they already support thousands of apps and millions of users! But shared public chains aren't for everyone. Some projects can benefit from their own AnyTrust or Rollup chains that afford the same security, but with a higher degree of control over the chain's features and governance (remember, these public L2 chains and their protocols are governed by the Arbitrum DAO).\n\nOrbit chains give you the ability to create your own AnyTrust and Rollup chains using your own infrastructure. You can think of your Orbit chain as a self-managed priority lane on Ethereum. Each Orbit chain is capable of supporting many times the capacity of Ethereum, all while benefitting directly from Ethereum's security.\n\nSaid simply:\n\nArbitrum One and Arbitrum Nova chains unlocked two options that scale Ethereum and meet most projects' needs.\nArbitrum Orbit chains unlock an infinite garden that scale Ethereum even further, with each individual Orbit chain being tailored precisely to its owner's needs.\nHow does Orbit help me build decentralized apps?​\nBenefit\tDescription\nDedicated throughput\tYou may need dedicated throughput if your dApp demands high-performance or consistent resource availability. Running your dApp on its own Orbit chain significantly increases resource availability, so you don’t need to compete for computation and storage resources.\nEVM+ compatibility\tOrbit chains will benefit the same EVM+ compatibility that Stylus introduces. This means that you'll be able to deploy EVM-compatible smart contracts using Solidity, C, C++, and Rust - no need to migrate away from the language and toolchain that you're already using!\nIndependent product roadmap\tIf you want to decouple your app chain's roadmap from that of Ethereum and/or Arbitrum, Orbit makes this possible. This lets you implement cutting-edge features like account abstraction ahead of projects following Ethereum's public roadmap.\nIncreased gas price reliability\tMany types of dApps rely on predictable transaction costs. Because Orbit chains are isolated from Arbitrum L2 and Ethereum L1 traffic, using Orbit chains means that you won't be significantly affected by other apps' on-chain activity, allowing your dApp's users to enjoy more reliable gas prices.\nAccount abstraction\tPredictable gas prices make it easy to model and predict business costs, which makes it easier to experiment with traditionally cost-prohibitive mechanisms like transaction fee subsidization. This makes it easier to further abstract the technical complexity of decentralized apps away from end-user experiences, allowing you to deliver decentralized experiences that feel familiar to nontechnical audiences (who may not understand or care about implementation details).\nCustom gas token\tOrbit chains can use alternative ERC-20 tokens as the native gas token on the network for gas fees, facilitating seamless integration with your app's ecosystem. This is currently supported for AnyTrust chains.\nCustomizable protocol logic\tYou may need to modify the logic of your chain's settlement, execution, or governance protocols in order to meet specific requirements. Orbit's chains let you do this, while benefiting from the security of Ethereum, through Arbitrum's DAO-governed L2 chains.\nNitro extensibility\tOrbit chains will have access to all Nitro code upgrades, feature additions, and improvements, giving your Orbit chain the option to stay up-to-date and incorporate the latest and greatest in Ethereum scaling technology.\nDecentralization options\tYou can build an Arbitrum Rollup chain that uses Ethereum for data availability, or you can build an Arbitrum AnyTrust chain that uses a Data Availability Committee (DAC) to expedite the settlement of transactions to your Orbit chain's base chain, making things even cheaper for you and your end-users. Orbit chains can use either of these technologies.\nLow prototyping costs\tOrbit chains can be easily created. See the Orbit Quickstart for step-by-step instructions.\nSecurity\tArbitrum technology powers the most secure L2s, and you can use this same mature technology stack for your Orbit chain.\nFlexible technology options\tOrbit lets you choose between Rollup, AnyTrust, or custom technology stacks. This makes Ethereum and Arbitrum technologies more adaptable by allowing you to incorporate only the elements of the technologies that you need.\nPermissioned access\tOrbit gives you the freedom to choose which contracts are deployed on your chain. You can keep it as open and permissionless as Ethereum, restrict contract deployment so that only your app can be deployed on this chain, or anything in between!\nHow does Orbit help the Ethereum ecosystem?​\n\nOrbit helps Ethereum move towards a multi-chain future. This is valuable for the following reasons:\n\nValue add\tDescription\nScalability\tMultiple chains help overcome scaling bottlenecks by dividing activity into opt-in environments with separate resource management.\nFlexible security models\tDifferent chains can experiment with different security models, allowing for tradeoffs. For example: Arbitrum One and Arbitrum Nova are both L2 chains, with Arbitrum Nova giving developers the ability to optimize for lower fees. With Arbitrum Orbit, extending the technology and experimenting is easier than ever.\nFlexible execution environments\tDifferent chains can experiment with more-or-less restrictive execution environments. For example, although Arbitrum chains are fully EVM compatible, Orbit chains can restrict smart contract functionality to optimize for your project's needs.\nFlexible governance\tOrbit chains let you define your own governance protocols.\nAre Orbit chains the same thing as \"app chains\"?​\n\nIt depends on your definition of \"app chain\". Orbit chains can be used as application-specific chains (often referred to as \"app chains\" or \"appchains\"). But they aren't just for apps. They're for hosting EVM-compatible smart contracts using self-managed infrastructure that isolates compute resources away from Arbitrum's public L2 chains based on your unique needs.\n\nYou can use your Orbit chain to host the smart contracts that support one app, two apps, an ecosystem of apps, or no apps at all.\nYou can use your Orbit chain to host a private, centralized service.\nYour Orbit chain can be special-purpose, general-purpose, and everything in-between.\nYou could even build an app that uses multiple Orbit chains to support strange new forms of redundancy, high availability, and trustlessness.\nWhat's the best model: AnyTrust or Rollup?​\n\nThe AnyTrust and Rollup data availability models reflect prioritization choices within the blockchain trilemma (scalability vs. security vs. decentralization), so the best option depends on what features matter most for your use case.\n\nHere's a short list to help you pick the model that meets your chain's requirements:\n\nI need my chain to be cost-efficient​\nAnyTrust: By leveraging a Data Availability Committee (DAC), AnyTrust significantly reduces data availability costs compared to storing all data on Ethereum L1.\nI need the most robust security model​\nRollup: By storing raw transaction data on Arbitrum One or Ethereum L1, Rollup chains inherit Ethereum's robust security model, offering high resilience against attacks.\nI need my chain to use a custom gas token​\nAnyTrust: The AnyTrust model allows you to use any ERC-20 token for gas fees.\nI want my chain to be trust-minimized and decentralized​\nRollup: If your Rollup Orbit chain settles to Arbitrum One or Ethereum, it inherits the highest levels of trustlessness and decentralization of the Ethereum environment.\nCan my Orbit chain talk to other Orbit chains?​\n\nYes! All Orbit chains are powered by self-managed nodes running their own instance of Arbitrum Nitro's node software. This software implements both AnyTrust and Rollup protocols; your Orbit chain can be configured to use either.\n\nThis means that your Orbit chain isn't a completely isolated blockchain network. When you launch an Orbit chain, you’re joining an ecosystem of connected chains that can exchange information.\n\nOur small-but-mighty team is hard at work developing tools and patterns that make it easy to launch natively interoperable Orbit chains. Interop features haven't been released just yet, but let us know if you need them - we'd like to learn from you as this capability matures.\n\nOrbit's product roadmap is firmly aligned with Ethereum's vision of a decentralized web - one that makes it easy for users to carry their digital swords, spells, skins, art, tokens, and other assets across digital boundaries of all kinds, without having to worry about security, censorship, or UX friction.\n\nWhat should I know about Orbit's licensing?​\n\nYou can launch any Orbit chain permissionlessly. Nitro is licensed under a Business Source license, similar to DeFi protocols like Uniswap and Aave, among others. This license contains an Additional Use Grant that permits the permissionless deployment of Nitro software on blockchains that settle to Arbitrum One or Nova. However, Orbit chains that settle to a parent chain other than Arbitrum One or Nova are subject to additional licensing guidelines under the AEP.\n\nI'd love to tinker with Orbit! What should I do next?​\n\nVisit the Orbit Quickstart, start tinkering, and let us know how it goes - we're excited to learn and grow with you! 🚀\n\nHow can I launch an Orbit chain on mainnet?​\n\nWhile launching a chain on your own is possible, there are multiple infrastructure providers such as Caldera, Conduit, AltLayer, and Gelato that are enabling developers to quickly launch their own rollups.\n\nEdit this page\nLast updated on Nov 21, 2024\nPrevious\nTypes\nNext\nQuickstart\nIn a nutshell:\nWhat's Orbit?\nWhat problem does Orbit solve?\nHow does Orbit help me build decentralized apps?\nHow does Orbit help the Ethereum ecosystem?\nAre Orbit chains the same thing as \"app chains\"?\nWhat's the best model: AnyTrust or Rollup?\nCan my Orbit chain talk to other Orbit chains?\nWhat should I know about Orbit's licensing?\nI'd love to tinker with Orbit! What should I do next?\nHow can I launch an Orbit chain on mainnet?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/stylus-gentle-introduction",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nA gentle introduction: Stylus\n\nThis introduction is for developers who want to build on Arbitrum using popular programming languages like Rust. This capability is made possible by Stylus, a new way to write EVM-compatible smart contracts using your favorite programming languages.\n\nIn a nutshell:​\nStylus lets you write smart contracts in programming languages that compile to WASM, such as Rust, C, C++, and many others.\nRich language support already exists for Rust: you can use the Stylus SDK and CLI tool to start building today.\nStylus smart contracts benefit from Arbitrum's EVM equivalence thanks to a second, coequal WASM virtual machine.\nSolidity contracts and Stylus contracts are fully interoperable. In Solidity, you can call a Rust program and vice versa.\nStylus contracts are significantly faster and have lower gas fees due to the superior efficiency of WASM programs.\nStylus makes it viable to consume RAM on the blockchain because it can greatly optimize memory use, enabling new use cases.\nWhat's Stylus?​\n\nStylus is an upgrade to Arbitrum Nitro, the tech stack powering Arbitrum One, Arbitrum Nova, and Arbitrum Orbit chains. This upgrade adds a second, coequal virtual machine to the EVM, where EVM contracts continue to behave exactly as they would in Ethereum. We call this paradigm MultiVM since everything is entirely additive.\n\nThis second virtual machine executes WebAssembly (WASM) rather than EVM bytecode. WASM is a modern binary format popularized by its use in major web standards, browsers, and companies to speed up computation. WASM is built to be fast, portable, and human-readable. It has sandboxed execution environments for security and simplicity. Working with WASM is nothing new for Arbitrum chains. Ever since the Nitro upgrade, WASM has been a fundamental component of Arbitrum's fully functioning fraud proofs.\n\nWith a WASM VM, any programming language that can compile to WASM is within Stylus's scope. While many popular programming languages can be compiled into WASM, some compilers are more suitable for smart contract development than others, like Rust, C, and C++. Other languages like Go, Sway, Move, and Cairo can also be supported. Languages that include their own runtimes, like Python and Javascript, are more complex for Stylus to support, although not impossible. Third-party contribution in the form of libraries for new and existing languages is welcomed!\n\nCompared to using Solidity, WASM programs are much more efficient. There are many reasons for this, including the decades of compiler development for Rust and C. WASM also has a faster runtime than the EVM, resulting in faster execution.\n\nHow is this possible?​\n\nStylus is only possible because of Arbitrum Nitro's unique fraud-proving technology. When there's a dispute on an Arbitrum network, Nitro replays the execution of the chain in WASM. Honest Arbitrum validators will then bisect what is being disputed until a single invalid step is identified and checked on-chain via a “one-step proof.”\n\nNitro's fraud-proving enables it to prove arbitrary WASM in a deterministic way.\n\nBecause any code logic can be proven with WASM, the correctness of any program compiling to WASM can also be proven. The combination of WASM's and Nitro's properties enables this technological leap we call Stylus.\n\nFor a detailed overview of Nitro's technical architecture, see the documentation or the Nitro whitepaper.\n\nWhy does this matter?​\n\nStylus innovates on many levels, with the key ones described here:\n\nOne chain, many languages​\n\nThere are estimated to be roughly 20k Solidity developers, compared to 3 million Rust developers or 12 million C developers [1]. Developers are now free to use their preferred programming language, all interoperable on any Arbitrum chain with Stylus. By onboarding the next million developers, scaling to the next billion users becomes possible.\n\nA better EVM​\n\nStylus' MultiVM brings the best of both worlds. Developers still get all of the benefits of the EVM, including the ecosystem and liquidity, while getting efficiency improvements and access to existing libraries in Rust, C, and C++, all without changing anything about how the EVM works. EVM equivalence is no longer the ceiling; it's the floor.\n\nCheaper execution​\n\nStylus is a more efficient execution environment than the EVM, leading directly to gas savings for complex smart contracts. Computation and memory can be significantly cheaper. Cryptography libraries can be permissionlessly deployed as custom application layer precompiles. Use cases that are impractical in the EVM are now possible in Stylus.\n\nOpt-in reentrancy​\n\nStylus doesn't just improve on cost and speed. WASM programs are also safer. Reentrancy is a common vulnerability that developers can only attempt to mitigate in Solidity. Stylus provides cheap reentrancy detection, and using the Rust SDK, reentrancy is disabled by default unless intentionally overridden.\n\nFully interoperable​\n\nSolidity programs and WASM programs are completely composable. If working in Solidity, a developer can call a Rust program or rely on another dependency in a different language. If working in Rust, all Solidity functionalities are accessible out of the box.\n\nHow does it work?​\n\nThere are four main steps for bringing a Stylus contract to life: coding, activation, execution, and proving.\n\nCoding​\n\nDevelopers can now write smart contracts in any programming language that compiles to WASM. Note that some high-level languages generate far more performant WASMs than others.\n\nInitially, there will be support for Rust, C, and C++. However, the levels of support will differ at first. Rust has rich language support from day one, with an open-source SDK that makes writing smart contracts in Rust as easy as possible. C and C++ are supported off the bat, too, enabling the deployment of existing contracts in those languages on-chain with minimal modifications.\n\nThe Stylus SDK for Rust contains the smart contract development framework and language features most developers will need to use in Stylus. The SDK also makes it possible to perform all of the EVM-specific functionalities that smart contract developers are used to. Check out the Rust SDK Guide and the Crate Docs.\n\nActivation​\n\nStylus contracts are compiled to WASM and then lowered to assembly. Starting from a high-level language (such as Rust, C, or C++), the first compilation stage happens either using the CLI provided in the Stylus SDK for Rust or any other compiler, such as Clang for C and C++. Once compiled, the WASM is posted onchain. Then, in a process called activation, WASM gets lowered to a node's native machine code (such as ARM or x86).\n\nActivating a Stylus contract requires a new precompile, ArbWasm. This precompile produces efficient binary code tailored to a node's native assembly. During this step, a series of middlewares ensure user programs can be safely executed and deterministically fraud-proven. Instrumentation includes gas metering, depth-checking, memory charging, and more to guarantee all WASM programs are safe for the chain to execute. Stylus contracts can be called only after they've been activated.\n\nGas metering is essential for certifying that computational resources are paid for. In Stylus, the unit for measuring cost is called “ink,” similar to Ethereum's gas but thousands of times smaller. There are two reasons why a new measurement is used: First, WASM execution is so much faster than the EVM that thousands of WASM opcodes could be executed in the same time it takes the EVM to execute one. Second, the conversion rate of ink to gas can change based on future hardware or VM improvements. For a conceptual introduction to Stylus gas and ink, see gas and ink (Stylus).\n\nExecution​\n\nStylus contracts are executed in a fork of Wasmer, the leading WebAssembly runtime, with minimal changes to optimize their codebase for blockchain-specific use cases. Wasmer executes native code much faster than Geth executes EVM bytecode, contributing to the significant gas savings that Stylus provides.\n\nEVM contracts continue to execute the same way they did before Stylus. When a contract is called, the difference between an EVM contract and a WASM program can be seen via an EOF-inspired contract header. From there, the contract is executed using its corresponding runtime. Contracts written in Solidity and WASM languages can make cross-contract calls to each other, meaning a developer never has to consider what language the contract was written in. Everything is interoperable.\n\nProving​\n\nNitro has a happy case and a sad case. Most of the time, it's in a happy case, compiling execution history to native code. In the sad case of a dispute between validators, Nitro compiles execution history to WASM to conduct interactive fraud proofs on Ethereum. Stylus is a natural extension to Nitro's fraud-proving technology, utilizing it to not only bisect execution history but also any WASM programs deployed by developers.\n\nNew use cases​\n\nIt's impossible to list all of the use cases Stylus enables, think about the properties of all WASM compatible languages!\n\nThat said, here are some new features that are particularly exciting:\n\nGenerative art libraries that consume a bunch of RAM\nBringing existing games written in C++ on-chain\nCompute-heavy AI models\nProjects using alternative signature schemes, such as secp256r1, via custom precompiles\nOptimization of Solidity-based projects for speed and cost\n\nWe leave it up to you to ideate blockchain projects that were not technically feasible until now.\n\nWhile many developers will be drawn to new use cases, rebuilding existing applications in Stylus will also open the door to innovation and optimization. dApps have never been faster, cheaper, or safer.\n\nStylus is open to all. Much thought has been given to creating the best programming experience possible. However, the work continues. Feedback gained from developers will help drive Stylus to the next level, improving tooling, documentation, and language features. Becoming an early adopter of Stylus is the best way to familiarize oneself with its opportunities.\n\nIf you're a developer interested in Stylus, visit the quickstart, join the Discord channel, and start building!\n\nWen mainnet?​\n\nStylus is now live on mainnet.\n\nTo keep up with the latest announcements and updates about Stylus:\n\nSubscribe to the Arbitrum Node Upgrade Announcement channel on Telegram\nJoin both the #dev-announcements and #node-runners Discord channels in the Arbitrum Discord server\nFollow the official Arbitrum (@Arbitrum) and Arbitrum Developers (@ArbitrumDevs) X accounts, formerly Twitter.\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nWrite Stylus contracts\nNext\nQuickstart (Rust)\nIn a nutshell:\nWhat's Stylus?\nHow is this possible?\nWhy does this matter?\nHow does it work?\nNew use cases\nWen mainnet?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Geth | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/arbos/geth",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nArbOS\nGeth\nFraud proofs\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nGeth\n\nNitro makes minimal modifications to Geth in hopes of not violating its assumptions. This document will explore the relationship between Geth and ArbOS, which consists of a series of hooks, interface implementations, and strategic re-appropriations of Geth's basic types.\n\nWe store ArbOS's state at an address inside a Geth statedb. In doing so, ArbOS inherits the statedb's statefulness and lifetime properties. For example, a transaction's direct state changes to ArbOS are discarded upon a revert.\n\n0xA4B05FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF\nThe fictional account representing ArbOS\n\nINFO\n\nPlease note any links on this page may be referencing old releases of Nitro or our fork of Geth. While we try to keep this up to date and most of this should be stable, please check against latest releases for Nitro and Geth for most recent changes.\n\nHooks​\n\nArbitrum uses various hooks to modify Geth's behavior when processing transactions. Each provides an opportunity for ArbOS to update its state and make decisions about the transaction during its lifetime. Transactions are applied using Geth's ApplyTransaction function.\n\nBelow is ApplyTransaction's callgraph, with additional info on where the various Arbitrum-specific hooks are inserted. Click on any to go to their section. By default, these hooks do nothing so as to leave Geth's default behavior unchanged, but for chains configured with EnableArbOS set to true, ReadyEVMForL2 installs the alternative L2 hooks.\n\ncore.ApplyTransaction ⮕ core.applyTransaction ⮕ core.ApplyMessage\ncore.NewStateTransition\nReadyEVMForL2\ncore.TransitionDb\nStartTxHook\ncore.transitionDbImpl\nif IsArbitrum() remove tip\nGasChargingHook\nevm.Call\ncore.vm.EVMInterpreter.Run\nPushCaller\nPopCaller\ncore.StateTransition.refundGas\nForceRefundGas\nNonrefundableGas\nEndTxHook\nadded return parameter: transactionResult\n\nWhat follows is an overview of each hook, in chronological order.\n\nReadyEVMForL2​\n\nA call to ReadyEVMForL2 installs the other transaction-specific hooks into each Geth EVM right before it performs a state transition. Without this call, the state transition will instead use the default DefaultTxProcessor and get exactly the same results as vanilla Geth. A TxProcessor object is what carries these hooks and the associated Arbitrum-specific state during the transaction's lifetime.\n\nStartTxHook​\n\nThe StartTxHook is called by Geth before a transaction starts executing. This allows ArbOS to handle two Arbitrum-specific transaction types.\n\nIf the transaction is ArbitrumDepositTx, ArbOS adds balance to the destination account. This is safe because the L1 bridge submits such a transaction only after collecting the same amount of funds on L1.\n\nIf the transaction is an ArbitrumSubmitRetryableTx, ArbOS creates a retryable based on the transaction's fields. If the transaction includes sufficient gas, ArbOS schedules a retry of the new retryable.\n\nThe hook returns true for both of these transaction types, signifying that the state transition is complete.\n\nGasChargingHook​\n\nThis fallible hook ensures the user has enough funds to pay their poster's L1 calldata costs. If not, the transaction is reverted and the EVM does not start. In the common case that the user can pay, the amount paid for calldata is set aside for later reimbursement of the poster. All other fees go to the network account, as they represent the transaction's burden on validators and nodes more generally.\n\nIf the user attempts to purchase compute gas in excess of ArbOS's per-block gas limit, the difference is set aside and refunded later via ForceRefundGas so that only the gas limit is used. Note that the limit observed may not be the same as that seen at the start of the block if ArbOS's larger gas pool falls below the MaxPerBlockGasLimit while processing the block's previous transactions.\n\nPushCaller​\n\nThese hooks track the callers within the EVM callstack, pushing and popping as calls are made and complete. This provides ArbSys with info about the callstack, which it uses to implement the methods WasMyCallersAddressAliased and MyCallersAddressWithoutAliasing.\n\nL1BlockHash​\n\nIn Arbitrum, the BlockHash and Number operations return data that relies on underlying L1 blocks instead of L2 blocks, to accommodate the normal use-case of these opcodes, which often assume Ethereum-like time passes between different blocks. The L1BlockHash and L1BlockNumber hooks have the required data for these operations.\n\nForceRefundGas​\n\nThis hook allows ArbOS to add additional refunds to the user's tx. This is currently only used to refund any compute gas purchased in excess of ArbOS's per-block gas limit during the GasChargingHook.\n\nNonrefundableGas​\n\nBecause poster costs come at the expense of L1 aggregators and not the network more broadly, the amounts paid for L1 calldata should not be refunded. This hook provides Geth access to the equivalent amount of L2 gas the poster's cost equals, ensuring this amount is not reimbursed for network-incentivized behaviors like freeing storage slots.\n\nEndTxHook​\n\nThe EndTxHook is called after the EVM has returned a transaction's result, allowing one last opportunity for ArbOS to intervene before the state transition is finalized. Final gas amounts are known at this point, enabling ArbOS to credit the network and poster each's share of the user's gas expenditures as well as adjust the pools. The hook returns from the TxProcessor a final time, in effect discarding its state as the system moves on to the next transaction where the hook's contents will be set afresh.\n\nInterfaces and components​\nAPIBackend​\n\nAPIBackend implements the ethapi.Backend interface, which allows simple integration of the Arbitrum chain to existing Geth API. Most calls are answered using the Backend member.\n\nBackend​\n\nThis struct was created as an Arbitrum equivalent to the Ethereum struct. It is mostly glue logic, including a pointer to the ArbInterface interface.\n\nArbInterface​\n\nThis interface is the main interaction-point between geth-standard APIs and the Arbitrum chain. Geth APIs mostly either check status by working on the Blockchain struct retrieved from the Blockchain call, or send transactions to Arbitrum using the PublishTransactions call.\n\nRecordingKV​\n\nRecordingKV is a read-only key-value store, which retrieves values from an internal trie database. All values accessed by a RecordingKV are also recorded internally. This is used to record all preimages accessed during block creation, which will be needed to prove execution of this particular block. A RecordingChainContext should also be used, to record which block headers the block execution reads (another option would be to always assume the last 256 block headers were accessed). The process is simplified using two functions: PrepareRecording creates a stateDB and chaincontext objects, running block creation process using these objects records the required preimages, and PreimagesFromRecording function extracts the preimages recorded.\n\nTransaction Types​\n\nNitro Geth includes a few L2-specific transaction types. Click on any to jump to their section.\n\nTx Type\tRepresents\tLast Hook Reached  \tSource\nArbitrumUnsignedTx\tAn L1 to L2 message\tEndTxHook\tBridge\nArbitrumContractTx\tA nonce-less L1 to L2 message  \tEndTxHook\tBridge\nArbitrumDepositTx\tA user deposit\tStartTxHook\tBridge\nArbitrumSubmitRetryableTx  \tCreating a retryable\tStartTxHook  \tBridge\nArbitrumRetryTx\tA retryable redeem attempt\tEndTxHook\tL2\nArbitrumInternalTx\tArbOS state update\tStartTxHook\tArbOS\n\nThe following reference documents each type.\n\nArbitrumUnsignedTx​\n\nProvides a mechanism for a user on L1 to message a contract on L2. This uses the bridge for authentication rather than requiring the user's signature. Note, the user's acting address will be remapped on L2 to distinguish them from a normal L2 caller.\n\nArbitrumContractTx​\n\nThese are like an ArbitrumUnsignedTx but are intended for smart contracts. These use the bridge's unique, sequential nonce rather than requiring the caller specify their own. An L1 contract may still use an ArbitrumUnsignedTx, but doing so may necessitate tracking the nonce in L1 state.\n\nArbitrumDepositTx​\n\nRepresents a user deposit from L1 to L2. This increases the user's balance by the amount deposited on L1.\n\nArbitrumSubmitRetryableTx​\n\nRepresents a retryable submission and may schedule an ArbitrumRetryTx if provided enough gas. Please see the retryables documentation for more info.\n\nArbitrumRetryTx​\n\nThese are scheduled by calls to the redeem method of the ArbRetryableTx precompile and via retryable auto-redemption. Please see the retryables documentation for more info.\n\nArbitrumInternalTx​\n\nBecause tracing support requires ArbOS's state-changes happen inside a transaction, ArbOS may create a transaction of this type to update its state in-between user-generated transactions. Such a transaction has a Type field signifying the state it will update, though currently this is just future-proofing as there's only one value it may have. Below are the internal transaction types.\n\nInternalTxStartBlock​\n\nUpdates the L1 block number and L1 base fee. This transaction is generated whenever a new block is created. They are guaranteed to be the first in their L2 block.\n\nTransaction Run Modes and Underlying Transactions​\n\nA geth message may be processed for various purposes. For example, a message may be used to estimate the gas of a contract call, whereas another may perform the corresponding state transition. Nitro Geth denotes the intent behind a message by means of its TxRunMode, which it sets before processing it. ArbOS uses this info to make decisions about the transaction the message ultimately constructs.\n\nA message derived from a transaction will carry that transaction in a field accessible via its UnderlyingTransaction method. While this is related to the way a given message is used, they are not one-to-one. The table below shows the various run modes and whether each could have an underlying transaction.\n\nRun Mode\tScope\tCarries an Underlying Tx?\nMessageCommitMode\tstate transition  \talways\nMessageGasEstimationMode  \tgas estimation\twhen created via NodeInterface or when scheduled\nMessageEthcallMode\teth_calls\tnever\nArbitrum Chain Parameters​\n\nNitro's Geth may be configured with the following l2-specific chain parameters. These allow the rollup creator to customize their rollup at genesis.\n\nEnableArbos​\n\nIntroduces ArbOS, converting what would otherwise be a vanilla L1 chain into an L2 Arbitrum rollup.\n\nAllowDebugPrecompiles​\n\nAllows access to debug precompiles. Not enabled for Arbitrum One. When false, calls to debug precompiles will always revert.\n\nDataAvailabilityCommittee​\n\nCurrently does nothing besides indicate that the rollup will access a data availability service for preimage resolution in the future. This is not enabled for Arbitrum One, which is a strict state-function of its L1 inbox messages.\n\nMiscellaneous Geth Changes​\nABI Gas Margin​\n\nVanilla Geth's abi library submits txes with the exact estimate the node returns, employing no padding. This means a transaction may revert should another arriving just before even slightly change the transaction's codepath. To account for this, we've added a GasMargin field to bind.TransactOpts that pads estimates by the number of basis points set.\n\nConservation of L2 ETH​\n\nThe total amount of L2 ether in the system should not change except in controlled cases, such as when bridging. As a safety precaution, ArbOS checks Geth's balance delta each time a block is created, alerting or panicking should conservation be violated.\n\nMixDigest and ExtraData​\n\nTo aid with outbox proof construction, the root hash and leaf count of ArbOS's send merkle accumulator are stored in the MixDigest and ExtraData fields of each L2 block. The yellow paper specifies that the ExtraData field may be no larger than 32 bytes, so we use the first 8 bytes of the MixDigest, which has no meaning in a system without miners/stakers, to store the send count.\n\nRetryable Support​\n\nRetryables are mostly implemented in ArbOS. Some modifications were required in Geth to support them.\n\nAdded ScheduledTxes field to ExecutionResult. This lists transactions scheduled during the execution. To enable using this field, we also pass the ExecutionResult to callers of ApplyTransaction.\nAdded gasEstimation param to DoCall. When enabled, DoCall will also also executing any retryable activated by the original call. This allows estimating gas to enable retryables.\nAdded accessors​\n\nAdded UnderlyingTransaction to Message interface Added GetCurrentTxLogs to StateDB We created the AdvancedPrecompile interface, which executes and charges gas with the same function call. This is used by Arbitrum's precompiles, and also wraps Geth's standard precompiles.\n\nWASM build support​\n\nThe WASM Arbitrum executable does not support file operations. We created fileutil.go to wrap fileutil calls, stubbing them out when building WASM. fake_leveldb.go is a similar WASM-mock for leveldb. These are not required for the WASM block-replayer.\n\nTypes​\n\nArbitrum introduces a new signer, and multiple new transaction types.\n\nReorgToOldBlock​\n\nGeth natively only allows reorgs to a fork of the currently-known network. In nitro, reorgs can sometimes be detected before computing the forked block. We added the ReorgToOldBlock function to support reorging to a block that's an ancestor of current head.\n\nGenesis block creation​\n\nGenesis block in nitro is not necessarily block #0. Nitro supports importing blocks that take place before genesis. We split out WriteHeadBlock from genesis.Commit and use it to commit non-zero genesis blocks.\n\nEdit this page\nLast updated on Nov 22, 2024\nPrevious\nArbOS\nNext\nInteractive challenges\nHooks\nReadyEVMForL2\nStartTxHook\nGasChargingHook\nPushCaller\nL1BlockHash\nForceRefundGas\nNonrefundableGas\nEndTxHook\nInterfaces and components\nAPIBackend\nBackend\nArbInterface\nRecordingKV\nTransaction Types\nArbitrumUnsignedTx\nArbitrumContractTx\nArbitrumDepositTx\nArbitrumSubmitRetryableTx\nArbitrumRetryTx\nArbitrumInternalTx\nTransaction Run Modes and Underlying Transactions\nArbitrum Chain Parameters\nEnableArbos\nAllowDebugPrecompiles\nDataAvailabilityCommittee\nMiscellaneous Geth Changes\nABI Gas Margin\nConservation of L2 ETH\nMixDigest and ExtraData\nRetryable Support\nAdded accessors\nWASM build support\nTypes\nReorgToOldBlock\nGenesis block creation\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "ChallengeManager | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/how-arbitrum-works/fraud-proofs/challenge-manager",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nIntroductory concepts\nAdvanced concepts\nDeep dive: Inside Arbitrum\nDeeper dive: Whitepaper\nAssertion tree\nNitro vs. Classic\nCross-chain messaging\nArbOS\nFraud proofs\nInteractive challenges\nOne step proof assumptions\nWasm To WAVM\nCustom WAVM opcodes\nWAVM floats\nWAVM modules\nThe BoLD dispute protocol\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nChallengeManager\n\nThe ChallengeManager arbitrates challenge games. Here's a diagram of the challenge state machine:\n\nBlock challenge​\n\nThe challenge begins by bisecting over global states (including block hashes). Before actual machine execution is disputed, the dispute is narrowed down to an individual block. Once the challenge has been bisected down to an individual block, challengeExecution can be called by the current responder. This operates similarly to a bisection in that the responder must provide a competing global state and machine state, but it uses that information to transition to the execution challenge phase.\n\nExecution challenge​\n\nOnce narrowed down to an individual block, the actual machine execution can be bisected. Once the execution has been bisected down to an individual step, oneStepProveExecution can be called by the current responder. The current responder must provide proof data to execute a step of the machine. If executing that step ends in a different state than was previously asserted, the current responder wins the challenge.\n\nGeneral bisection protocol​\n\nNote: the term bisection in this document is used for clarity but refers to a dissection of any degree.\n\nThe ChallengeLib helper library contains a hashChallengeState method which hashes a list of segment hashes, a start position, and a total segments length, which generates the ChallengeLib.Challenge's challengeStateHash. This is enough information to infer the position of each segment hash. The challenge \"degree\" refers to the number of segment hashes minus one. The distance (in steps) between one segment and the next is floor(segmentsLength / degree), except for the last pair of segments, where segmentsLength % degree is added to the normal distance, so that the total distance is segmentsLength.\n\nA challenge begins with only two segments (a degree of one), which is the asserter's initial assertion. Then, the bisection game begins on the challenger's turn. In each round of the game, the current responder must choose an adjacent pair of segments to challenge. By doing so, they are disputing their opponent's claim that starting with the first segment and executing for the specified distance (number of steps) will result in the second segment. At this point the two parties agree on the correctness of the first segment but disagree about the correctness of the second segment. The responder must provide a bisection with a start segment equal to the first segment, but an end segment different from the second segment. In doing so, they break the challenge down into smaller distances, and it becomes their opponent's turn. Each bisection must have degree min(40, numStepsInChallengedSegment), ensuring the challenge makes progress.\n\nIn addition, a segment with a length of only one step cannot be bisected. What happens there is specific to the phase of the challenge, as either a challengeExecution or oneStepProveExecution.\n\nNote that unlike in a traditional bisection protocol, where one party proposes segments and the other decides which to challenge, this protocol is symmetric in that both players take turns deciding where to challenge and proposing bisections when challenging.\n\nWinning the challenge​\n\nNote that for the time being, winning the challenge isn't instant. Instead, it simply makes the current responder the winner's opponent, and sets the state hash to 0. In that state the party does not have any valid moves, so it will eventually lose by timeout. This is done as a precaution, so that if a challenge is resolved incorrectly, there is time to diagnose and fix the error with a contract upgrade.\n\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nGeth\nNext\nOne step proof assumptions\nBlock challenge\nExecution challenge\nGeneral bisection protocol\nWinning the challenge\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/audit-reports",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nSecurity Audit Reports\nAuditor\tAudit date\tAudited code\tView report\nTrail of Bits\t10/30/2024\tBoLD contracts in Nitro due to changes to support EIP7702 & Fast Withdrawals\tview\nTrail of Bits\t09/25/2024\tTimeboost Auction Contracts\tview\nOpen Zeppelin\t09/05/2024\tStylus Rust SDK\tview\nTrail of Bits\t08/29/2024\tOrbit & Governance Upgrade Actions Contracts v2.1\tview\nTrail of Bits\t08/29/2024\tUSDC Custom Gateway & ArbOS Timestamp Upgrade Action contract\tview\nTrail of Bits\t08/01/2024\tCustom fee token\tview\nTrail of Bits\t07/26/2024\tArbOS 31 Bianca: Nitro Upgrade\tview\nTrail of Bits\t07/26/2024\tArbOS 30 Atlas: Nitro Upgrade\tview\nCode4rena\t06/17/2024\tArbitrum BoLD: Public Audit Competition Report\tview\nTrail of Bits\t06/10/2024\tArbitrum Stylus\tview\nTrail of Bits\t05/02/2024\tArbitrum BoLD & Delay Buffer\tview\nChainsecurity\t03/20/2024\tNova Fee Router Updates (ArbOS 31)\tview\nTrail of Bits\t03/18/2024\tl1-l3-teleporter\tview\nTrail of Bits\t01/06/2023\tGovernance & Token Bridge\tview\nTrail of Bits\t10/10/2022\tNitro Node & Core Contracts, 2 of 2\tview\nConsenSys Diligence\t06/24/2022\tNitro Node & Core Contracts\tview\nTrail of Bits\t03/14/2022\tNitro Node & Core Contracts, 1 of 2\tview\nConsenSys Diligence\t11/05/2021\tCore Contracts, Token Bridge\tview\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nContribute docs\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Contribute docs | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/contribute",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nOracles\nContribute third-party docs\nCircle\nCovalent\nCrossmint\nEnvio\nFlair\nGelato\nMoralis\nOpenfort\nPARSIQ\nParticle Network\nQuickNode\nThe Graph\nContribute docs\nAudit reports\nDAO docs\nPrysm docs\nContribute docs\n\nThe docs.arbitrum.io docs portal is the single source of truth for documentation that supports Offchain Labs' product portfolio. Contributions are welcome from the entire Ethereum community.\n\nThis document shows you how to craft and publish Arbitrum documentation. Familiarity with Markdown syntax, Github, and Docusaurus is expected.\n\nAdd a new core document​\n\nIf a document isn't in a Third-party content sidebar node, it's a core document. To contribute a new core doc:\n\nBegin by creating a branch (internal) or fork (external) of the Arbitrum docs repo.\nIssue a Draft pull request into master. Pull requests into master generate a preview of your changes via a PR-specific Docusaurus deployment; this preview will update as you push commits to your remote.\nInclude answers to the following questions in your PR description:\n1. Audience: Who am I writing for?\n2. Problem: What specific problem are they trying to solve?\n3. Discovery: How are they looking for a solution to this problem? What search terms are they using?\n4. Document type: Which document type is most suitable?\n5. Policy acknowledgment (Third-party docs only): Do you agree to the third-party content policy outlined within \"Contribute docs\"?\n\nAs you craft your contribution, refer to the document types, Style guidance, and other conventions below.\nMark your PR as Open when it's ready for review.\nAdd a new third-party document​\n\nThird-party docs are documents that help readers of Arbitrum docs use other products, services, and protocols (like the ones listed in the Arbitrum portal) with Arbitrum products.\n\nSee Contribute third-party docs for detailed instructions.\n\nRequest an update​\n\nIf you'd like to request an update or share a suggestion related to an existing document without submitting a pull request to implement the improvement yourself, click the Request an update button located at the top of each published document. This button will lead you to a prefilled Github issue that you can use to elaborate on your request or suggestion.\n\nAdd a new translation page​\n\nIf you would like to participate in translating the Arbitrum docs, you can:\n\nCheck whether /website/i18n has a corresponding language (currently there are ja and zh). If not, you can use the following command to add it (we take adding French as an example):\ncd ./website\nnpm run write-translations -- --locale fr\n\n\nIt will help generate folder website/i18n/fr.\n\nCreate the folders current and translated under the newly generated folder website/i18n/fr/docusaurus-plugin-content-docs:\nmkdir i18n/{Your_language}/docusaurus-plugin-content-docs/current && mkdir i18n/{Your_language}/docusaurus-plugin-content-docs/translated\n\n\nTranslate one of more docs files located in /arbitrum-docs.\n\nPlace the translated document into the folder i18n/{Your_language}/docusaurus-plugin-content-docs/translated according to its relative path in arbitrum-docs. For example, if you translated /arbitrum-docs/how-arbitrum-works/arbos/introduction.md, then its path in i18n should be i18n/{Your_language}/docusaurus-plugin-content-docs/translated/how-arbitrum-works/arbos/introduction.md.\n\nTest run:\n\nCheck that the i18n settings in website/docusaurus.config.js have included your new language:\ni18n: {\n    defaultLocale: 'en',\n    // locales: ['en', 'ja', 'zh'],\n    locales: ['en'], // You can add your new language to this array\n  },\n\nCheck whether the locale Dropdown component exists in navbar, if not, add it:\nnavbar: {\n    title: 'Arbitrum Docs',\n    logo: {\n        alt: 'My Site Logo',\n        src: 'img/logo.svg',\n        href: '/welcome/arbitrum-gentle-introduction',\n    },\n    items: [\n        // note:  we can uncomment this when we want to display the locale dropdown in the top navbar\n        //        if we enable this now, the dropdown will appear above every document; if `ja` is selected for a document that isn't yet translated, it will 404\n        //        there may be a way to show the dropdown only on pages that have been translated, but that's out of scope for the initial version\n        {\n        type: 'localeDropdown',\n        position: 'right',\n        }\n    ],\n},\n\nBuild translation and docs:\nyarn build_translation && yarn build\n\nStart docs:\nnpm run serve\n\n\n\nDocument type conventions​\n\nEvery document should be a specific type of document. Each type of document has its own purpose:\n\nDocument type\tPurpose\tExample(s) to refer to\nGentle introduction\tOnboard a specific reader audience with tailored questions and answers\tA gentle introduction to Orbit\nQuickstart\tOnboard a specific reader audience with step-by-step \"learn by doing\" instructions\tQuickstart: Build dApps\nHow-to\tProvide task-oriented procedural guidance\tHow to run a full chain simulation\nConcept\tExplain what things are and how they work\tToken bridging\nNodes and networks\nFAQ\tAddress frequently asked questions\tFAQ: Run a node\nTroubleshooting\tList common troubleshooting scenarios and solutions\tTroubleshooting: Run a node\nReference\tLists and tables of things, such as API endpoints and developer resources\tRPC endpoints and providers\n\nThis isn't an exhaustive list, but it includes most of the document types that we use.\n\nStyle conventions​\n\nThe following style guidelines provide a number of loose recommendations that help us deliver a consistent content experience across our docs:\n\nCasing\nSentence-case \"content labels\": document titles, sidebar titles, menu items, section headers, etc.\nLinking\nAvoid anchoring links to words like \"here\" or \"this\". Descriptive anchor text can help set expectations for readers who may hesitate to click on ambiguous links. When linking to docs, try to link to the document's title verbatim.\nTitling\nTitles should balance brevity with precision - Node running overview is preferred to Overview. This helps with SEO and reader UX.\nSeparate procedural from conceptual (most of the time)\nWithin procedural docs like how-tos and quickstarts, avoid including too much conceptual content. Provide only the conceptual information that the target reader needs in order to complete the task at hand. Otherwise, organize conceptual information within conceptual docs, and link to them \"just in case\" from other docs.\nVoice\nAddress the reader as \"you\".\nWrite like you'd speak to a really smart friend who's in a rush.\nOpt for short, clear sentences that use translation-friendly, plain language.\nUse contractions wherever it feels natural - this can help convey a friendly and conversational tone.\nFormality\nDon't worry too much about formality. The most valuable writing is writing that provides value to readers, and readers generally want to \"flow\" through guidance.\nAim at \"informal professionalism\" that prioritizes audience-tailored problem-solving and consistent style and structure.\nTargeting\nDon't try to write for everyone; write for a specific reader persona (also referred to as \"audience\" in this document) who has a specific need.\nMake assumptions about prior knowledge (or lack thereof) and make these assumptions explicit in the beginning of your document.\nFlow\nSet expectations: Begin documents by setting expectations. Who is the document for? What value will it provide to your target audience? What assumptions are you making about their prior knowledge? Are there any prerequisites?\nValue up front: Lead with what matters most to the reader persona you're targeting. Then, progressively build a bridge that carries them towards task completion as efficiently as possible.\nCross-linking\nWe want to maintain both high discoverability and high relevance. As a general rule of thumb, links to other docs should be \"very likely to be useful for most readers\". Every link is a subtle call to action; we want to avoid CTA overload.\nThings to avoid\nSymbols where words will do: Minimize usage of & and / - spell out words like \"and\" and \"or\".\nJargon: Using precise technical terminology is ok, as long as your target audience is likely to understand the terminology. When in doubt, opt for clear, unambiguous, accessible language.\n\nDon't stress too much about checking off all of these boxes; we periodically review and edit our most heavily-trafficked docs, bringing them up to spec with the latest style guidelines.\n\nSome important disclaimers:\n\nThis isn't an exhaustive list. These are just the min-bar guidelines that will be applied to all new content moving forward.\nMany of our docs don't yet follow this guidance. Our small-but-mighty team is working on it! If you notice an obvious content bug, feel free to submit an issue or PR.\nBanner conventions​\n\nYou can use banners (Docusaurus refers to them as \"admonitions\") to set expectations for your readers and to emphasize important callouts. Use these conservatively, as they interrupt the flow of the document.\n\nUnder construction banner​\n\nExample:\n\nUNDER CONSTRUCTION\n\nThe following steps are under construction and will be updated with more detailed guidance soon. Stay tuned, and don't hesitate to click the Request an update at the top of this document if you have any feedback along the way.\n\nUsage:\n\n:::caution[UNDER CONSTRUCTION]\n\nThe following steps are under construction and will be updated with more detailed guidance soon. Stay tuned, and don't hesitate to click the `Request an update` at the top of this document if you have any feedback along the way.\n\n:::\n\n\n\nCommunity member contribution banner​\n\nExample:\n\nCOMMUNITY MEMBER CONTRIBUTION\n\nThe following document was contributed by @todo-twitter-handle. Give them a shoutout if you find it useful!\n\nUsage:\n\n:::info[Community member contribution]\n\nThe following document was contributed by @todo-twitter-handle. Give them a shoutout if you find it useful!\n\n:::\n\nFrequently asked questions​\nCan I point to my product from core docs? For example - if my product hosts a public RPC endpoint, can I add it to your RPC endpoints and providers page?​\n\nThese types of contributions are generally not merged unless they're submitted by employees of Offchain Labs.\n\nInstead of opening a PR for this type of contribution, click the Request an update button at the top of the published document to create an issue. Generally, third-party services are included in core docs only if we can confidently assert that the services are \"trustworthy, highly relevant to the core document at hand, and battle-tested by Arbitrum developers\" under a reasonable amount of scrutiny.\n\nCan I use AI-generated content?​\n\n\"No\". By issuing PRs into our docs repo, you're acknowledging that your content has been produced organically. Content produced under the influence of AI/ML tooling, such as ChatGPT, is \"strictly not allowed\".\n\nShould I be wary of contributing to FAQs and Glossaries? It looks like there are some automations configured against these document types.​\n\nYou're right! We draft FAQs and Glossaries on Notion to make it easier for nontechnical internal contributors to contribute. This content is then published to our docs repo using a script that reads from Notion and writes to Markdown.\n\nYou can still submit changes to the Glossary and FAQ markdown files; we manually synchronize these types of changes with Notion content whenever we need to.\n\nHow long does it take for my third-party content contribution to be reviewed?​\n\nOur small-but-mighty team is continuously balancing competing priorities, so we can't guarantee a specific turnaround time for third-party docs PRs. They're processed in the order in which they're received, generally within a week or two.\n\nIs there any way to expedite third-party content contribution reviews?​\n\nThe most effective way to expedite processing is to ensure that your PR incorporates the conventions outlined in this document. Please don't ask for status updates - if you've submitted a PR, it's on our radar!\n\nEdit this page\nLast updated on Nov 21, 2024\nPrevious\nGlossary\nNext\nOracles overview\nAdd a new core document\nAdd a new third-party document\nRequest an update\nAdd a new translation page\nDocument type conventions\nStyle conventions\nBanner conventions\nFrequently asked questions\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/intro/glossary",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nArbitrum glossary\nActive Validator​\n\nA staked Validator that makes disputable assertions to advance the state of an Arbitrum chain or to challenge the validity of others' assertions. (Not to be confused with the Sequencer ).\n\nAddress Alias​\n\nAn address deterministically generated from an L1 contract address used on L2 to safely identify the source of an L1 to L2 message.\n\nArb Token Bridge​\n\nA series of contracts on an Arbitrum chain and its underlying chain that facilitate trustless movement of ERC-20 tokens between the two layers.\n\nArbified Token List​\n\nA token list that conforms to Uniswap's token list specification; Arbified lists are generated by inputting externally maintained list (i.e., coinmarketcap's list) and outputting a list that includes all of the instances of token contracts on the Arbitrum chain bridged via the canonical Arb Token Bridge from tokens on the inputted list. (See code here.)\n\nArbitrum​\n\nA suite of Ethereum layer-2 scaling technologies built with the Arbitrum Nitro tech stack that includes Arbitrum One (a live implementation of the Arbitrum Rollup Protocol) and Arbitrum Nova (a live implementation of the Arbitrum AnyTrust Protocol).\n\nArbitrum AnyTrust Chain​\n\nAn Arbitrum chain that implements the Arbitrum AnyTrust Protocol.\n\nArbitrum AnyTrust Protocol​\n\nAn Arbitrum protocol that manages data availability with a permissioned set of parties known as the Data Availability Committee (DAC). This protocol reduces transaction fees by introducing an additional trust assumption for data availability in lieu of Ethereum's Trustless data availability mechanism. Arbitrum Nova is an example of an AnyTrust chain; Arbitrum One is an alternative chain that implements the purely trustless (and more L1-gas intensive) Arbitrum Rollup Protocol.\n\nArbitrum Bridge UI​\n\nWeb application built and maintained by Offchain Labs for user-interactions with the Arb Token Bridge; visit it here.\n\nArbitrum chain​\n\nA blockchain that runs on the Arbitrum protocol. Arbitrum chains are EVM compatible, and use an underlying EVM chain (e.g., Ethereum) for settlement and for succinct fraud-proofs (as needed). Arbitrum chains come in two forms: Arbitrum Rollup Chains and Arbitrum AnyTrust Chains.\n\nArbitrum Classic​\n\nOld Arbitrum stack that used custom virtual machine (\"AVM\"); no public Arbitrum chain uses the classic stack as of 8/31/2022 (they instead use Arbitrum Nitro ).\n\nArbitrum Full Node​\n\nA party who keeps track of the state of an Arbitrum chain and receives remote procedure calls (RPCs) from clients. Analogous to a non-staking L1 Ethereum node.\n\nArbitrum Nitro​\n\nCurrent Arbitrum tech stack; runs a fork of Geth and uses WebAssembly as its underlying VM for fraud proofs.\n\nArbitrum Nova​\n\nThe first Arbitrum AnyTrust Chain running on Ethereum mainnet. Introduces cheaper transactions; great for gaming and social use-cases. Implements the Arbitrum AnyTrust Protocol, not the Arbitrum Rollup Protocol protocol. Governed by the Arbitrum DAO.\n\nArbitrum One​\n\nThe first Arbitrum Rollup Chain running on Ethereum mainnet. Great for decentralized finance and other use-cases that demand strong security guarantees. Governed by the Arbitrum DAO.\n\nArbitrum Orbit​\n\nArbitrum Orbit refers to the ability for anyone to permissionlessly deploy Layer 3 (L3) chains on top of Arbitrum Layer 2 (L2) chains.\n\nArbitrum Rollup Chain​\n\nAn Arbitrum chain that implements the Arbitrum Rollup Protocol.\n\nArbitrum Rollup Protocol​\n\nA trustless, permissionless Arbitrum protocol that uses its underlying base layer for data availability and inherits its security. This protocol is implemented by our Arbitrum One chain.\n\nArbOS​\n\nArbitrum's \"operating system\" that trustlessly handles system-level operations; includes the ability to emulate the EVM.\n\nAssertion​\n\nA staked claim by an Arbitrum Validator. An assertion may, e.g., propose a new RBlock, or may be a step in a Challenge.\n\nAuction Contract​\n\nA smart contract that handles the state, accounting of funds for bids, and various operations of the Timeboost auction. The contract is deployed on the target chain for which Timeboost is enabled.\n\nAutonomous Auctioneer​\n\nOff chain software that receives bids from Timeboost participants, processes and validates bids, and then posts the top valid bid (or top two valid bids in the case of a tie) to the Auction Contract to resolve the on-going Timeboost auction. The autonomous auctioneer, for a given chain, is provisioned & deployed by an entity designated by the chain's owner.\n\nBatch​\n\nA group of Arbitrum transactions posted in a single transaction on the Underlying Chain into the Fast Inbox by the Sequencer.\n\nBlockchain​\n\nA distributed digital ledger that is used to record transactions and store data in a secure, transparent, and tamper-resistant way, notably in cryptocurrency protocols.\n\nBLS Signature​\n\nA cryptographic scheme that allows multiple signatures to be aggregated and compacted into one efficiently verifiable, constant-sized signature. Used in the Arbitrum AnyTrust Protocol for the Data Availability Committee (DAC)'s signatures.\n\nBoLD​\n\nShort for \"Bounded Liquidity Delay\"; latest version of the Arbitrum Challenge protocol designed to eliminate delay attack vectors (see here for more). Not currently on mainnet.\n\nBridge​\n\nA set of smart contracts for sending Cross-chain messages between blockchains. Every Arbitrum chain includes a bridge to/from its Parent chain.\n\nChain Owner​\n\nAn entity (i.e., a smart contract) with affordance to carry out critical upgrades to an Arbitrum chain's core protocol; this includes upgrading protocol contracts, setting core system parameters, and adding and removing other chain owners.\n\nChain state​\n\nA particular point in the history of an Arbitrum chain. A chain's state is determined by applying Arbitrum state-transition function to sequence of transactions (i.e., the chain's history).\n\nChallenge​\n\nWhen two Stakers disagree about the correct verdict on an Assertion, those stakers can be put in a challenge. The challenge is refereed by the contracts on the underlying chain. Eventually one staker wins the challenge. The protocol guarantees that an honest party will always win a challenge; the loser forfeits their stake.\n\nChallenge Period​\n\nWindow of time (1 week on Arbitrum One) over which an asserted RBlock can be challenged, and after which the RBlock can be confirmed.\n\nChallenge protocol​\n\nThe protocol by which RBlocks are submitted, disputed, and ultimately confirmed. The Challenge Protocol guarantees that only valid RBlocks will be confirmed provided that there is at least one honest Active Validator.\n\nChild chain​\n\nAn Arbitrum Chain that settles to an underlying Parent chain . For example, Arbitrum One and Arbitrum Nova are child chains of Ethereum.\n\nClient​\n\nA program running on a user's machine, often in the user's browser, that interacts with contracts on an Arbitrum chain and provides a user interface.\n\nConfirmation​\n\nThe decision by an Arbitrum chain to finalize an RBlock as part of the chain's history. Once an RBlock is confirmed its L2 to L1 Messages (e.g., withdrawals) can be executed.\n\nCross-chain message​\n\nAn action taken on some chain A which asynchronously initiates an additional action on chain B.\n\nCustom Arb-Token​\n\nAny L2 token contract registered to the Arb Token Bridge that isn't a standard arb-token (i.e., a token that uses any gateway other than the StandardERC20 gateway ).\n\nCustom gateway​\n\nAny Token Gateway that isn't the StandardERC20 gateway.\n\ndApp​\n\nShort for \"decentralized application.\" A dApp typically consists of smart contracts as well as a user-interface for interacting with them.\n\nData Availability Certificate​\n\nSigned promise from a Data Availability Committee (DAC) attesting to the availability of a batch of data for an Arbitrum AnyTrust Chain.\n\nData Availability Committee (DAC)​\n\nA permissioned set of parties responsible for enforcing data availability in an Arbitrum AnyTrust Protocol chain. See Introducing AnyTrust Chains: Cheaper, Faster L2 Chains with Minimal Trust Assumptions to learn more.\n\nDefensive Validator​\n\nA Validator that watches an Arbitrum chain and takes action (i.e., stakes and challenges) only when and if an invalid Assertion occurs.\n\nDelayed Inbox​\n\nA contract that holds Parent chain initiated messages to be eventually included in the Fast Inbox. Inclusion of messages doesn't depend on the Sequencer.\n\nDev-Tools Dashboard​\n\nWeb application built and maintained by Offchain Labs for developers and users to debug Arbitrum transactions; i.e., executing or checking the status of Cross-chain messages; visit it here.\n\nDissection​\n\nA step in the Challenge protocol in which two challenging parties interactively narrow down their disagreement until they reach a One Step Proof.\n\nEthereum Wallet​\n\nA software application used for transacting with the Ethereum Blockchain.\n\nEVM+​\n\nThe paradigm introduced by Stylus in which Arbitrum's EVM compatibility is preserved while new features and improvements are introduced.\n\nExpress Lane​\n\nA component of Timeboost, the express lane is a special endpoint on the Sequencer that immediately sequences incoming, valid transactions signed by the current express lane controller.\n\nExpress Lane Controller​\n\nAn address, defined in the Auction Contract, that is granted the privilege to use the Express Lane. These privileges are granted after verifying that the incoming transactions were properly signed by the express lane controller, among other checks.\n\nFair Ordering Algorithm​\n\nBFT algorithm in which a committee comes to consensus on transaction ordering; current single-party Sequencer on Arbitrum may eventually be replaced by a fair-ordering committee.\n\nFast Exit / Liquidity Exit​\n\nA means by which a user can bypass an Arbitrum chain's Challenge Period when withdrawing fungible assets (or more generally, executing some \"fungible\" L2 to L1 operation); for trustless fast exits, a liquidity provider facilitates an atomic swap of the asset on L2 directly to L1.\n\nFast Inbox​\n\nContract that holds a sequence of messages sent by clients to an Arbitrum Chain; a message can be put into the fast Inbox directly by the Sequencer or indirectly through the Delayed Inbox.\n\nFirst Come First Serve (FCFS)​\n\nA type of Transaction Ordering Policy used by the sequencer in Arbitrum chains whereby incoming transactions are sequenced into a block in the order that the transactions arrived.\n\nForce-Inclusion​\n\nCensorship resistant path for including a message into an Arbitrum chain via the Delayed Inbox on its Parent chain; bypasses any Sequencer involvement.\n\nFraud proof​\n\nThe means by which an Active Validator proves to its underlying chain that an invalid state transition has taken place.\n\nGas Price Floor​\n\nProtocol-enforced minimum gas price on an Arbitrum chain; currently 0.1 gwei on Arbitrum One and 0.01 gwei on Arbitrum Nova.\n\nGateway Router​\n\nContracts in the Arb Token Bridge responsible for mapping tokens to their appropriate Token Gateway.\n\nGeneric-Custom Gateway​\n\nA particular Custom gateway via which an L1 token contract can be registered to a token contract deployed to L2. A useful alternative to the StandardERC20 gateway for projects that wish to control the address of their L2 token contract, maintain L2 token contract upgradability, and for various other use-cases.\n\nGeth​\n\nAn execution-layer client that defines the Ethereum state transition function and handles network-layer logic like transaction memory pooling. Arbitrum Nitro utilizes a fork of Geth to implement Arbitrum's state transition function.\n\nInk​\n\nThe equivalent of gas in the Stylus vm. Ink is introduced for finer granularity than gas offers since Stylus's operations are considerably cheaper than their EVM analogs.\n\nL2 Block​\n\nData structure that represents a group of L2 transactions (analogous to L1 blocks).\n\nL2 to L1 Message​\n\nA message initiated from within an Arbitrum chain to be eventually executed on Layer 1 (L1) (e.g., token or Ether withdrawals). On Rollup chains like Arbitrum One, the Challenge Period must pass before an L2 to L1 message is executed.\n\nLayer 1 (L1)​\n\nThe base protocol and underlying blockchain of the Ethereum network. Responsible for maintaining the integrity of the distributed ledger and executing smart contracts. Contains both Ethereum's execution layer and consensus layer.\n\nLayer 2 (L2)​\n\nTrustless scaling solutions built on top of Ethereum's Layer 1 (L1) base protocol, such as state channels, plasma chains, optimistic rollups, and ZK-rollups. Layer 2 solutions aim to increase scalability and reduce the cost of transactions on Ethereum's Layer 1 without introducing additional trust assumptions.\n\nLayer 3 (L3)​\n\nAn Arbitrum chain whose core contract reside on an Arbitrum Layer 2 (L2) chain.\n\nNative Fee Token​\n\nAn ERC-20 token used as the native currency for gas fees on an Arbitrum chain (i.e., as opposed to using Ether). Arbitrum Orbit introduced the option for chains to use native fee tokens.\n\nOffchain Labs​\n\nThe initial builders Arbitrum; current contributors to the Arbitrum ecosystem and service providers to the Arbitrum DAO. Offchain also runs and maintains the Sequencers for Arbitrum One and Arbitrum Nova.\n\nOne Step Proof​\n\nFinal step in a challenge; a single operation of the Arbitrum VM (WASM ) is executed on the underlying chain, and the validity of its state transition is verified.\n\nOutbox​\n\nAn L1 contract responsible for tracking L2 to L1 Messages, including withdrawals, which can be executed once they are confirmed. The outbox stores a Merkle Root of all outgoing messages.\n\nParent chain​\n\nEVM compatible chain that acts as the settlement layer for one or more Arbitrum Chains (aka Child chain ). E.g., Ethereum is the parent chain of both Arbitrum One and Arbitrum Nova. Parent chain is synonymous with \"underlying chain.\"\n\nPortal​\n\nA web application maintained by Offchain Labs showcasing the Arbitrum ecosystem; visit it here.\n\nRBlock​\n\nAn assertion by an Arbitrum Validator that represents a claim about an Arbitrum chain's state.\n\nReorg​\n\nA situation in which transactions on a chain that were at some point considered accepted then get rejected. In the context of an Arbitrum chain, once transactions are posted in the chain's Fast Inbox, the only way the chain can experience a reorg is if its Underlying Chain itself reorgs. Of note, Fraud proofs do not cause reorgs.\n\nRetryable Autoredeem​\n\nThe \"automatic\" (i.e., requiring no additional user action) execution of a Retryable Ticket on an Arbitrum chain.\n\nRetryable Redeem​\n\nThe execution of a Retryable Ticket on L2; can be automatic (see Retryable Autoredeem) or manual via a user-initiated L2 transaction.\n\nRetryable Ticket​\n\nAn L1 to L2 cross chain message initiated by an L1 transaction sent to an Arbitrum chain for execution (e.g., a token deposit).\n\nReverse Token Gateway​\n\nA Token Gateway in which the Child chain gateway contract escrows and releases tokens, which the Parent chain Gateway contract mints and burns tokens. This in the inverse to how \"typical\" gateways work.\n\nSequencer​\n\nAn entity (currently a single-party on Arbitrum One) given rights to reorder transactions in the Fast Inbox over a fixed window of time, who can thus give clients sub-blocktime Soft Confirmations. (Not to be confused with a Validator).\n\nSequencer Feed​\n\nOff chain data feed published by the Sequencer which clients can subscribe to for Soft Confirmations of transactions before they are posted in Batches.\n\nShared Sequencing​\n\nA protocol design space in which multiple rollups use the same entity as their Sequencer; potential benefits include enhanced interoperability and credible neutrality.\n\nSmart Contract​\n\nA computer program whose operations are defined and executed within a blockchain consensus protocol.\n\nSoft Confirmation​\n\nA semi-trusted promise from the Sequencer to post a user's transaction in the near future; soft-confirmations happen prior to posting on the Parent chain, and thus can be given near-instantaneously (i.e., faster than the parent chain's block times)\n\nSpeed Limit​\n\nTarget computation limit for an Arbitrum chain. Arbitrum One and Arbitrum Nova currently target 7,000,000 gas / second. When computation exceeds this limit, fees rise, ala EIP-1559.\n\nStaker​\n\nA Validator who deposits a stake (in Ether on Arbitrum One and Arbitrum Nova ) to vouch for a particular RBlock in an Arbitrum Chain. A validator who stakes on a false RBlock can expect to lose their stake. An honest staker can recover their stake once the RBlock they are staked on has been confirmed.\n\nStandard Arb-Token​\n\nAn token contract on an Arbitrum chain deployed via the StandardERC20 gateway; offers basic ERC20 functionality in addition to deposit / withdrawal affordances.\n\nStandardERC20 gateway​\n\nToken Gateway via which any underlying chain's ERC20 token can permissionlessly bridge; the StandardERC20 gateway contracts deploy a Standard Arb-Token on the Child chain for each bridged token.\n\nState Transition Function​\n\nThe STF (State Transition Function) defines how new blocks are produced from input messages (i.e. transactions) in an Arbitrum chain.\n\nStylus​\n\nUpgrade to the Arbitrum Nitro virtual machine that allows smart contract support for languages like Rust and C++ by taking advantage of Nitro's use of WASM. Currently on testnet (read more).\n\nTimeboost​\n\nA transaction ordering policy in which entities can bid for the right to access an express lane on the Sequencer for faster transaction inclusion. See the research specification to learn more.\n\nToken Gateway​\n\nA pair of contracts in the token bridge — one on the Parent chain , one on the Child chain — that provide a particular mechanism for handling the transfer of tokens between layers. Token gateways currently active in the bridge include the StandardERC20 gateway , the Generic-Custom Gateway , and the WETH Gateway.\n\nTransaction​\n\nA user-initiated interaction with a Blockchain. Transactions are typically signed by users via wallets and are paid for via transaction fees.\n\nTransaction Ordering Policy​\n\nThe rules and logic employed by a chain to order incoming transactions into a block.\n\nTrustless​\n\nIn the context of Ethereum, trustless refers to the ability of a system to operate without reliance on a central authority or intermediary. Instead, users place their trust in math and protocols.\n\n\n\n\n\nThis is achieved through the use of cryptographic techniques and decentralized consensus mechanisms that let users verify the integrity of network transactions using open-source software. Trustless systems are considered to be more secure and resistant to fraud or tampering because they don't rely on a single point of failure that can be exploited by attackers.\n\nUnderlying Chain​\n\nSynonymous with Parent chain.\n\nValidator​\n\nAn Arbitrum Full Node that tracks the status of the chains' Assertions. A validator may be a Watchtower Validator, a Defensive Validator, or an Active Validator.\n\nWASM​\n\nWidely supported binary code format for executable programs. Used by Arbitrum Nitro for Fraud proofs , and more broadly used by Stylus to support performant smart contracts in a wide variety of languages.\n\nWASMer​\n\nA popular WebAssembly runtime for executing WASM binaries. A fork of WASMer is used for executing Stylus programs. WASMer executes considerably faster than Geth executes EVM code, contributing to Stylus's lower fees.\n\nWatchtower Validator​\n\nA Validator that never stakes / never takes on chain action, who raises the alarm (by whatever off-chain means it chooses) if it witnesses an invalid assertion.\n\nWETH Gateway​\n\nToken Gateway for handing the bridging of wrapped Ether (WETH). WETH is unwrapped on L1 and rewrapped on L1 upon depositing (and vice-versa upon withdrawing), ensuring WETH on L2 always remains collateralized.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nFAQ\nNext\nContribute docs\nActive Validator\nAddress Alias\nArb Token Bridge\nArbified Token List\nArbitrum\nArbitrum AnyTrust Chain\nArbitrum AnyTrust Protocol\nArbitrum Bridge UI\nArbitrum chain\nArbitrum Classic\nArbitrum Full Node\nArbitrum Nitro\nArbitrum Nova\nArbitrum One\nArbitrum Orbit\nArbitrum Rollup Chain\nArbitrum Rollup Protocol\nArbOS\nAssertion\nAuction Contract\nAutonomous Auctioneer\nBatch\nBlockchain\nBLS Signature\nBoLD\nBridge\nChain Owner\nChain state\nChallenge\nChallenge Period\nChallenge protocol\nChild chain\nClient\nConfirmation\nCross-chain message\nCustom Arb-Token\nCustom gateway\ndApp\nData Availability Certificate\nData Availability Committee (DAC)\nDefensive Validator\nDelayed Inbox\nDev-Tools Dashboard\nDissection\nEthereum Wallet\nEVM+\nExpress Lane\nExpress Lane Controller\nFair Ordering Algorithm\nFast Exit / Liquidity Exit\nFast Inbox\nFirst Come First Serve (FCFS)\nForce-Inclusion\nFraud proof\nGas Price Floor\nGateway Router\nGeneric-Custom Gateway\nGeth\nInk\nL2 Block\nL2 to L1 Message\nLayer 1 (L1)\nLayer 2 (L2)\nLayer 3 (L3)\nNative Fee Token\nOffchain Labs\nOne Step Proof\nOutbox\nParent chain\nPortal\nRBlock\nReorg\nRetryable Autoredeem\nRetryable Redeem\nRetryable Ticket\nReverse Token Gateway\nSequencer\nSequencer Feed\nShared Sequencing\nSmart Contract\nSoft Confirmation\nSpeed Limit\nStaker\nStandard Arb-Token\nStandardERC20 gateway\nState Transition Function\nStylus\nTimeboost\nToken Gateway\nTransaction\nTransaction Ordering Policy\nTrustless\nUnderlying Chain\nValidator\nWASM\nWASMer\nWatchtower Validator\nWETH Gateway\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/learn-more/faq",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nArbitrum FAQ\nWhy do I need ETH to use the Arbitrum network?​\n\nETH is the currency used to pay gas fees on Arbitrum, and all Arbitrum transactions are powered by ETH. You can bridge ETH (and other tokens) from Ethereum to Arbitrum through Arbitrum's bridge.\n\nDo I need to pay a tip or priority fee for my Arbitrum transactions?​\n\nSince transactions are processed in the order that the Sequencer receives them, no priority fee is necessary for Arbitrum transactions; if a transaction does include a priority fee, it will be refunded to the transaction's origin address at the end of the execution.\n\nHow can I see the balance of ETH and other tokens in my wallet on Arbitrum?​\n\nMost wallets are \"connected\" to one given network at a time. To view your ETH or token balances, ensure that you are connected to the appropriate Arbitrum chain. In MetaMask, you can switch networks via the \"networks\" dropdown. In this dropdown, select your desired network (either Arbitrum One or Arbitrum Nova for our mainnet networks). If your desired network hasn't been added to your wallet yet, you can add it at https://bridge.arbitrum.io/.\n\nWhat happens if I send my funds to an exchange that doesn't support Arbitrum?​\n\nIf you send the funds and the receiving wallet/exchange doesn't support the Arbitrum network you are sending funds through, there is unfortunately nothing that we can do to recover your funds. You would need to contact the wallet/exchange support and see if they can do anything to help you retrieve the funds.\n\nDoes Arbitrum have a mempool?​\n\nThe Arbitrum Sequencer orders transactions on a first come, first served basis; the Sequencer inserts transactions into a queue based on the order they are received and executes them accordingly. This queue thus exists in lieu of a mempool. The Sequencer's queue has no space limit; transactions on the queue will eventually timeout and be discarded if not executed in time. Under normal conditions, the queue is empty, since transactions are executed near-instantaneously.\n\nWhat's the difference between Arbitrum Rollup and Arbitrum AnyTrust?​\n\nArbitrum Rollup is an Optimistic Rollup protocol; it is trustless and permissionless. Part of how these properties are achieved is by requiring all chain data to be posted on layer 1. This means the availability of this data follows directly from the security properties of Ethereum itself, and, in turn, that any party can participate in validating the chain and ensuring its safety. For more information, see Inside Arbitrum Nitro.\n\nBy contrast, Arbitrum AnyTrust introduces a trust assumption in exchange for lower fees; data availability is managed by a Data Availability Committee (DAC), a fixed, permissioned set of entities. We introduce some threshold, K, with the assumption that at least K members of the committee are honest. For simplicity, we'll hereby assume a committee of size 20 and a K value of 2:\n\nIf 19 out of the 20 committee members and the Sequencer are malicious and colluding together, they can break the chain's safety (and, e.g., steal users' funds); this is the new trust assumption.\n\nIf anywhere between 2 and 18 of the committee members are well behaved, the AnyTrust chain operates in \"Rollup mode\"; i.e., data gets posted on L1.\n\nIn what should be the common and happy case, however, in which at least 19 of the 20 committee members are well behaved, the system operates without posting the L2 chain's data on L1, and thus, users pay significantly lower fees. This is the core upside of AnyTrust chains over rollups.\n\nVariants of the AnyTrust model in which the new trust assumption is minimized are under consideration; stay tuned.\n\nFor more, see Inside AnyTrust.\n\nHow can I check the status of my cross chain message?​\n\nYou can check the status of any Arbitrum cross chain message at https://retryable-dashboard.arbitrum.io/ (you will also be able to execute the cross chain message there, if applicable).\n\nYou'll need the transaction hash of the \"initiating transaction\": the L1 transaction hash for an L1-to-L2 message (e.g., a deposit), or the L2 transaction hash for an L2-to-L1 message (e.g., a withdrawal).\n\nIf you cross-chain message was initiated from https://bridge.arbitrum.io/, you can also check its status / execute it at that site in the transaction history tab.\n\nIf there is a dispute, can my L2 transaction get reorged / thrown out / \"yeeted\"?​\n\nNope; once an Arbitrum transaction is included on L1, there is no way it can be reorged (unless the L1 itself reorgs, of course). A \"dispute\" involves Validators disagreeing over execution, i.e., the outputted state of a chain. The inputs, however, can't be disputed; they are determined by the Inbox on L1. (See Transaction Lifecycle)\n\n...okay but if there's a dispute, will my transaction get delayed?​\n\nThe only thing that a dispute can add delay to is the confirmation of L2-to-L1 messages. All other transactions continue to be processed, even while a dispute is still undergoing. (Additionally: in practice, most L2-to-L1 messages represent withdrawals of fungible assets; these can be trustlessly completed even during a dispute via trustless fast \"liquidity exit\" applications. See L2-to-L1 Messages).\n\nAre \"Sequencers\" the same entities as \"Validators\"? Can a centralized Sequencer act maliciously (e.g., steal all my money)?​\n\nNo and no!\n\nAn Arbitrum Chain's Sequencer(s) and Validators and completely distinct entities, with their own distinct roles.\n\nThe Sequencer is the entity granted specific privileges over ordering transactions; once the Sequencer commits to an ordering (by posting a batch on Ethereum), it has no say over what happens next (i.e., execution). A malicious/faulty Sequencer can do things like reordering transactions or temporarily delaying a transaction's inclusion — things which could be, to be sure, annoying and bad — but can do nothing to compromise the chain's safety.\n\nThe Validators are the ones responsible for the safety of the chain; i.e., making staked claims about the chain state, disputing each other, etc.\n\nCurrently, on Arbitrum One, the Sequencer is a centralized entity maintained by Offchain Labs. Eventually, we expect the single Sequencer to be replaced by a distributed committee of Sequencers who come to consensus on transaction ordering. This upgrade will be an improvement; we don't want you to have to trust us not to reorder your transactions. However, it also isn't strictly necessary for Arbitrum One to achieve its most fundamental properties.\n\nIn other words: An Arbitrum Rollup chain with a centralized Sequencer could theoretically still be trustless!\n\nWhich is to say — the more important thing than decentralizing the Sequencer, i.e., the thing you ought to care more about — is decentralizing the Validators.\n\nArbitrum One's validator set is currently allowlisted; over time, we expect governance to expand the allowlist and eventually be removed entirely.\n\nFor more info see \"State of Progressive Decentralization\".\n\nWhy was \"one week\" chosen for Arbitrum One's dispute window?​\n\nGenerally, some amount of time is necessary for the Arbitrum validators to dispute an invalid assertion.\n\nA week is expected to be more than enough time for validators to carry out an interactive dispute, assuming they don't encounter difficulty in getting their transactions included on L1. One week was chosen following the general consensus among the Ethereum research community — as well as other layer 2 projects — to provide enough time for the community to socially coordinate in the case of a coordinated Ethereum-staker censorship attack.\n\nWhat's the state of Arbitrum One's decentralization?​\n\nSee \"State of Progressive Decentralization\", or check out the work of our friends at L2BEAT.\n\nAre there any Fiat on-ramps that support Arbitrum?​\n\nYes, you can find a list of Fiat on-ramps that support Arbitrum on our portal.\n\nHow many blocks are needed for a transaction to be confirmed/finalized in Arbitrum?​\n\nThere are two levels of finality in a transaction lifecycle:\n\nSoft finality: once the Sequencer receives and processes a transaction, it emits a receipt through the Sequencer's feed. At this point, if the Sequencer is trusted, the transaction will not be reordered and the state of the chain after processing the transaction can be determined.\nHard finality: at this stage, assuming there's at least one well-behaved active Arbitrum validator, the client can treat their transaction's finality as equivalent to an ordinary Ethereum transaction.\n\nWhere can I find stats for Arbitrum?​\n\nAlthough we currently don't maintain any stats dashboard for Arbitrum, you can find many community created dashboards in Dune.\n\nWill transactions with a higher \"gas price bid\" be confirmed first?​\n\nThere is no notion of mempool on Arbitrum, transactions are processed on a first come first served basis by the Sequencer. Thus, the gas price bid parameter does not influence the order in which a transaction is processed.\n\nWhere can I find a list of the current validators of the Arbitrum chains?​\n\nValidation on both Arbitrum One and Arbitrum Nova is currently allow-listed to a committee of public entities. You can see the list of validators here. Governance currently has the power to change this status.\n\nWhere can I find the current Data Availability Committee members?​\n\nThe Arbitrum Nova chain has a 7-party DAC, whose members can be seen here. Governance has the ability to remove or add members to the committee.\n\nCan I withdraw my funds from Arbitrum back to Ethereum without going through the Sequencer? What about funds that are in a contract?​\n\nYes, it is possible to permissionlessly send a message from Ethereum to be executed on Arbitrum, while bypassing the Sequencer. You can do this by using the DelayedInbox contract and force-including the message after a certain amount of time has passed (currently ~24 hours). You can find more information about this behavior here.\n\nKeep in mind that you can execute any message in this way, be it a withdrawal of funds back to Ethereum, or a call to a contract.\n\nYou can also find an example of force-inclusion in this tutorial.\n\nAre there any plans to reduce the time a transaction needs to wait before being able to be force-included from Ethereum into the Arbitrum chain, bypassing the sequencer? (Currently 24 hours)​\n\nThe mechanism that allows force-including transactions from Ethereum (bypassing the sequencer) is intended to be used in very rare cases, especially when it is expected that the sequencer will not be operational again, so that users have a way of interacting with Arbitrum in a trustless way.\n\nWhen using this mechanism, if the sequencer is down for longer than the time window for force-including transactions from Ethereum, the moment it is online again, it can lead to a reorganization of blocks in Arbitrum (it would have received transactions timestamped before the force-included one).\n\n24 hours was chosen because it provides a comfortable period of time for the team running the sequencer infrastructure to fix any bugs that may cause the sequencer to not work. While there aren't any active initiatives to lower that time, the decision ultimately falls in the hands of the Arbitrum DAO, who has discussed the topic in their governance forum (see here for more information).\n\nIn any case, we could also analyze why would someone use this mechanism having an honest and functional sequencer. For instance, if the reason is a distrust of the sequencer, a centralised agent as of now, one potential solution could be to decentralize the sequencer instead of reducing the force-inclusion delay time.\n\nWhat is the difference between an L2 block and a RBlock?​\n\nAn L2 block is very similar to the concept of an L1 block. These blocks are generated by validator nodes of Arbitrum by executing the state transition function on sequenced transactions. The structure of an L2 block is similar to that of an Ethereum block, with a few differences that you can see here.\n\nOn the other hand, an RBlock is a distinctive block that is transmitted back to L1 to serve as a fingerprint of the most recent state of the Arbitrum chain. It comprises an assertion of the present state root of the Arbitrum chain and other essential information pertaining to withdrawals and challenges. The structure of RBlocks can be viewed here.\n\nThese RBlocks are also generated by validators, but they are appended to the L1 chain. Other validators can challenge them during a specific time frame of approximately one week if they discover that the current state hash of the chain varies from the one that was initially claimed. Once the challenge period elapses, the RBlock is confirmed on L1.\n\nWhy do Arbitrum chains enforce a speed limit? Isn't it better that the speed grows without limits?​\n\nThe transaction lifecycle sets a limit that we have to take into account: validators have to execute each transaction, get the status of the chain, and post an assertion to Ethereum every certain amount of time. If the speed of the chain increases too much, there is a risk that validators won't have enough computation power to process all transactions in a timely manner, and will fall behind on validating them, which would cause the chain to delay confirmations of its state.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nPublic preview\nNext\nGlossary\nWhy do I need ETH to use the Arbitrum network?\nDo I need to pay a tip or priority fee for my Arbitrum transactions?\nHow can I see the balance of ETH and other tokens in my wallet on Arbitrum?\nWhat happens if I send my funds to an exchange that doesn't support Arbitrum?\nDoes Arbitrum have a mempool?\nWhat's the difference between Arbitrum Rollup and Arbitrum AnyTrust?\nHow can I check the status of my cross chain message?\nIf there is a dispute, can my L2 transaction get reorged / thrown out / \"yeeted\"?\n...okay but if there's a dispute, will my transaction get delayed?\nAre \"Sequencers\" the same entities as \"Validators\"? Can a centralized Sequencer act maliciously (e.g., steal all my money)?\nWhy was \"one week\" chosen for Arbitrum One's dispute window?\nWhat's the state of Arbitrum One's decentralization?\nAre there any Fiat on-ramps that support Arbitrum?\nHow many blocks are needed for a transaction to be confirmed/finalized in Arbitrum?\nWhere can I find stats for Arbitrum?\nWill transactions with a higher \"gas price bid\" be confirmed first?\nWhere can I find a list of the current validators of the Arbitrum chains?\nWhere can I find the current Data Availability Committee members?\nCan I withdraw my funds from Arbitrum back to Ethereum without going through the Sequencer? What about funds that are in a contract?\nAre there any plans to reduce the time a transaction needs to wait before being able to be force-included from Ethereum into the Arbitrum chain, bypassing the sequencer? (Currently 24 hours)\nWhat is the difference between an L2 block and a RBlock?\nWhy do Arbitrum chains enforce a speed limit? Isn't it better that the speed grows without limits?\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Write Stylus Contracts | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/stylus/stylus-overview",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nWrite Stylus Contracts\n\nLet's learn how to write contracts with Stylus!\n\nA gentle introduction\n\nStart with the basics of Stylus contracts.\n\nQuickstart (Rust)\n\nGet started quickly with Rust.\n\nTestnet\n\nExplore the testnet environment.\n\nStylus by example\n\nLearn Stylus through examples.\n\nStylus Rust SDK\n\nDive into the Stylus Rust SDK.\n\nGas, ink and caching\n\nLearn about gas, ink, and caching strategies.\n\nCLI tools (cargo-stylus)\n\nMaster the CLI tools for Stylus.\n\nRun a Stylus dev node\n\nSet up and run a development node.\n\nOther supported languages\n\nExplore other languages supported by Stylus.\n\nTroubleshooting\n\nFind solutions to common issues.\n\nSource code repository\n\nCheck out the source code.\n\nPublic preview\n\nView the public preview of Stylus.\n\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nFAQ\nNext\nA gentle introduction\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/for-devs/dev-tools-and-resources/chain-info",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nA gentle introduction\nQuickstart (Rust)\nChain info\nArbiscan contract verification\nStylus Rust SDK\nGas, ink and caching\nCLI tools (cargo-stylus)\nRun a Stylus dev node\n↑\nOther supported languages\nTroubleshooting\nSource code repository\nPublic preview\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nArbitrum chain information\nArbitrum public RPC endpoints​\nCAUTION\nUnlike the RPC Urls, the Sequencer endpoints only support eth_sendRawTransaction and eth_sendRawTransactionConditional calls.\nArbitrum public RPCs do not provide Websocket support.\nVisit Quicknode's Arbitrum Sepolia faucet for testnet Sepolia tokens on L2.\n\nThis section provides an overview of the available public RPC endpoints for different Arbitrum chains and necessary details to interact with them.\n\nName\tRPC Url(s)\tChain ID\tBlock explorer\tUnderlying chain\tTech stack\tSequencer feed URL\tSequencer endpoint⚠️\nArbitrum One\thttps://arb1.arbitrum.io/rpc\t42161\tArbiscan, Blockscout\tEthereum\tNitro (Rollup)\twss://arb1.arbitrum.io/feed\thttps://arb1-sequencer.arbitrum.io/rpc\nArbitrum Nova\thttps://nova.arbitrum.io/rpc\t42170\tArbiscan, Blockscout\tEthereum\tNitro (AnyTrust)\twss://nova.arbitrum.io/feed\thttps://nova-sequencer.arbitrum.io/rpc\nArbitrum Sepolia (Testnet)\thttps://sepolia-rollup.arbitrum.io/rpc\t421614\tArbiscan, Blockscout\tSepolia\tNitro (Rollup)\twss://sepolia-rollup.arbitrum.io/feed\thttps://sepolia-rollup-sequencer.arbitrum.io/rpc\nMORE RPC ENDPOINTS\n\nMore Arbitrum chain RPC endpoints can be found in Chain Connect: Arbitrum One and Arbitrum Nova.\n\nAlternatively, to interact with public Arbitrum chains, you can rely on many of the same popular node providers that you are already using on Ethereum:\n\nThird-party RPC providers​\nWANT TO BE LISTED HERE?\n\nComplete this form , if you'd like to see your project added to this list (and the Arbitrum portal).\n\nProvider\tArb One?\tArb Nova?\tArb Sepolia?\tWebsocket?\tStylus Tracing?\n1RPC\t✅\t\t\t\t\nAlchemy\t✅\t✅\t✅\t✅\tAvailable on paid plans\nAllnodes\t✅\t✅\t\t✅\t\nAnkr\t✅\t\t\t✅\tAvailable on paid plans\nBlast\t✅\t✅\t\t✅\t\nBlockPi\t✅\t✅\t\t\t\nBlockVision\t✅\t\t\t\t\nChainbase\t✅\t\t\t✅\t\nChainnodes\t✅\t\t\t\t\nChainstack\t✅\t\t\t✅\tAvailable on paid plans\nDataHub\t✅\t\t\t\t\nDRPC\t✅\t✅\t\t✅\t\nGetBlock\t✅\t\t\t✅\t\nInfura\t✅\t\t✅\t✅\tEnabled on request\nLava\t✅\t✅\t\t\t\nMoralis\t✅\t\t\t\t\nNirvana Labs\t✅\t✅\t✅\t✅\t\nNodeReal\t✅\t✅\t\t\t\nNOWNodes\t✅\t\t\t\t\nPocket Network\t✅\t\t\t\t\nQuicknode\t✅\t✅\t✅\t✅\tTestnet supported in free tier\nUnifra\t✅\t\t\t\t\nTenderly\t✅\t✅\t✅\t✅\tTestnet supported in free tier\nArbitrum Smart Contract Addresses​\n\nThe following information may be useful to those building on Arbitrum. We list the addresses of the smart contracts related to the protocol, the token bridge and precompiles of the different Arbitrum chains.\n\nProtocol smart contracts​\nCore contracts​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nRollup\t0x5eF0...Ba35\t0xFb20...AD88\t0xd808...81C8\nSequencer Inbox\t0x1c47...82B6\t0x211E...c21b\t0x6c97...be0D\nCoreProxyAdmin\t0x5547...2dbD\t0x71D7...7148\t0x1ed7...0686\nCross-chain messaging contracts​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nDelayed Inbox\t0x4Dbd...AB3f\t0xc444...3949\t0xaAe2...ae21\nBridge\t0x8315...ed3a\t0xC1Eb...76Bd\t0x38f9...33a9\nOutbox\t0x0B98...4840\t0xD4B8...cc58\t0x65f0...B78F\nClassic Outbox***\t0x7607...1A40\n0x667e...337a\t\t\n\n***Migrated Network Only\n\nFraud proof contracts​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nChallengeManager\t0xe589...6f58\t0xA590...af0D\t0x84ED...0700\nOneStepProver0\t0x499A...EfcC\t0x8323...d236\t0xAF57...0ddA\nOneStepProverMemory\t0xb556...B676\t0x7a6C...9979\t0xA6Ac...f0c5\nOneStepProverMath\t0xd315...7970\t0x1efb...f2F5\t0xfEe5...42F4\nOneStepProverHostIo\t0xb965...D13A\t0x9CBC...7613\t0xA53a...752a\nOneStepProofEntry\t0x3E1f...A1DF\t0x7Adc...0Fc5\t0x08a2...5961\nToken bridge smart contracts​\nCore contracts​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nL1 Gateway Router\t0x72Ce...31ef\t0xC840...cD48\t0xcE18...8264\nL1 ERC20 Gateway\t0xa3A7...0EeC\t0xB253...21bf\t0x902b...3aFF\nL1 Arb-Custom Gateway\t0xcEe2...180d\t0x2312...232f\t0xba2F...40F3\nL1 Weth Gateway\t0xd920...e2db\t0xE4E2...0BaE\t0xA8aD...0e1E\nL1 Weth\t0xC02a...6Cc2\t0xC02a...6Cc2\t0x7b79...E7f9\nL1 Proxy Admin\t0x9aD4...0aDa\t0xa8f7...e560\t0xDBFC...44b0\n\nThe following contracts are deployed on the corresponding L2 chain\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nL2 Gateway Router\t0x5288...F933\t0x2190...DFa8\t0x9fDD...43C7\nL2 ERC20 Gateway\t0x09e9...1EEe\t0xcF9b...9257\t0x6e24...b502\nL2 Arb-Custom Gateway\t0x0967...5562\t0xbf54...51F4\t0x8Ca1...42C5\nL2 Weth Gateway\t0x6c41...623B\t0x7626...D9eD\t0xCFB1...556D\nL2 Weth\t0x82aF...Bab1\t0x722E...5365\t0x980B...7c73\nL2 Proxy Admin\t0xd570...2a86\t0xada7...d92C\t0x715D...5FdF\nThird party gateways​\n\nThe following contracts are deployed on Ethereum (L1)\n\n\tArbitrum One\nL1 Dai Gateway\t0xD3B5...3011\nL1 Livepeer Gateway\t0x6142...0676\n\nThe following contracts are deployed on the corresponding L2 chain\n\n\tArbitrum One\nL2 Dai Gateway\t0x4671...6C65\nL2 Livepeer Gateway\t0x6D24...D318\nPrecompiles​\n\nThe following precompiles are deployed on every L2 chain and always have the same address\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nArbAddressTable\t0x0000...0066\t0x0000...0066\t0x0000...0066\nArbAggregator\t0x0000...006D\t0x0000...006D\t0x0000...006D\nArbFunctionTable\t0x0000...0068\t0x0000...0068\t0x0000...0068\nArbGasInfo\t0x0000...006C\t0x0000...006C\t0x0000...006C\nArbInfo\t0x0000...0065\t0x0000...0065\t0x0000...0065\nArbOwner\t0x0000...0070\t0x0000...0070\t0x0000...0070\nArbOwnerPublic\t0x0000...006b\t0x0000...006b\t0x0000...006b\nArbRetryableTx\t0x0000...006E\t0x0000...006E\t0x0000...006E\nArbStatistics\t0x0000...006F\t0x0000...006F\t0x0000...006F\nArbSys\t0x0000...0064\t0x0000...0064\t0x0000...0064\nArbWasm\t-\t-\t0x0000...0071\nArbWasmCache\t-\t-\t0x0000...0072\nNodeInterface\t0x0000...00C8\t0x0000...00C8\t0x0000...00C8\nMisc​\n\nThe following contracts are deployed on the corresponding L2 chain\n\n\tArbitrum One\tArbitrum Nova\tArbitrum Sepolia\nL2 Multicall\t0x842e...4EB2\t0x5e1e...cB86\t0xA115...d092\nStylus​\nFaucets​\n\nBelow you can find faucets for obtaining testnet ETH. If using a faucet on Ethereum Sepolia or Arbitrum Sepolia, your testnet ETH can be bridged to the Stylus testnet on the Arbitrum Bridge.\n\nFaucet Operator\tFaucet URL\tChain\nQuickNode\thttps://faucet.quicknode.com/arbitrum/sepolia\tArbitrum Sepolia\nAlchemy\thttps://www.alchemy.com/faucets/arbitrum-sepolia\tArbitrum Sepolia\nSepolia PoW Faucet\thttps://sepolia-faucet.pk910.de/\tEthereum Sepolia\nEdit this page\nLast updated on Nov 18, 2024\nPrevious\nGet started\nNext\nQuickstart (Solidity)\nArbitrum public RPC endpoints\nThird-party RPC providers\nArbitrum Smart Contract Addresses\nProtocol smart contracts\nCore contracts\nCross-chain messaging contracts\nFraud proof contracts\nToken bridge smart contracts\nCore contracts\nThird party gateways\nPrecompiles\nMisc\nStylus\nFaucets\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "Arbitrum Docs",
    "url": "https://docs.arbitrum.io/welcome/get-started",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\nGet started with Arbitrum\n\nArbitrum is a suite of Ethereum scaling solutions that make it easy to build and use decentralized applications. This document provides a high-level overview of the Arbitrum suite along with onboarding guidance tailored to specific audiences.\n\nThe Arbitrum suite​\n\nThe Arbitrum suite includes the protocols, chains, services, and SDKs that power the Arbitrum ecosystem:\n\nComponent\tDescription\nArbitrum Rollup\tA protocol for scaling Ethereum smart contracts.\nArbitrum AnyTrust\tA protocol for scaling Ethereum smart contracts even further, with a mild trust assumption.\nArbitrum Nitro\tThe node software that codifies the Rollup and AnyTrust protocols.\nArbitrum nodes\tMachines that run Nitro in order to service and/or interact with an Arbitrum chain.\nArbitrum One\tA public Rollup chain.\nArbitrum Nova\tA public AnyTrust chain.\nArbitrum bridge\tLets you move ETH and ERC-20 tokens between Ethereum, Arbitrum, and select Orbit chains.\nArbitrum Orbit\tLets you run your own Rollup and AnyTrust chains.\nArbitrum Stylus\tLets you write EVM-compatible smart contracts in Rust and any other language that compiles to Wasm.\nArbitrum for users​\n\nUsers interact with Arbitrum either through the Arbitrum bridge or by using dApps that have been deployed to an Arbitrum chain.\n\nResource\tDescription\nArbitrum bridge\tLets you move ETH and ERC-20 tokens between Ethereum, Arbitrum, and select Orbit chains.\nArbitrum Portal\tA directory of dApps on Arbitrum.\nQuickstart (bridge)\tProvides step-by-step instructions for first-time bridge users.\nArbitrum for developers​\n\nDevelopers build Arbitrum dApps by deploying smart contracts to an Arbitrum chain.\n\nResource\tDescription\nA gentle introduction to Arbitrum\tA technical introduction to Arbitrum's suite of scaling solutions.\nQuickstart (Solidity)\tTargeted at web2 developers who want to deploy their first Solidity smart contract to Arbitrum.\nQuickstart (Rust)\tTargeted at web3 developers who want to deploy their first Rust smart contract to Arbitrum using Stylus.\nArbitrum for node runners​\n\nNode runners run the machines that support the Arbitrum ecosystem.\n\nResource\tDescription\nRun a full node\tTargeted at node runners who want to access Arbitrum chains without having to connect to a third-party node.\nConfigure a Data Availability Committee\tTargeted at Data Availability Committee members and Orbit chain operators who want to run a Data Availability Server.\nArbitrum for chain operators​\n\nChain operators use Arbitrum Orbit to run special-purpose Rollup and AnyTrust chains.\n\nResource\tDescription\nOrbit gentle introduction\tTargeted at readers who want to understand Orbit's value proposition and use cases.\nOrbit quickstart\tTargeted at chain operators who want to deploy their first Arbitrum chain using Arbitrum Orbit.\nHow it works​\nResource\tDescription\nInside Nitro\tA technical deep dive into Nitro's architecture.\nInside AnyTrust\tA technical deep dive into the AnyTrust protocol.\nArbitrum whitepaper\tThe original whitepaper that introduced Nitro.\nDAO docs\tDocs that support members of the Arbitrum DAO.\nEdit this page\nLast updated on Nov 19, 2024\nPrevious\nA gentle introduction\nNext\nChain info\nThe Arbitrum suite\nArbitrum for users\nArbitrum for developers\nArbitrum for node runners\nArbitrum for chain operators\nHow it works\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  },
  {
    "title": "A gentle introduction to Arbitrum | Arbitrum Docs",
    "url": "https://docs.arbitrum.io/welcome/arbitrum-gentle-introduction",
    "html": "Skip to main content\nArbitrum Docs\nWelcome\nA gentle introduction\nGet started\nChain info\nBuild decentralized apps\nRun an Orbit chain\nWrite Stylus contracts\nRun an Arbitrum node\nArbitrum bridge\nHow Arbitrum works\nFAQ\nGlossary\nContribute docs\nThird-party docs\nAudit reports\nDAO docs\nPrysm docs\n✏️Request an update\nA gentle introduction to Arbitrum\nQ: Hello! What’s Arbitrum?​\n\nHi! Arbitrum is a technology suite designed to scale Ethereum. You can use Arbitrum chains to do all things you do on Ethereum — use Web3 apps, deploy smart contracts, etc., but your transactions will be cheaper and faster. Our flagship product — Arbitrum Rollup — is an Optimistic rollup protocol that inherits Ethereum-level security.\n\nQ: What, what’s “Ethereum”? What's a “smart contract”? Where am I?​\n\nIf you aren’t yet familiar with the Ethereum ecosystem, you can check out ethereum.org for an intro. Come back whenever you're ready, no rush.\n\nQ: You said Arbitrum exists to “scale” Ethereum; why does Ethereum need this help? Is there something wrong with Ethereum?​\n\nEthereum is awesome; on its own, however, it’s also very limited. The Ethereum blockchain only allows about 20-40 transactions per second (TPS) (that’s in total, for all Ethereum users); when the limit is reached, users are forced to compete against each other for their transactions to be included, which causes fees to go up.\n\nQ: Why does Ethereum have such low TPS?​\n\nThis was a deliberate decision in Ethereum’s design. Ethereum requires that its nodes (computers running the Ethereum software) have a way of coming to consensus on the current state of things; the way they do this is by processing every transaction in Ethereum’s history; i.e., if you’ve ever used Ethereum, every Ethereum full node has a copy of your transactions in its blockchain ledger.\n\nOne of the Ethereum community’s precepts, being an open, decentralized, peer to peer system, is that it should be reasonably accessible for anyone to run an Ethereum node and validate the chain for themselves; i.e., if it gets too expensive (in terms of hardware requirements / computational resources), this undercuts the fundamental goal of decentralization. The combination of these two factors — every node has to process every transaction, and we want it to be relatively feasible to run a node — means Ethereum transaction throughput has to be capped fairly low.\n\nQ: And Arbitrum Rollup fixes this?​\n\nArbitrum rollup fixes this! The basic idea is this: an Arbitrum Rollup chain runs as a sort of sub-module within Ethereum. Unlike regular, layer 1 ( “L1”) Ethereum transactions, we don’t require Ethereum nodes to process every Arbitrum transaction; rather, Ethereum adopts an “innocent until proven guilty\" attitude to Arbitrum. Layer 1 initially “optimistically assumes” activity on Arbitrum is following the proper rules. If a violation occurs (i.e., somebody claims “now I have all of your money”), this claim can be disputed back on L1; fraud will be proven, the invalid claim disregarded, and the malicious party will be financially penalized.\n\nThis ability to adjudicate and prove fraud on L1 is Arbitrum’s key, fundamental feature, and is how and why the system inherits Ethereum’s security.\n\nQ: So we can use Ethereum to prove fraud on Arbitrum; cool! But if fraud is committed, can we be absolutely sure that we'll be able to prove it?​\n\nYes, indeed we can be. This is where the “rollup” part comes in. The data that gets fed into an Arbitrum Rollup chain (i.e., user’s transaction data) is posted directly on Ethereum. Thus, as long as Ethereum itself is running securely, anybody who’s interested has visibility into what’s going on in Arbitrum, and has the ability to detect and prove fraud.\n\nQ: Who actually does this work (of checking for fraud, proving it, etc?)​\n\nThe parties who move the Arbitrum chain state forward on L1 — i.e., making claims about the chain’s state, disputing other’s claims, etc. — are called validators. In practice, we don’t expect the average Arbitrum user to be interested in running a validator, just like the average Ethereum user typically doesn’t run their own layer 1 staking node. The crucial property, however, is that anybody can; becoming an Arbitrum validator requires no special permission (once the allowlist is lifted), only that a user runs the open source validator software (and stakes Ether when/if they need to take action).\n\nAdditionally, as long as there’s even just one honest validator, the chain will remain secure; i.e., it only takes one non-malicious fraud-prover to catch any number of malicious trouble-makers. These properties together make the system “trustless”; users are not relying on any special designated party for their funds to be secure.\n\nQ: And how exactly is “fraud” “proven”? Sounds complicated.​\n\nOh, it’s not so bad. In essence: if two validators disagree, only one of them (at most) can be telling the truth. In a dispute, the two validators play an interactive, call-and-response game, in which they narrow down their dispute to a single computational step (think of something small and simple, like multiplying two numbers). This one step gets executed on L1, and will, by necessity, prove that the honest party was telling the truth. For a more detailed rundown, see here.\n\nQ: This dispute game obviously takes some time; does this impose any sort of delay on Arbitrum users' transactions?​\n\nThe only delay that's felt by a user is in \"withdrawing\" — moving their funds from Arbitrum back to Ethereum; if users are withdrawing directly from Arbitrum to Ethereum, they must typically wait 1 week before receiving their funds on L1. If users use a fast-bridge application, however, they can bypass this delay period entirely (likely for a small fee). Anything else a user does — i.e., depositing funds from Ethereum onto Arbitrum, or using a dapp deployed on an Arbitrum chain — doesn't incur this delay period.\n\nQ: Okay, so backing up: the “optimistic execution” part is how and why Arbitrum is able to offer low fees, yes?​\n\nPrimarily, yes, this is the heart of where the savings come from. However, there are a number of other means by which Arbitrum alleviates the burden on L1, all of which translate to lower transaction costs for end users. For one, Arbitrum transactions are submitted on the L1 in batches; typically, a single batch (submitted in a single L1 transaction) will contain several hundred L2 transactions. Batching amortizes the overhead cost of interacting with the L1, and thus offers significant savings over posting individual transactions at a time. Furthermore, the transaction data is posted on L1 in compressed form (and only decompressed within the L2 environment), further minimizing the transaction’s L1 footprint.\n\nQ: As far as the experience of using Arbitrum: when you said that it’s very similar to using Ethereum…​\n\nWe really meant it, yes. Different layer 2 protocols emphasize and optimize for different things; Arbitrum was created with Ethereum compatibility as a top priority. This means users can use Arbitrum with all their favorite Ethereum wallets; developers can build and deploy contracts with all their favorite Ethereum libraries and tooling; in fact, most of the time, the experience of using Arbitrum will feel identical to that of using Ethereum (with the important exception of it being much cheaper and faster).\n\nMuch development went into achieving this level of Ethereum compatibility. But at its core: the Arbitrum itself uses a fork of Geth — the most widely used Ethereum implementation — with modifications to transform it into a trustless layer 2. This means most of the code running in Arbitrum is identical to the code running in Ethereum. We call this cutting-edge approach Nitro (developers can see the codebase here).\n\nQ: So builders can do all the stuff they do on Ethereum on Arbitrum, nice! But can they do more?​\n\nThey can; the latest version of the Arbitrum tech stack, called Stylus, keeps Nitro's Ethereum compatibility, while adding on powerful new features, namely the ability to write highly performant smart contracts in programming languages like Rust, C++, and more. Stylus is currently on public testnet; you can read more about it here.\n\nQ: So it sounds like Arbitrum Rollup is an ideal solution that solves any and all scaling problems…?​\n\nArbitrum Rollup is very awesome and cool; its design is geared heavily toward avoidance of introducing any centralization or trust assumptions, and it is thus a clear, strict net-win for the Ethereum ecosystem. Decentralization, however, comes at a (literal) price, and not all applications and users necessarily want or need to pay that price. For dapp use-cases with different security considerations, different tools in the Arbitrum suite are appropriate; i.e., Arbitrum AnyTrust chains!\n\nQ: What’s an AnyTrust chain?​\n\nAn Arbitrum AnyTrust chain doesn’t have the same decentralization / trustlessness / permissionless security guarantees of a Rollup chain, and thus can offer lower fees. Rollup and AnyTrust are similar in many ways, though have one key difference: whereas in Rollup, all data is posted on L1 (which allows anyone to permissionless join as a validator), in AnyTrust, data is managed off-chain. In the case of a challenge, an AnyTrust chain reverts back to “rollup mode”; the security assumption here is that at least 2 of the committee members are honest (i.e., they will provide the data when it’s necessary). Keeping the data off-chain in the happy/common case means the system can charge the user significantly lower fees. For applications that require high transaction throughput and don’t require the full decentralization that rollups provide, AnyTrust could be a sensible tradeoff.\n\nQ: So there's more than one Arbitrum chain out there?​\n\nYep! The fact that multiple chains can run in parallel is a crucial perk to off-chain scaling technology. Currently, on Ethereum mainnet, there are 2 Arbitrum chains: one Arbitrum Rollup chain, called \"Arbitrum One,\" and one AnyTrust chain, called \"Nova\"; users and developers can pick whatever suits their security / transaction cost needs.\n\nDevelopers also have the option of launching their own Arbitrum chains that run top an Arbitrum layer 2. These are called Orbit chains and you can read more about them here.\n\nQ: Who makes decisions about the future of Arbitrum One and Arbitrum Nova?​\n\nThe Arbitrum One and Nova chains are owned by the Governance system; to learn more, see the Arbitrum Governance docs.\n\nEdit this page\nLast updated on Nov 18, 2024\nNext\nGet started\nArbitrum.io\nArbitrum Rollup\nArbitrum AnyTrust\nArbitrum Orbit\nArbitrum Stylus\nArbitrum Foundation\nNitro whitepaper\nNetwork status\nPortal\nBridge\nGovernance docs\nCareers\nSupport\nBug Bounties\nDiscord\nTwitter\nYoutube\nMedium Blog\nResearch forum\nPrivacy Policy\nTerms of Service\n© 2024 Offchain Labs"
  }
]